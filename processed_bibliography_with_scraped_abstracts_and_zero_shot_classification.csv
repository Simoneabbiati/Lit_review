Title,Authors,Scraped_Abstract,Year,Scraped_Year,Scraped_Month,Venue,Scrape_Status,Processed_URL,DOI,DOI link,Citation count,abstract_text,title_or_id,zsl_predicted_label,zsl_score,zsl_category
A Deep Learning Model for Information Loss Prevention From Multi-Page Digital Documents,"Abhijit Guha, Debabrata Samanta, A. Banerjee, Daksh Agarwal","World Wide Web has redefined almost all the business models in the past twenty-five to thirty years. IoT, Big Data, AI are some of the comparatively recent technologies which brought in a revolution in the digitization and management of data. Along with the revolution arose the need for data security and consumer privacy protection, primarily concerning financial institutions. The data breach of Equifax in 2017 and personal information leaks from Facebook in 2021 led to general skepticism among the customers of large corporations. The GLBA, 1999, also known as the Financial Modernization Act, was implemented by US federal law to enforce the financial institutions to protect their private information. Built upon the GLBA, guidelines are paved by FTC for all financial institutions of the United States of America, including TI companies. In this paper, an ANN-based content classification technique using MLP architecture in combination with n-gram TF-IDF feature descriptor is proposed to detect and protect the customers’ sensitive information of a reputed TI company securing it’s one of the digital image-document stores. The proposed technique is compared with other state-of-the-art strategies. Data samples from the digital document store of the company have been taken into consideration in the study, and the prediction accuracy metrics obtained are found to be substantially better and within the acceptable range defined by the organization’s information security monitoring team.",2021,2021,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2021.3084841,10.1109/ACCESS.2021.3084841,https://doi.org/10.1109/ACCESS.2021.3084841,15,"World Wide Web has redefined almost all the business models in the past twenty-five to thirty years. IoT, Big Data, AI are some of the comparatively recent technologies which brought in a revolution in the digitization and management of data. Along with the revolution arose the need for data security and consumer privacy protection, primarily concerning financial institutions. The data breach of Equifax in 2017 and personal information leaks from Facebook in 2021 led to general skepticism among the customers of large corporations. The GLBA, 1999, also known as the Financial Modernization Act, was implemented by US federal law to enforce the financial institutions to protect their private information. Built upon the GLBA, guidelines are paved by FTC for all financial institutions of the United States of America, including TI companies. In this paper, an ANN-based content classification technique using MLP architecture in combination with n-gram TF-IDF feature descriptor is proposed to detect and protect the customers’ sensitive information of a reputed TI company securing it’s one of the digital image-document stores. The proposed technique is compared with other state-of-the-art strategies. Data samples from the digital document store of the company have been taken into consideration in the study, and the prediction accuracy metrics obtained are found to be substantially better and within the acceptable range defined by the organization’s information security monitoring team.",Document_0,Aligning AI implementation with financial regulatory requirements,0.1833125203847885,Regulatory Engagement and Proactive Compliance Strategies
Word Embeddings-Based Uncertainty Detection in Financial Disclosures,"Kilian Theil, Sanja Štajner, H. Stuckenschmidt","Word Embeddings-Based Uncertainty Detection in Financial Disclosures Abstract In this paper, we use NLP techniques to detect linguistic uncertainty in financial disclosures. Leveraging general-domain and domain-specific word embedding models, we automatically expand an existing dictionary of uncertainty triggers. We furthermore examine how an expert filtering affects the quality of such an expansion. We show that the dictionary expansions significantly improve regressions on stock return volatility. Lastly, we prove that the expansions significantly boost the automatic detection of uncertain sentences. Anthology ID: W18-3104 Volume: Proceedings of the First Workshop on Economics and Natural Language Processing Month: July Year: 2018 Address: Melbourne, Australia Editors: Udo Hahn , Véronique Hoste , Ming-Feng Tsai Venue: ACL SIG: Publisher: Association for Computational Linguistics Note: Pages: 32–37 Language: URL: https://aclanthology.org/W18-3104/ DOI: 10.18653/v1/W18-3104 Bibkey: Cite (ACL): Christoph Kilian Theil, Sanja Štajner, and Heiner Stuckenschmidt. 2018. Word Embeddings-Based Uncertainty Detection in Financial Disclosures . In Proceedings of the First Workshop on Economics and Natural Language Processing , pages 32–37, Melbourne, Australia. Association for Computational Linguistics. Cite (Informal): Word Embeddings-Based Uncertainty Detection in Financial Disclosures (Theil et al., ACL 2018) Copy Citation: PDF",2018,2018,7.0,ECONLP@ACL,"Success (LLM (Filtered HTML), Score: 0.17) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/W18-3104,10.18653/v1/W18-3104,https://doi.org/10.18653/v1/W18-3104,21,"Word Embeddings-Based Uncertainty Detection in Financial Disclosures Abstract In this paper, we use NLP techniques to detect linguistic uncertainty in financial disclosures. Leveraging general-domain and domain-specific word embedding models, we automatically expand an existing dictionary of uncertainty triggers. We furthermore examine how an expert filtering affects the quality of such an expansion. We show that the dictionary expansions significantly improve regressions on stock return volatility. Lastly, we prove that the expansions significantly boost the automatic detection of uncertain sentences. Anthology ID: W18-3104 Volume: Proceedings of the First Workshop on Economics and Natural Language Processing Month: July Year: 2018 Address: Melbourne, Australia Editors: Udo Hahn , Véronique Hoste , Ming-Feng Tsai Venue: ACL SIG: Publisher: Association for Computational Linguistics Note: Pages: 32–37 Language: URL: https://aclanthology.org/W18-3104/ DOI: 10.18653/v1/W18-3104 Bibkey: Cite (ACL): Christoph Kilian Theil, Sanja Štajner, and Heiner Stuckenschmidt. 2018. Word Embeddings-Based Uncertainty Detection in Financial Disclosures . In Proceedings of the First Workshop on Economics and Natural Language Processing , pages 32–37, Melbourne, Australia. Association for Computational Linguistics. Cite (Informal): Word Embeddings-Based Uncertainty Detection in Financial Disclosures (Theil et al., ACL 2018) Copy Citation: PDF",Document_1,Improving data quality is crucial for successful AI in finance,0.0643882006406784,Data Improvement and Availability Strategies
Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness?,"Alon Jacovi, Yoav Goldberg","With the growing popularity of deep-learning based NLP models, comes a need for interpretable systems. But what is interpretability, and what constitutes a high-quality interpretation? In this opinion piece we reflect on the current state of interpretability evaluation research. We call for more clearly differentiating between different desired criteria an interpretation should satisfy, and focus on the faithfulness criteria. We survey the literature with respect to faithfulness evaluation, and arrange the current approaches around three assumptions, providing an explicit form to how faithfulness is “defined” by the community. We provide concrete guidelines on how evaluation of interpretation methods should and should not be conducted. Finally, we claim that the current binary definition for faithfulness sets a potentially unrealistic bar for being considered faithful. We call for discarding the binary notion of faithfulness in favor of a more graded one, which we believe will be of greater practical utility.",2020,2020,7.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.acl-main.386,10.18653/v1/2020.acl-main.386,https://doi.org/10.18653/v1/2020.acl-main.386,516,"With the growing popularity of deep-learning based NLP models, comes a need for interpretable systems. But what is interpretability, and what constitutes a high-quality interpretation? In this opinion piece we reflect on the current state of interpretability evaluation research. We call for more clearly differentiating between different desired criteria an interpretation should satisfy, and focus on the faithfulness criteria. We survey the literature with respect to faithfulness evaluation, and arrange the current approaches around three assumptions, providing an explicit form to how faithfulness is “defined” by the community. We provide concrete guidelines on how evaluation of interpretation methods should and should not be conducted. Finally, we claim that the current binary definition for faithfulness sets a potentially unrealistic bar for being considered faithful. We call for discarding the binary notion of faithfulness in favor of a more graded one, which we believe will be of greater practical utility.",Document_2,Technical aspects or methods of AI or machine learning,0.09794260561466217,Other Categories
"TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP","John X. Morris, Eli Lifland, Jin Yong Yoo, J. Grigsby, Di Jin, Yanjun Qi","While there has been substantial research using adversarial attacks to analyze NLP models, each attack is implemented in its own code repository. It remains challenging to develop NLP attacks and utilize them to improve model performance. This paper introduces TextAttack, a Python framework for adversarial attacks, data augmentation, and adversarial training in NLP. TextAttack builds attacks from four components: a goal function, a set of constraints, a transformation, and a search method. TextAttack’s modular design enables researchers to easily construct attacks from combinations of novel and existing components. TextAttack provides implementations of 16 adversarial attacks from the literature and supports a variety of models and datasets, including BERT and other transformers, and all GLUE tasks. TextAttack also includes data augmentation and adversarial training modules for using components of adversarial attacks to improve model accuracy and robustness. TextAttack is democratizing NLP: anyone can try data augmentation and adversarial training on any model or dataset, with just a few lines of code. Code and tutorials are available at https://github.com/QData/TextAttack .",2020,2020,10.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.emnlp-demos.16,10.18653/v1/2020.emnlp-demos.16,https://doi.org/10.18653/v1/2020.emnlp-demos.16,675,"While there has been substantial research using adversarial attacks to analyze NLP models, each attack is implemented in its own code repository. It remains challenging to develop NLP attacks and utilize them to improve model performance. This paper introduces TextAttack, a Python framework for adversarial attacks, data augmentation, and adversarial training in NLP. TextAttack builds attacks from four components: a goal function, a set of constraints, a transformation, and a search method. TextAttack’s modular design enables researchers to easily construct attacks from combinations of novel and existing components. TextAttack provides implementations of 16 adversarial attacks from the literature and supports a variety of models and datasets, including BERT and other transformers, and all GLUE tasks. TextAttack also includes data augmentation and adversarial training modules for using components of adversarial attacks to improve model accuracy and robustness. TextAttack is democratizing NLP: anyone can try data augmentation and adversarial training on any model or dataset, with just a few lines of code. Code and tutorials are available at https://github.com/QData/TextAttack .",Document_3,Technical aspects or methods of AI or machine learning,0.07682181894779205,Other Categories
Is NLP Ready for Standardization?,Lauriane Aufrant,"While standardization is a well-established activity in other scientific fields such as telecommunications, networks or multimedia, in the field of AI and more specifically NLP it is still at its dawn. In this paper, we explore how various aspects of NLP (evaluation, data, tasks...) lack standards and how that can impact science, but also the society, the industry, and regulations. We argue that the numerous initiatives to rationalize the field and establish good practices are only the first step, and developing formal standards remains needed to bring further clarity to NLP research and industry, at a time where this community faces various crises regarding ethics or reproducibility. We thus encourage NLP researchers to contribute to existing and upcoming standardization projects, so that they can express their needs and concerns, while sharing their expertise.",2022,2022,12.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2022.findings-emnlp.202,10.18653/v1/2022.findings-emnlp.202,https://doi.org/10.18653/v1/2022.findings-emnlp.202,2,"While standardization is a well-established activity in other scientific fields such as telecommunications, networks or multimedia, in the field of AI and more specifically NLP it is still at its dawn. In this paper, we explore how various aspects of NLP (evaluation, data, tasks...) lack standards and how that can impact science, but also the society, the industry, and regulations. We argue that the numerous initiatives to rationalize the field and establish good practices are only the first step, and developing formal standards remains needed to bring further clarity to NLP research and industry, at a time where this community faces various crises regarding ethics or reproducibility. We thus encourage NLP researchers to contribute to existing and upcoming standardization projects, so that they can express their needs and concerns, while sharing their expertise.",Document_4,Building organizational support for AI through education and communication,0.10105906426906586,"Education, Awareness, and Policy Strategies"
Auditing Deep Learning processes through Kernel-based Explanatory Models,"D. Croce, D. Rossini, R. Basili","While NLP systems become more pervasive, their accountability gains value as a focal point of effort. Epistemological opaqueness of nonlinear learning methods, such as deep learning models, can be a major drawback for their adoptions. In this paper, we discuss the application of Layerwise Relevance Propagation over a linguistically motivated neural architecture, the Kernel-based Deep Architecture, in order to trace back connections between linguistic properties of input instances and system decisions. Such connections then guide the construction of argumentations on network’s inferences, i.e., explanations based on real examples, semantically related to the input. We propose here a methodology to evaluate the transparency and coherence of analogy-based explanations modeling an audit stage for the system. Quantitative analysis on two semantic tasks, i.e., question classification and semantic role labeling, show that the explanatory capabilities (native in KDAs) are effective and they pave the way to more complex argumentation methods.",2019,2019,11.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/D19-1415,10.18653/v1/D19-1415,https://doi.org/10.18653/v1/D19-1415,21,"While NLP systems become more pervasive, their accountability gains value as a focal point of effort. Epistemological opaqueness of nonlinear learning methods, such as deep learning models, can be a major drawback for their adoptions. In this paper, we discuss the application of Layerwise Relevance Propagation over a linguistically motivated neural architecture, the Kernel-based Deep Architecture, in order to trace back connections between linguistic properties of input instances and system decisions. Such connections then guide the construction of argumentations on network’s inferences, i.e., explanations based on real examples, semantically related to the input. We propose here a methodology to evaluate the transparency and coherence of analogy-based explanations modeling an audit stage for the system. Quantitative analysis on two semantic tasks, i.e., question classification and semantic role labeling, show that the explanatory capabilities (native in KDAs) are effective and they pave the way to more complex argumentation methods.",Document_5,Technical aspects or methods of AI or machine learning,0.14831040799617767,Other Categories
NLP-Based Automated Compliance Checking of Data Processing Agreements Against GDPR,"Orlando Amaral Cejas, M. Azeem, S. Abualhaija, L. Briand","When the entity processing personal data (the processor) differs from the one collecting personal data (the controller), processing personal data is regulated in Europe by the General Data Protection Regulation (GDPR) through <i>data processing agreements (DPAs)</i>. Checking the compliance of DPAs contributes to the compliance verification of software systems as DPAs are an important source of requirements for software development involving the processing of personal data. However, manually checking whether a given DPA complies with GDPR is challenging as it requires significant time and effort for understanding and identifying DPA-relevant compliance requirements in GDPR and then verifying these requirements in the DPA. Legal texts introduce additional complexity due to convoluted language and inherent ambiguity leading to potential misunderstandings. In this paper, we propose an automated solution to check the compliance of a given DPA against GDPR. In close interaction with legal experts, we first built two artifacts: (i) the “shall” requirements extracted from the GDPR provisions relevant to DPA compliance and (ii) a glossary table defining the legal concepts in the requirements. Then, we developed an automated solution that leverages natural language processing (NLP) technologies to check the compliance of a given DPA against these “shall” requirements. Specifically, our approach automatically generates phrasal-level representations for the textual content of the DPA and compares them against predefined representations of the “shall” requirements. By comparing these two representations, the approach not only assesses whether the DPA is GDPR compliant but it further provides recommendations about missing information in the DPA. Over a dataset of 30 actual DPAs, the approach correctly finds 618 out of 750 genuine violations while raising 76 false violations, and further correctly identifies 524 satisfied requirements. The approach has thus an average precision of 89.1%, a recall of 82.4%, and an accuracy of 84.6%. Compared to a baseline that relies on off-the-shelf NLP tools, our approach provides an average accuracy gain of <inline-formula><tex-math notation=""LaTeX"">$\approx$</tex-math></inline-formula>20 percentage points. The accuracy of our approach can be improved to <inline-formula><tex-math notation=""LaTeX"">$\approx$</tex-math></inline-formula>94% with limited manual verification effort.",2022,2022,,IEEE Transactions on Software Engineering,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/TSE.2023.3288901,10.1109/TSE.2023.3288901,https://doi.org/10.1109/TSE.2023.3288901,27,"When the entity processing personal data (the processor) differs from the one collecting personal data (the controller), processing personal data is regulated in Europe by the General Data Protection Regulation (GDPR) through <i>data processing agreements (DPAs)</i>. Checking the compliance of DPAs contributes to the compliance verification of software systems as DPAs are an important source of requirements for software development involving the processing of personal data. However, manually checking whether a given DPA complies with GDPR is challenging as it requires significant time and effort for understanding and identifying DPA-relevant compliance requirements in GDPR and then verifying these requirements in the DPA. Legal texts introduce additional complexity due to convoluted language and inherent ambiguity leading to potential misunderstandings. In this paper, we propose an automated solution to check the compliance of a given DPA against GDPR. In close interaction with legal experts, we first built two artifacts: (i) the “shall” requirements extracted from the GDPR provisions relevant to DPA compliance and (ii) a glossary table defining the legal concepts in the requirements. Then, we developed an automated solution that leverages natural language processing (NLP) technologies to check the compliance of a given DPA against these “shall” requirements. Specifically, our approach automatically generates phrasal-level representations for the textual content of the DPA and compares them against predefined representations of the “shall” requirements. By comparing these two representations, the approach not only assesses whether the DPA is GDPR compliant but it further provides recommendations about missing information in the DPA. Over a dataset of 30 actual DPAs, the approach correctly finds 618 out of 750 genuine violations while raising 76 false violations, and further correctly identifies 524 satisfied requirements. The approach has thus an average precision of 89.1%, a recall of 82.4%, and an accuracy of 84.6%. Compared to a baseline that relies on off-the-shelf NLP tools, our approach provides an average accuracy gain of <inline-formula><tex-math notation=""LaTeX"">$\approx$</tex-math></inline-formula>20 percentage points. The accuracy of our approach can be improved to <inline-formula><tex-math notation=""LaTeX"">$\approx$</tex-math></inline-formula>94% with limited manual verification effort.",Document_6,Technical aspects or methods of AI or machine learning,0.11422699689865112,Other Categories
Language (Technology) is Power: A Critical Survey of “Bias” in NLP,"Su Lin Blodgett, Solon Barocas, Hal Daum'e, Hanna M. Wallach","We survey 146 papers analyzing “bias” in NLP systems, finding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing “bias” is an inherently normative process. We further find that these papers’ proposed quantitative techniques for measuring or mitigating “bias” are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these findings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing “bias” in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of “bias”—i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements—and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities.",2020,2020,7.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.acl-main.485,10.18653/v1/2020.acl-main.485,https://doi.org/10.18653/v1/2020.acl-main.485,1088,"We survey 146 papers analyzing “bias” in NLP systems, finding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing “bias” is an inherently normative process. We further find that these papers’ proposed quantitative techniques for measuring or mitigating “bias” are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these findings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing “bias” in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of “bias”—i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements—and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities.",Document_7,Building organizational support for AI through education and communication,0.05111297592520714,"Education, Awareness, and Policy Strategies"
Adversarial Semantic Collisions,"Congzheng Song, Alexander M. Rush, Vitaly Shmatikov","We study semantic collisions : texts that are semantically unrelated but judged as similar by NLP models. We develop gradient-based approaches for generating semantic collisions and demonstrate that state-of-the-art models for many tasks which rely on analyzing the meaning and similarity of texts—including paraphrase identification, document retrieval, response suggestion, and extractive summarization—are vulnerable to semantic collisions. For example, given a target query, inserting a crafted collision into an irrelevant document can shift its retrieval rank from 1000 to top 3. We show how to generate semantic collisions that evade perplexity-based filtering and discuss other potential mitigations. Our code is available at https://github.com/csong27/collision-bert .",2020,2020,11.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.emnlp-main.344,10.18653/v1/2020.emnlp-main.344,https://doi.org/10.18653/v1/2020.emnlp-main.344,47,"We study semantic collisions : texts that are semantically unrelated but judged as similar by NLP models. We develop gradient-based approaches for generating semantic collisions and demonstrate that state-of-the-art models for many tasks which rely on analyzing the meaning and similarity of texts—including paraphrase identification, document retrieval, response suggestion, and extractive summarization—are vulnerable to semantic collisions. For example, given a target query, inserting a crafted collision into an irrelevant document can shift its retrieval rank from 1000 to top 3. We show how to generate semantic collisions that evade perplexity-based filtering and discuss other potential mitigations. Our code is available at https://github.com/csong27/collision-bert .",Document_8,Technical aspects or methods of AI or machine learning,0.12295855581760406,Other Categories
EDGAR-CORPUS: Billions of Tokens Make The World Go Round,"Lefteris Loukas, Manos Fergadiotis, Ion Androutsopoulos, Prodromos Malakasiotis","We release EDGAR-CORPUS, a novel corpus comprising annual reports from all the publicly traded companies in the US spanning a period of more than 25 years. To the best of our knowledge, EDGAR-CORPUS is the largest financial NLP corpus available to date. All the reports are downloaded, split into their corresponding items (sections), and provided in a clean, easy-to-use JSON format. We use EDGAR-CORPUS to train and release EDGAR-W2V, which are WORD2VEC embeddings for the financial domain. We employ these embeddings in a battery of financial NLP tasks and showcase their superiority over generic GloVe embeddings and other existing financial word embeddings. We also open-source EDGAR-CRAWLER, a toolkit that facilitates downloading and extracting future annual reports.",2021,2021,11.0,ECONLP,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2021.econlp-1.2,10.18653/v1/2021.econlp-1.2,https://doi.org/10.18653/v1/2021.econlp-1.2,27,"We release EDGAR-CORPUS, a novel corpus comprising annual reports from all the publicly traded companies in the US spanning a period of more than 25 years. To the best of our knowledge, EDGAR-CORPUS is the largest financial NLP corpus available to date. All the reports are downloaded, split into their corresponding items (sections), and provided in a clean, easy-to-use JSON format. We use EDGAR-CORPUS to train and release EDGAR-W2V, which are WORD2VEC embeddings for the financial domain. We employ these embeddings in a battery of financial NLP tasks and showcase their superiority over generic GloVe embeddings and other existing financial word embeddings. We also open-source EDGAR-CRAWLER, a toolkit that facilitates downloading and extracting future annual reports.",Document_9,Improving data quality is crucial for successful AI in finance,0.07661735266447067,Data Improvement and Availability Strategies
Business Event Curation: Merging Human and Automated Approaches,"Yiqi Wang, Huiying Ma, N. Lowe, M. Feldman, Charles Schmitt","We present preliminary work to construct a knowledge curation system to advance research in the study of regional economics. The proposed system exploits natural language processing (NLP) techniques to automatically implement business event extraction, provides a user-facing interface to assist human curators, and a feedback loop to improve the performance of the Information Extraction Model for the automated parts of the system. Progress to date has shown that we can improve standard NLP approaches for entity and relationship extraction through heuristic means and provide indexing of extracted relationships to aid curation.",2016,2016,,AAAI Conference on Artificial Intelligence,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1609/aaai.v30i1.9934,10.1609/aaai.v30i1.9934,https://doi.org/10.1609/aaai.v30i1.9934,4,"We present preliminary work to construct a knowledge curation system to advance research in the study of regional economics. The proposed system exploits natural language processing (NLP) techniques to automatically implement business event extraction, provides a user-facing interface to assist human curators, and a feedback loop to improve the performance of the Information Extraction Model for the automated parts of the system. Progress to date has shown that we can improve standard NLP approaches for entity and relationship extraction through heuristic means and provide indexing of extracted relationships to aid curation.",Document_10,Technical aspects or methods of AI or machine learning,0.13048647344112396,Other Categories
The Woman Worked as a Babysitter: On Biases in Language Generation,"Emily Sheng, Kai-Wei Chang, P. Natarajan, Nanyun Peng","We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a defining metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for regard. To this end, we collect strategically-generated text from language models and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classifier through transfer learning, so that we can analyze biases in unseen text. Together, these methods reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.",2019,2019,11.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/D19-1339,10.18653/v1/D19-1339,https://doi.org/10.18653/v1/D19-1339,567,"We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a defining metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for regard. To this end, we collect strategically-generated text from language models and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classifier through transfer learning, so that we can analyze biases in unseen text. Together, these methods reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.",Document_11,Building organizational support for AI through education and communication,0.06249015033245087,"Education, Awareness, and Policy Strategies"
Data Extraction Using NLP Techniques and Its Transformation to Linked Data,"Vincent Kríz, Barbora Hladká, M. Nečaský, T. Knap","We present a system that extracts a knowledge base from raw unstructured texts that is designed as a set of entities and their relations and represented in an ontological framework. The extraction pipeline processes input texts by linguistically-aware tools and extracts entities and relations from their syntactic representation. Consequently, the extracted data is represented according to the Linked Data principles. The system is designed both domain and language independent and provides users with data for more intelligent search than full-text search. We present our first case study on processing Czech legal texts.",2014,2014,4.0,Mexican International Conference on Artificial Intelligence,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.34) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-319-13647-9_13,10.1007/978-3-319-13647-9_13,https://doi.org/10.1007/978-3-319-13647-9_13,14,"We present a system that extracts a knowledge base from raw unstructured texts that is designed as a set of entities and their relations and represented in an ontological framework. The extraction pipeline processes input texts by linguistically-aware tools and extracts entities and relations from their syntactic representation. Consequently, the extracted data is represented according to the Linked Data principles. The system is designed both domain and language independent and provides users with data for more intelligent search than full-text search. We present our first case study on processing Czech legal texts.",Document_12,Difficulty in understanding AI decision-making is a barrier in finance,0.08652874827384949,Explainability and Transparency Barriers
Multi-Language Surface Realisation as REST API based NLG Microservice,"Andreas Madsack, Johanna Heininger, Nyamsuren Davaasambuu, Vitaliia Voronik, Michael Käufl, Robert Weißgraeber","We present a readily available API that solves the morphology component for surface realizers in 10 languages (e.g., English, German and Finnish) for any topic and is available as REST API. This can be used to add morphology to any kind of NLG application (e.g., a multi-language chatbot), without requiring computational linguistic knowledge by the integrator.",2018,2018,11.0,International Conference on Natural Language Generation,"Success (Selector (div[class*=""abstract""]) - Truncation Suspected) / Date (Meta (citation_publication_date)) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.16) (URL Source: DOI Link)",https://doi.org/10.18653/V1/W18-6560,10.18653/V1/W18-6560,https://doi.org/10.18653/V1/W18-6560,2,"We present a readily available API that solves the morphology component for surface realizers in 10 languages (e.g., English, German and Finnish) for any topic and is available as REST API. This can be used to add morphology to any kind of NLG application (e.g., a multi-language chatbot), without requiring computational linguistic knowledge by the integrator.",Document_13,Security risks associated with AI are a concern in financial regulation,0.04960330203175545,Organizational and Human Barriers
Developing and Orchestrating a Portfolio of Natural Legal Language Processing and Document Curation Services,"Georg Rehm, J. Moreno-Schneider, Jorge Gracia, Artem Revenko, V. Mireles, Maria Khvalchik, Ilan Kernerman, Andis Lagzdins, Marcis Pinnis, Artus Vasilevskis, Elena Leitner, J. Milde, Pia Weissenhorn","We present a portfolio of natural legal language processing and document curation services currently under development in a collaborative European project. First, we give an overview of the project and the different use cases, while, in the main part of the article, we focus upon the 13 different processing services that are being deployed in different prototype applications using a flexible and scalable microservices architecture. Their orchestration is operationalised using a content and document curation workflow manager.",2019,2019,6.0,Proceedings of the Natural Legal Language Processing Workshop 2019,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/W19-2207,10.18653/v1/W19-2207,https://doi.org/10.18653/v1/W19-2207,10,"We present a portfolio of natural legal language processing and document curation services currently under development in a collaborative European project. First, we give an overview of the project and the different use cases, while, in the main part of the article, we focus upon the 13 different processing services that are being deployed in different prototype applications using a flexible and scalable microservices architecture. Their orchestration is operationalised using a content and document curation workflow manager.",Document_14,Technical aspects or methods of AI or machine learning,0.09768961369991302,Other Categories
Discovering and Categorising Language Biases in Reddit,"Xavier Ferrer Aran, T. Nuenen, J. Such, N. Criado","We present a data-driven approach using word embeddings to discover and categorise language biases on the discussion platform Reddit. As spaces for isolated user communities, platforms such as Reddit are increasingly connected to issues of racism, sexism and other forms of discrimination, signalling the need to monitor the language of these groups. One of the most promising AI approaches to trace linguistic biases in large textual datasets involves word embeddings, which transform text into high-dimensional dense vectors and capture semantic relations between words. Yet, previous studies require predefined sets of potential biases to study, e.g., whether gender is more or less associated with particular types of jobs. This makes these approaches unfit to deal with smaller and community-centric datasets such as those on Reddit, which contain smaller vocabularies and slang, as well as biases that may be particular to that community. This paper proposes a data-driven approach to automatically discover language biases encoded in the vocabulary of online discourse communities on Reddit. In our approach, protected attributes are connected to evaluative words found in the data, which are then categorised through a semantic analysis system. We verify the effectiveness of our method by comparing the biases we discover in the Google News dataset with those found in previous literature. We then successfully discover gender bias, religion bias, and ethnic bias in different Reddit communities. We conclude by discussing potential application scenarios and limitations of this data-driven bias discovery method.",2020,2020,,International Conference on Web and Social Media,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1609/icwsm.v15i1.18048,10.1609/icwsm.v15i1.18048,https://doi.org/10.1609/icwsm.v15i1.18048,45,"We present a data-driven approach using word embeddings to discover and categorise language biases on the discussion platform Reddit. As spaces for isolated user communities, platforms such as Reddit are increasingly connected to issues of racism, sexism and other forms of discrimination, signalling the need to monitor the language of these groups. One of the most promising AI approaches to trace linguistic biases in large textual datasets involves word embeddings, which transform text into high-dimensional dense vectors and capture semantic relations between words. Yet, previous studies require predefined sets of potential biases to study, e.g., whether gender is more or less associated with particular types of jobs. This makes these approaches unfit to deal with smaller and community-centric datasets such as those on Reddit, which contain smaller vocabularies and slang, as well as biases that may be particular to that community. This paper proposes a data-driven approach to automatically discover language biases encoded in the vocabulary of online discourse communities on Reddit. In our approach, protected attributes are connected to evaluative words found in the data, which are then categorised through a semantic analysis system. We verify the effectiveness of our method by comparing the biases we discover in the Google News dataset with those found in previous literature. We then successfully discover gender bias, religion bias, and ethnic bias in different Reddit communities. We conclude by discussing potential application scenarios and limitations of this data-driven bias discovery method.",Document_15,Technical aspects or methods of AI or machine learning,0.1867157369852066,Other Categories
Problems and Solutions with Integrating Terminologies into Evolving Knowledge Bases,"K. Rickard, J. Mejino, Richard F. Martin, Augusto V. Agoncillo, C. Rosse",We have merged two established anatomical terminologies with an evolving ontology of biological structure: the Foundational Model of Anatomy. We describe the problems we have encountered and the solutions we have developed. We believe that both the problems and solutions generalize to the integration of any legacy terminology with a disciplined ontology within the same domain.,2004,2004,4.0,Medinfo,Success (Selector (div.abstract) - Truncation Suspected) / Date (Meta (citation_publication_date)) / LLM Skipped (Context Error) (URL Source: DOI Link),https://doi.org/10.3233/978-1-60750-949-3-420,10.3233/978-1-60750-949-3-420,https://doi.org/10.3233/978-1-60750-949-3-420,15,We have merged two established anatomical terminologies with an evolving ontology of biological structure: the Foundational Model of Anatomy. We describe the problems we have encountered and the solutions we have developed. We believe that both the problems and solutions generalize to the integration of any legacy terminology with a disciplined ontology within the same domain.,Document_16,Poor data quality hinders AI adoption in finance and regulation,0.04338979721069336,Data Quality and Privacy Barriers
Gender Bias in Neural Natural Language Processing,"Kaiji Lu, Piotr (Peter) Mardziel, Fangjing Wu, Preetam Amancharla, Anupam Datta","We examine whether neural natural language processing (NLP) systems reflect historical biases in training data. We define a general benchmark to quantify gender bias in a variety of neural NLP tasks. Our empirical evaluation with state-of-the-art neural coreference resolution and textbook RNN-based language models trained on benchmark data sets finds significant gender bias in how models view occupations. We then mitigate bias with counterfactual data augmentation (CDA): a generic methodology for corpus augmentation via causal interventions that breaks associations between gendered and gender-neutral words. We empirically show that CDA effectively decreases gender bias while preserving accuracy. We also explore the space of mitigation strategies with CDA, a prior approach to word embedding debiasing (WED), and their compositions. We show that CDA outperforms WED, drastically so when word embeddings are trained. For pre-trained embeddings, the two methods can be effectively composed. We also find that as training proceeds on the original data set with gradient descent the gender bias grows as the loss reduces, indicating that the optimization encourages bias; CDA mitigates this behavior.",2018,2020,4.0,"Logic, Language, and Security","Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.29) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-030-62077-6_14,10.1007/978-3-030-62077-6_14,https://doi.org/10.1007/978-3-030-62077-6_14,323,"We examine whether neural natural language processing (NLP) systems reflect historical biases in training data. We define a general benchmark to quantify gender bias in a variety of neural NLP tasks. Our empirical evaluation with state-of-the-art neural coreference resolution and textbook RNN-based language models trained on benchmark data sets finds significant gender bias in how models view occupations. We then mitigate bias with counterfactual data augmentation (CDA): a generic methodology for corpus augmentation via causal interventions that breaks associations between gendered and gender-neutral words. We empirically show that CDA effectively decreases gender bias while preserving accuracy. We also explore the space of mitigation strategies with CDA, a prior approach to word embedding debiasing (WED), and their compositions. We show that CDA outperforms WED, drastically so when word embeddings are trained. For pre-trained embeddings, the two methods can be effectively composed. We also find that as training proceeds on the original data set with gradient descent the gender bias grows as the loss reduces, indicating that the optimization encourages bias; CDA mitigates this behavior.",Document_17,Technical aspects or methods of AI or machine learning,0.10069862008094788,Other Categories
Did the Model Understand the Question?,"Pramod Kaushik Mudrakarta, Ankur Taly, Mukund Sundararajan, Kedar Dhamdhere","We analyze state-of-the-art deep learning models for three tasks: question answering on (1) images, (2) tables, and (3) passages of text. Using the notion of “attribution” (word importance), we find that these deep networks often ignore important question terms. Leveraging such behavior, we perturb questions to craft a variety of adversarial examples. Our strongest attacks drop the accuracy of a visual question answering model from 61.1% to 19%, and that of a tabular question answering model from 33.5% to 3.3%. Additionally, we show how attributions can strengthen attacks proposed by Jia and Liang (2017) on paragraph comprehension models. Our results demonstrate that attributions can augment standard measures of accuracy and empower investigation of model performance. When a model is accurate but for the wrong reasons, attributions can surface erroneous logic in the model that indicates inadequacies in the test data.",2018,2018,7.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/P18-1176,10.18653/v1/P18-1176,https://doi.org/10.18653/v1/P18-1176,195,"We analyze state-of-the-art deep learning models for three tasks: question answering on (1) images, (2) tables, and (3) passages of text. Using the notion of “attribution” (word importance), we find that these deep networks often ignore important question terms. Leveraging such behavior, we perturb questions to craft a variety of adversarial examples. Our strongest attacks drop the accuracy of a visual question answering model from 61.1% to 19%, and that of a tabular question answering model from 33.5% to 3.3%. Additionally, we show how attributions can strengthen attacks proposed by Jia and Liang (2017) on paragraph comprehension models. Our results demonstrate that attributions can augment standard measures of accuracy and empower investigation of model performance. When a model is accurate but for the wrong reasons, attributions can surface erroneous logic in the model that indicates inadequacies in the test data.",Document_18,Technical aspects or methods of AI or machine learning,0.14553403854370117,Other Categories
Sexism in the Judiciary: The Importance of Bias Definition in NLP and In Our Courts,Noa Baker Gillis,"We analyze 6.7 million case law documents to determine the presence of gender bias within our judicial system. We find that current bias detection methods in NLP are insufficient to determine gender bias in our case law database and propose an alternative approach. We show that existing algorithms’ inconsistent results are consequences of prior research’s inconsistent definitions of biases themselves. Bias detection algorithms rely on groups of words to represent bias (e.g., ‘salary,’ ‘job,’ and ‘boss’ to represent employment as a potentially biased theme against women in text). However, the methods to build these groups of words have several weaknesses, primarily that the word lists are based on the researchers’ own intuitions. We suggest two new methods of automating the creation of word lists to represent biases. We find that our methods outperform current NLP bias detection methods. Our research improves the capabilities of NLP technology to detect bias and highlights gender biases present in influential case law. In order to test our NLP bias detection method’s performance, we regress our results of bias in case law against U.S census data of women’s participation in the workforce in the last 100 years.",2021,2021,8.0,GEBNLP,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2021.gebnlp-1.6,10.18653/v1/2021.gebnlp-1.6,https://doi.org/10.18653/v1/2021.gebnlp-1.6,11,"We analyze 6.7 million case law documents to determine the presence of gender bias within our judicial system. We find that current bias detection methods in NLP are insufficient to determine gender bias in our case law database and propose an alternative approach. We show that existing algorithms’ inconsistent results are consequences of prior research’s inconsistent definitions of biases themselves. Bias detection algorithms rely on groups of words to represent bias (e.g., ‘salary,’ ‘job,’ and ‘boss’ to represent employment as a potentially biased theme against women in text). However, the methods to build these groups of words have several weaknesses, primarily that the word lists are based on the researchers’ own intuitions. We suggest two new methods of automating the creation of word lists to represent biases. We find that our methods outperform current NLP bias detection methods. Our research improves the capabilities of NLP technology to detect bias and highlights gender biases present in influential case law. In order to test our NLP bias detection method’s performance, we regress our results of bias in case law against U.S census data of women’s participation in the workforce in the last 100 years.",Document_19,Building organizational support for AI through education and communication,0.05186569318175316,"Education, Awareness, and Policy Strategies"
Social Bias Frames: Reasoning about Social and Power Implications of Language,"Maarten Sap, Saadia Gabriel, Lianhui Qin, Dan Jurafsky, Noah A. Smith, Yejin Choi","Warning: this paper contains content that may be offensive or upsetting. Language has the power to reinforce stereotypes and project social biases onto others. At the core of the challenge is that it is rarely what is stated explicitly, but rather the implied meanings, that frame people’s judgments about others. For example, given a statement that “we shouldn’t lower our standards to hire more women,” most listeners will infer the implicature intended by the speaker - that “women (candidates) are less qualified.” Most semantic formalisms, to date, do not capture such pragmatic implications in which people express social biases and power differentials in language. We introduce Social Bias Frames, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others. In addition, we introduce the Social Bias Inference Corpus to support large-scale modelling and evaluation with 150k structured annotations of social media posts, covering over 34k implications about a thousand demographic groups. We then establish baseline approaches that learn to recover Social Bias Frames from unstructured text. We find that while state-of-the-art neural models are effective at high-level categorization of whether a given statement projects unwanted social bias (80% F1), they are not effective at spelling out more detailed explanations in terms of Social Bias Frames. Our study motivates future work that combines structured pragmatic inference with commonsense reasoning on social implications.",2019,2020,7.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.acl-main.486,10.18653/v1/2020.acl-main.486,https://doi.org/10.18653/v1/2020.acl-main.486,451,"Warning: this paper contains content that may be offensive or upsetting. Language has the power to reinforce stereotypes and project social biases onto others. At the core of the challenge is that it is rarely what is stated explicitly, but rather the implied meanings, that frame people’s judgments about others. For example, given a statement that “we shouldn’t lower our standards to hire more women,” most listeners will infer the implicature intended by the speaker - that “women (candidates) are less qualified.” Most semantic formalisms, to date, do not capture such pragmatic implications in which people express social biases and power differentials in language. We introduce Social Bias Frames, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others. In addition, we introduce the Social Bias Inference Corpus to support large-scale modelling and evaluation with 150k structured annotations of social media posts, covering over 34k implications about a thousand demographic groups. We then establish baseline approaches that learn to recover Social Bias Frames from unstructured text. We find that while state-of-the-art neural models are effective at high-level categorization of whether a given statement projects unwanted social bias (80% F1), they are not effective at spelling out more detailed explanations in terms of Social Bias Frames. Our study motivates future work that combines structured pragmatic inference with commonsense reasoning on social implications.",Document_20,Building organizational support for AI through education and communication,0.04814375936985016,"Education, Awareness, and Policy Strategies"
High Quality Topic Extraction from Business News Explains Abnormal Financial Market Volatility,"Ryohei Hisano, D. Sornette, T. Mizuno, T. Ohnishi, Tsutomu Watanabe","Understanding the mutual relationships between information flows and social activity in society today is one of the cornerstones of the social sciences. In financial economics, the key issue in this regard is understanding and quantifying how news of all possible types (geopolitical, environmental, social, financial, economic, etc.) affects trading and the pricing of firms in organized stock markets. In this article, we seek to address this issue by performing an analysis of more than 24 million news records provided by Thompson Reuters and of their relationship with trading activity for 206 major stocks in the S&P US stock index. We show that the whole landscape of news that affects stock price movements can be automatically summarized via simple regularized regressions between trading activity and news information pieces decomposed, with the help of simple topic modeling techniques, into their “thematic” features. Using these methods, we are able to estimate and quantify the impacts of news on trading. We introduce network-based visualization techniques to represent the whole landscape of news information associated with a basket of stocks. The examination of the words that are representative of the topic distributions confirms that our method is able to extract the significant pieces of information influencing the stock market. Our results show that one of the most puzzling stylized facts in financial economies, namely that at certain times trading volumes appear to be “abnormally large,” can be partially explained by the flow of news. In this sense, our results prove that there is no “excess trading,” when restricting to times when news is genuinely novel and provides relevant financial information.",2012,2012,,PLoS ONE,Selector (div.abstract > div > p / Date Not Found (URL Source: DOI Link),https://doi.org/10.1371/journal.pone.0064846,10.1371/journal.pone.0064846,https://doi.org/10.1371/journal.pone.0064846,44,"Understanding the mutual relationships between information flows and social activity in society today is one of the cornerstones of the social sciences. In financial economics, the key issue in this regard is understanding and quantifying how news of all possible types (geopolitical, environmental, social, financial, economic, etc.) affects trading and the pricing of firms in organized stock markets. In this article, we seek to address this issue by performing an analysis of more than 24 million news records provided by Thompson Reuters and of their relationship with trading activity for 206 major stocks in the S&P US stock index. We show that the whole landscape of news that affects stock price movements can be automatically summarized via simple regularized regressions between trading activity and news information pieces decomposed, with the help of simple topic modeling techniques, into their “thematic” features. Using these methods, we are able to estimate and quantify the impacts of news on trading. We introduce network-based visualization techniques to represent the whole landscape of news information associated with a basket of stocks. The examination of the words that are representative of the topic distributions confirms that our method is able to extract the significant pieces of information influencing the stock market. Our results show that one of the most puzzling stylized facts in financial economies, namely that at certain times trading volumes appear to be “abnormally large,” can be partially explained by the flow of news. In this sense, our results prove that there is no “excess trading,” when restricting to times when news is genuinely novel and provides relevant financial information.",Document_21,Collaborating with regulators to create AI compliance frameworks,0.04773903265595436,Regulatory Engagement and Proactive Compliance Strategies
Differential Privacy and the GDPR,J. Hölzel,"Under the European General Data Protection Regulation, anonymisation of personal data may not only provide a legal loophole for controllers to escape their regulatory burden. Considering specific circumstances, it can even be a legal duty for controllers to anonymise their personal data. Differential privacy has been proposed as a new approach to the problem of anonymisation. This article aims to assess the appropriateness of this approach with regards to the legal problem of anonymisation. Keywords: Anonymisation, Differential Privacy, Privacy Model, Model Comparison, Anonymisation Techniques",2019,2019,4.0,European Data Protection Law Review,"Success (Selector (div[id*=""abstract""])) / Date (Meta (citation_publication_date)) (Possible Paywall/Login Page Detected) (URL Source: DOI Link)",https://doi.org/10.21552/edpl/2019/2/8,10.21552/edpl/2019/2/8,https://doi.org/10.21552/edpl/2019/2/8,9,"Under the European General Data Protection Regulation, anonymisation of personal data may not only provide a legal loophole for controllers to escape their regulatory burden. Considering specific circumstances, it can even be a legal duty for controllers to anonymise their personal data. Differential privacy has been proposed as a new approach to the problem of anonymisation. This article aims to assess the appropriateness of this approach with regards to the legal problem of anonymisation. Keywords: Anonymisation, Differential Privacy, Privacy Model, Model Comparison, Anonymisation Techniques",Document_22,Difficulty in understanding AI decision-making is a barrier in finance,0.04822792112827301,Explainability and Transparency Barriers
Bringing order into the realm of Transformer-based language models for artificial intelligence and law,"C. M. Greco, Andrea Tagarelli","Transformer-based language models (TLMs) have widely been recognized to be a cutting-edge technology for the successful development of deep-learning-based solutions to problems and applications that require natural language processing and understanding. Like for other textual domains, TLMs have indeed pushed the state-of-the-art of AI approaches for many tasks of interest in the legal domain. Despite the first Transformer model being proposed about six years ago, there has been a rapid progress of this technology at an unprecedented rate, whereby BERT and related models represent a major reference, also in the legal domain. This article provides the first systematic overview of TLM-based methods for AI-driven problems and tasks in the legal sphere. A major goal is to highlight research advances in this field so as to understand, on the one hand, how the Transformers have contributed to the success of AI in supporting legal processes, and on the other hand, what are the current limitations and opportunities for further research development.",2023,2024,12.0,Artificial Intelligence and Law,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10506-023-09374-7,10.1007/s10506-023-09374-7,https://doi.org/10.1007/s10506-023-09374-7,14,"Transformer-based language models (TLMs) have widely been recognized to be a cutting-edge technology for the successful development of deep-learning-based solutions to problems and applications that require natural language processing and understanding. Like for other textual domains, TLMs have indeed pushed the state-of-the-art of AI approaches for many tasks of interest in the legal domain. Despite the first Transformer model being proposed about six years ago, there has been a rapid progress of this technology at an unprecedented rate, whereby BERT and related models represent a major reference, also in the legal domain. This article provides the first systematic overview of TLM-based methods for AI-driven problems and tasks in the legal sphere. A major goal is to highlight research advances in this field so as to understand, on the one hand, how the Transformers have contributed to the success of AI in supporting legal processes, and on the other hand, what are the current limitations and opportunities for further research development.",Document_23,Technical aspects or methods of AI or machine learning,0.2858896851539612,Other Categories
A Differentiable Language Model Adversarial Attack on Text Classifiers,"I. Fursov, A. Zaytsev, Pavel Burnyshev, Ekaterina Dmitrieva, Nikita Klyuchnikov, A. Kravchenko, E. Artemova, Evgeny Burnaev","Transformer models play a crucial role in state of the art solutions to problems arising in the field of natural language processing (NLP). They have billions of parameters and are typically considered as black boxes. Robustness of huge Transformer-based models for NLP is an important question due to their wide adoption. One way to understand and improve robustness of these models is an exploration of an adversarial attack scenario: check if a small perturbation of an input invisible to a human eye can fool a model. Due to the discrete nature of textual data, gradient-based adversarial methods, widely used in computer vision, are not applicable per se. The standard strategy to overcome this issue is to develop token-level transformations, which do not take the whole sentence into account. The semantic meaning and grammatical correctness of the sentence are often lost in such approaches In this paper, we propose a new black-box sentence-level attack. Our method fine-tunes a pre-trained language model to generate adversarial examples. A proposed differentiable loss function depends on a substitute classifier score and an approximate edit distance computed via a deep learning model. We show that the proposed attack outperforms competitors on a diverse set of NLP problems for both computed metrics and human evaluation. Moreover, due to the usage of the fine-tuned language model, the generated adversarial examples are hard to detect, thus current models are not robust. Hence, it is difficult to defend from the proposed attack, which is not the case for others. Our attack demonstrates the highest decrease of classification accuracy on all datasets(on AG news: 0.95 without attack, 0.89 under SamplingFool attack, 0.82 under DILMA attack).",2021,2021,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2022.3148413,10.1109/ACCESS.2022.3148413,https://doi.org/10.1109/ACCESS.2022.3148413,15,"Transformer models play a crucial role in state of the art solutions to problems arising in the field of natural language processing (NLP). They have billions of parameters and are typically considered as black boxes. Robustness of huge Transformer-based models for NLP is an important question due to their wide adoption. One way to understand and improve robustness of these models is an exploration of an adversarial attack scenario: check if a small perturbation of an input invisible to a human eye can fool a model. Due to the discrete nature of textual data, gradient-based adversarial methods, widely used in computer vision, are not applicable per se. The standard strategy to overcome this issue is to develop token-level transformations, which do not take the whole sentence into account. The semantic meaning and grammatical correctness of the sentence are often lost in such approaches In this paper, we propose a new black-box sentence-level attack. Our method fine-tunes a pre-trained language model to generate adversarial examples. A proposed differentiable loss function depends on a substitute classifier score and an approximate edit distance computed via a deep learning model. We show that the proposed attack outperforms competitors on a diverse set of NLP problems for both computed metrics and human evaluation. Moreover, due to the usage of the fine-tuned language model, the generated adversarial examples are hard to detect, thus current models are not robust. Hence, it is difficult to defend from the proposed attack, which is not the case for others. Our attack demonstrates the highest decrease of classification accuracy on all datasets(on AG news: 0.95 without attack, 0.89 under SamplingFool attack, 0.82 under DILMA attack).",Document_24,Technical aspects or methods of AI or machine learning,0.15014871954917908,Other Categories
It’s Morphin’ Time! Combating Linguistic Discrimination with Inflectional Perturbations,"Samson Tan, Shafiq R. Joty, Min-Yen Kan, R. Socher","Training on only perfect Standard English corpora predisposes pre-trained neural networks to discriminate against minorities from non-standard linguistic backgrounds (e.g., African American Vernacular English, Colloquial Singapore English, etc.). We perturb the inflectional morphology of words to craft plausible and semantically similar adversarial examples that expose these biases in popular NLP models, e.g., BERT and Transformer, and show that adversarially fine-tuning them for a single epoch significantly improves robustness without sacrificing performance on clean data.",2020,2020,7.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""]) - Truncation Suspected) / Date (Meta (citation_publication_date)) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.06) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.acl-main.263,10.18653/v1/2020.acl-main.263,https://doi.org/10.18653/v1/2020.acl-main.263,98,"Training on only perfect Standard English corpora predisposes pre-trained neural networks to discriminate against minorities from non-standard linguistic backgrounds (e.g., African American Vernacular English, Colloquial Singapore English, etc.). We perturb the inflectional morphology of words to craft plausible and semantically similar adversarial examples that expose these biases in popular NLP models, e.g., BERT and Transformer, and show that adversarially fine-tuning them for a single epoch significantly improves robustness without sacrificing performance on clean data.",Document_25,Technical aspects or methods of AI or machine learning,0.12167928367853165,Other Categories
Choosing an NLP Library for Analyzing Software Documentation: A Systematic Literature Review and a Series of Experiments,"Fouad Nasser A. Al Omran, Christoph Treude","To uncover interesting and actionable information from natural language documents authored by software developers, many researchers rely on ""out-of-the-box"" NLP libraries. However, software artifacts written in natural language are different from other textual documents due to the technical language used. In this paper, we first analyze the state of the art through a systematic literature review in which we find that only a small minority of papers justify their choice of an NLP library. We then report on a series of experiments in which we applied four state-of-the-art NLP libraries to publicly available software artifacts from three different sources. Our results show low agreement between different libraries (only between 60% and 71% of tokens were assigned the same part-of-speech tag by all four libraries) as well as differences in accuracy depending on source: For example, spaCy achieved the best accuracy on Stack Overflow data with nearly 90% of tokens tagged correctly, while it was clearly outperformed by Google's SyntaxNet when parsing GitHub ReadMe files. Our work implies that researchers should make an informed decision about the particular NLP library they choose and that customizations to libraries might be necessary to achieve good results when analyzing software artifacts written in natural language.",2017,2017,,IEEE Working Conference on Mining Software Repositories,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/MSR.2017.42,10.1109/MSR.2017.42,https://doi.org/10.1109/MSR.2017.42,85,"To uncover interesting and actionable information from natural language documents authored by software developers, many researchers rely on ""out-of-the-box"" NLP libraries. However, software artifacts written in natural language are different from other textual documents due to the technical language used. In this paper, we first analyze the state of the art through a systematic literature review in which we find that only a small minority of papers justify their choice of an NLP library. We then report on a series of experiments in which we applied four state-of-the-art NLP libraries to publicly available software artifacts from three different sources. Our results show low agreement between different libraries (only between 60% and 71% of tokens were assigned the same part-of-speech tag by all four libraries) as well as differences in accuracy depending on source: For example, spaCy achieved the best accuracy on Stack Overflow data with nearly 90% of tokens tagged correctly, while it was clearly outperformed by Google's SyntaxNet when parsing GitHub ReadMe files. Our work implies that researchers should make an informed decision about the particular NLP library they choose and that customizations to libraries might be necessary to achieve good results when analyzing software artifacts written in natural language.",Document_26,Technical aspects or methods of AI or machine learning,0.0929284617304802,Other Categories
SensitiveNets: Learning Agnostic Representations with Application to Face Images,"A. Morales, Julian Fierrez, R. Vera-Rodríguez, Rubén Tolosana","This work proposes a novel privacy-preserving neural network feature representation to suppress the sensitive information of a learned space while maintaining the utility of the data. The new international regulation for personal data protection forces data controllers to guarantee privacy and avoid discriminative hazards while managing sensitive data of users. In our approach, privacy and discrimination are related to each other. Instead of existing approaches aimed directly at fairness improvement, the proposed feature representation enforces the privacy of selected attributes. This way fairness is not the objective, but the result of a privacy-preserving learning method. This approach guarantees that sensitive information cannot be exploited by any agent who process the output of the model, ensuring both privacy and equality of opportunity. Our method is based on an adversarial regularizer that introduces a sensitive information removal function in the learning objective. The method is evaluated on three different primary tasks (identity, attractiveness, and smiling) and three publicly available benchmarks. In addition, we present a new face annotation dataset with balanced distribution between genders and ethnic origins. The experiments demonstrate that it is possible to improve the privacy and equality of opportunity while retaining competitive performance independently of the task.",2019,2019,,IEEE Transactions on Pattern Analysis and Machine Intelligence,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/TPAMI.2020.3015420,10.1109/TPAMI.2020.3015420,https://doi.org/10.1109/TPAMI.2020.3015420,126,"This work proposes a novel privacy-preserving neural network feature representation to suppress the sensitive information of a learned space while maintaining the utility of the data. The new international regulation for personal data protection forces data controllers to guarantee privacy and avoid discriminative hazards while managing sensitive data of users. In our approach, privacy and discrimination are related to each other. Instead of existing approaches aimed directly at fairness improvement, the proposed feature representation enforces the privacy of selected attributes. This way fairness is not the objective, but the result of a privacy-preserving learning method. This approach guarantees that sensitive information cannot be exploited by any agent who process the output of the model, ensuring both privacy and equality of opportunity. Our method is based on an adversarial regularizer that introduces a sensitive information removal function in the learning objective. The method is evaluated on three different primary tasks (identity, attractiveness, and smiling) and three publicly available benchmarks. In addition, we present a new face annotation dataset with balanced distribution between genders and ethnic origins. The experiments demonstrate that it is possible to improve the privacy and equality of opportunity while retaining competitive performance independently of the task.",Document_27,Demonstrating the value of AI for compliance and risk management,0.17256517708301544,Business Case and Value Demonstration Strategies
SemEval-2017 Task 11: End-User Development using Natural Language,"J. Sales, S. Handschuh, A. Freitas","This task proposes a challenge to support the interaction between users and applications, micro-services and software APIs using natural language. The task aims for supporting the evaluation and evolution of the discussions surrounding the natural language processing approaches within the context of end-user natural language programming, under scenarios of high semantic heterogeneity/gap.",2017,2017,8.0,International Workshop on Semantic Evaluation,"Success (Selector (div[class*=""abstract""]) - Truncation Suspected) / Date (Meta (citation_publication_date)) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.15) (URL Source: DOI Link)",https://doi.org/10.18653/v1/S17-2092,10.18653/v1/S17-2092,https://doi.org/10.18653/v1/S17-2092,14,"This task proposes a challenge to support the interaction between users and applications, micro-services and software APIs using natural language. The task aims for supporting the evaluation and evolution of the discussions surrounding the natural language processing approaches within the context of end-user natural language programming, under scenarios of high semantic heterogeneity/gap.",Document_28,Technical aspects or methods of AI or machine learning,0.06899803876876831,Other Categories
Implementing data governance in financial systems: Strategies for ensuring compliance and security in multi-source data integration projects,"David Akokodaripon, Favour Oluwaseun Alonge-Essiet, Akorede Victor Aderoju, Oluwatosin Reis","This study explores the complexities of implementing data governance within financial systems, focusing on strategies to ensure compliance and security in multi-source data integration projects. The primary aim was to identify challenges and establish a comprehensive framework to enhance data integrity, confidentiality, and regulatory adherence in the financial sector. Using a mixed-methods approach, the research included an extensive literature review, case studies, and expert interviews to gain insights into current practices, challenges, and emerging trends in data governance. Key findings reveal that while multi-source data integration offers significant opportunities for enhanced decision-making, it also presents substantial risks, including data breaches and regulatory non-compliance. The study underscores the pivotal role of data governance frameworks in mitigating these risks through the establishment of clear data policies, the implementation of robust cybersecurity measures, and the promotion of a compliance-focused organizational culture. Additionally, the analysis highlights the necessity for harmonized global data privacy laws to address the diverse regulatory environments that financial institutions operate within. The research concludes that effective data governance is crucial for financial institutions to safeguard their data assets, ensure regulatory compliance, and maintain stakeholder trust. Recommendations include the adoption of advanced technologies like artificial intelligence and blockchain to enhance data governance capabilities, the provision of ongoing employee training to foster a culture of compliance, and the implementation of dynamic compliance monitoring systems to keep pace with evolving regulatory demands. By embracing these strategies, financial institutions can develop a resilient data governance framework that not only ensures compliance and security but also drives operational excellence, competitive advantage, and sustained trust in the increasingly digital financial landscape. Keywords : Data Governance, Financial Systems, Multi-Source Data Integration, Regulatory Compliance, Cybersecurity, Data Privacy.",2024,2024,,Computer Science &amp; IT Research Journal,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.51594/csitrj.v5i10.1631,10.51594/csitrj.v5i10.1631,https://doi.org/10.51594/csitrj.v5i10.1631,1,"This study explores the complexities of implementing data governance within financial systems, focusing on strategies to ensure compliance and security in multi-source data integration projects. The primary aim was to identify challenges and establish a comprehensive framework to enhance data integrity, confidentiality, and regulatory adherence in the financial sector. Using a mixed-methods approach, the research included an extensive literature review, case studies, and expert interviews to gain insights into current practices, challenges, and emerging trends in data governance. Key findings reveal that while multi-source data integration offers significant opportunities for enhanced decision-making, it also presents substantial risks, including data breaches and regulatory non-compliance. The study underscores the pivotal role of data governance frameworks in mitigating these risks through the establishment of clear data policies, the implementation of robust cybersecurity measures, and the promotion of a compliance-focused organizational culture. Additionally, the analysis highlights the necessity for harmonized global data privacy laws to address the diverse regulatory environments that financial institutions operate within. The research concludes that effective data governance is crucial for financial institutions to safeguard their data assets, ensure regulatory compliance, and maintain stakeholder trust. Recommendations include the adoption of advanced technologies like artificial intelligence and blockchain to enhance data governance capabilities, the provision of ongoing employee training to foster a culture of compliance, and the implementation of dynamic compliance monitoring systems to keep pace with evolving regulatory demands. By embracing these strategies, financial institutions can develop a resilient data governance framework that not only ensures compliance and security but also drives operational excellence, competitive advantage, and sustained trust in the increasingly digital financial landscape. Keywords : Data Governance, Financial Systems, Multi-Source Data Integration, Regulatory Compliance, Cybersecurity, Data Privacy.",Document_29,General discussion of financial or regulatory topics (non-AI focus),0.07100662589073181,Other Categories
Migrating Monoliths to Microservices Integrating Robotic Process Automation into the Migration Approach,"B. Bamberger, Bastian Körber","This research should help scholars and practitioners to manage the transition of monolithic legacy application systems to microservices and to better understand the migration process, its steps, characteristics and provide guidance on how best to approach it. We performed a systematic literature review and analyzed migration approaches presented by other researches. We propose to leverage Robotic Process Automation technology to extract business logic, create and deploy bots, which are then used to mimic microservices. In essence, this represents a novel use case, integrating RPA technology into the migration approach in order to reduce uncertainty and risk of failure.",2022,2022,,"Journal of Automation, Mobile Robotics & Intelligent Systems",Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.14313/jamris/1-2022/8,10.14313/jamris/1-2022/8,https://doi.org/10.14313/jamris/1-2022/8,1,"This research should help scholars and practitioners to manage the transition of monolithic legacy application systems to microservices and to better understand the migration process, its steps, characteristics and provide guidance on how best to approach it. We performed a systematic literature review and analyzed migration approaches presented by other researches. We propose to leverage Robotic Process Automation technology to extract business logic, create and deploy bots, which are then used to mimic microservices. In essence, this represents a novel use case, integrating RPA technology into the migration approach in order to reduce uncertainty and risk of failure.",Document_30,Technical aspects or methods of AI or machine learning,0.3320460617542267,Other Categories
"Advancing electronic communication Compliance and fraud detection Through Machine Learning, NLP and generative AI: A Pathway to Enhanced Cybersecurity and Regulatory Adherence","Iga Daniel Ssetimba, Jimmy Kato, Eria Othieno Pinyi, Evans Twineamatsiko, Harriet Norah Nakayenga, Eudis Muhangi","This research investigates the application of advanced technologies, specifically machine learning (ML), natural language processing (NLP), and generative artificial intelligence (AI), to enhance regulatory compliance and fraud detection within the financial services sector. Machine learning, with its ability to analyze vast amounts of data and identify patterns, provides predictive capabilities that can significantly improve the accuracy of fraud detection systems. NLP, on the other hand, offers a nuanced understanding of textual data, facilitating more efficient processing of compliance documentation and communication logs. Generative AI introduces innovative approaches by simulating potential fraud scenarios, thereby allowing organizations to anticipate and mitigate emerging threats. The study aims to integrate these technologies into a cohesive framework that enhances both the detection of fraudulent activities and the efficiency of compliance processes. By leveraging ML's predictive power, NLP's textual analysis capabilities, and generative AI's scenario simulation, this research seeks to address existing limitations in traditional fraud detection and regulatory adherence systems. Traditional methods often struggle with adapting to new fraud tactics and managing large volumes of compliance data, leading to inefficiencies and increased vulnerability. Key findings of this research demonstrate that the implementation of machine learning algorithms results in a 30% increase in fraud detection accuracy and a 25% reduction in false positives compared to conventional approaches. NLP techniques have been shown to enhance processing efficiency for compliance documentation by 40%, reducing errors and speeding up the review process. Additionally, generative AI models have contributed to a 35% improvement in predicting and addressing potential fraud scenarios, thus enhancing overall system robustness. This study provides a comprehensive examination of methodologies, benefits, and future directions for deploying ML, NLP, and generative AI in financial services. It underscores the transformative potential of these technologies in strengthening security measures, ensuring meticulous adherence to evolving regulatory standards, and fostering a trustworthy operational environment. The integration of these advanced technologies promises not only to bolster the security framework but also to offer a more dynamic and adaptive approach to regulatory compliance and fraud detection.",2024,2024,4.0,World Journal of Advanced Research and Reviews,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.30574/wjarr.2024.23.2.2364,10.30574/wjarr.2024.23.2.2364,https://doi.org/10.30574/wjarr.2024.23.2.2364,1,"This research investigates the application of advanced technologies, specifically machine learning (ML), natural language processing (NLP), and generative artificial intelligence (AI), to enhance regulatory compliance and fraud detection within the financial services sector. Machine learning, with its ability to analyze vast amounts of data and identify patterns, provides predictive capabilities that can significantly improve the accuracy of fraud detection systems. NLP, on the other hand, offers a nuanced understanding of textual data, facilitating more efficient processing of compliance documentation and communication logs. Generative AI introduces innovative approaches by simulating potential fraud scenarios, thereby allowing organizations to anticipate and mitigate emerging threats. The study aims to integrate these technologies into a cohesive framework that enhances both the detection of fraudulent activities and the efficiency of compliance processes. By leveraging ML's predictive power, NLP's textual analysis capabilities, and generative AI's scenario simulation, this research seeks to address existing limitations in traditional fraud detection and regulatory adherence systems. Traditional methods often struggle with adapting to new fraud tactics and managing large volumes of compliance data, leading to inefficiencies and increased vulnerability. Key findings of this research demonstrate that the implementation of machine learning algorithms results in a 30% increase in fraud detection accuracy and a 25% reduction in false positives compared to conventional approaches. NLP techniques have been shown to enhance processing efficiency for compliance documentation by 40%, reducing errors and speeding up the review process. Additionally, generative AI models have contributed to a 35% improvement in predicting and addressing potential fraud scenarios, thus enhancing overall system robustness. This study provides a comprehensive examination of methodologies, benefits, and future directions for deploying ML, NLP, and generative AI in financial services. It underscores the transformative potential of these technologies in strengthening security measures, ensuring meticulous adherence to evolving regulatory standards, and fostering a trustworthy operational environment. The integration of these advanced technologies promises not only to bolster the security framework but also to offer a more dynamic and adaptive approach to regulatory compliance and fraud detection.",Document_31,Technical aspects or methods of AI or machine learning,0.22512826323509216,Other Categories
Text Analytics and Big Data in the Financial domain,"Jean-Pierre Kuilboer, Tristan Stull","This research attempts to provide some insights on the application of text mining and Natural Language Processing (NLP). The application domain is consumer complaints about financial institutions in the USA. As an advanced analytics discipline embedded within the Big Data paradigm, the practice of text analytics contains elements of emergent knowledge processes. Since our experiment should be able to scale up we make use of a pipeline based on Spark-NLP. The usage scenario is adapting the model to a specific industrial context and using the dataset offered by the ""Consumer Financial Protection Bureau"" to illustrate the application.",2021,2021,,Iberian Conference on Information Systems and Technologies,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.23919/CISTI52073.2021.9476434,10.23919/CISTI52073.2021.9476434,https://doi.org/10.23919/CISTI52073.2021.9476434,1,"This research attempts to provide some insights on the application of text mining and Natural Language Processing (NLP). The application domain is consumer complaints about financial institutions in the USA. As an advanced analytics discipline embedded within the Big Data paradigm, the practice of text analytics contains elements of emergent knowledge processes. Since our experiment should be able to scale up we make use of a pipeline based on Spark-NLP. The usage scenario is adapting the model to a specific industrial context and using the dataset offered by the ""Consumer Financial Protection Bureau"" to illustrate the application.",Document_32,Highlighting the benefits of AI for customer insights in finance,0.1753840446472168,Business Case and Value Demonstration Strategies
"Anonymisation Models for Text Data: State of the art, Challenges and Future Directions","Pierre Lison, I. Pilán, David Sánchez, Montserrat Batet, Lilja Øvrelid","This position paper investigates the problem of automated text anonymisation, which is a prerequisite for secure sharing of documents containing sensitive information about individuals. We summarise the key concepts behind text anonymisation and provide a review of current approaches. Anonymisation methods have so far been developed in two fields with little mutual interaction, namely natural language processing and privacy-preserving data publishing. Based on a case study, we outline the benefits and limitations of these approaches and discuss a number of open challenges, such as (1) how to account for multiple types of semantic inferences, (2) how to strike a balance between disclosure risk and data utility and (3) how to evaluate the quality of the resulting anonymisation. We lay out a case for moving beyond sequence labelling models and incorporate explicit measures of disclosure risk into the text anonymisation process.",2021,2021,8.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2021.acl-long.323,10.18653/v1/2021.acl-long.323,https://doi.org/10.18653/v1/2021.acl-long.323,73,"This position paper investigates the problem of automated text anonymisation, which is a prerequisite for secure sharing of documents containing sensitive information about individuals. We summarise the key concepts behind text anonymisation and provide a review of current approaches. Anonymisation methods have so far been developed in two fields with little mutual interaction, namely natural language processing and privacy-preserving data publishing. Based on a case study, we outline the benefits and limitations of these approaches and discuss a number of open challenges, such as (1) how to account for multiple types of semantic inferences, (2) how to strike a balance between disclosure risk and data utility and (3) how to evaluate the quality of the resulting anonymisation. We lay out a case for moving beyond sequence labelling models and incorporate explicit measures of disclosure risk into the text anonymisation process.",Document_33,Other AI topic (not related to finance/regulation),0.07596758753061295,Other Categories
Ethical considerations in the use of Machine Learning for research and statistics.,-,"This paper, based upon new guidance created in collaboration with researchers from several national statistical institutes, explores the main ethical considerations associated with the use of machine learning techniques for aggregate statistics. The aim of this paper is to provide applied, practical ethical guidance for researchers using machine learning techniques. Following an extensive literature review, alongside discussion and collaboration with a number of national statistical institutes, it was identified that there was a need for applied guidance on the use of machine learning for the production of official statistics by the international research and statistical community. Feedback was gathered from interested stakeholders, which found that whilst there were resources available to researchers relating to the ethical considerations of machine learning projects, these focus mainly on operational uses of machine learning, and furthermore, lacked advice on how to practically mitigate ethical issues that arise throughout the project lifecycle. The guidance focuses on four main ethical considerations, found to be prevalent within machine learning research, and offers ways to mitigate these issues should they arise. These are: the importance of minimising and mitigating social bias and discrimination within machine learning research, and clearly communicating these, and the limitations of our research; the need to consider the transparency and explainability of machine learning research, and the implications this has for reproducibility; the importance of maintaining accountability throughout machine learning processes, ensuring that models are used only for their intended purposes, and that different stakeholders are aware of their responsibilities; the need to consider the confidentiality and privacy risks arising from the data used, both in relation to training data which is fed into the machine, and outputs resulting from the machine learning’s findings. The guidance has been well-received following its release, and feedback from the wider user community to date has been positive. The IPDLN conference provides an opportunity for further feedback to be collated to ensure that the guidance continues to be valuable to its intended audience.",2022,2022,,International Journal of Population Data Science,"Selector (div[class*=""abstract""] / Date Not Found (URL Source: DOI Link)",https://doi.org/10.23889/ijpds.v7i3.1921,10.23889/ijpds.v7i3.1921,https://doi.org/10.23889/ijpds.v7i3.1921,4,"This paper, based upon new guidance created in collaboration with researchers from several national statistical institutes, explores the main ethical considerations associated with the use of machine learning techniques for aggregate statistics. The aim of this paper is to provide applied, practical ethical guidance for researchers using machine learning techniques. Following an extensive literature review, alongside discussion and collaboration with a number of national statistical institutes, it was identified that there was a need for applied guidance on the use of machine learning for the production of official statistics by the international research and statistical community. Feedback was gathered from interested stakeholders, which found that whilst there were resources available to researchers relating to the ethical considerations of machine learning projects, these focus mainly on operational uses of machine learning, and furthermore, lacked advice on how to practically mitigate ethical issues that arise throughout the project lifecycle. The guidance focuses on four main ethical considerations, found to be prevalent within machine learning research, and offers ways to mitigate these issues should they arise. These are: the importance of minimising and mitigating social bias and discrimination within machine learning research, and clearly communicating these, and the limitations of our research; the need to consider the transparency and explainability of machine learning research, and the implications this has for reproducibility; the importance of maintaining accountability throughout machine learning processes, ensuring that models are used only for their intended purposes, and that different stakeholders are aware of their responsibilities; the need to consider the confidentiality and privacy risks arising from the data used, both in relation to training data which is fed into the machine, and outputs resulting from the machine learning’s findings. The guidance has been well-received following its release, and feedback from the wider user community to date has been positive. The IPDLN conference provides an opportunity for further feedback to be collated to ensure that the guidance continues to be valuable to its intended audience.",Document_34,Technical aspects or methods of AI or machine learning,0.11395933479070663,Other Categories
Developing a portable natural language processing based phenotyping system,"Himanshu Sharma, Chengsheng Mao, Yizhen Zhang, H. Vatani, Liang Yao, Yizhen Zhong, L. Rasmussen, Guoqian Jiang, Jyotishman Pathak, Yuan Luo","This paper presents a portable phenotyping system that is capable of integrating both rule-based and statistical machine learning based approaches. Our system utilizes UMLS to extract clinically relevant features from the unstructured text and then facilitates portability across different institutions and data systems by incorporating OHDSI’s OMOP Common Data Model (CDM) to standardize necessary data elements. Our system can also store the key components of rule-based systems (e.g., regular expression matches) in the format of OMOP CDM, thus enabling the reuse, adaptation and extension of many existing rule-based clinical NLP systems. We experimented with our system on the corpus from i2b2’s Obesity Challenge as a pilot study. Our system facilitates portable phenotyping of obesity and its 15 comorbidities based on the unstructured patient discharge summaries, while achieving a performance that often ranked among the top 10 of the challenge participants. Our system of standardization enables a consistent application of numerous rule-based and machine learning based classification techniques downstream across disparate datasets which may originate across different institutions and data systems.",2018,2019,4.0,BMC Medical Informatics and Decision Making,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1186/s12911-019-0786-z,10.1186/s12911-019-0786-z,https://doi.org/10.1186/s12911-019-0786-z,36,"This paper presents a portable phenotyping system that is capable of integrating both rule-based and statistical machine learning based approaches. Our system utilizes UMLS to extract clinically relevant features from the unstructured text and then facilitates portability across different institutions and data systems by incorporating OHDSI’s OMOP Common Data Model (CDM) to standardize necessary data elements. Our system can also store the key components of rule-based systems (e.g., regular expression matches) in the format of OMOP CDM, thus enabling the reuse, adaptation and extension of many existing rule-based clinical NLP systems. We experimented with our system on the corpus from i2b2’s Obesity Challenge as a pilot study. Our system facilitates portable phenotyping of obesity and its 15 comorbidities based on the unstructured patient discharge summaries, while achieving a performance that often ranked among the top 10 of the challenge participants. Our system of standardization enables a consistent application of numerous rule-based and machine learning based classification techniques downstream across disparate datasets which may originate across different institutions and data systems.",Document_35,Technical aspects or methods of AI or machine learning,0.1236422136425972,Other Categories
Microservices opportunity: Dawn of the open API era,Eiichiro Yanagawa,"This paper explores the innovative and promising software engineering concept of microservices and the revolutionary architecture that is being built on modularisation approaches for systems and businesses using them. Increasingly, microservices have been thrust into the limelight as a transformative tool in software engineering. Microservices architecture, or more simply microservices, refers to a method of designing and developing software as self-contained, deployable components that can be combined to create services. This approach to development is extremely amenable to the current environment characterised by the proliferation of online services and accompanying noise about fostering FinTech partnerships. Indeed, the very concept and approach to development, operations and maintenance of microservices is progressive. It also sits at the opposite end of the spectrum from the highly integrated monolithic core systems of Japanese banks — both the massive self-run, in-house megabank operated systems and the shared regional bank systems. This paper defines each of these architectural elements and specifies their essential value propositions, which are as follows: faster to build; easier to maintain; quickly scalable; and able to leverage advanced analytics and security services offered by cloud providers. Microservices offer potential insights on a number of levels for banks currently facing issues from how to create loyal digital communities to establishing new digital customer relationships. The Japanese financial industry and banking industry spent about three years, beginning in 2015, to develop a legal framework for Open application programming interface (API) and fostered a Japan-style consensus, laying a foundation on which to build a new ecosystem.",2019,2019,,Journal of digital banking,Selector (div.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.69554/kzgw8682,10.69554/kzgw8682,https://doi.org/10.69554/kzgw8682,1,"This paper explores the innovative and promising software engineering concept of microservices and the revolutionary architecture that is being built on modularisation approaches for systems and businesses using them. Increasingly, microservices have been thrust into the limelight as a transformative tool in software engineering. Microservices architecture, or more simply microservices, refers to a method of designing and developing software as self-contained, deployable components that can be combined to create services. This approach to development is extremely amenable to the current environment characterised by the proliferation of online services and accompanying noise about fostering FinTech partnerships. Indeed, the very concept and approach to development, operations and maintenance of microservices is progressive. It also sits at the opposite end of the spectrum from the highly integrated monolithic core systems of Japanese banks — both the massive self-run, in-house megabank operated systems and the shared regional bank systems. This paper defines each of these architectural elements and specifies their essential value propositions, which are as follows: faster to build; easier to maintain; quickly scalable; and able to leverage advanced analytics and security services offered by cloud providers. Microservices offer potential insights on a number of levels for banks currently facing issues from how to create loyal digital communities to establishing new digital customer relationships. The Japanese financial industry and banking industry spent about three years, beginning in 2015, to develop a legal framework for Open application programming interface (API) and fostered a Japan-style consensus, laying a foundation on which to build a new ecosystem.",Document_36,General discussion of financial or regulatory topics (non-AI focus),0.0654020830988884,Other Categories
Access to Finance for Artificial Intelligence Regulation in the Financial Services Industry,Joseph Lee,"This paper discusses the design of the legal and regulatory framework for using artificial intelligence (AI) in the financial services markets to enhance access to finance (financial inclusion). The author argues that the development of AI should continue to adhere to the regulatory objectives of market safety, consumer protection, and market integrity. However, to ensure equality and fairness, access to finance should be made a clear policy choice. In the first part, the author discusses how AI can lead to systemic risks and market manipulation on trading platforms. For example, by examining the use of algorithms for trading on the capital market, the author discerns the regulatory objectives and the possible methods of regulation for peer-to-peer platforms. In the second part, the author discusses how the use of AI to provide consumers with investment advice, such as financial advice provided from robo-advisers, can close the investment advisory gap and provide consumers with access to finance. The current regime does not provide adequate protection to financial consumers in this regard. In the third part, the author discusses how AI can be used as a form of RegTech to streamline compliance processes, thereby increasing competition in financial markets and providing a benefit to consumers. However, this use may be in conflict with privacy, data protection, and ethical concerns. The author makes policy recommendations and suggests some directions for governance in the use of AI in financial services to enhance access to finance. The findings of this paper are relevant to research on the future governance of AI in financial services, public policy innovation, and urban development.",2019,2020,12.0,European Business Organization Law Review,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s40804-020-00200-0,10.1007/s40804-020-00200-0,https://doi.org/10.1007/s40804-020-00200-0,57,"This paper discusses the design of the legal and regulatory framework for using artificial intelligence (AI) in the financial services markets to enhance access to finance (financial inclusion). The author argues that the development of AI should continue to adhere to the regulatory objectives of market safety, consumer protection, and market integrity. However, to ensure equality and fairness, access to finance should be made a clear policy choice. In the first part, the author discusses how AI can lead to systemic risks and market manipulation on trading platforms. For example, by examining the use of algorithms for trading on the capital market, the author discerns the regulatory objectives and the possible methods of regulation for peer-to-peer platforms. In the second part, the author discusses how the use of AI to provide consumers with investment advice, such as financial advice provided from robo-advisers, can close the investment advisory gap and provide consumers with access to finance. The current regime does not provide adequate protection to financial consumers in this regard. In the third part, the author discusses how AI can be used as a form of RegTech to streamline compliance processes, thereby increasing competition in financial markets and providing a benefit to consumers. However, this use may be in conflict with privacy, data protection, and ethical concerns. The author makes policy recommendations and suggests some directions for governance in the use of AI in financial services to enhance access to finance. The findings of this paper are relevant to research on the future governance of AI in financial services, public policy innovation, and urban development.",Document_37,Security risks associated with AI are a concern in financial regulation,0.2917896509170532,Organizational and Human Barriers
"Eunomos, a legal document and knowledge management system for the Web to provide relevant, reliable and up-to-date information on the law","G. Boella, Luigi Di Caro, Llio Humphreys, Livio Robaldo, P. Rossi, Leendert van der Torre","This paper describes the Eunomos software, an advanced legal document and knowledge management system, based on legislative XML and ontologies. We describe the challenges of legal research in an increasingly complex, multi-level and multi-lingual world and how the Eunomos software helps users cut through the information overload to get the legal information they need in an organized and structured way and keep track of the state of the relevant law on any given topic. Using NLP tools to semi-automate the lower-skill tasks makes this ambitious project a realistic commercial prospect as it helps keep costs down while at the same time allowing greater coverage. We describe the core system from workflow and technical perspectives, and discuss applications of the system for various user groups.",2016,2016,9.0,Artificial Intelligence and Law,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10506-016-9184-3,10.1007/s10506-016-9184-3,https://doi.org/10.1007/s10506-016-9184-3,93,"This paper describes the Eunomos software, an advanced legal document and knowledge management system, based on legislative XML and ontologies. We describe the challenges of legal research in an increasingly complex, multi-level and multi-lingual world and how the Eunomos software helps users cut through the information overload to get the legal information they need in an organized and structured way and keep track of the state of the relevant law on any given topic. Using NLP tools to semi-automate the lower-skill tasks makes this ambitious project a realistic commercial prospect as it helps keep costs down while at the same time allowing greater coverage. We describe the core system from workflow and technical perspectives, and discuss applications of the system for various user groups.",Document_38,Technical aspects or methods of AI or machine learning,0.13970829546451569,Other Categories
Cognitive Compliance: Assessing Regulatory Risk in Financial Advice Documents,"W. Sherchan, S. A. Chen, Simon Harris, Nebula Alam, Khoi-Nguyen Tran, Christopher J. Butler","This paper describes Cognitive Compliance - a solution that automates the complex manual process of assessing regulatory compliance of personal financial advice. The solution uses natural language processing (NLP), machine learning and deep learning to characterise the regulatory risk status of personal financial advice documents with traffic light rating for various risk factors. This enables comprehensive coverage of the review and rapid identification of documents at high risk of non-compliance with government regulations.",2020,2020,,AAAI Conference on Artificial Intelligence,"Selector (section.abstract - Truncation Suspected / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.07) (URL Source: DOI Link)",https://doi.org/10.1609/aaai.v34i09.7105,10.1609/aaai.v34i09.7105,https://doi.org/10.1609/aaai.v34i09.7105,2,"This paper describes Cognitive Compliance - a solution that automates the complex manual process of assessing regulatory compliance of personal financial advice. The solution uses natural language processing (NLP), machine learning and deep learning to characterise the regulatory risk status of personal financial advice documents with traffic light rating for various risk factors. This enables comprehensive coverage of the review and rapid identification of documents at high risk of non-compliance with government regulations.",Document_39,Demonstrating the value of AI for compliance and risk management,0.18320365250110626,Business Case and Value Demonstration Strategies
Standardizing formats of corporate source data,"C. Galvez, F. Moya-Anegón","This paper describe an approach for improving the data quality of corporate sources when databases are used for bibliometric purposes. Research management relies on bibliographic databases and citation index systems as analytical tools, yet the raw resources for bibliometric studies are plagued by a lack of consistency in fied formatting for institution data. The present contribution puts forth a Natural Language Processing (NLP)-oriented method for the identification of the structures guiding corporate data and their mapping into a standardized format. The proposed unification process is based on the definition of address patterns and the ensuing application of Enhanced Finite-State Transducers (E-FST). Our procedure was tested on address formats downloaded from the INSPEC, MEDLINE and CAB Abstracts. The results demonstrate the helpfulness of the method as long as close control of errors is exercised as far as the formats to be unified. The computational efficacy of the model is noteworthy, due to the fact that it is firmly guided by the definition of data in the application domain.",2007,2007,1.0,Scientometrics,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s11192-007-0101-0,10.1007/s11192-007-0101-0,https://doi.org/10.1007/s11192-007-0101-0,30,"This paper describe an approach for improving the data quality of corporate sources when databases are used for bibliometric purposes. Research management relies on bibliographic databases and citation index systems as analytical tools, yet the raw resources for bibliometric studies are plagued by a lack of consistency in fied formatting for institution data. The present contribution puts forth a Natural Language Processing (NLP)-oriented method for the identification of the structures guiding corporate data and their mapping into a standardized format. The proposed unification process is based on the definition of address patterns and the ensuing application of Enhanced Finite-State Transducers (E-FST). Our procedure was tested on address formats downloaded from the INSPEC, MEDLINE and CAB Abstracts. The results demonstrate the helpfulness of the method as long as close control of errors is exercised as far as the formats to be unified. The computational efficacy of the model is noteworthy, due to the fact that it is firmly guided by the definition of data in the application domain.",Document_40,Technical aspects or methods of AI or machine learning,0.09401321411132812,Other Categories
Poison Attacks against Text Datasets with Conditional Adversarially Regularized Autoencoder,"Alvin Chan, Yi Tay, Y. Ong, Aston Zhang","This paper demonstrates a fatal vulnerability in natural language inference (NLI) and text classification systems. More concretely, we present a ‘backdoor poisoning’ attack on NLP models. Our poisoning attack utilizes conditional adversarially regularized autoencoder (CARA) to generate poisoned training samples by poison injection in latent space. Just by adding 1% poisoned data, our experiments show that a victim BERT finetuned classifier’s predictions can be steered to the poison target class with success rates of >80% when the input hypothesis is injected with the poison signature, demonstrating that NLI and text classification systems face a huge security risk.",2020,2020,11.0,Findings,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.findings-emnlp.373,10.18653/v1/2020.findings-emnlp.373,https://doi.org/10.18653/v1/2020.findings-emnlp.373,51,"This paper demonstrates a fatal vulnerability in natural language inference (NLI) and text classification systems. More concretely, we present a ‘backdoor poisoning’ attack on NLP models. Our poisoning attack utilizes conditional adversarially regularized autoencoder (CARA) to generate poisoned training samples by poison injection in latent space. Just by adding 1% poisoned data, our experiments show that a victim BERT finetuned classifier’s predictions can be steered to the poison target class with success rates of >80% when the input hypothesis is injected with the poison signature, demonstrating that NLI and text classification systems face a huge security risk.",Document_41,Technical aspects or methods of AI or machine learning,0.10393645614385605,Other Categories
Scientific landscape on opportunities and challenges of large language models and natural language processing,"Rachel Edita O. Roxas, Reginald Neil C. Recario","This paper conducted a systematic review of Scopus-indexed publications on large language models (LLMs) and natural language processing (NLP) extracted in October 2023 to address the dearth of literature on their opportunities and challenges. Through bibliometric analysis, from the 1,600 relevant documents, the study explored research productivity, revealing both opportunities and challenges spanning research and real-world applications in education, medicine, and health care, citations, and keyword co-occurrence networks. Results highlighted distribution patterns and dominant players like Google LLC and Stanford University. Opportunities such as technological development in generative artificial intelligence (AI), were contrasted with challenges such as biases and ethical concerns. The intellectual structure analysis revealed prominent application areas in health and education and also emphasized issues such as AI divide and human-AI partnership. Improvement on the technology performance of LLM and NLP remains to be a challenge. Recommendations include further exploration of open research problems and bibliometric studies using other research databases given the research bias towards Scopus-indexed English publications.",2024,2024,,Indonesian Journal of Electrical Engineering and Computer Science,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.19) (URL Source: DOI Link)",https://doi.org/10.11591/ijeecs.v36.i1.pp252-263,10.11591/ijeecs.v36.i1.pp252-263,https://doi.org/10.11591/ijeecs.v36.i1.pp252-263,2,"This paper conducted a systematic review of Scopus-indexed publications on large language models (LLMs) and natural language processing (NLP) extracted in October 2023 to address the dearth of literature on their opportunities and challenges. Through bibliometric analysis, from the 1,600 relevant documents, the study explored research productivity, revealing both opportunities and challenges spanning research and real-world applications in education, medicine, and health care, citations, and keyword co-occurrence networks. Results highlighted distribution patterns and dominant players like Google LLC and Stanford University. Opportunities such as technological development in generative artificial intelligence (AI), were contrasted with challenges such as biases and ethical concerns. The intellectual structure analysis revealed prominent application areas in health and education and also emphasized issues such as AI divide and human-AI partnership. Improvement on the technology performance of LLM and NLP remains to be a challenge. Recommendations include further exploration of open research problems and bibliometric studies using other research databases given the research bias towards Scopus-indexed English publications.",Document_42,Technical aspects or methods of AI or machine learning,0.1598544716835022,Other Categories
On the role of ontology-based RegTech for managing risk and compliance reporting in the age of regulation,"T. Butler, R. Brooks","This paper addresses important questions such as: what challenges are presented by new regulation to banks’ infrastructure, risk management and profitability, and how can these challenges be best addressed? It also examines the potential impact FinTech has on the riskiness of banks and proposes RegTech as the solution. Following a brief overview of the impact and costs of regulation since the financial crisis, the paper introduces RegTech in the context of challenges facing financial institutions and the limitations of governance, risk and compliance (GRC) systems. This paper’s main contribution is in its delineation of a regulatory compliance and risk ontology, the technologies that underpin it and the related objective-risk-control (ORC) model. The paper argues that these provide a platform on which RegTech can perform effective risk management and compliance reporting in a global post-crisis regulatory environment.",2018,2018,,Journal of Risk Management in Financial Institutions,Selector (div.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.69554/lxst2119,10.69554/lxst2119,https://doi.org/10.69554/lxst2119,14,"This paper addresses important questions such as: what challenges are presented by new regulation to banks’ infrastructure, risk management and profitability, and how can these challenges be best addressed? It also examines the potential impact FinTech has on the riskiness of banks and proposes RegTech as the solution. Following a brief overview of the impact and costs of regulation since the financial crisis, the paper introduces RegTech in the context of challenges facing financial institutions and the limitations of governance, risk and compliance (GRC) systems. This paper’s main contribution is in its delineation of a regulatory compliance and risk ontology, the technologies that underpin it and the related objective-risk-control (ORC) model. The paper argues that these provide a platform on which RegTech can perform effective risk management and compliance reporting in a global post-crisis regulatory environment.",Document_43,General discussion of financial or regulatory topics (non-AI focus),0.1743551790714264,Other Categories
Text and Context: Language Analytics in Finance,Sanjiv Ranjan Das,"This monograph surveys the technology and empirics of text analytics in finance. I present various tools of information extraction and basic text analytics. I survey a range of techniques of classification and predictive analytics, and metrics  used to assess the performance of text analytics algorithms. I then review the literature on text mining and predictive 
analytics in finance, and its connection to networks, covering a wide range of text sources such as blogs, news, web posts, corporate filings, etc. I end with textual content presenting forecasts and predictions about future directions.",2014,2014,11.0,-,Success (Heading+Sibling) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1561/0500000045,10.1561/0500000045,https://doi.org/10.1561/0500000045,90,"This monograph surveys the technology and empirics of text analytics in finance. I present various tools of information extraction and basic text analytics. I survey a range of techniques of classification and predictive analytics, and metrics  used to assess the performance of text analytics algorithms. I then review the literature on text mining and predictive 
analytics in finance, and its connection to networks, covering a wide range of text sources such as blogs, news, web posts, corporate filings, etc. I end with textual content presenting forecasts and predictions about future directions.",Document_44,General discussion of financial or regulatory topics (non-AI focus),0.10875331610441208,Other Categories
Understanding RegTech for Digital Regulatory Compliance,"T. Butler, Leona O'Brien","This chapter explores the promise and potential of Regulatory Technologies (RegTech), a new and vital dimension to FinTechFinTech. It draws on the findings and outcomes of a five-year research programme to highlight the role that RegTech can play in making regulatory complianceCompliance more efficient and effective. The chapter presents research on the Bank of England/Financial Conduct Authority (FCA) RegTech Sprint initiative, whose objective was to demonstrate how straight-through processing of regulations and regulatory complianceCompliance reporting using semantically enabled applications can be made possible by RegTech. The chapter notes that the full benefits of RegTech will only materialise if the pitfalls of a fragmented Tower of Babel approach are avoided. Semantic standards, we argue, are the key to all this.",2018,2019,4.0,Disrupting Finance,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML) - Short, Score: 0.41) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-030-02330-0_6,10.1007/978-3-030-02330-0_6,https://doi.org/10.1007/978-3-030-02330-0_6,55,"This chapter explores the promise and potential of Regulatory Technologies (RegTech), a new and vital dimension to FinTechFinTech. It draws on the findings and outcomes of a five-year research programme to highlight the role that RegTech can play in making regulatory complianceCompliance more efficient and effective. The chapter presents research on the Bank of England/Financial Conduct Authority (FCA) RegTech Sprint initiative, whose objective was to demonstrate how straight-through processing of regulations and regulatory complianceCompliance reporting using semantically enabled applications can be made possible by RegTech. The chapter notes that the full benefits of RegTech will only materialise if the pitfalls of a fragmented Tower of Babel approach are avoided. Semantic standards, we argue, are the key to all this.",Document_45,General discussion of financial or regulatory topics (non-AI focus),0.1872178167104721,Other Categories
In Machines We Trust: Are Robo-Advisers More Trustworthy Than Human Financial Advisers?,Hui Chia,"This article examines the use of artificial intelligence (AI) and deep learning, specifically, to create financial robo-advisers. These machines have the potential to be perfectly honest fiduciaries, acting in their client’s best interests without conflicting self-interest or greed, unlike their human counterparts. However, the application of AI technology to create financial robo-advisers is not without risk. This article will focus on the unique risks posed by deep learning technology. One of the main fears regarding deep learning is that it is a “black box”, its decision-making process is opaque and not open to scrutiny even by the people who developed it. This poses a significant challenge to financial regulators, whom would not be able to examine the underlying rationale and rules of the robo-adviser to determine its safety for public use. The rise of deep learning has been met with calls for ‘explainability’ of how deep learning agents make their decisions. This paper argues that greater explainability can be achieved by describing the ‘personality’ of deep learning robo-advisers, and further proposes a framework for describing the parameters of the deep learning model using concepts that can be readily understood by people without technical expertise. This regards whether the robo-adviser is ‘greedy’, ‘selfish’ or ‘prudent’. Greater understanding will enable regulators and consumers to better judge the safety and suitability of deep learning financial robo-advisers.",2019,2019,9.0,"Law, Technology and Humans","Success (Retry Selector (div[class*=""abstract""]) after Retry) / Date (JSON-LD) (URL Source: DOI Link)",https://doi.org/10.5204/lthj.v1i0.1261,10.5204/lthj.v1i0.1261,https://doi.org/10.5204/lthj.v1i0.1261,7,"This article examines the use of artificial intelligence (AI) and deep learning, specifically, to create financial robo-advisers. These machines have the potential to be perfectly honest fiduciaries, acting in their client’s best interests without conflicting self-interest or greed, unlike their human counterparts. However, the application of AI technology to create financial robo-advisers is not without risk. This article will focus on the unique risks posed by deep learning technology. One of the main fears regarding deep learning is that it is a “black box”, its decision-making process is opaque and not open to scrutiny even by the people who developed it. This poses a significant challenge to financial regulators, whom would not be able to examine the underlying rationale and rules of the robo-adviser to determine its safety for public use. The rise of deep learning has been met with calls for ‘explainability’ of how deep learning agents make their decisions. This paper argues that greater explainability can be achieved by describing the ‘personality’ of deep learning robo-advisers, and further proposes a framework for describing the parameters of the deep learning model using concepts that can be readily understood by people without technical expertise. This regards whether the robo-adviser is ‘greedy’, ‘selfish’ or ‘prudent’. Greater understanding will enable regulators and consumers to better judge the safety and suitability of deep learning financial robo-advisers.",Document_46,Transparency is a challenge for AI adoption in financial services,0.1895340085029602,Explainability and Transparency Barriers
Three Challenges to Secure AI Systems in the Context of AI Regulations,"Ronan Hamon, Henrik Junklewitz, Josep Soler Garrido, Ignacio Sanchez","This article examines the interplay between artificial intelligence (AI) and cybersecurity in light of future regulatory requirements on the security of AI systems, specifically focusing on the robustness of high-risk AI systems against cyberattacks in the context of the European Union’s AI Act. The paper identifies and analyses three challenges to achieve compliance of AI systems with the cybersecurity requirement: accounting for the diversity and the complexity of AI technologies, assessing AI-specific risks, and developing secure-by-design AI systems. The contribution of the article consists in providing an overview of AI cybersecurity practices and identifying gaps in current approaches to security conformity assessment for AI systems. Our analysis highlights the unique vulnerabilities present in AI systems and the absence of established cybersecurity practices tailored to these systems, and emphasises the need for continuous alignment between legal requirements and technological capabilities, acknowledging the necessity for further research and development to address the challenges. It concludes that comprehensive cybersecurity practices must evolve to accommodate the unique aspects of AI, with a collaborative effort from various sectors to ensure effective implementation and standardisation.",2024,2024,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2024.3391021,10.1109/ACCESS.2024.3391021,https://doi.org/10.1109/ACCESS.2024.3391021,1,"This article examines the interplay between artificial intelligence (AI) and cybersecurity in light of future regulatory requirements on the security of AI systems, specifically focusing on the robustness of high-risk AI systems against cyberattacks in the context of the European Union’s AI Act. The paper identifies and analyses three challenges to achieve compliance of AI systems with the cybersecurity requirement: accounting for the diversity and the complexity of AI technologies, assessing AI-specific risks, and developing secure-by-design AI systems. The contribution of the article consists in providing an overview of AI cybersecurity practices and identifying gaps in current approaches to security conformity assessment for AI systems. Our analysis highlights the unique vulnerabilities present in AI systems and the absence of established cybersecurity practices tailored to these systems, and emphasises the need for continuous alignment between legal requirements and technological capabilities, acknowledging the necessity for further research and development to address the challenges. It concludes that comprehensive cybersecurity practices must evolve to accommodate the unique aspects of AI, with a collaborative effort from various sectors to ensure effective implementation and standardisation.",Document_47,Collaborating with regulators to create AI compliance frameworks,0.11633830517530441,Regulatory Engagement and Proactive Compliance Strategies
Privacy-preserving Neural Representations of Text,"Maximin Coavoux, Shashi Narayan, Shay B. Cohen","This article deals with adversarial attacks towards deep learning systems for Natural Language Processing (NLP), in the context of privacy protection. We study a specific type of attack: an attacker eavesdrops on the hidden representations of a neural text classifier and tries to recover information about the input text. Such scenario may arise in situations when the computation of a neural network is shared across multiple devices, e.g. some hidden representation is computed by a user’s device and sent to a cloud-based model. We measure the privacy of a hidden representation by the ability of an attacker to predict accurately specific private information from it and characterize the tradeoff between the privacy and the utility of neural representations. Finally, we propose several defense methods based on modified training objectives and show that they improve the privacy of neural representations.",2018,2018,4.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/D18-1001,10.18653/v1/D18-1001,https://doi.org/10.18653/v1/D18-1001,109,"This article deals with adversarial attacks towards deep learning systems for Natural Language Processing (NLP), in the context of privacy protection. We study a specific type of attack: an attacker eavesdrops on the hidden representations of a neural text classifier and tries to recover information about the input text. Such scenario may arise in situations when the computation of a neural network is shared across multiple devices, e.g. some hidden representation is computed by a user’s device and sent to a cloud-based model. We measure the privacy of a hidden representation by the ability of an attacker to predict accurately specific private information from it and characterize the tradeoff between the privacy and the utility of neural representations. Finally, we propose several defense methods based on modified training objectives and show that they improve the privacy of neural representations.",Document_48,Technical aspects or methods of AI or machine learning,0.12277825176715851,Other Categories
Exploring the opportunities and challenges of NLP models in higher education: is Chat GPT a blessing or a curse?,K. Fuchs,"The world has changed a lot in the past few decades, and it continues to change. Chat GPT has created tremendous speculation among stakeholders in academia, not the least researchers and teaching staff (Biswas, 2023). Chat GPT is a Natural Language Processing (NLP) model developed by OpenAI that uses a large dataset to generate text responses to student queries, feedback, and prompts (Gilson et al., 2023). It can simulate conversations with students to provide feedback, answer questions, and provide support (OpenAI, 2023). It has the potential to aid students in staying engaged with the course material and feeling more connected to their learning experience. However, the rapid implementation of these NLP models, like Chat GPT by OpenAI or Bard by Google, also poses a range of challenges. In this article, I will discuss a range of challenges and opportunities for higher education, as well as conclude with implications that (hopefully) expose gaps in the literature, stimulate research ideas, and finally, advance the discussion about NLP in higher education.Natural Language Processing (NLP) models have been in development since the 1950s, (Jones, 1994) but it was not until the past decade that they gained significant attention and advancement, particularly with the development of deep learning techniques and large datasets (Kang et al., 2020). NLP models are rapidly becoming relevant to higher education, as they have the potential to transform teaching and learning by enabling personalized learning, on-demand support, and other innovative approaches (Odden et al., 2021). In higher education, NLP models have significant relevance for supporting student learning in multiple ways. These models can be employed to analyze and process vast amounts of textual data, such as academic papers, textbooks, and other course materials, to provide students with personalized recommendations for further study based on their learning requirements and preferences. In addition, NLP models can be used to develop chatbots and virtual assistants that offer on-demand support and guidance to students, enabling them to access help and information as and when they need it.Chat GPT by OpenAI or Bard (Google's response to Chat GPT) are examples of an NLP model that has the potential to transform higher education. These generative language models, i.e. Chat GPT or Google Bard, have the ability to generate human-like responses to open-ended prompts, such as questions, statements, or prompts related to academic material. The recent release (early 2023) of Chat GPT and Google Bard made it particularly relevant for supporting student learning in a range of contexts, such as language learning, writing, research, and general academic inquiry. Therefore, the use of NLP models in higher education expands beyond the aforementioned examples with new applications being developed to aid students in their academic pursuits.Personalized learning is an approach to education that aims to tailor instruction to the unique needs, interests, and abilities of individual learners. NLP models can facilitate personalized learning by analyzing students' language patterns, feedback, and performance to create customized learning plans that include content, activities, and assessments that are tailored to the individual student's needs. Personalized learning can be particularly effective in improving student outcomes. Research has shown that personalized learning can improve academic achievement, engagement, and self-efficacy (Wu, 2017). By providing students with content that is relevant to their interests and abilities, they are more likely to engage with the material and develop a deeper understanding of the subject matter. NLP models can provide students with personalized learning experiences by generating content that is specifically tailored to their individual learning needs.For example, when a student submits a response to a question, the model can analyze the response and provide feedback that is customized to the student's understanding of the material. This feedback can help the student identify areas where they may need additional support or where they have demonstrated mastery of the material. Furthermore, the processing models can generate customized learning plans for individual students based on their performance and feedback. These plans may include additional practice activities, assessments, or reading materials that are designed to support the student's learning goals. By providing students with these customized learning plans, these models have the potential to help students to develop self-directed learning skills and take ownership of their learning process.Moreover, on-demand support is a crucial aspect of effective learning. Particularly for students who are working independently or in online learning environments. The NLP models can provide on-demand support by offering real-time assistance to students who are struggling with a particular concept or problem. The benefits of on-demand support are numerous. It can help students to overcome learning obstacles and enhance their understanding of the material. In addition, on-demand support can help to build students' confidence and sense of self-efficacy by providing them with the resources and assistance they need to succeed. These models can offer on-demand support by generating responses to student queries and feedback in real time.When a student submits a question or response, the model can analyze the input and generate a response that is tailored to the student's needs.This can be particularly helpful for students who are working independently or in online learning environments where they may not have immediate access to a teacher or tutor. Furthermore, they can offer support to students at any time and from any location. Students can access the system from their mobile devices, laptops, or desktop computers, enabling them to receive assistance whenever they need it. This flexibility can help to accommodate students' busy schedules and provide them with the support they need to succeed. Additionally, NLP models can provide students with on-demand support in a variety of formats, including textbased chat, audio, or video. This can help to cater to students' individual learning preferences and provide them with the type of support that is most effective for them.Although there is a wide range of opportunities for NLP models, like Chat GPT or Google Bard, there are also several challenges (or ethical concerns) that should be addressed. The first challenge is the issue of accuracy. The accuracy of the system depends heavily on the quality, diversity, and complexity of the training data, as well as the quality of the input data provided by students. In previous research, Fuchs (2022) alluded to the importance of competence development in higher education and discusses the need for students to acquire higher-order thinking skills (e.g. critical thinking or problem-solving). The system may struggle to understand the nuances and complexities of human language, leading to misunderstandings and incorrect responses. Moreover, a potential source of inaccuracies is related to the quality and diversity of the training data used to develop the NLP model.If the training data is not diverse enough or is of low quality, the system may learn incorrect or incomplete patterns, leading to inaccurate responses. The accuracy of NP models may be impacted by the complexity of the input data, particularly when dealing with idiomatic expressions or other forms of linguistic subtlety. Additionally, the accuracy of the model may be impacted by the quality of the input data provided by students. If students do not provide clear, concise, and relevant input, the system may struggle to generate an accurate response. This is particularly challenging in cases where students are not sure what information they need or are not able to articulate their queries in a way that is easily understandable by the system.Another significant challenge that students may face when using NLP models in higher education is the potential risk of over-reliance on technology, which could potentially undermine the development of important critical thinking skills. While these models can offer valuable support and personalized learning experiences, students must be careful not to rely too heavily on the system at the expense of developing their own analytical and critical thinking skills. Over-reliance on systems such as Chat GPT or Google Bard could lead to students becoming passive learners who simply accept the responses generated by the system without questioning or critically evaluating the accuracy or relevance of the information provided. This could potentially lead to a failure to develop important critical thinking skills, such as the ability to evaluate the quality and reliability of sources, make informed judgments, and generate creative and original ideas.Moreover, over-reliance could potentially reinforce existing biases and perpetuate inequalities in education. For example, if the system is trained on biased or incomplete data, it may generate responses that reflect these biases, leading to a reinforcement of existing inequalities and a failure to challenge and disrupt discriminatory practices in higher education. To address these challenges, institutions need to provide clear guidance to students on how to use NLP models as a tool to support their learning, rather than a replacement for critical thinking and independent learning. Institutions must also ensure that students are provided with opportunities to engage in active learning experiences that encourage critical thinking, problem-solving, and independent inquiry.In this article, I discussed the challenges and opportunities regarding natural language processing (NLP) models like Chat GPT and Google Bard and how they will transform teaching and learning in higher education. The article highlights the potential benefits of using NLP models for personalized learning and on-demand support, such as providing customized learning plans, generating feedback and support, and offering resources to students whenever and wherever they need them. However, the article also acknowledges the challenges that NLP models may bring, including the potential loss of human interaction, bias, and ethical implications. To address the challenges highlighted, universities should ensure that NLP models are not used as a replacement for human interaction, but as a supplement. Institutions should also develop guidelines and ethical frameworks for the use of NLP models, ensuring that student privacy is protected and that bias is minimized.Additionally, universities should involve students in the development and implementation of NLP models to address their unique needs and preferences. Finally, universities should invest in training their faculty to use and adapt to the technology, as well as providing resources and support for students to use the models effectively. In summary, universities should consider the opportunities and challenges of using NLP models in higher education, while ensuring that they are used ethically and with a focus on enhancing student learning rather than replacing human interaction. Overall, NLP models are a powerful tool for improving the quality of education by providing students with personalized learning experiences and automating administrative tasks, while institutions need to tackle the previously mentioned challenges to safeguard high-quality education for their students.",2023,2023,5.0,Frontiers in Education,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.12) (URL Source: DOI Link)",https://doi.org/10.3389/feduc.2023.1166682,10.3389/feduc.2023.1166682,https://doi.org/10.3389/feduc.2023.1166682,156,"The world has changed a lot in the past few decades, and it continues to change. Chat GPT has created tremendous speculation among stakeholders in academia, not the least researchers and teaching staff (Biswas, 2023). Chat GPT is a Natural Language Processing (NLP) model developed by OpenAI that uses a large dataset to generate text responses to student queries, feedback, and prompts (Gilson et al., 2023). It can simulate conversations with students to provide feedback, answer questions, and provide support (OpenAI, 2023). It has the potential to aid students in staying engaged with the course material and feeling more connected to their learning experience. However, the rapid implementation of these NLP models, like Chat GPT by OpenAI or Bard by Google, also poses a range of challenges. In this article, I will discuss a range of challenges and opportunities for higher education, as well as conclude with implications that (hopefully) expose gaps in the literature, stimulate research ideas, and finally, advance the discussion about NLP in higher education.Natural Language Processing (NLP) models have been in development since the 1950s, (Jones, 1994) but it was not until the past decade that they gained significant attention and advancement, particularly with the development of deep learning techniques and large datasets (Kang et al., 2020). NLP models are rapidly becoming relevant to higher education, as they have the potential to transform teaching and learning by enabling personalized learning, on-demand support, and other innovative approaches (Odden et al., 2021). In higher education, NLP models have significant relevance for supporting student learning in multiple ways. These models can be employed to analyze and process vast amounts of textual data, such as academic papers, textbooks, and other course materials, to provide students with personalized recommendations for further study based on their learning requirements and preferences. In addition, NLP models can be used to develop chatbots and virtual assistants that offer on-demand support and guidance to students, enabling them to access help and information as and when they need it.Chat GPT by OpenAI or Bard (Google's response to Chat GPT) are examples of an NLP model that has the potential to transform higher education. These generative language models, i.e. Chat GPT or Google Bard, have the ability to generate human-like responses to open-ended prompts, such as questions, statements, or prompts related to academic material. The recent release (early 2023) of Chat GPT and Google Bard made it particularly relevant for supporting student learning in a range of contexts, such as language learning, writing, research, and general academic inquiry. Therefore, the use of NLP models in higher education expands beyond the aforementioned examples with new applications being developed to aid students in their academic pursuits.Personalized learning is an approach to education that aims to tailor instruction to the unique needs, interests, and abilities of individual learners. NLP models can facilitate personalized learning by analyzing students' language patterns, feedback, and performance to create customized learning plans that include content, activities, and assessments that are tailored to the individual student's needs. Personalized learning can be particularly effective in improving student outcomes. Research has shown that personalized learning can improve academic achievement, engagement, and self-efficacy (Wu, 2017). By providing students with content that is relevant to their interests and abilities, they are more likely to engage with the material and develop a deeper understanding of the subject matter. NLP models can provide students with personalized learning experiences by generating content that is specifically tailored to their individual learning needs.For example, when a student submits a response to a question, the model can analyze the response and provide feedback that is customized to the student's understanding of the material. This feedback can help the student identify areas where they may need additional support or where they have demonstrated mastery of the material. Furthermore, the processing models can generate customized learning plans for individual students based on their performance and feedback. These plans may include additional practice activities, assessments, or reading materials that are designed to support the student's learning goals. By providing students with these customized learning plans, these models have the potential to help students to develop self-directed learning skills and take ownership of their learning process.Moreover, on-demand support is a crucial aspect of effective learning. Particularly for students who are working independently or in online learning environments. The NLP models can provide on-demand support by offering real-time assistance to students who are struggling with a particular concept or problem. The benefits of on-demand support are numerous. It can help students to overcome learning obstacles and enhance their understanding of the material. In addition, on-demand support can help to build students' confidence and sense of self-efficacy by providing them with the resources and assistance they need to succeed. These models can offer on-demand support by generating responses to student queries and feedback in real time.When a student submits a question or response, the model can analyze the input and generate a response that is tailored to the student's needs.This can be particularly helpful for students who are working independently or in online learning environments where they may not have immediate access to a teacher or tutor. Furthermore, they can offer support to students at any time and from any location. Students can access the system from their mobile devices, laptops, or desktop computers, enabling them to receive assistance whenever they need it. This flexibility can help to accommodate students' busy schedules and provide them with the support they need to succeed. Additionally, NLP models can provide students with on-demand support in a variety of formats, including textbased chat, audio, or video. This can help to cater to students' individual learning preferences and provide them with the type of support that is most effective for them.Although there is a wide range of opportunities for NLP models, like Chat GPT or Google Bard, there are also several challenges (or ethical concerns) that should be addressed. The first challenge is the issue of accuracy. The accuracy of the system depends heavily on the quality, diversity, and complexity of the training data, as well as the quality of the input data provided by students. In previous research, Fuchs (2022) alluded to the importance of competence development in higher education and discusses the need for students to acquire higher-order thinking skills (e.g. critical thinking or problem-solving). The system may struggle to understand the nuances and complexities of human language, leading to misunderstandings and incorrect responses. Moreover, a potential source of inaccuracies is related to the quality and diversity of the training data used to develop the NLP model.If the training data is not diverse enough or is of low quality, the system may learn incorrect or incomplete patterns, leading to inaccurate responses. The accuracy of NP models may be impacted by the complexity of the input data, particularly when dealing with idiomatic expressions or other forms of linguistic subtlety. Additionally, the accuracy of the model may be impacted by the quality of the input data provided by students. If students do not provide clear, concise, and relevant input, the system may struggle to generate an accurate response. This is particularly challenging in cases where students are not sure what information they need or are not able to articulate their queries in a way that is easily understandable by the system.Another significant challenge that students may face when using NLP models in higher education is the potential risk of over-reliance on technology, which could potentially undermine the development of important critical thinking skills. While these models can offer valuable support and personalized learning experiences, students must be careful not to rely too heavily on the system at the expense of developing their own analytical and critical thinking skills. Over-reliance on systems such as Chat GPT or Google Bard could lead to students becoming passive learners who simply accept the responses generated by the system without questioning or critically evaluating the accuracy or relevance of the information provided. This could potentially lead to a failure to develop important critical thinking skills, such as the ability to evaluate the quality and reliability of sources, make informed judgments, and generate creative and original ideas.Moreover, over-reliance could potentially reinforce existing biases and perpetuate inequalities in education. For example, if the system is trained on biased or incomplete data, it may generate responses that reflect these biases, leading to a reinforcement of existing inequalities and a failure to challenge and disrupt discriminatory practices in higher education. To address these challenges, institutions need to provide clear guidance to students on how to use NLP models as a tool to support their learning, rather than a replacement for critical thinking and independent learning. Institutions must also ensure that students are provided with opportunities to engage in active learning experiences that encourage critical thinking, problem-solving, and independent inquiry.In this article, I discussed the challenges and opportunities regarding natural language processing (NLP) models like Chat GPT and Google Bard and how they will transform teaching and learning in higher education. The article highlights the potential benefits of using NLP models for personalized learning and on-demand support, such as providing customized learning plans, generating feedback and support, and offering resources to students whenever and wherever they need them. However, the article also acknowledges the challenges that NLP models may bring, including the potential loss of human interaction, bias, and ethical implications. To address the challenges highlighted, universities should ensure that NLP models are not used as a replacement for human interaction, but as a supplement. Institutions should also develop guidelines and ethical frameworks for the use of NLP models, ensuring that student privacy is protected and that bias is minimized.Additionally, universities should involve students in the development and implementation of NLP models to address their unique needs and preferences. Finally, universities should invest in training their faculty to use and adapt to the technology, as well as providing resources and support for students to use the models effectively. In summary, universities should consider the opportunities and challenges of using NLP models in higher education, while ensuring that they are used ethically and with a focus on enhancing student learning rather than replacing human interaction. Overall, NLP models are a powerful tool for improving the quality of education by providing students with personalized learning experiences and automating administrative tasks, while institutions need to tackle the previously mentioned challenges to safeguard high-quality education for their students.",Document_49,Planning for seamless integration of AI into financial systems,0.055609989911317825,Integration and Standardization Strategies
K-LM: Knowledge Augmenting in Language Models Within the Scholarly Domain,"Vivek Kumar (Ph.D), Diego Reforgiato Recupero, Rim Helaoui, Daniele Riboni","The use of superior algorithms and complex architectures in language models have successfully imparted human-like abilities to machines for specific tasks. But two significant constraints, the available training data size and the understanding of domain-specific context, hamper the pre-trained language models from optimal and reliable performance. A potential solution to tackle these limitations is to equip the language models with domain knowledge. While the commonly adopted techniques use Knowledge Graphs Embeddings (KGEs) to inject domain knowledge, we provide a Knowledge Language Model (K-LM) to use the Resource Description Framework (RDF) triples directly, extracted from world knowledge bases. The proposed model works in conjunction with Generative Pretrained Transformer (GPT-2) and Bidirectional Encoder Representations from Transformers (BERT) and uses a well-defined pipeline to select, categorize, and filter the RDF triples. In addition, we introduce heuristic methods to inject domain-specific knowledge in K-LM, leveraging knowledge graphs (KGs). We tested our approaches on the classification task within the scholarly domain using two KGs, and our results show that our proposed language model has significantly outperformed the baselines and BERT for each KG. Our experimental findings also help us conclude the importance of relevance of KG used over the quantity of injected RDF triples. Also, each of our proposed methods for injecting the RDF triples has increased the overall model’s accuracy, demonstrating that K-LM is a potential choice for domain adaptation to solve knowledge-driven problems.",2022,2022,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2022.3201542,10.1109/ACCESS.2022.3201542,https://doi.org/10.1109/ACCESS.2022.3201542,13,"The use of superior algorithms and complex architectures in language models have successfully imparted human-like abilities to machines for specific tasks. But two significant constraints, the available training data size and the understanding of domain-specific context, hamper the pre-trained language models from optimal and reliable performance. A potential solution to tackle these limitations is to equip the language models with domain knowledge. While the commonly adopted techniques use Knowledge Graphs Embeddings (KGEs) to inject domain knowledge, we provide a Knowledge Language Model (K-LM) to use the Resource Description Framework (RDF) triples directly, extracted from world knowledge bases. The proposed model works in conjunction with Generative Pretrained Transformer (GPT-2) and Bidirectional Encoder Representations from Transformers (BERT) and uses a well-defined pipeline to select, categorize, and filter the RDF triples. In addition, we introduce heuristic methods to inject domain-specific knowledge in K-LM, leveraging knowledge graphs (KGs). We tested our approaches on the classification task within the scholarly domain using two KGs, and our results show that our proposed language model has significantly outperformed the baselines and BERT for each KG. Our experimental findings also help us conclude the importance of relevance of KG used over the quantity of injected RDF triples. Also, each of our proposed methods for injecting the RDF triples has increased the overall model’s accuracy, demonstrating that K-LM is a potential choice for domain adaptation to solve knowledge-driven problems.",Document_50,Technical aspects or methods of AI or machine learning,0.12054131925106049,Other Categories
Core techniques of question answering systems over knowledge bases: a survey,"Dennis Diefenbach, V. López, K. Singh, P. Maret","The Semantic Web contains an enormous amount of information in the form of knowledge bases (KB). To make this information available, many question answering (QA) systems over KBs were created in the last years. Building a QA system over KBs is difficult because there are many different challenges to be solved. In order to address these challenges, QA systems generally combine techniques from natural language processing, information retrieval, machine learning and Semantic Web. The aim of this survey is to give an overview of the techniques used in current QA systems over KBs. We present the techniques used by the QA systems which were evaluated on a popular series of benchmarks: Question Answering over Linked Data. Techniques that solve the same task are first grouped together and then described. The advantages and disadvantages are discussed for each technique. This allows a direct comparison of similar techniques. Additionally, we point to techniques that are used over WebQuestions and SimpleQuestions, which are two other popular benchmarks for QA systems.",2017,2018,6.0,Knowledge and Information Systems,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10115-017-1100-y,10.1007/s10115-017-1100-y,https://doi.org/10.1007/s10115-017-1100-y,270,"The Semantic Web contains an enormous amount of information in the form of knowledge bases (KB). To make this information available, many question answering (QA) systems over KBs were created in the last years. Building a QA system over KBs is difficult because there are many different challenges to be solved. In order to address these challenges, QA systems generally combine techniques from natural language processing, information retrieval, machine learning and Semantic Web. The aim of this survey is to give an overview of the techniques used in current QA systems over KBs. We present the techniques used by the QA systems which were evaluated on a popular series of benchmarks: Question Answering over Linked Data. Techniques that solve the same task are first grouped together and then described. The advantages and disadvantages are discussed for each technique. This allows a direct comparison of similar techniques. Additionally, we point to techniques that are used over WebQuestions and SimpleQuestions, which are two other popular benchmarks for QA systems.",Document_51,Technical aspects or methods of AI or machine learning,0.14311881363391876,Other Categories
Semantics of the Black-Box: Can Knowledge Graphs Help Make Deep Learning Systems More Interpretable and Explainable?,"Manas Gaur, Keyur Faldu, A. Sheth, A. Sheth","The recent series of innovations in deep learning (DL) have shown enormous potential to impact individuals and society, both positively and negatively. DL models utilizing massive computing power and enormous datasets have significantly outperformed prior historical benchmarks on increasingly difficult, well-defined research tasks across technology domains such as computer vision, natural language processing, and human-computer interactions. However, DL's black-box nature and over-reliance on massive amounts of data condensed into labels and dense representations pose challenges for interpretability and explainability. Furthermore, DLs have not proven their ability to effectively utilize relevant domain knowledge critical to human understanding. This aspect was missing in early data-focused approaches and necessitated knowledge-infused learning (K-iL) to incorporate computational knowledge. This article demonstrates how knowledge, provided as a knowledge graph, is incorporated into DL using K-iL. Through examples from natural language processing applications in healthcare and education, we discuss the utility of K-iL towards interpretability and explainability.",2020,2020,,IEEE Internet Computing,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/MIC.2020.3031769,10.1109/MIC.2020.3031769,https://doi.org/10.1109/MIC.2020.3031769,103,"The recent series of innovations in deep learning (DL) have shown enormous potential to impact individuals and society, both positively and negatively. DL models utilizing massive computing power and enormous datasets have significantly outperformed prior historical benchmarks on increasingly difficult, well-defined research tasks across technology domains such as computer vision, natural language processing, and human-computer interactions. However, DL's black-box nature and over-reliance on massive amounts of data condensed into labels and dense representations pose challenges for interpretability and explainability. Furthermore, DLs have not proven their ability to effectively utilize relevant domain knowledge critical to human understanding. This aspect was missing in early data-focused approaches and necessitated knowledge-infused learning (K-iL) to incorporate computational knowledge. This article demonstrates how knowledge, provided as a knowledge graph, is incorporated into DL using K-iL. Through examples from natural language processing applications in healthcare and education, we discuss the utility of K-iL towards interpretability and explainability.",Document_52,Technical aspects or methods of AI or machine learning,0.18073977530002594,Other Categories
An empirical study of automated privacy requirements classification in issue reports,"Pattaraporn Sangaroonsilp, Morakot Choetkiertikul, K. Dam, Aditya K. Ghose","The recent advent of data protection laws and regulations has emerged to protect privacy and personal information of individuals. As the cases of privacy breaches and vulnerabilities are rapidly increasing, people are aware and more concerned about their privacy. These bring a significant attention to software development teams to address privacy concerns in developing software applications. As today’s software development adopts an agile, issue-driven approach, issues in an issue tracking system become a centralised pool that gathers new requirements, requests for modification and all the tasks of the software project. Hence, establishing an alignment between those issues and privacy requirements is an important step in developing privacy-aware software systems. This alignment also facilitates privacy compliance checking which may be required as an underlying part of regulations for organisations. However, manually establishing those alignments is labour intensive and time consuming. In this paper, we explore a wide range of machine learning and natural language processing techniques which can automatically classify privacy requirements in issue reports. We employ six popular techniques namely Bag-of-Words (BoW), N-gram Inverse Document Frequency (N-gram IDF), Term Frequency-Inverse Document Frequency (TF-IDF), Word2Vec, Convolutional Neural Network (CNN) and Bidirectional Encoder Representations from Transformers (BERT) to perform the classification on privacy-related issue reports in Google Chrome and Moodle projects. The evaluation showed that BoW, N-gram IDF, TF-IDF and Word2Vec techniques are suitable for classifying privacy requirements in those issue reports. In addition, N-gram IDF is the best performer in both projects.",2023,2023,11.0,International Conference on Automated Software Engineering,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10515-023-00387-9,10.1007/s10515-023-00387-9,https://doi.org/10.1007/s10515-023-00387-9,3,"The recent advent of data protection laws and regulations has emerged to protect privacy and personal information of individuals. As the cases of privacy breaches and vulnerabilities are rapidly increasing, people are aware and more concerned about their privacy. These bring a significant attention to software development teams to address privacy concerns in developing software applications. As today’s software development adopts an agile, issue-driven approach, issues in an issue tracking system become a centralised pool that gathers new requirements, requests for modification and all the tasks of the software project. Hence, establishing an alignment between those issues and privacy requirements is an important step in developing privacy-aware software systems. This alignment also facilitates privacy compliance checking which may be required as an underlying part of regulations for organisations. However, manually establishing those alignments is labour intensive and time consuming. In this paper, we explore a wide range of machine learning and natural language processing techniques which can automatically classify privacy requirements in issue reports. We employ six popular techniques namely Bag-of-Words (BoW), N-gram Inverse Document Frequency (N-gram IDF), Term Frequency-Inverse Document Frequency (TF-IDF), Word2Vec, Convolutional Neural Network (CNN) and Bidirectional Encoder Representations from Transformers (BERT) to perform the classification on privacy-related issue reports in Google Chrome and Moodle projects. The evaluation showed that BoW, N-gram IDF, TF-IDF and Word2Vec techniques are suitable for classifying privacy requirements in those issue reports. In addition, N-gram IDF is the best performer in both projects.",Document_53,Technical aspects or methods of AI or machine learning,0.37117066979408264,Other Categories
KDPII: A New Korean Dialogic Dataset for the Deidentification of Personally Identifiable Information,"Li Fei, Yejee Kang, Seoyoon Park, Yeonji Jang, Jongkyu Lee, Hansaem Kim","The rapid growth of social media in the era of big data and artificial intelligence has raised significant safety concerns related to the communication of sensitive personal information. In modern society, awareness of the importance of preserving privacy is growing, so there is a rising advocacy for adopting language modeling technology to mitigate the risk of personal information leakage and to deidentify sensitive information depending on the situation. Thus far, several theoretical analyses of privacy protection in Korea have been conducted. However, the technical development of language model training resources for Korean has been slower than those of widely spoken languages such as English and Chinese. To address this problem, we developed a comprehensive and organized framework for classifying Korean personally identifiable information (PII) by investigating pertinent examples, such as “Text Anonymization Benchmark” and “Network Intrusion Detection Dataset,” from within and outside Korea. Subsequently, we created a new Korean dataset for PII deidentification, KDPII, which consists of many conversational texts incorporating plentiful Korean PII. Based on this, we examined the Korean PII processing performances of many representative language models that are available on the market. Finally, we found that although the performance of language models in identifying PII varied by model size, model architecture, and training source, most of them were significantly better at recognizing universal PII than language-specific PII, which indicates a prospective direction of expanding training data for implementing Korean-specific PII deidentification in the future.",2024,2024,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2024.3461804,10.1109/ACCESS.2024.3461804,https://doi.org/10.1109/ACCESS.2024.3461804,1,"The rapid growth of social media in the era of big data and artificial intelligence has raised significant safety concerns related to the communication of sensitive personal information. In modern society, awareness of the importance of preserving privacy is growing, so there is a rising advocacy for adopting language modeling technology to mitigate the risk of personal information leakage and to deidentify sensitive information depending on the situation. Thus far, several theoretical analyses of privacy protection in Korea have been conducted. However, the technical development of language model training resources for Korean has been slower than those of widely spoken languages such as English and Chinese. To address this problem, we developed a comprehensive and organized framework for classifying Korean personally identifiable information (PII) by investigating pertinent examples, such as “Text Anonymization Benchmark” and “Network Intrusion Detection Dataset,” from within and outside Korea. Subsequently, we created a new Korean dataset for PII deidentification, KDPII, which consists of many conversational texts incorporating plentiful Korean PII. Based on this, we examined the Korean PII processing performances of many representative language models that are available on the market. Finally, we found that although the performance of language models in identifying PII varied by model size, model architecture, and training source, most of them were significantly better at recognizing universal PII than language-specific PII, which indicates a prospective direction of expanding training data for implementing Korean-specific PII deidentification in the future.",Document_54,Demonstrating the value of AI for compliance and risk management,0.10934943705797195,Business Case and Value Demonstration Strategies
SecureBoost: A Lossless Federated Learning Framework,"Kewei Cheng, Tao Fan, Yilun Jin, Yang Liu, Tianjian Chen, Qiang Yang","The protection of user privacy is an important concern in machine learning, as evidenced by the rolling out of the General Data Protection Regulation (GDPR) in the European Union (EU) in May 2018. The GDPR is designed to give users more control over their personal data, which motivates us to explore machine learning frameworks for data sharing that do not violate user privacy. To meet this goal, in this article, we propose a novel lossless privacy-preserving tree-boosting system known as SecureBoost in the setting of federated learning. SecureBoost first conducts entity alignment under a privacy-preserving protocol and then constructs boosting trees across multiple parties with a carefully designed encryption strategy. This federated learning system allows the learning process to be jointly conducted over multiple parties with common user samples but different feature sets, which corresponds to a vertically partitioned dataset. An advantage of SecureBoost is that it provides the same level of accuracy as the non -privacy-preserving approach while at the same time, reveals no information of each private data provider. We show that the SecureBoost framework is as accurate as other nonfederated gradient tree-boosting algorithms that require centralized data, and thus, it is highly scalable and practical for industrial applications such as credit risk analysis. To this end, we discuss information leakage during the protocol execution and propose ways to provably reduce it.",2019,2019,,IEEE Intelligent Systems,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/MIS.2021.3082561,10.1109/MIS.2021.3082561,https://doi.org/10.1109/MIS.2021.3082561,541,"The protection of user privacy is an important concern in machine learning, as evidenced by the rolling out of the General Data Protection Regulation (GDPR) in the European Union (EU) in May 2018. The GDPR is designed to give users more control over their personal data, which motivates us to explore machine learning frameworks for data sharing that do not violate user privacy. To meet this goal, in this article, we propose a novel lossless privacy-preserving tree-boosting system known as SecureBoost in the setting of federated learning. SecureBoost first conducts entity alignment under a privacy-preserving protocol and then constructs boosting trees across multiple parties with a carefully designed encryption strategy. This federated learning system allows the learning process to be jointly conducted over multiple parties with common user samples but different feature sets, which corresponds to a vertically partitioned dataset. An advantage of SecureBoost is that it provides the same level of accuracy as the non -privacy-preserving approach while at the same time, reveals no information of each private data provider. We show that the SecureBoost framework is as accurate as other nonfederated gradient tree-boosting algorithms that require centralized data, and thus, it is highly scalable and practical for industrial applications such as credit risk analysis. To this end, we discuss information leakage during the protocol execution and propose ways to provably reduce it.",Document_55,Technical aspects or methods of AI or machine learning,0.1137697845697403,Other Categories
Conformity Assessments and Post-market Monitoring: A Guide to the Role of Auditing in the Proposed European AI Regulation,"Jakob Mökander, M. Axente, F. Casolari, L. Floridi","The proposed European Artificial Intelligence Act (AIA) is the first attempt to elaborate a general legal framework for AI carried out by any major global economy. As such, the AIA is likely to become a point of reference in the larger discourse on how AI systems can (and should) be regulated. In this article, we describe and discuss the two primary enforcement mechanisms proposed in the AIA: the conformity assessments that providers of high-risk AI systems are expected to conduct, and the post-market monitoring plans that providers must establish to document the performance of high-risk AI systems throughout their lifetimes. We argue that the AIA can be interpreted as a proposal to establish a Europe-wide ecosystem for conducting AI auditing, albeit in other words. Our analysis offers two main contributions. First, by describing the enforcement mechanisms included in the AIA in terminology borrowed from existing literature on AI auditing, we help providers of AI systems understand how they can prove adherence to the requirements set out in the AIA in practice. Second, by examining the AIA from an auditing perspective, we seek to provide transferable lessons from previous research about how to refine further the regulatory approach outlined in the AIA. We conclude by highlighting seven aspects of the AIA where amendments (or simply clarifications) would be helpful. These include, above all, the need to translate vague concepts into verifiable criteria and to strengthen the institutional safeguards concerning conformity assessments based on internal checks.",2021,2022,6.0,Minds and Machines,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s11023-021-09577-4,10.1007/s11023-021-09577-4,https://doi.org/10.1007/s11023-021-09577-4,69,"The proposed European Artificial Intelligence Act (AIA) is the first attempt to elaborate a general legal framework for AI carried out by any major global economy. As such, the AIA is likely to become a point of reference in the larger discourse on how AI systems can (and should) be regulated. In this article, we describe and discuss the two primary enforcement mechanisms proposed in the AIA: the conformity assessments that providers of high-risk AI systems are expected to conduct, and the post-market monitoring plans that providers must establish to document the performance of high-risk AI systems throughout their lifetimes. We argue that the AIA can be interpreted as a proposal to establish a Europe-wide ecosystem for conducting AI auditing, albeit in other words. Our analysis offers two main contributions. First, by describing the enforcement mechanisms included in the AIA in terminology borrowed from existing literature on AI auditing, we help providers of AI systems understand how they can prove adherence to the requirements set out in the AIA in practice. Second, by examining the AIA from an auditing perspective, we seek to provide transferable lessons from previous research about how to refine further the regulatory approach outlined in the AIA. We conclude by highlighting seven aspects of the AIA where amendments (or simply clarifications) would be helpful. These include, above all, the need to translate vague concepts into verifiable criteria and to strengthen the institutional safeguards concerning conformity assessments based on internal checks.",Document_56,Demonstrating the value of AI for compliance and risk management,0.09061739593744278,Business Case and Value Demonstration Strategies
Language Processing Modelling Notation - Orchestration of NLP Microservices,T. Walkowiak,The paper presents Language Processing Modelling Notation (LPMN). It is a formal language used to orchestrate a set of NLP microservices. The LPMN allows modeling and running complex workflows of language and machine learning tools. The scalability of the solution was achieved by a usage of message-oriented middleware. LPMN is used for developing text mining application with web-based interface and performing research experiments that requires a usage of NLP and machine learning tools.,2017,2018,4.0,International Conference on Dependability of Computer Systems,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.55) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-319-59415-6_44,10.1007/978-3-319-59415-6_44,https://doi.org/10.1007/978-3-319-59415-6_44,16,The paper presents Language Processing Modelling Notation (LPMN). It is a formal language used to orchestrate a set of NLP microservices. The LPMN allows modeling and running complex workflows of language and machine learning tools. The scalability of the solution was achieved by a usage of message-oriented middleware. LPMN is used for developing text mining application with web-based interface and performing research experiments that requires a usage of NLP and machine learning tools.,Document_57,Technical aspects or methods of AI or machine learning,0.1415117084980011,Other Categories
Integrating Multiple NLP Technologies into an Open-source Platform for Multilingual Media Monitoring,"Ulrich Germann, Renars Liepins, D. Gosko, Guntis Barzdins","The open-source SUMMA Platform is a highly scalable distributed architecture for monitoring a large number of media broadcasts in parallel, with a lag behind actual broadcast time of at most a few minutes. It assembles numerous state-of-the-art NLP technologies into a fully automated media ingestion pipeline that can record live broadcasts, detect and transcribe spoken content, translate from several languages (original text or transcribed speech) into English, recognize Named Entities, detect topics, cluster and summarize documents across language barriers, and extract and store factual claims in these news items. This paper describes the intended use cases and discusses the system design decisions that allowed us to integrate state-of-the-art NLP modules into an effective workflow with comparatively little effort.",2018,2018,7.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/W18-2508,10.18653/v1/W18-2508,https://doi.org/10.18653/v1/W18-2508,4,"The open-source SUMMA Platform is a highly scalable distributed architecture for monitoring a large number of media broadcasts in parallel, with a lag behind actual broadcast time of at most a few minutes. It assembles numerous state-of-the-art NLP technologies into a fully automated media ingestion pipeline that can record live broadcasts, detect and transcribe spoken content, translate from several languages (original text or transcribed speech) into English, recognize Named Entities, detect topics, cluster and summarize documents across language barriers, and extract and store factual claims in these news items. This paper describes the intended use cases and discusses the system design decisions that allowed us to integrate state-of-the-art NLP modules into an effective workflow with comparatively little effort.",Document_58,Technical aspects or methods of AI or machine learning,0.07547999173402786,Other Categories
Using Natural Language Processing to Automatically Detect Self-Admitted Technical Debt,"Everton da S. Maldonado, Emad Shihab, Nikolaos Tsantalis","The metaphor of technical debt was introduced to express the trade off between productivity and quality, i.e., when developers take shortcuts or perform quick hacks. More recently, our work has shown that it is possible to detect technical debt using source code comments (i.e., self-admitted technical debt), and that the most common types of self-admitted technical debt are design and requirement debt. However, all approaches thus far heavily depend on the manual classification of source code comments. In this paper, we present an approach to automatically identify design and requirement self-admitted technical debt using Natural Language Processing (NLP). We study 10 open source projects: Ant, ArgoUML, Columba, EMF, Hibernate, JEdit, JFreeChart, JMeter, JRuby and SQuirrel SQL and find that 1) we are able to accurately identify self-admitted technical debt, significantly outperforming the current state-of-the-art based on fixed keywords and phrases; 2) words related to sloppy code or mediocre source code quality are the best indicators of design debt, whereas words related to the need to complete a partially implemented requirement in the future are the best indicators of requirement debt; and 3) we can achieve 90 percent of the best classification performance, using as little as 23 percent of the comments for both design and requirement self-admitted technical debt, and 80 percent of the best performance, using as little as 9 and 5 percent of the comments for design and requirement self-admitted technical debt, respectively. The last finding shows that the proposed approach can achieve a good accuracy even with a relatively small training dataset.",2017,2017,,IEEE Transactions on Software Engineering,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/TSE.2017.2654244,10.1109/TSE.2017.2654244,https://doi.org/10.1109/TSE.2017.2654244,181,"The metaphor of technical debt was introduced to express the trade off between productivity and quality, i.e., when developers take shortcuts or perform quick hacks. More recently, our work has shown that it is possible to detect technical debt using source code comments (i.e., self-admitted technical debt), and that the most common types of self-admitted technical debt are design and requirement debt. However, all approaches thus far heavily depend on the manual classification of source code comments. In this paper, we present an approach to automatically identify design and requirement self-admitted technical debt using Natural Language Processing (NLP). We study 10 open source projects: Ant, ArgoUML, Columba, EMF, Hibernate, JEdit, JFreeChart, JMeter, JRuby and SQuirrel SQL and find that 1) we are able to accurately identify self-admitted technical debt, significantly outperforming the current state-of-the-art based on fixed keywords and phrases; 2) words related to sloppy code or mediocre source code quality are the best indicators of design debt, whereas words related to the need to complete a partially implemented requirement in the future are the best indicators of requirement debt; and 3) we can achieve 90 percent of the best classification performance, using as little as 23 percent of the comments for both design and requirement self-admitted technical debt, and 80 percent of the best performance, using as little as 9 and 5 percent of the comments for design and requirement self-admitted technical debt, respectively. The last finding shows that the proposed approach can achieve a good accuracy even with a relatively small training dataset.",Document_59,Technical aspects or methods of AI or machine learning,0.11335498094558716,Other Categories
Policy advice and best practices on bias and fairness in AI,"Jose M. Alvarez, A. Colmenarejo, Alaa Elobaid, Simone Fabbrizzi, Miriam Fahimi, Antonio Ferrara, Siamak Ghodsi, Carlos Mougan, Ioanna Papageorgiou, Paula Reyero Lobo, Mayra Russo, Kristen M. Scott, Laura State, Xuan Zhao, Salvatore Ruggieri","The literature addressing bias and fairness in AI models ( fair-AI ) is growing at a fast pace, making it difficult for novel researchers and practitioners to have a bird’s-eye view picture of the field. In particular, many policy initiatives, standards, and best practices in fair-AI have been proposed for setting principles, procedures, and knowledge bases to guide and operationalize the management of bias and fairness. The first objective of this paper is to concisely survey the state-of-the-art of fair-AI methods and resources, and the main policies on bias in AI, with the aim of providing such a bird’s-eye guidance for both researchers and practitioners. The second objective of the paper is to contribute to the policy advice and best practices state-of-the-art by leveraging from the results of the NoBIAS research project. We present and discuss a few relevant topics organized around the NoBIAS architecture, which is made up of a Legal Layer, focusing on the European Union context, and a Bias Management Layer, focusing on understanding, mitigating, and accounting for bias.",2024,2024,6.0,Ethics and Information Technology,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10676-024-09746-w,10.1007/s10676-024-09746-w,https://doi.org/10.1007/s10676-024-09746-w,15,"The literature addressing bias and fairness in AI models ( fair-AI ) is growing at a fast pace, making it difficult for novel researchers and practitioners to have a bird’s-eye view picture of the field. In particular, many policy initiatives, standards, and best practices in fair-AI have been proposed for setting principles, procedures, and knowledge bases to guide and operationalize the management of bias and fairness. The first objective of this paper is to concisely survey the state-of-the-art of fair-AI methods and resources, and the main policies on bias in AI, with the aim of providing such a bird’s-eye guidance for both researchers and practitioners. The second objective of the paper is to contribute to the policy advice and best practices state-of-the-art by leveraging from the results of the NoBIAS research project. We present and discuss a few relevant topics organized around the NoBIAS architecture, which is made up of a Legal Layer, focusing on the European Union context, and a Bias Management Layer, focusing on understanding, mitigating, and accounting for bias.",Document_60,Technical aspects or methods of AI or machine learning,0.07055411487817764,Other Categories
An AI framework to support decisions on GDPR compliance,"Filippo Lorè, Pierpaolo Basile, A. Appice, Marco de Gemmis, D. Malerba, G. Semeraro","The Italian Public Administration (PA) relies on costly manual analyses to ensure the GDPR compliance of public documents and secure personal data. Despite recent advances in Artificial Intelligence (AI) have benefited many legal fields, the automation of workflows for data protection of public documents is still only marginally affected. The main aim of this work is to design a framework that can be effectively adopted to check whether PA documents written in Italian meet the GDPR requirements. The main outcome of our interdisciplinary research is INTREPID (art I ficial i NT elligence for gdp R complianc E of P ublic adm I nistration D ocuments), an AI-based framework that can help the Italian PA to ensure GDPR compliance of public documents. INTREPID is realized by tuning some linguistic resources for Italian language processing (i.e. SpaCy and Tint) to the GDPR intelligence. In addition, we set the foundations for a text classification methodology to recognise the public documents published by the Italian PA, which perform data breaches. We show the effectiveness of the framework over a text corpus of public documents that were published online by the Italian PA. We also perform an inter-annotator study and analyse the agreement of the annotation predictions of the proposed methodology with the annotations by domain experts. Finally, we evaluate the accuracy of the proposed text classification model in detecting breaches of security.",2023,2023,10.0,Journal of Intelligence and Information Systems,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10844-023-00782-4,10.1007/s10844-023-00782-4,https://doi.org/10.1007/s10844-023-00782-4,8,"The Italian Public Administration (PA) relies on costly manual analyses to ensure the GDPR compliance of public documents and secure personal data. Despite recent advances in Artificial Intelligence (AI) have benefited many legal fields, the automation of workflows for data protection of public documents is still only marginally affected. The main aim of this work is to design a framework that can be effectively adopted to check whether PA documents written in Italian meet the GDPR requirements. The main outcome of our interdisciplinary research is INTREPID (art I ficial i NT elligence for gdp R complianc E of P ublic adm I nistration D ocuments), an AI-based framework that can help the Italian PA to ensure GDPR compliance of public documents. INTREPID is realized by tuning some linguistic resources for Italian language processing (i.e. SpaCy and Tint) to the GDPR intelligence. In addition, we set the foundations for a text classification methodology to recognise the public documents published by the Italian PA, which perform data breaches. We show the effectiveness of the framework over a text corpus of public documents that were published online by the Italian PA. We also perform an inter-annotator study and analyse the agreement of the annotation predictions of the proposed methodology with the annotations by domain experts. Finally, we evaluate the accuracy of the proposed text classification model in detecting breaches of security.",Document_61,Demonstrating the value of AI for compliance and risk management,0.13101869821548462,Business Case and Value Demonstration Strategies
Shortcut Learning Explanations for Deep Natural Language Processing: A Survey on Dataset Biases,"Varun Dogra, Sahil Verma, .. Kavita, Marcin Woźniak, Jana Shafi, M. Ijaz","The introduction of pre-trained large language models (LLMs) has transformed NLP by fine-tuning task-specific datasets, enabling notable advancements in news classification, language translation, and sentiment analysis. This has revolutionized the field, driving remarkable breakthroughs and progress. However, the growing recognition of bias in textual data has emerged as a critical focus in the NLP community, revealing the inherent limitations of models trained on specific datasets. LLMs exploit these dataset biases and artifacts as expedient shortcuts for prediction. The reliance of LLMs on dataset bias and artifacts as shortcuts for prediction has hindered their generalizability and adversarial robustness. Addressing this issue is crucial to enhance the reliability and resilience of LLMs in various contexts. This survey provides a comprehensive overview of the rapidly growing body of research on shortcut learning in language models, classifying the research into four main areas: the factors of shortcut learning, the origin of bias, the detection methods of dataset biases, and understanding mitigation strategies to address data biases. The goal of this study is to offer a contextualized, in-depth look at the state of learning models, highlighting the major areas of attention and suggesting possible directions for further research.",2024,2024,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2024.3360306,10.1109/ACCESS.2024.3360306,https://doi.org/10.1109/ACCESS.2024.3360306,6,"The introduction of pre-trained large language models (LLMs) has transformed NLP by fine-tuning task-specific datasets, enabling notable advancements in news classification, language translation, and sentiment analysis. This has revolutionized the field, driving remarkable breakthroughs and progress. However, the growing recognition of bias in textual data has emerged as a critical focus in the NLP community, revealing the inherent limitations of models trained on specific datasets. LLMs exploit these dataset biases and artifacts as expedient shortcuts for prediction. The reliance of LLMs on dataset bias and artifacts as shortcuts for prediction has hindered their generalizability and adversarial robustness. Addressing this issue is crucial to enhance the reliability and resilience of LLMs in various contexts. This survey provides a comprehensive overview of the rapidly growing body of research on shortcut learning in language models, classifying the research into four main areas: the factors of shortcut learning, the origin of bias, the detection methods of dataset biases, and understanding mitigation strategies to address data biases. The goal of this study is to offer a contextualized, in-depth look at the state of learning models, highlighting the major areas of attention and suggesting possible directions for further research.",Document_62,Technical aspects or methods of AI or machine learning,0.08611320704221725,Other Categories
Explainable AI for Compliance and Regulatory Models,"Indra Reddy Mallela, Sneha Aravind, Ojaswin Tharan, Dr. Punit Goel, Dr Satendra Pal, Singh","The increasing complexity of compliance and regulatory frameworks across industries demands innovative solutions for managing and interpreting large volumes of data. Explainable Artificial Intelligence (XAI) offers a promising approach by providing transparent and interpretable AI models that can be utilized for compliance and regulatory decision-making. Traditional AI systems, often viewed as ""black boxes,"" have been met with scepticism due to their opacity, especially in high-stakes domains like finance, healthcare, and legal sectors, where accountability and trust are paramount. XAI addresses these challenges by making the decision-making process more transparent, enabling stakeholders to understand the logic behind AI-driven recommendations and actions. In regulatory environments, XAI can be used to explain the rationale behind risk assessments, fraud detection, or legal interpretations, thus ensuring compliance with laws and policies. Moreover, the integration of XAI into compliance models enhances auditability and traceability, providing regulators and auditors with the tools to validate and verify the adherence to standards. This transparency is crucial for building trust in AI systems and fostering collaboration between human decision-makers and AI tools.",2020,2020,,International Journal for Research Publication and Seminar,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.36676/jrps.v11.i4.1584,10.36676/jrps.v11.i4.1584,https://doi.org/10.36676/jrps.v11.i4.1584,4,"The increasing complexity of compliance and regulatory frameworks across industries demands innovative solutions for managing and interpreting large volumes of data. Explainable Artificial Intelligence (XAI) offers a promising approach by providing transparent and interpretable AI models that can be utilized for compliance and regulatory decision-making. Traditional AI systems, often viewed as ""black boxes,"" have been met with scepticism due to their opacity, especially in high-stakes domains like finance, healthcare, and legal sectors, where accountability and trust are paramount. XAI addresses these challenges by making the decision-making process more transparent, enabling stakeholders to understand the logic behind AI-driven recommendations and actions. In regulatory environments, XAI can be used to explain the rationale behind risk assessments, fraud detection, or legal interpretations, thus ensuring compliance with laws and policies. Moreover, the integration of XAI into compliance models enhances auditability and traceability, providing regulators and auditors with the tools to validate and verify the adherence to standards. This transparency is crucial for building trust in AI systems and fostering collaboration between human decision-makers and AI tools.",Document_63,Demonstrating the value of AI for compliance and risk management,0.29767343401908875,Business Case and Value Demonstration Strategies
Using Semantic Frames for Automatic Annotation of Regulatory Texts,"Kartik Asooja, Georgeta Bordea, P. Buitelaar","The global legislation system is being actively updated, especially after the financial crisis of 2007–2008. This results in a significant amount of work load for the different industries, in order to cope up with the volume, velocity, variety, and complexity of the regulations in order to be compliant. So far, this is mainly being handled manually by the regulatory experts in the industries. In this paper, we explore the space of providing automatic assistance to experts in compliance verification pipeline. This work specifically focuses on performing automatic semantic annotations of the regulatory documents with a set of predefined categories. This is achieved by using text classification approaches using linguistically motivated features.",2016,2016,4.0,International Conference on Applications of Natural Language to Data Bases,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML) - Short, Score: 0.49) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-319-41754-7_38,10.1007/978-3-319-41754-7_38,https://doi.org/10.1007/978-3-319-41754-7_38,4,"The global legislation system is being actively updated, especially after the financial crisis of 2007–2008. This results in a significant amount of work load for the different industries, in order to cope up with the volume, velocity, variety, and complexity of the regulations in order to be compliant. So far, this is mainly being handled manually by the regulatory experts in the industries. In this paper, we explore the space of providing automatic assistance to experts in compliance verification pipeline. This work specifically focuses on performing automatic semantic annotations of the regulatory documents with a set of predefined categories. This is achieved by using text classification approaches using linguistically motivated features.",Document_64,General discussion of financial or regulatory topics (non-AI focus),0.07789944857358932,Other Categories
Exploring Automated GDPR-Compliance in Requirements Engineering: A Systematic Mapping Study,"A. Aberkane, G. Poels, S. V. Broucke","The General Data Protection Regulation (GDPR), adopted in 2018, profoundly impacts information processing organizations as they must comply with this regulation. In this research, we consider GDPR-compliance as a high-level goal in software development that should be addressed at the outset of software development, meaning during requirements engineering (RE). In this work, we hypothesize that natural language processing (NLP) can offer a viable means to automate this process. We conducted a systematic mapping study to explore the existing literature on the intersection of GDPR, NLP, and RE. As a result, we identified 448 relevant studies, of which the majority (420) were related to NLP and RE. Research on the intersection of GDPR and NLP yielded nine studies, while 20 studies were related to GDPR and RE. Even though only one study was identified on the convergence of GDPR, NLP, and RE, the mapping results indicate opportunities for bridging the gap between these fields. In particular, we identified possibilities for introducing NLP techniques to automate manual RE tasks in the crossing of GDPR and RE, in addition to possibilities of using NLP-based machine learning techniques to achieve GDPR-compliance in RE.",2021,2021,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2021.3076921,10.1109/ACCESS.2021.3076921,https://doi.org/10.1109/ACCESS.2021.3076921,15,"The General Data Protection Regulation (GDPR), adopted in 2018, profoundly impacts information processing organizations as they must comply with this regulation. In this research, we consider GDPR-compliance as a high-level goal in software development that should be addressed at the outset of software development, meaning during requirements engineering (RE). In this work, we hypothesize that natural language processing (NLP) can offer a viable means to automate this process. We conducted a systematic mapping study to explore the existing literature on the intersection of GDPR, NLP, and RE. As a result, we identified 448 relevant studies, of which the majority (420) were related to NLP and RE. Research on the intersection of GDPR and NLP yielded nine studies, while 20 studies were related to GDPR and RE. Even though only one study was identified on the convergence of GDPR, NLP, and RE, the mapping results indicate opportunities for bridging the gap between these fields. In particular, we identified possibilities for introducing NLP techniques to automate manual RE tasks in the crossing of GDPR and RE, in addition to possibilities of using NLP-based machine learning techniques to achieve GDPR-compliance in RE.",Document_65,Technical aspects or methods of AI or machine learning,0.13521011173725128,Other Categories
Using artificial intelligence to support compliance with the general data protection regulation,John K. C. Kingston,"The General Data Protection Regulation (GDPR) is a European Union regulation that will replace the existing Data Protection Directive on 25 May 2018. The most significant change is a huge increase in the maximum fine that can be levied for breaches of the regulation. Yet fewer than half of UK companies are fully aware of GDPR—and a number of those who were preparing for it stopped doing so when the Brexit vote was announced. A last-minute rush to become compliant is therefore expected, and numerous companies are starting to offer advice, checklists and consultancy on how to comply with GDPR. In such an environment, artificial intelligence technologies ought to be able to assist by providing best advice; asking all and only the relevant questions; monitoring activities; and carrying out assessments. The paper considers four areas of GDPR compliance where rule based technologies and/or machine learning techniques may be relevant: Following compliance checklists and codes of conduct; Supporting risk assessments; Complying with the new regulations regarding technologies that perform automatic profiling; Complying with the new regulations concerning recognising and reporting breaches of security. It concludes that AI technology can support each of these four areas. The requirements that GDPR (or organisations that need to comply with GDPR) state for explanation and justification of reasoning imply that rule-based approaches are likely to be more helpful than machine learning approaches. However, there may be good business reasons to take a different approach in some circumstances.",2017,2017,12.0,Artificial Intelligence and Law,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10506-017-9206-9,10.1007/s10506-017-9206-9,https://doi.org/10.1007/s10506-017-9206-9,41,"The General Data Protection Regulation (GDPR) is a European Union regulation that will replace the existing Data Protection Directive on 25 May 2018. The most significant change is a huge increase in the maximum fine that can be levied for breaches of the regulation. Yet fewer than half of UK companies are fully aware of GDPR—and a number of those who were preparing for it stopped doing so when the Brexit vote was announced. A last-minute rush to become compliant is therefore expected, and numerous companies are starting to offer advice, checklists and consultancy on how to comply with GDPR. In such an environment, artificial intelligence technologies ought to be able to assist by providing best advice; asking all and only the relevant questions; monitoring activities; and carrying out assessments. The paper considers four areas of GDPR compliance where rule based technologies and/or machine learning techniques may be relevant: Following compliance checklists and codes of conduct; Supporting risk assessments; Complying with the new regulations regarding technologies that perform automatic profiling; Complying with the new regulations concerning recognising and reporting breaches of security. It concludes that AI technology can support each of these four areas. The requirements that GDPR (or organisations that need to comply with GDPR) state for explanation and justification of reasoning imply that rule-based approaches are likely to be more helpful than machine learning approaches. However, there may be good business reasons to take a different approach in some circumstances.",Document_66,Demonstrating the value of AI for compliance and risk management,0.5392402410507202,Business Case and Value Demonstration Strategies
Legal implications of automated suspicious transaction monitoring: enhancing integrity of AI,"Umut Turksen, Vladlena Benson, Bogdan Adamyk","The fast-paced advances of technology, including artificial intelligence (AI) and machine learning (ML), continue to create new opportunities for banks and other financial institutions. This study reveals the barriers to trust in AI by prudential banking supervisors (compliance with regulations). We conducted a qualitative study on the drivers for adoption of explainability technologies that increase transparency and understanding of complex algorithms (some of the underpinning legal principles in the proposed EU AI Act). By using human-centred and ethics-by-design methods coupled with interviews of the key stakeholders from Eastern European private and public banks and IT AI/ML developers, this research has identified the key challenges concerning the employment of AI algorithms. The results indicate a conflicting view of AI barriers whilst revealing the importance of AI/ML systems in banks, the growing willingness of banks to use such systems more widely, and the problematic aspects of implementing AI/ML systems related to their cost and economic efficiency. Keeping up with the complex regulation requirements comes at a significant cost to banks and financial firms. The focus of the empirical study, stakeholders in Ukraine, Estonia and Poland, was chosen because of the fact that there has been a sharp increase in the adoption of AI/ML models in this jurisdiction in the context of its war with Russia and the ensuing sanctions regime. While the “leapfrogging” AI/ML paths in each bank surveyed had its own drivers and challenges, these insights provide lessons for banks in other European jurisdictions. The analysis of four criminal cases brought against top banks and conclusions of the study indicate that the increase in predicate crimes for money laundering, constantly evolving sanctions regime along with the enhanced scrutiny and enforcement action against banks are hindering technology innovation and legal implications of using AI driven tools for compliance.",2024,2024,12.0,Journal of Banking Regulation,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1057/s41261-024-00233-2,10.1057/s41261-024-00233-2,https://doi.org/10.1057/s41261-024-00233-2,2,"The fast-paced advances of technology, including artificial intelligence (AI) and machine learning (ML), continue to create new opportunities for banks and other financial institutions. This study reveals the barriers to trust in AI by prudential banking supervisors (compliance with regulations). We conducted a qualitative study on the drivers for adoption of explainability technologies that increase transparency and understanding of complex algorithms (some of the underpinning legal principles in the proposed EU AI Act). By using human-centred and ethics-by-design methods coupled with interviews of the key stakeholders from Eastern European private and public banks and IT AI/ML developers, this research has identified the key challenges concerning the employment of AI algorithms. The results indicate a conflicting view of AI barriers whilst revealing the importance of AI/ML systems in banks, the growing willingness of banks to use such systems more widely, and the problematic aspects of implementing AI/ML systems related to their cost and economic efficiency. Keeping up with the complex regulation requirements comes at a significant cost to banks and financial firms. The focus of the empirical study, stakeholders in Ukraine, Estonia and Poland, was chosen because of the fact that there has been a sharp increase in the adoption of AI/ML models in this jurisdiction in the context of its war with Russia and the ensuing sanctions regime. While the “leapfrogging” AI/ML paths in each bank surveyed had its own drivers and challenges, these insights provide lessons for banks in other European jurisdictions. The analysis of four criminal cases brought against top banks and conclusions of the study indicate that the increase in predicate crimes for money laundering, constantly evolving sanctions regime along with the enhanced scrutiny and enforcement action against banks are hindering technology innovation and legal implications of using AI driven tools for compliance.",Document_67,AI-specific regulations pose challenges for financial institutions,0.11138509958982468,Regulatory and Ethical Barriers
Upcoming European Regulations on Artificial Intelligence and Cybersecurity,"M. Mueck, Amit Elazari Bar On, Stephane Du Boispean","The European Commission is in the process of fundamentally revising the regulatory framework and related market access conditions in key technological areas, including Artificial Intelligence as well as Digital Technology in general. In the present article, we provide an overview on the status of related policy actions, specifically addressing the novel upcoming Artificial Intelligence (AI) Act and Cyber Resilience Act (CRA) initiatives. Finally, an outlook is given on architectural choices which will help manufacturers to comply with the upcoming new requirements and thus maintain access to the European Single Market.",2023,2023,,IEEE Communications Magazine,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/MCOM.004.2200612,10.1109/MCOM.004.2200612,https://doi.org/10.1109/MCOM.004.2200612,6,"The European Commission is in the process of fundamentally revising the regulatory framework and related market access conditions in key technological areas, including Artificial Intelligence as well as Digital Technology in general. In the present article, we provide an overview on the status of related policy actions, specifically addressing the novel upcoming Artificial Intelligence (AI) Act and Cyber Resilience Act (CRA) initiatives. Finally, an outlook is given on architectural choices which will help manufacturers to comply with the upcoming new requirements and thus maintain access to the European Single Market.",Document_68,Collaborating with regulators to create AI compliance frameworks,0.0900455042719841,Regulatory Engagement and Proactive Compliance Strategies
Computational Data Sciences and the Regulation of Banking and Financial Services,"Sharyn O'Halloran, M. Dumas, S. Maskey, Geraldine McAllister, David K. Park","The development of computational data science techniques in natural language processing (NLP) and machine learning (ML) algorithms to analyze large and complex textual information opens new avenues to study intricate policy processes at a scale unimaginable even a few years ago. We apply these scalable NLP and ML techniques to analyze the United States Government’s regulation of the banking and financial services sector. First, we employ NLP techniques to convert the text of financial regulation laws into feature vectors and infer representative “topics” across all the laws. Second, we apply ML algorithms to the feature vectors to predict various attributes of each law, focusing on the amount of authority delegated to regulators. Lastly, we compare the power of alternative models in predicting regulators’ discretion to oversee financial markets. These methods allow us to efficiently process large amounts of documents and represent the text of the laws in feature vectors, taking into account words, phrases, syntax, and semantics. The vectors can be paired with predefined policy features, thereby enabling us to build better predictive measures of financial sector regulation. The analysis offers policymakers and the business community alike a tool to automatically score policy features of financial regulation laws to and measure their impact on market performance.",2017,2017,4.0,-,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.34) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-319-51367-6_8,10.1007/978-3-319-51367-6_8,https://doi.org/10.1007/978-3-319-51367-6_8,2,"The development of computational data science techniques in natural language processing (NLP) and machine learning (ML) algorithms to analyze large and complex textual information opens new avenues to study intricate policy processes at a scale unimaginable even a few years ago. We apply these scalable NLP and ML techniques to analyze the United States Government’s regulation of the banking and financial services sector. First, we employ NLP techniques to convert the text of financial regulation laws into feature vectors and infer representative “topics” across all the laws. Second, we apply ML algorithms to the feature vectors to predict various attributes of each law, focusing on the amount of authority delegated to regulators. Lastly, we compare the power of alternative models in predicting regulators’ discretion to oversee financial markets. These methods allow us to efficiently process large amounts of documents and represent the text of the laws in feature vectors, taking into account words, phrases, syntax, and semantics. The vectors can be paired with predefined policy features, thereby enabling us to build better predictive measures of financial sector regulation. The analysis offers policymakers and the business community alike a tool to automatically score policy features of financial regulation laws to and measure their impact on market performance.",Document_69,Technical aspects or methods of AI or machine learning,0.13806872069835663,Other Categories
"Securing Personally Identifiable Information: A Survey of SOTA Techniques, and a Way Forward","Imran Makhdoom, M. Abolhasan, J. Lipman, N. Shariati, Daniel Franklin, Massimo Piccardi","The current age is witnessing an unprecedented dependence on data originating from humans through the devices that comprise the Internet of Things. The data collected by these devices are used for many purposes, including predictive maintenance, smart analytics, preventive healthcare, disaster protection, and increased operational efficiency and performance. However, most applications and systems that rely on user data to achieve their business objectives fail to comply with privacy regulations and expose users to numerous privacy threats. Such privacy breaches raise concerns about the legitimacy of the data being processed. Hence, this paper reviews some notable techniques for transparently, securely, and privately separating and sharing personally identifiable and non-personally identifiable information in various domains. One of the key findings of this study is that, despite various advantages, none of the existing techniques or data sharing applications preserve data/user privacy throughout the data life cycle. Another significant issue is the lack of transparency for data subjects during the collection, storage, and processing of private data. In addition, as privacy is unique to every user, there cannot be a single autonomous solution to identify and secure personally identifiable information for users of a particular application, system, or people living in different states/countries. Therefore, this research suggests a way forward to prevent the leakage of personally identifiable information at various stages of the data life cycle in compliance with some of the common privacy regulations around the world. The proposed approach aims to empower data owners to select, share, monitor, and control access to their data. In addition, the data owner is a stakeholder and a party to all data sharing contracts related to his personal data. The proposed solution has broad security and privacy controls that can be tailored to the privacy needs of specific applications.",2024,2024,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2024.3447017,10.1109/ACCESS.2024.3447017,https://doi.org/10.1109/ACCESS.2024.3447017,2,"The current age is witnessing an unprecedented dependence on data originating from humans through the devices that comprise the Internet of Things. The data collected by these devices are used for many purposes, including predictive maintenance, smart analytics, preventive healthcare, disaster protection, and increased operational efficiency and performance. However, most applications and systems that rely on user data to achieve their business objectives fail to comply with privacy regulations and expose users to numerous privacy threats. Such privacy breaches raise concerns about the legitimacy of the data being processed. Hence, this paper reviews some notable techniques for transparently, securely, and privately separating and sharing personally identifiable and non-personally identifiable information in various domains. One of the key findings of this study is that, despite various advantages, none of the existing techniques or data sharing applications preserve data/user privacy throughout the data life cycle. Another significant issue is the lack of transparency for data subjects during the collection, storage, and processing of private data. In addition, as privacy is unique to every user, there cannot be a single autonomous solution to identify and secure personally identifiable information for users of a particular application, system, or people living in different states/countries. Therefore, this research suggests a way forward to prevent the leakage of personally identifiable information at various stages of the data life cycle in compliance with some of the common privacy regulations around the world. The proposed approach aims to empower data owners to select, share, monitor, and control access to their data. In addition, the data owner is a stakeholder and a party to all data sharing contracts related to his personal data. The proposed solution has broad security and privacy controls that can be tailored to the privacy needs of specific applications.",Document_70,Technical aspects or methods of AI or machine learning,0.047482412308454514,Other Categories
Man vs the machine in the struggle for effective text anonymisation in the age of large language models,"Constantinos Patsakis, Nikolaos Lykousas","The collection and use of personal data are becoming more common in today’s data-driven culture. While there are many advantages to this, including better decision-making and service delivery, it also poses significant ethical issues around confidentiality and privacy. Text anonymisation tries to prune and/or mask identifiable information from a text while keeping the remaining content intact to alleviate privacy concerns. Text anonymisation is especially important in industries like healthcare, law, as well as research, where sensitive and personal information is collected, processed, and exchanged under high legal and ethical standards. Although text anonymisation is widely adopted in practice, it continues to face considerable challenges. The most significant challenge is striking a balance between removing information to protect individuals’ privacy while maintaining the text’s usability for future purposes. The question is whether these anonymisation methods sufficiently reduce the risk of re-identification, in which an individual can be identified based on the remaining information in the text. In this work, we challenge the effectiveness of these methods and how we perceive identifiers. We assess the efficacy of these methods against the elephant in the room, the use of AI over big data. While most of the research is focused on identifying and removing personal information, there is limited discussion on whether the remaining information is sufficient to deanonymise individuals and, more precisely, who can do it. To this end, we conduct an experiment using GPT over anonymised texts of famous people to determine whether such trained networks can deanonymise them. The latter allows us to revise these methods and introduce a novel methodology that employs Large Language Models to improve the anonymity of texts.",2023,2023,9.0,Scientific Reports,Success (Selector (#Abs1-content)) / Date (Time Tag) (URL Source: DOI Link),https://doi.org/10.1038/s41598-023-42977-3,10.1038/s41598-023-42977-3,https://doi.org/10.1038/s41598-023-42977-3,11,"The collection and use of personal data are becoming more common in today’s data-driven culture. While there are many advantages to this, including better decision-making and service delivery, it also poses significant ethical issues around confidentiality and privacy. Text anonymisation tries to prune and/or mask identifiable information from a text while keeping the remaining content intact to alleviate privacy concerns. Text anonymisation is especially important in industries like healthcare, law, as well as research, where sensitive and personal information is collected, processed, and exchanged under high legal and ethical standards. Although text anonymisation is widely adopted in practice, it continues to face considerable challenges. The most significant challenge is striking a balance between removing information to protect individuals’ privacy while maintaining the text’s usability for future purposes. The question is whether these anonymisation methods sufficiently reduce the risk of re-identification, in which an individual can be identified based on the remaining information in the text. In this work, we challenge the effectiveness of these methods and how we perceive identifiers. We assess the efficacy of these methods against the elephant in the room, the use of AI over big data. While most of the research is focused on identifying and removing personal information, there is limited discussion on whether the remaining information is sufficient to deanonymise individuals and, more precisely, who can do it. To this end, we conduct an experiment using GPT over anonymised texts of famous people to determine whether such trained networks can deanonymise them. The latter allows us to revise these methods and introduce a novel methodology that employs Large Language Models to improve the anonymity of texts.",Document_71,Technical aspects or methods of AI or machine learning,0.16537539660930634,Other Categories
Transfer Learning in Natural Language Processing,"Sebastian Ruder, Matthew E. Peters, Swabha Swayamdipta, Thomas Wolf","The classic supervised machine learning paradigm is based on learning in isolation, a single predictive model for a task using a single dataset. This approach requires a large number of training examples and performs best for well-defined and narrow tasks. Transfer learning refers to a set of methods that extend this approach by leveraging data from additional domains or tasks to train a model with better generalization properties. Over the last two years, the field of Natural Language Processing (NLP) has witnessed the emergence of several transfer learning methods and architectures which significantly improved upon the state-of-the-art on a wide range of NLP tasks. These improvements together with the wide availability and ease of integration of these methods are reminiscent of the factors that led to the success of pretrained word embeddings and ImageNet pretraining in computer vision, and indicate that these methods will likely become a common tool in the NLP landscape as well as an important research direction. We will present an overview of modern transfer learning methods in NLP, how models are pre-trained, what information the representations they learn capture, and review examples and case studies on how these models can be integrated and adapted in downstream NLP tasks.",2019,2019,6.0,North American Chapter of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/N19-5004,10.18653/v1/N19-5004,https://doi.org/10.18653/v1/N19-5004,476,"The classic supervised machine learning paradigm is based on learning in isolation, a single predictive model for a task using a single dataset. This approach requires a large number of training examples and performs best for well-defined and narrow tasks. Transfer learning refers to a set of methods that extend this approach by leveraging data from additional domains or tasks to train a model with better generalization properties. Over the last two years, the field of Natural Language Processing (NLP) has witnessed the emergence of several transfer learning methods and architectures which significantly improved upon the state-of-the-art on a wide range of NLP tasks. These improvements together with the wide availability and ease of integration of these methods are reminiscent of the factors that led to the success of pretrained word embeddings and ImageNet pretraining in computer vision, and indicate that these methods will likely become a common tool in the NLP landscape as well as an important research direction. We will present an overview of modern transfer learning methods in NLP, how models are pre-trained, what information the representations they learn capture, and review examples and case studies on how these models can be integrated and adapted in downstream NLP tasks.",Document_72,Technical aspects or methods of AI or machine learning,0.28295713663101196,Other Categories
Anonymization of German financial documents using neural network-based language models with contextual word representations,"D. Biesner, Rajkumar Ramamurthy, Robin Stenzel, Max Lübbering, L. Hillebrand, Anna Ladi, Maren Pielka, Rüdiger Loitz, C. Bauckhage, R. Sifa","The automatization and digitalization of business processes have led to an increase in the need for efficient information extraction from business documents. However, financial and legal documents are often not utilized effectively by text processing or machine learning systems, partly due to the presence of sensitive information in these documents, which restrict their usage beyond authorized parties and purposes. To overcome this limitation, we develop an anonymization method for German financial and legal documents using state-of-the-art natural language processing methods based on recurrent neural nets and transformer architectures. We present a web-based application to anonymize financial documents and a large-scale evaluation of different deep learning techniques.",2021,2022,3.0,International Journal of Data Science and Analysis,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s41060-021-00285-x,10.1007/s41060-021-00285-x,https://doi.org/10.1007/s41060-021-00285-x,25,"The automatization and digitalization of business processes have led to an increase in the need for efficient information extraction from business documents. However, financial and legal documents are often not utilized effectively by text processing or machine learning systems, partly due to the presence of sensitive information in these documents, which restrict their usage beyond authorized parties and purposes. To overcome this limitation, we develop an anonymization method for German financial and legal documents using state-of-the-art natural language processing methods based on recurrent neural nets and transformer architectures. We present a web-based application to anonymize financial documents and a large-scale evaluation of different deep learning techniques.",Document_73,Data privacy concerns limit the use of AI in financial applications,0.15112677216529846,Data Quality and Privacy Barriers
Document Representation for Text Analytics in Finance,"Jan Röder, Matthias Palmer","The automated analysis of unstructured data that is directly or indirectly relevant to developments on financial markets has attracted attention from researchers and practitioners alike. Recent advances in natural language processing enable a richer representation of textual data with respect to semantical and syntactical characteristics. Specifically, distributed representations of words and documents, commonly referred to as embeddings, are a promising alternative. Consequently, this paper investigates the utilization of these approaches for text analytics in finance. To this end, we synthesize traditional and more recent text representation techniques into a coherent framework and provide explanations of the illustrated methods. Building on this distinction, we systematically analyze the hitherto usage of these methods in the financial domain. The results indicate a surprisingly rare application of the outlined techniques. It is precisely for this reason that this paper aims to connect both finance and natural language processing research and might therefore be helpful in applying new methods at the intersection of the respective research areas.",2018,2019,4.0,Enterprise Applications and Services in the Finance Industry,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML) - Short, Score: 0.46) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-030-19037-8_9,10.1007/978-3-030-19037-8_9,https://doi.org/10.1007/978-3-030-19037-8_9,1,"The automated analysis of unstructured data that is directly or indirectly relevant to developments on financial markets has attracted attention from researchers and practitioners alike. Recent advances in natural language processing enable a richer representation of textual data with respect to semantical and syntactical characteristics. Specifically, distributed representations of words and documents, commonly referred to as embeddings, are a promising alternative. Consequently, this paper investigates the utilization of these approaches for text analytics in finance. To this end, we synthesize traditional and more recent text representation techniques into a coherent framework and provide explanations of the illustrated methods. Building on this distinction, we systematically analyze the hitherto usage of these methods in the financial domain. The results indicate a surprisingly rare application of the outlined techniques. It is precisely for this reason that this paper aims to connect both finance and natural language processing research and might therefore be helpful in applying new methods at the intersection of the respective research areas.",Document_74,Improving data quality is crucial for successful AI in finance,0.07080339640378952,Data Improvement and Availability Strategies
Few-shot and Zero-shot Approaches to Legal Text Classification: A Case Study in the Financial Sector,"Rajdeep Sarkar, Atul Kr. Ojha, Jay Megaro, J. Mariano, Vall Herard, John P. Mccrae","The application of predictive coding techniques to legal texts has the potential to greatly reduce the cost of legal review of documents, however, there is such a wide array of legal tasks and continuously evolving legislation that it is hard to construct sufficient training data to cover all cases. In this paper, we investigate few-shot and zero-shot approaches that require substantially less training data and introduce a triplet architecture, which for promissory statements produces performance close to that of a supervised system. This method allows predictive coding methods to be rapidly developed for new regulations and markets.",2021,2021,11.0,NLLP,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2021.nllp-1.10,10.18653/v1/2021.nllp-1.10,https://doi.org/10.18653/v1/2021.nllp-1.10,13,"The application of predictive coding techniques to legal texts has the potential to greatly reduce the cost of legal review of documents, however, there is such a wide array of legal tasks and continuously evolving legislation that it is hard to construct sufficient training data to cover all cases. In this paper, we investigate few-shot and zero-shot approaches that require substantially less training data and introduce a triplet architecture, which for promissory statements produces performance close to that of a supervised system. This method allows predictive coding methods to be rapidly developed for new regulations and markets.",Document_75,Difficulty in understanding AI decision-making is a barrier in finance,0.06568451225757599,Explainability and Transparency Barriers
Language Models Fine-Tuning for Automatic Format Reconstruction of SEC Financial Filings,"Gianfranco Lombardo, Giuseppe Trimigno, Mattia Pellegrino, S. Cagnoni","The analysis of financial reports is a crucial task for investors and regulators, especially the mandatory annual reports (10-K) required by the SEC (Securities and Exchange Commission) that provide crucial information about a public company in the American stock market. Although SEC suggests a specific document format to standardize and simplify the analysis, in recent years, several companies have introduced their own format and organization of the contents, making human-based and automatic knowledge extraction inherently more difficult. In this research work, we investigate different Neural language models based on Transformer networks (Bidirectional recurrence-based, Autoregressive-based, and Autoencoders-based approaches) to automatically reconstruct an SEC-like format of the documents as a multi-class classification task with 18 classes at the sentence level. In particular, we propose a Bidirectional fine-tuning procedure to specialize pre-trained language models on this task. We propose and make the resulting novel transformer model, named SEC-former, publicly available to deal with this task. We evaluate SEC-former in three different scenarios: 1) in terms of topic detection performances; 2) in terms of document similarity (TF-IDF Bag-of-words and Doc2Vec) achieved with respect to original and trustable financial reports since this operation is leveraged for portfolio optimization tasks; and 3) testing the model in a real use-case scenario related to a public company that does not respect the SEC format but provides a human-supervised reference to reconstruct it.",2024,2024,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2024.3370444,10.1109/ACCESS.2024.3370444,https://doi.org/10.1109/ACCESS.2024.3370444,1,"The analysis of financial reports is a crucial task for investors and regulators, especially the mandatory annual reports (10-K) required by the SEC (Securities and Exchange Commission) that provide crucial information about a public company in the American stock market. Although SEC suggests a specific document format to standardize and simplify the analysis, in recent years, several companies have introduced their own format and organization of the contents, making human-based and automatic knowledge extraction inherently more difficult. In this research work, we investigate different Neural language models based on Transformer networks (Bidirectional recurrence-based, Autoregressive-based, and Autoencoders-based approaches) to automatically reconstruct an SEC-like format of the documents as a multi-class classification task with 18 classes at the sentence level. In particular, we propose a Bidirectional fine-tuning procedure to specialize pre-trained language models on this task. We propose and make the resulting novel transformer model, named SEC-former, publicly available to deal with this task. We evaluate SEC-former in three different scenarios: 1) in terms of topic detection performances; 2) in terms of document similarity (TF-IDF Bag-of-words and Doc2Vec) achieved with respect to original and trustable financial reports since this operation is leveraged for portfolio optimization tasks; and 3) testing the model in a real use-case scenario related to a public company that does not respect the SEC format but provides a human-supervised reference to reconstruct it.",Document_76,Aligning AI implementation with financial regulatory requirements,0.28943610191345215,Regulatory Engagement and Proactive Compliance Strategies
Utility-Preserving Privacy Protection of Textual Documents via Word Embeddings,"Fadi Hassan, David Sánchez, J. Domingo-Ferrer","Text is the most usual way to share information in society. Yet, if textual documents contain personal sensitive information, they cannot be shared with third parties or released publicly without adequate protection. Privacy-preserving mechanisms provide ways to sanitize data so that identities and/or confidential attributes are not disclosed. In the last twenty years, a great variety of mechanisms have been proposed to protect structured databases with numerical and categorical attributes; however, little attention has been devoted to unstructured textual data. In general, textual data protection requires first detecting pieces of text that may lead to disclosure of sensitive information and then masking those pieces via suppression or generalization. Current solutions rely on pre-trained classifiers that can recognize a fixed set of (allegedly disclosive) named entities, such as names or locations. Yet, such approaches fall short of providing adequate protection because in reality disclosive information is not limited to a predefined set of entity types, and not all the appearances of certain entity type result in disclosure. Besides, named entity recognition requires considerable manual effort to tag the training data needed to build classifiers. In this work we propose a more general and flexible solution for textual data protection. By means of word embeddings we build vectors that numerically capture the semantic relationships of the textual terms appearing in a collection of documents. Then we evaluate the disclosure caused by the textual terms on the entity to be protected (e.g., an individual’s identity or a confidential attribute) according to the similarity between their vector representations. Our method also limits the semantic loss (and, therefore, the utility loss) of the document by replacing (rather than just suppressing) disclosive terms with privacy-preserving generalizations. Empirical results show that our approach offers much more robust protection and greater utility preservation than methods based on named entity recognition, with the additional important advantage of avoiding the burden of manual data tagging.",2023,2023,,IEEE Transactions on Knowledge and Data Engineering,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/TKDE.2021.3076632,10.1109/TKDE.2021.3076632,https://doi.org/10.1109/TKDE.2021.3076632,15,"Text is the most usual way to share information in society. Yet, if textual documents contain personal sensitive information, they cannot be shared with third parties or released publicly without adequate protection. Privacy-preserving mechanisms provide ways to sanitize data so that identities and/or confidential attributes are not disclosed. In the last twenty years, a great variety of mechanisms have been proposed to protect structured databases with numerical and categorical attributes; however, little attention has been devoted to unstructured textual data. In general, textual data protection requires first detecting pieces of text that may lead to disclosure of sensitive information and then masking those pieces via suppression or generalization. Current solutions rely on pre-trained classifiers that can recognize a fixed set of (allegedly disclosive) named entities, such as names or locations. Yet, such approaches fall short of providing adequate protection because in reality disclosive information is not limited to a predefined set of entity types, and not all the appearances of certain entity type result in disclosure. Besides, named entity recognition requires considerable manual effort to tag the training data needed to build classifiers. In this work we propose a more general and flexible solution for textual data protection. By means of word embeddings we build vectors that numerically capture the semantic relationships of the textual terms appearing in a collection of documents. Then we evaluate the disclosure caused by the textual terms on the entity to be protected (e.g., an individual’s identity or a confidential attribute) according to the similarity between their vector representations. Our method also limits the semantic loss (and, therefore, the utility loss) of the document by replacing (rather than just suppressing) disclosive terms with privacy-preserving generalizations. Empirical results show that our approach offers much more robust protection and greater utility preservation than methods based on named entity recognition, with the additional important advantage of avoiding the burden of manual data tagging.",Document_77,Technical aspects or methods of AI or machine learning,0.08031786233186722,Other Categories
"""What is relevant in a text document?"": An interpretable machine learning approach","L. Arras, F. Horn, G. Montavon, K. Müller, W. Samek","Text documents can be described by a number of abstract concepts such as semantic category, writing style, or sentiment. Machine learning (ML) models have been trained to automatically map documents to these abstract concepts, allowing to annotate very large text collections, more than could be processed by a human in a lifetime. Besides predicting the text’s category very accurately, it is also highly desirable to understand how and why the categorization process takes place. In this paper, we demonstrate that such understanding can be achieved by tracing the classification decision back to individual words using layer-wise relevance propagation (LRP), a recently developed technique for explaining predictions of complex non-linear classifiers. We train two word-based ML models, a convolutional neural network (CNN) and a bag-of-words SVM classifier, on a topic categorization task and adapt the LRP method to decompose the predictions of these models onto words. Resulting scores indicate how much individual words contribute to the overall classification decision. This enables one to distill relevant information from text documents without an explicit semantic information extraction step. We further use the word-wise relevance scores for generating novel vector-based document representations which capture semantic information. Based on these document vectors, we introduce a measure of model explanatory power and show that, although the SVM and CNN models perform similarly in terms of classification accuracy, the latter exhibits a higher level of explainability which makes it more comprehensible for humans and potentially more useful for other applications.",2016,2016,,PLoS ONE,Selector (div.abstract > div > p / Date Not Found (URL Source: DOI Link),https://doi.org/10.1371/journal.pone.0181142,10.1371/journal.pone.0181142,https://doi.org/10.1371/journal.pone.0181142,280,"Text documents can be described by a number of abstract concepts such as semantic category, writing style, or sentiment. Machine learning (ML) models have been trained to automatically map documents to these abstract concepts, allowing to annotate very large text collections, more than could be processed by a human in a lifetime. Besides predicting the text’s category very accurately, it is also highly desirable to understand how and why the categorization process takes place. In this paper, we demonstrate that such understanding can be achieved by tracing the classification decision back to individual words using layer-wise relevance propagation (LRP), a recently developed technique for explaining predictions of complex non-linear classifiers. We train two word-based ML models, a convolutional neural network (CNN) and a bag-of-words SVM classifier, on a topic categorization task and adapt the LRP method to decompose the predictions of these models onto words. Resulting scores indicate how much individual words contribute to the overall classification decision. This enables one to distill relevant information from text documents without an explicit semantic information extraction step. We further use the word-wise relevance scores for generating novel vector-based document representations which capture semantic information. Based on these document vectors, we introduce a measure of model explanatory power and show that, although the SVM and CNN models perform similarly in terms of classification accuracy, the latter exhibits a higher level of explainability which makes it more comprehensible for humans and potentially more useful for other applications.",Document_78,Technical aspects or methods of AI or machine learning,0.12110888957977295,Other Categories
A Survey of Text Classification With Transformers: How Wide? How Large? How Long? How Accurate? How Expensive? How Safe?,"John Fields, Kevin Chovanec, Praveen Madiraju","Text classification in natural language processing (NLP) is evolving rapidly, particularly with the surge in transformer-based models, including large language models (LLM). This paper presents an in-depth survey of text classification techniques across diverse benchmarks, addressing applications from sentiment analysis to chatbot-driven question-answering. Methodologically, it utilizes NLP-facilitated approaches such as co-citation and bibliographic coupling alongside traditional research techniques. Because new use cases continue to emerge in this dynamic field, the study proposes an expanded taxonomy of text classification applications, extending the focus beyond unimodal (text-only) inputs to explore the emerging field of multimodal classification. While offering a comprehensive review of text classification with LLMs, this review highlights novel questions that arise when approaching the task with transformers: It evaluates the use of multimodal data, including text, numeric, and columnar data, and discusses the evolution of text input lengths (tokens) for long text classification; it covers the historical development of transformer-based models, emphasizing recent advancements in LLMs; it evaluates model accuracy on 358 datasets across 20 applications, with results challenging the assumption that LLMs are universally superior, revealing unexpected findings related to accuracy, cost, and safety; and it explores issues related to cost and access as models become increasingly expensive. Finally, the survey discusses new social and ethical implications raised when using LLMs for text classification, including bias and copyright. Throughout, the review emphasizes the importance of a nuanced understanding of model performance and a holistic approach to deploying transformer-based models in real-world applications.",2024,2024,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2024.3349952,10.1109/ACCESS.2024.3349952,https://doi.org/10.1109/ACCESS.2024.3349952,28,"Text classification in natural language processing (NLP) is evolving rapidly, particularly with the surge in transformer-based models, including large language models (LLM). This paper presents an in-depth survey of text classification techniques across diverse benchmarks, addressing applications from sentiment analysis to chatbot-driven question-answering. Methodologically, it utilizes NLP-facilitated approaches such as co-citation and bibliographic coupling alongside traditional research techniques. Because new use cases continue to emerge in this dynamic field, the study proposes an expanded taxonomy of text classification applications, extending the focus beyond unimodal (text-only) inputs to explore the emerging field of multimodal classification. While offering a comprehensive review of text classification with LLMs, this review highlights novel questions that arise when approaching the task with transformers: It evaluates the use of multimodal data, including text, numeric, and columnar data, and discusses the evolution of text input lengths (tokens) for long text classification; it covers the historical development of transformer-based models, emphasizing recent advancements in LLMs; it evaluates model accuracy on 358 datasets across 20 applications, with results challenging the assumption that LLMs are universally superior, revealing unexpected findings related to accuracy, cost, and safety; and it explores issues related to cost and access as models become increasingly expensive. Finally, the survey discusses new social and ethical implications raised when using LLMs for text classification, including bias and copyright. Throughout, the review emphasizes the importance of a nuanced understanding of model performance and a holistic approach to deploying transformer-based models in real-world applications.",Document_79,Technical aspects or methods of AI or machine learning,0.1331508457660675,Other Categories
AI-Enabled Automation for Completeness Checking of Privacy Policies,"Orlando Amaral, Sallam Abualhaija, Damiano Torre, M. Sabetzadeh, L. Briand","Technological advances in information sharing have raised concerns about data protection. Privacy policies contain privacy-related requirements about how the personal data of individuals will be handled by an organization or a software system (e.g., a web service or an app). In Europe, privacy policies are subject to compliance with the General Data Protection Regulation (GDPR). A prerequisite for GDPR compliance checking is to verify whether the content of a privacy policy is complete according to the provisions of GDPR. Incomplete privacy policies might result in large fines on violating organization as well as incomplete privacy-related software specifications. Manual completeness checking is both time-consuming and error-prone. In this paper, we propose AI-based automation for the completeness checking of privacy policies. Through systematic qualitative methods, we first build two artifacts to characterize the privacy-related provisions of GDPR, namely a conceptual model and a set of completeness criteria. Then, we develop an automated solution on top of these artifacts by leveraging a combination of natural language processing and supervised machine learning. Specifically, we identify the GDPR-relevant information content in privacy policies and subsequently check them against the completeness criteria. To evaluate our approach, we collected 234 real privacy policies from the fund industry. Over a set of 48 unseen privacy policies, our approach detected 300 of the total of 334 violations of some completeness criteria correctly, while producing 23 false positives. The approach thus has a precision of 92.9% and recall of 89.8%. Compared to a baseline that applies keyword search only, our approach results in an improvement of 24.5% in precision and 38% in recall.",2021,2021,,IEEE Transactions on Software Engineering,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/TSE.2021.3124332,10.1109/TSE.2021.3124332,https://doi.org/10.1109/TSE.2021.3124332,30,"Technological advances in information sharing have raised concerns about data protection. Privacy policies contain privacy-related requirements about how the personal data of individuals will be handled by an organization or a software system (e.g., a web service or an app). In Europe, privacy policies are subject to compliance with the General Data Protection Regulation (GDPR). A prerequisite for GDPR compliance checking is to verify whether the content of a privacy policy is complete according to the provisions of GDPR. Incomplete privacy policies might result in large fines on violating organization as well as incomplete privacy-related software specifications. Manual completeness checking is both time-consuming and error-prone. In this paper, we propose AI-based automation for the completeness checking of privacy policies. Through systematic qualitative methods, we first build two artifacts to characterize the privacy-related provisions of GDPR, namely a conceptual model and a set of completeness criteria. Then, we develop an automated solution on top of these artifacts by leveraging a combination of natural language processing and supervised machine learning. Specifically, we identify the GDPR-relevant information content in privacy policies and subsequently check them against the completeness criteria. To evaluate our approach, we collected 234 real privacy policies from the fund industry. Over a set of 48 unseen privacy policies, our approach detected 300 of the total of 334 violations of some completeness criteria correctly, while producing 23 false positives. The approach thus has a precision of 92.9% and recall of 89.8%. Compared to a baseline that applies keyword search only, our approach results in an improvement of 24.5% in precision and 38% in recall.",Document_80,Technical aspects or methods of AI or machine learning,0.18212568759918213,Other Categories
Naturally!: How Breakthroughs in Natural Language Processing Can Dramatically Help Developers,"A. Sawant, Prem Devanbu","Taking advantage of the naturalness hypothesis for code, recent development, and research has focused on applying machine learning (ML) techniques originally developed for natural language processing (NLP) to drive a new wave of tools and applications aimed specifically for software engineering (SE) tasks. This drive to apply ML and deep learning (DL) has been animated by the large-scale availability of software development data (e.g., source code, code comments, code review comments, commit data, and so on) available from open source platforms such as GitHub and Bitbucket.",2021,2021,,IEEE Software,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/MS.2021.3086338,10.1109/MS.2021.3086338,https://doi.org/10.1109/MS.2021.3086338,9,"Taking advantage of the naturalness hypothesis for code, recent development, and research has focused on applying machine learning (ML) techniques originally developed for natural language processing (NLP) to drive a new wave of tools and applications aimed specifically for software engineering (SE) tasks. This drive to apply ML and deep learning (DL) has been animated by the large-scale availability of software development data (e.g., source code, code comments, code review comments, commit data, and so on) available from open source platforms such as GitHub and Bitbucket.",Document_81,Technical aspects or methods of AI or machine learning,0.42050600051879883,Other Categories
Potential of natural language processing for metadata extraction from environmental scientific publications,"G. Blanchy, Lukas Albrecht, J. Koestel, S. Garré","Summarizing information from large bodies of scientific literature is an essential but work-intensive task. This is especially true in environmental studies where multiple factors (e.g., soil, climate, vegetation) can contribute to the effects observed. Meta-analyses, studies that quantitatively summarize findings of a large body of literature, rely on manually curated databases built upon primary publications. However, given the increasing amount of literature, this manual work is likely to require more and more effort in the future. Natural language processing (NLP) facilitates this task, but it is not clear yet to which extent the extraction process is reliable or complete. In this work, we explore three NLP techniques that can help support this task: topic modeling, tailored regular expressions and the shortest dependency path method. We apply these techniques in a practical and reproducible workflow on two corpora of documents: the Open Tension-disk Infiltrometer Meta-database (OTIM) and the Meta corpus. The OTIM corpus contains the source publications of the entries of the OTIM database of near-saturated hydraulic conductivity from tension-disk infiltrometer measurements The Meta corpus is constituted of all primary studies from 36 selected meta-analyses on the impact of agricultural practices on sustainable water management in Europe. As a first step of our practical workflow, we identified different topics from the individual source publications of the Meta corpus using topic modeling. This enabled us to distinguish well-researched topics (e.g., conventional tillage, cover crops), where meta-analysis would be useful, from neglected topics (e.g., effect of irrigation on soil properties), showing potential knowledge gaps. Then, we used tailored regular expressions to extract coordinates, soil texture, soil type, rainfall, disk diameter and tensions from the OTIM corpus to build a quantitative database. We were able to retrieve the respective information with 56â% up to 100â% of all relevant information (recall) and with a precision between 83â% and 100â%. Finally, we extracted relationships between a set of drivers corresponding to different soil management practices or amendments (e.g., âbiocharâ, âzero tillageâ) and target variables (e.g., âsoil aggregateâ, âhydraulic conductivityâ, âcrop yieldâ) from thesource publications' abstracts of the Meta corpus using the shortestdependency path between them. These relationships were further classified according to positive, negative or absent correlations between the driver and the target variable. This quickly provided an overview of the different driverâvariable relationships and their abundance for an entire body of literature. Overall, we found that all three tested NLP techniques were able to support evidence synthesis tasks. While human supervision remains essential, NLP methods have the potential to support automated evidence synthesis which can be continuously updated as new publications become available.",2023,2023,3.0,The Soil,Success (Selector (div.abstract > div > p)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.5194/soil-9-155-2023,10.5194/soil-9-155-2023,https://doi.org/10.5194/soil-9-155-2023,5,"Summarizing information from large bodies of scientific literature is an essential but work-intensive task. This is especially true in environmental studies where multiple factors (e.g., soil, climate, vegetation) can contribute to the effects observed. Meta-analyses, studies that quantitatively summarize findings of a large body of literature, rely on manually curated databases built upon primary publications. However, given the increasing amount of literature, this manual work is likely to require more and more effort in the future. Natural language processing (NLP) facilitates this task, but it is not clear yet to which extent the extraction process is reliable or complete. In this work, we explore three NLP techniques that can help support this task: topic modeling, tailored regular expressions and the shortest dependency path method. We apply these techniques in a practical and reproducible workflow on two corpora of documents: the Open Tension-disk Infiltrometer Meta-database (OTIM) and the Meta corpus. The OTIM corpus contains the source publications of the entries of the OTIM database of near-saturated hydraulic conductivity from tension-disk infiltrometer measurements The Meta corpus is constituted of all primary studies from 36 selected meta-analyses on the impact of agricultural practices on sustainable water management in Europe. As a first step of our practical workflow, we identified different topics from the individual source publications of the Meta corpus using topic modeling. This enabled us to distinguish well-researched topics (e.g., conventional tillage, cover crops), where meta-analysis would be useful, from neglected topics (e.g., effect of irrigation on soil properties), showing potential knowledge gaps. Then, we used tailored regular expressions to extract coordinates, soil texture, soil type, rainfall, disk diameter and tensions from the OTIM corpus to build a quantitative database. We were able to retrieve the respective information with 56â% up to 100â% of all relevant information (recall) and with a precision between 83â% and 100â%. Finally, we extracted relationships between a set of drivers corresponding to different soil management practices or amendments (e.g., âbiocharâ, âzero tillageâ) and target variables (e.g., âsoil aggregateâ, âhydraulic conductivityâ, âcrop yieldâ) from thesource publications' abstracts of the Meta corpus using the shortestdependency path between them. These relationships were further classified according to positive, negative or absent correlations between the driver and the target variable. This quickly provided an overview of the different driverâvariable relationships and their abundance for an entire body of literature. Overall, we found that all three tested NLP techniques were able to support evidence synthesis tasks. While human supervision remains essential, NLP methods have the potential to support automated evidence synthesis which can be continuously updated as new publications become available.",Document_82,Technical aspects or methods of AI or machine learning,0.15108121931552887,Other Categories
Certified Robustness to Adversarial Word Substitutions,"Robin Jia, Aditi Raghunathan, Kerem Göksel, Percy Liang","State-of-the-art NLP models can often be fooled by adversaries that apply seemingly innocuous label-preserving transformations (e.g., paraphrasing) to input text. The number of possible transformations scales exponentially with text length, so data augmentation cannot cover all transformations of an input. This paper considers one exponentially large family of label-preserving transformations, in which every word in the input can be replaced with a similar word. We train the first models that are provably robust to all word substitutions in this family. Our training procedure uses Interval Bound Propagation (IBP) to minimize an upper bound on the worst-case loss that any combination of word substitutions can induce. To evaluate models’ robustness to these transformations, we measure accuracy on adversarially chosen word substitutions applied to test examples. Our IBP-trained models attain 75% adversarial accuracy on both sentiment analysis on IMDB and natural language inference on SNLI; in comparison, on IMDB, models trained normally and ones trained with data augmentation achieve adversarial accuracy of only 12% and 41%, respectively.",2019,2019,11.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/D19-1423,10.18653/v1/D19-1423,https://doi.org/10.18653/v1/D19-1423,283,"State-of-the-art NLP models can often be fooled by adversaries that apply seemingly innocuous label-preserving transformations (e.g., paraphrasing) to input text. The number of possible transformations scales exponentially with text length, so data augmentation cannot cover all transformations of an input. This paper considers one exponentially large family of label-preserving transformations, in which every word in the input can be replaced with a similar word. We train the first models that are provably robust to all word substitutions in this family. Our training procedure uses Interval Bound Propagation (IBP) to minimize an upper bound on the worst-case loss that any combination of word substitutions can induce. To evaluate models’ robustness to these transformations, we measure accuracy on adversarially chosen word substitutions applied to test examples. Our IBP-trained models attain 75% adversarial accuracy on both sentiment analysis on IMDB and natural language inference on SNLI; in comparison, on IMDB, models trained normally and ones trained with data augmentation achieve adversarial accuracy of only 12% and 41%, respectively.",Document_83,Technical aspects or methods of AI or machine learning,0.08190080523490906,Other Categories
ERASER: A Benchmark to Evaluate Rationalized NLP Models,"Jay DeYoung, Sarthak Jain, Nazneen Rajani, Eric P. Lehman, Caiming Xiong, R. Socher, Byron C. Wallace","State-of-the-art models in NLP are now predominantly based on deep neural networks that are opaque in terms of how they come to make predictions. This limitation has increased interest in designing more interpretable deep models for NLP that reveal the ‘reasoning’ behind model outputs. But work in this direction has been conducted on different datasets and tasks with correspondingly unique aims and metrics; this makes it difficult to track progress. We propose the E valuating R ationales A nd S imple E nglish R easoning ( ERASER a benchmark to advance research on interpretable models in NLP. This benchmark comprises multiple datasets and tasks for which human annotations of “rationales” (supporting evidence) have been collected. We propose several metrics that aim to capture how well the rationales provided by models align with human rationales, and also how faithful these rationales are (i.e., the degree to which provided rationales influenced the corresponding predictions). Our hope is that releasing this benchmark facilitates progress on designing more interpretable NLP systems. The benchmark, code, and documentation are available at https://www.eraserbenchmark.com/",2019,2020,7.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.acl-main.408,10.18653/v1/2020.acl-main.408,https://doi.org/10.18653/v1/2020.acl-main.408,579,"State-of-the-art models in NLP are now predominantly based on deep neural networks that are opaque in terms of how they come to make predictions. This limitation has increased interest in designing more interpretable deep models for NLP that reveal the ‘reasoning’ behind model outputs. But work in this direction has been conducted on different datasets and tasks with correspondingly unique aims and metrics; this makes it difficult to track progress. We propose the E valuating R ationales A nd S imple E nglish R easoning ( ERASER a benchmark to advance research on interpretable models in NLP. This benchmark comprises multiple datasets and tasks for which human annotations of “rationales” (supporting evidence) have been collected. We propose several metrics that aim to capture how well the rationales provided by models align with human rationales, and also how faithful these rationales are (i.e., the degree to which provided rationales influenced the corresponding predictions). Our hope is that releasing this benchmark facilitates progress on designing more interpretable NLP systems. The benchmark, code, and documentation are available at https://www.eraserbenchmark.com/",Document_84,Technical aspects or methods of AI or machine learning,0.09617407619953156,Other Categories
Reevaluating Adversarial Examples in Natural Language,"John X. Morris, Eli Lifland, Jack Lanchantin, Yangfeng Ji, Yanjun Qi","State-of-the-art attacks on NLP models lack a shared definition of a what constitutes a successful attack. We distill ideas from past work into a unified framework: a successful natural language adversarial example is a perturbation that fools the model and follows some linguistic constraints. We then analyze the outputs of two state-of-the-art synonym substitution attacks. We find that their perturbations often do not preserve semantics, and 38% introduce grammatical errors. Human surveys reveal that to successfully preserve semantics, we need to significantly increase the minimum cosine similarities between the embeddings of swapped words and between the sentence encodings of original and perturbed sentences. With constraints adjusted to better preserve semantics and grammaticality, the attack success rate drops by over 70 percentage points.",2020,2020,11.0,Findings,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.findings-emnlp.341,10.18653/v1/2020.findings-emnlp.341,https://doi.org/10.18653/v1/2020.findings-emnlp.341,107,"State-of-the-art attacks on NLP models lack a shared definition of a what constitutes a successful attack. We distill ideas from past work into a unified framework: a successful natural language adversarial example is a perturbation that fools the model and follows some linguistic constraints. We then analyze the outputs of two state-of-the-art synonym substitution attacks. We find that their perturbations often do not preserve semantics, and 38% introduce grammatical errors. Human surveys reveal that to successfully preserve semantics, we need to significantly increase the minimum cosine similarities between the embeddings of swapped words and between the sentence encodings of original and perturbed sentences. With constraints adjusted to better preserve semantics and grammaticality, the attack success rate drops by over 70 percentage points.",Document_85,Security risks associated with AI are a concern in financial regulation,0.06854119896888733,Organizational and Human Barriers
Assessing the quality of the requirements specification by applying GQM approach and using NLP tools,Evgeny Timoshchuk,"Software requirements are quite difficult to measure in terms of quality without reviews and subjective opinions of stakeholders. Quality assessment of specifications in an automated way saves project resources and prevents future latent defects in software. Requirements quality can be evaluated based on a huge variety of attributes, but their meaning is quite vague without any mapping to specific measurement metrics. Application of goal-question-metric (GQM) approach in the quality model helps to choose the most important quality attributes and create a mapping with metrics, which can be collected and calculated automatically. Text of software requirements written in natural language can be analyzed by NLP tools due to identify weak signle words and phrases, which make statements ambiguous. Metrics for such quality attributes as ambiguity, singularity, subjectivity, completeness, and readability are proposed in this work. The quality model was implemented in a prototype by adopting natural language processing techniques for requirements written in the Russian language with the support of external API.",2020,2020,6.0,Proceedings of the Institute for System Programming of RAS,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (Meta (article:published_time)) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.58) (URL Source: DOI Link)",https://doi.org/10.15514/ispras-2020-32(2)-2,10.15514/ispras-2020-32(2)-2,https://doi.org/10.15514/ispras-2020-32(2)-2,3,"Software requirements are quite difficult to measure in terms of quality without reviews and subjective opinions of stakeholders. Quality assessment of specifications in an automated way saves project resources and prevents future latent defects in software. Requirements quality can be evaluated based on a huge variety of attributes, but their meaning is quite vague without any mapping to specific measurement metrics. Application of goal-question-metric (GQM) approach in the quality model helps to choose the most important quality attributes and create a mapping with metrics, which can be collected and calculated automatically. Text of software requirements written in natural language can be analyzed by NLP tools due to identify weak signle words and phrases, which make statements ambiguous. Metrics for such quality attributes as ambiguity, singularity, subjectivity, completeness, and readability are proposed in this work. The quality model was implemented in a prototype by adopting natural language processing techniques for requirements written in the Russian language with the support of external API.",Document_86,Technical aspects or methods of AI or machine learning,0.06608162075281143,Other Categories
Bad Characters: Imperceptible NLP Attacks,"N. Boucher, Ilia Shumailov, Ross Anderson, Nicolas Papernot","Several years of research have shown that machine-learning systems are vulnerable to adversarial examples, both in theory and in practice. Until now, such attacks have primarily targeted visual models, exploiting the gap between human and machine perception. Although text-based models have also been attacked with adversarial examples, such attacks struggled to preserve semantic meaning and indistinguishability. In this paper, we explore a large class of adversarial examples that can be used to attack text-based models in a black-box setting without making any human-perceptible visual modification to inputs. We use encoding-specific perturbations that are imperceptible to the human eye to manipulate the outputs of a wide range of Natural Language Processing (NLP) systems from neural machine-translation pipelines to web search engines. We find that with a single imperceptible encoding injection – representing one invisible character, homoglyph, reordering, or deletion – an attacker can significantly reduce the performance of vulnerable models, and with three injections most models can be functionally broken. Our attacks work against currently-deployed commercial systems, including those produced by Microsoft and Google, in addition to open source models published by Facebook, IBM, and HuggingFace. This novel series of attacks presents a significant threat to many language processing systems: an attacker can affect systems in a targeted manner without any assumptions about the underlying model. We conclude that text-based NLP systems require careful input sanitization, just like conventional applications, and that given such systems are now being deployed rapidly at scale, the urgent attention of architects and operators is required.",2021,2021,,IEEE Symposium on Security and Privacy,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/sp46214.2022.9833641,10.1109/sp46214.2022.9833641,https://doi.org/10.1109/sp46214.2022.9833641,93,"Several years of research have shown that machine-learning systems are vulnerable to adversarial examples, both in theory and in practice. Until now, such attacks have primarily targeted visual models, exploiting the gap between human and machine perception. Although text-based models have also been attacked with adversarial examples, such attacks struggled to preserve semantic meaning and indistinguishability. In this paper, we explore a large class of adversarial examples that can be used to attack text-based models in a black-box setting without making any human-perceptible visual modification to inputs. We use encoding-specific perturbations that are imperceptible to the human eye to manipulate the outputs of a wide range of Natural Language Processing (NLP) systems from neural machine-translation pipelines to web search engines. We find that with a single imperceptible encoding injection – representing one invisible character, homoglyph, reordering, or deletion – an attacker can significantly reduce the performance of vulnerable models, and with three injections most models can be functionally broken. Our attacks work against currently-deployed commercial systems, including those produced by Microsoft and Google, in addition to open source models published by Facebook, IBM, and HuggingFace. This novel series of attacks presents a significant threat to many language processing systems: an attacker can affect systems in a targeted manner without any assumptions about the underlying model. We conclude that text-based NLP systems require careful input sanitization, just like conventional applications, and that given such systems are now being deployed rapidly at scale, the urgent attention of architects and operators is required.",Document_87,Technical aspects or methods of AI or machine learning,0.08333844691514969,Other Categories
An automated framework for the extraction of semantic legal metadata from legal texts,"Amin Sleimi, Nicolas Sannier, M. Sabetzadeh, L. Briand, M. Ceci, J. Dann","Semantic legal metadata provides information that helps with understanding and interpreting legal provisions. Such metadata is therefore important for the systematic analysis of legal requirements. However, manually enhancing a large legal corpus with semantic metadata is prohibitively expensive. Our work is motivated by two observations: (1) the existing requirements engineering (RE) literature does not provide a harmonized view on the semantic metadata types that are useful for legal requirements analysis; (2) automated support for the extraction of semantic legal metadata is scarce, and it does not exploit the full potential of artificial intelligence technologies, notably natural language processing (NLP) and machine learning (ML). Our objective is to take steps toward overcoming these limitations. To do so, we review and reconcile the semantic legal metadata types proposed in the RE literature. Subsequently, we devise an automated extraction approach for the identified metadata types using NLP and ML. We evaluate our approach through two case studies over the Luxembourgish legislation. Our results indicate a high accuracy in the generation of metadata annotations. In particular, in the two case studies, we were able to obtain precision scores of 97,2% and 82,4%, and recall scores of 94,9% and 92,4%.",2020,2021,5.0,Empirical Software Engineering,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10664-020-09933-5,10.1007/s10664-020-09933-5,https://doi.org/10.1007/s10664-020-09933-5,25,"Semantic legal metadata provides information that helps with understanding and interpreting legal provisions. Such metadata is therefore important for the systematic analysis of legal requirements. However, manually enhancing a large legal corpus with semantic metadata is prohibitively expensive. Our work is motivated by two observations: (1) the existing requirements engineering (RE) literature does not provide a harmonized view on the semantic metadata types that are useful for legal requirements analysis; (2) automated support for the extraction of semantic legal metadata is scarce, and it does not exploit the full potential of artificial intelligence technologies, notably natural language processing (NLP) and machine learning (ML). Our objective is to take steps toward overcoming these limitations. To do so, we review and reconcile the semantic legal metadata types proposed in the RE literature. Subsequently, we devise an automated extraction approach for the identified metadata types using NLP and ML. We evaluate our approach through two case studies over the Luxembourgish legislation. Our results indicate a high accuracy in the generation of metadata annotations. In particular, in the two case studies, we were able to obtain precision scores of 97,2% and 82,4%, and recall scores of 94,9% and 92,4%.",Document_88,Technical aspects or methods of AI or machine learning,0.23072464764118195,Other Categories
Privacy-aware blockchain for personal data sharing and tracking,"Md. Mehedi Hassan Onik, Chul-Soo Kim, N. Lee, Jinhong Yang","Secure data distribution is critical for data accountability. Surveillance caused privacy breaching incidents have already questioned existing personal data collection techniques. Organizations assemble a huge amount of personally identifiable information (PII) for data-driven market analysis and prediction. However, the limitation of data tracking tools restricts the detection of exact data breaching points. Blockchain technology, an ‘immutable’ distributed ledger, can be leveraged to establish a transparent data auditing platform. However, Art. 42 and Art. 25 of general data protection regulation (GDPR) demands ‘right to forget’ and ‘right to erase’ of personal information, which goes against the immutability of blockchain technology. This paper proposes a GDPR complied decentralized and trusted PII sharing and tracking scheme. Proposed blockchain based personally identifiable information management system (BcPIIMS) demonstrates data movement among GDPR entities (user, controller and processor). Considering GDPR limitations, BcPIIMS used off-the-chain data storing architecture. A prototype was created to validate the proposed architecture using multichain. The use of off-the-chain storage reduces individual block size. Additionally, private blockchain also limits personal data leaking by collecting fast approval from restricted peers. This study presents personal data sharing, deleting, modifying and tracking features to verify the privacy of proposed blockchain based personally identifiable information management system.",2019,2019,1.0,Open Computer Science,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML) - Short, Score: 0.38) (URL Source: DOI Link)",https://doi.org/10.1515/comp-2019-0005,10.1515/comp-2019-0005,https://doi.org/10.1515/comp-2019-0005,50,"Secure data distribution is critical for data accountability. Surveillance caused privacy breaching incidents have already questioned existing personal data collection techniques. Organizations assemble a huge amount of personally identifiable information (PII) for data-driven market analysis and prediction. However, the limitation of data tracking tools restricts the detection of exact data breaching points. Blockchain technology, an ‘immutable’ distributed ledger, can be leveraged to establish a transparent data auditing platform. However, Art. 42 and Art. 25 of general data protection regulation (GDPR) demands ‘right to forget’ and ‘right to erase’ of personal information, which goes against the immutability of blockchain technology. This paper proposes a GDPR complied decentralized and trusted PII sharing and tracking scheme. Proposed blockchain based personally identifiable information management system (BcPIIMS) demonstrates data movement among GDPR entities (user, controller and processor). Considering GDPR limitations, BcPIIMS used off-the-chain data storing architecture. A prototype was created to validate the proposed architecture using multichain. The use of off-the-chain storage reduces individual block size. Additionally, private blockchain also limits personal data leaking by collecting fast approval from restricted peers. This study presents personal data sharing, deleting, modifying and tracking features to verify the privacy of proposed blockchain based personally identifiable information management system.",Document_89,General discussion of financial or regulatory topics (non-AI focus),0.0654376819729805,Other Categories
NgramPOS: a bigram-based linguistic and statistical feature process model for unstructured text classification,"Sepideh Foroozan Yazdani, Zhiyuan Tan, Mohsen Kakavand, A. Mustapha","Research in financial domain has shown that sentiment aspects of stock news have a profound impact on volume trades, volatility, stock prices and firm earnings. In-depth analysis of stock news is now sourced from financial reviews by various social networking and marketing sites to help improve decision making. Nonetheless, such reviews are in the form of unstructured text, which requires natural language processing (NLP) in order to extract the sentiments. Accordingly, in this study we investigate the use of NLP tasks in effort to improve the performance of sentiment classification in evaluating the information content of financial news as an instrument in investment decision support system. At present, feature extraction approach is mainly based on the occurrence frequency of words. Therefore low-frequency linguistic features that could be critical in sentiment classification are typically ignored. In this research, we attempt to improve current sentiment analysis approaches for financial news classification by focusing on low-frequency but informative linguistic expressions. Our proposed combination of low and high-frequency linguistic expressions contributes a novel set of features for sentiment classification. The experimental results show that an optimal Ngram feature selection (combination of optimal unigram and bigram features) enhances sentiment classification accuracy as compared to other types of feature sets.",2018,2022,4.0,Wireless networks,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s11276-018-01909-0,10.1007/s11276-018-01909-0,https://doi.org/10.1007/s11276-018-01909-0,5,"Research in financial domain has shown that sentiment aspects of stock news have a profound impact on volume trades, volatility, stock prices and firm earnings. In-depth analysis of stock news is now sourced from financial reviews by various social networking and marketing sites to help improve decision making. Nonetheless, such reviews are in the form of unstructured text, which requires natural language processing (NLP) in order to extract the sentiments. Accordingly, in this study we investigate the use of NLP tasks in effort to improve the performance of sentiment classification in evaluating the information content of financial news as an instrument in investment decision support system. At present, feature extraction approach is mainly based on the occurrence frequency of words. Therefore low-frequency linguistic features that could be critical in sentiment classification are typically ignored. In this research, we attempt to improve current sentiment analysis approaches for financial news classification by focusing on low-frequency but informative linguistic expressions. Our proposed combination of low and high-frequency linguistic expressions contributes a novel set of features for sentiment classification. The experimental results show that an optimal Ngram feature selection (combination of optimal unigram and bigram features) enhances sentiment classification accuracy as compared to other types of feature sets.",Document_90,Highlighting the benefits of AI for customer insights in finance,0.07116010040044785,Business Case and Value Demonstration Strategies
"NLP for Requirements Engineering: Tasks, Techniques, Tools, and Technologies","Alessio Ferrari, Liping Zhao, Waad Alhoshan","Requirements engineering (RE) is one of the most natural language-intensive fields within the software engineering area. Therefore, several works have been developed across the years to automate the analysis of natural language artifacts that are relevant for RE, including requirements documents, but also app reviews, privacy policies, and social media content related to software products. Furthermore, the recent diffusion of game-changing natural language processing (NLP) techniques and plat-forms has also boosted the interest of RE researchers. However, a reference framework to provide a holistic understanding of the field of NLP for RE is currently missing. Based on the results of a recent systematic mapping study, and stemming from a previous ICSE tutorial by one of the authors, this technical briefing gives an overview of NLP for RE tasks, available techniques, supporting tools and NLP technologies. It is oriented to both researchers and practitioners, and will gently guide the audience towards a clearer view of how NLP can empower RE, providing pointers to representative works and specialised tools.",2021,2021,,2021 IEEE/ACM 43rd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion),"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ICSE-Companion52605.2021.00137,10.1109/ICSE-Companion52605.2021.00137,https://doi.org/10.1109/ICSE-Companion52605.2021.00137,18,"Requirements engineering (RE) is one of the most natural language-intensive fields within the software engineering area. Therefore, several works have been developed across the years to automate the analysis of natural language artifacts that are relevant for RE, including requirements documents, but also app reviews, privacy policies, and social media content related to software products. Furthermore, the recent diffusion of game-changing natural language processing (NLP) techniques and plat-forms has also boosted the interest of RE researchers. However, a reference framework to provide a holistic understanding of the field of NLP for RE is currently missing. Based on the results of a recent systematic mapping study, and stemming from a previous ICSE tutorial by one of the authors, this technical briefing gives an overview of NLP for RE tasks, available techniques, supporting tools and NLP technologies. It is oriented to both researchers and practitioners, and will gently guide the audience towards a clearer view of how NLP can empower RE, providing pointers to representative works and specialised tools.",Document_91,Building organizational support for AI through education and communication,0.10725663602352142,"Education, Awareness, and Policy Strategies"
Responsible model deployment via model-agnostic uncertainty learning,"Preethi Lahoti, K. Gummadi, G. Weikum","Reliably predicting potential failure risks of machine learning (ML) systems when deployed with production data is a crucial aspect of trustworthy AI. This paper introduces the Risk Advisor , a novel post-hoc meta-learner for estimating failure risks and predictive uncertainties of any already-trained black-box classification model. In addition to providing a risk score , the Risk Advisor decomposes the uncertainty estimates into aleatoric and epistemic uncertainty components, thus giving informative insights into the sources of uncertainty inducing the failures. Consequently, Risk Advisor can distinguish between failures caused by data variability, data shifts and model limitations and provide useful guidance on appropriate risk mitigation actions (e.g., collecting more data to counter data shift). Extensive experiments on various families of black-box classification models and on real-world and synthetic datasets covering common ML failure scenarios show that the Risk Advisor reliably predicts deployment-time failure risks in all the scenarios, and outperforms strong baselines.",2022,2023,3.0,Machine-mediated learning,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10994-022-06248-y,10.1007/s10994-022-06248-y,https://doi.org/10.1007/s10994-022-06248-y,3,"Reliably predicting potential failure risks of machine learning (ML) systems when deployed with production data is a crucial aspect of trustworthy AI. This paper introduces the Risk Advisor , a novel post-hoc meta-learner for estimating failure risks and predictive uncertainties of any already-trained black-box classification model. In addition to providing a risk score , the Risk Advisor decomposes the uncertainty estimates into aleatoric and epistemic uncertainty components, thus giving informative insights into the sources of uncertainty inducing the failures. Consequently, Risk Advisor can distinguish between failures caused by data variability, data shifts and model limitations and provide useful guidance on appropriate risk mitigation actions (e.g., collecting more data to counter data shift). Extensive experiments on various families of black-box classification models and on real-world and synthetic datasets covering common ML failure scenarios show that the Risk Advisor reliably predicts deployment-time failure risks in all the scenarios, and outperforms strong baselines.",Document_92,Demonstrating the value of AI for compliance and risk management,0.15169762074947357,Business Case and Value Demonstration Strategies
Cognitive Compliance for Financial Regulations,"Arvind Agarwal, Balaji Ganesan, Ankush Gupta, Nitisha Jain, Hima P. Karanam, Arun Kumar, Nishtha Madaan, Vitobha Munigala, Srikanth G. Tamilselvam","Regulations are rules and directives published by authorities to safeguard consumer interest in an industry. Compliance with such regulations is getting increasingly hard due both to the complexity of these documents, which require experts to read, understand, and interpret them manually, and to the sheer volume of regulatory change. Many CFOs rate this as their top challenge. The authors' Cogpliance platform uses a cognitive approach to achieve regulatory compliance. Here, they describe key compliance-related tasks and demonstrate how Cogpliance helps compliance officers to handle those tasks effectively.",2017,2017,,IT Professional,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/MITP.2017.3051333,10.1109/MITP.2017.3051333,https://doi.org/10.1109/MITP.2017.3051333,11,"Regulations are rules and directives published by authorities to safeguard consumer interest in an industry. Compliance with such regulations is getting increasingly hard due both to the complexity of these documents, which require experts to read, understand, and interpret them manually, and to the sheer volume of regulatory change. Many CFOs rate this as their top challenge. The authors' Cogpliance platform uses a cognitive approach to achieve regulatory compliance. Here, they describe key compliance-related tasks and demonstrate how Cogpliance helps compliance officers to handle those tasks effectively.",Document_93,Demonstrating the value of AI for compliance and risk management,0.10901293158531189,Business Case and Value Demonstration Strategies
Weight Poisoning Attacks on Pretrained Models,"Keita Kurita, Paul Michel, Graham Neubig","Recently, NLP has seen a surge in the usage of large pre-trained models. Users download weights of models pre-trained on large datasets, then fine-tune the weights on a task of their choice. This raises the question of whether downloading untrusted pre-trained weights can pose a security threat. In this paper, we show that it is possible to construct “weight poisoning” attacks where pre-trained weights are injected with vulnerabilities that expose “backdoors” after fine-tuning, enabling the attacker to manipulate the model prediction simply by injecting an arbitrary keyword. We show that by applying a regularization method which we call RIPPLe and an initialization procedure we call Embedding Surgery, such attacks are possible even with limited knowledge of the dataset and fine-tuning procedure. Our experiments on sentiment classification, toxicity detection, and spam detection show that this attack is widely applicable and poses a serious threat. Finally, we outline practical defenses against such attacks.",2020,2020,7.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.acl-main.249,10.18653/v1/2020.acl-main.249,https://doi.org/10.18653/v1/2020.acl-main.249,388,"Recently, NLP has seen a surge in the usage of large pre-trained models. Users download weights of models pre-trained on large datasets, then fine-tune the weights on a task of their choice. This raises the question of whether downloading untrusted pre-trained weights can pose a security threat. In this paper, we show that it is possible to construct “weight poisoning” attacks where pre-trained weights are injected with vulnerabilities that expose “backdoors” after fine-tuning, enabling the attacker to manipulate the model prediction simply by injecting an arbitrary keyword. We show that by applying a regularization method which we call RIPPLe and an initialization procedure we call Embedding Surgery, such attacks are possible even with limited knowledge of the dataset and fine-tuning procedure. Our experiments on sentiment classification, toxicity detection, and spam detection show that this attack is widely applicable and poses a serious threat. Finally, we outline practical defenses against such attacks.",Document_94,Technical aspects or methods of AI or machine learning,0.11445154249668121,Other Categories
Privacy Risks of General-Language Models,"Xudong Pan, Mi Zhang, S. Ji, Min Yang","Recently, a new paradigm of building general-purpose language models (e.g., Google’s Bert and OpenAI’s GPT-2) in Natural Language Processing (NLP) for text feature extraction, a standard procedure in NLP systems that converts texts to vectors (i.e., embeddings) for downstream modeling, has arisen and starts to find its application in various downstream NLP tasks and real world systems (e.g., Google’s search engine [6]). To obtain general-purpose text embeddings, these language models have highly complicated architectures with millions of learnable parameters and are usually pretrained on billions of sentences before being utilized. As is widely recognized, such a practice indeed improves the state-of-the-art performance of many downstream NLP tasks. However, the improved utility is not for free. We find the text embeddings from general-purpose language models would capture much sensitive information from the plain text. Once being accessed by the adversary, the embeddings can be reverse-engineered to disclose sensitive information of the victims for further harassment. Although such a privacy risk can impose a real threat to the future leverage of these promising NLP tools, there are neither published attacks nor systematic evaluations by far for the mainstream industry-level language models. To bridge this gap, we present the first systematic study on the privacy risks of 8 state-of-the-art language models with 4 diverse case studies. By constructing 2 novel attack classes, our study demonstrates the aforementioned privacy risks do exist and can impose practical threats to the application of general-purpose language models on sensitive data covering identity, genome, healthcare and location. For example, we show the adversary with nearly no prior knowledge can achieve about 75% accuracy when inferring the precise disease site from Bert embeddings of patients’ medical descriptions. As possible countermeasures, we propose 4 different defenses (via rounding, differential privacy, adversarial training and subspace projection) to obfuscate the unprotected embeddings for mitigation purpose. With extensive evaluations, we also provide a preliminary analysis on the utility-privacy trade-off brought by each defense, which we hope may foster future mitigation researches.",2020,2020,,IEEE Symposium on Security and Privacy,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/SP40000.2020.00095,10.1109/SP40000.2020.00095,https://doi.org/10.1109/SP40000.2020.00095,180,"Recently, a new paradigm of building general-purpose language models (e.g., Google’s Bert and OpenAI’s GPT-2) in Natural Language Processing (NLP) for text feature extraction, a standard procedure in NLP systems that converts texts to vectors (i.e., embeddings) for downstream modeling, has arisen and starts to find its application in various downstream NLP tasks and real world systems (e.g., Google’s search engine [6]). To obtain general-purpose text embeddings, these language models have highly complicated architectures with millions of learnable parameters and are usually pretrained on billions of sentences before being utilized. As is widely recognized, such a practice indeed improves the state-of-the-art performance of many downstream NLP tasks. However, the improved utility is not for free. We find the text embeddings from general-purpose language models would capture much sensitive information from the plain text. Once being accessed by the adversary, the embeddings can be reverse-engineered to disclose sensitive information of the victims for further harassment. Although such a privacy risk can impose a real threat to the future leverage of these promising NLP tools, there are neither published attacks nor systematic evaluations by far for the mainstream industry-level language models. To bridge this gap, we present the first systematic study on the privacy risks of 8 state-of-the-art language models with 4 diverse case studies. By constructing 2 novel attack classes, our study demonstrates the aforementioned privacy risks do exist and can impose practical threats to the application of general-purpose language models on sensitive data covering identity, genome, healthcare and location. For example, we show the adversary with nearly no prior knowledge can achieve about 75% accuracy when inferring the precise disease site from Bert embeddings of patients’ medical descriptions. As possible countermeasures, we propose 4 different defenses (via rounding, differential privacy, adversarial training and subspace projection) to obfuscate the unprotected embeddings for mitigation purpose. With extensive evaluations, we also provide a preliminary analysis on the utility-privacy trade-off brought by each defense, which we hope may foster future mitigation researches.",Document_95,Technical aspects or methods of AI or machine learning,0.21899288892745972,Other Categories
Trojaning Language Models for Fun and Profit,"Xinyang Zhang, Zheng Zhang, Ting Wang","Recent years have witnessed the emergence of a new paradigm of building natural language processing (NLP) systems: general-purpose, pre-trained language models (LMs) are composed with simple downstream models and fine-tuned for a variety of NLP tasks. This paradigm shift significantly simplifies the system development cycles. However, as many LMs are provided by untrusted third parties, their lack of standardization or regulation entails profound security implications, which are largely unexplored. To bridge this gap, this work studies the security threats posed by malicious LMs to NLP systems. Specifically, we present Trojan<sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">LM</sup>, a new class of trojaning attacks in which maliciously crafted LMs trigger host NLP systems to malfunction in a highly predictable manner. By empirically studying three state-of-the-art LMs (BERT, GPT-2, XLNet) in a range of security-critical NLP tasks (toxic comment detection, question answering, text completion) as well as user studies on crowdsourcing platforms, we demonstrate that Trojan<sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">LM</sup> possesses the following properties: (i) flexibility - the adversary is able to flexibly define logical combinations (e.g., ‘and’, ‘or’, ‘xor’) of arbitrary words as triggers, (ii) efficacy - the host systems misbehave as desired by the adversary with high probability when “trigger” -embedded inputs are present, (iii) specificity - the trojan LMs function indistinguishably from their benign counterparts on clean inputs, and (iv) fluency - the trigger-embedded inputs appear as fluent natural language and highly relevant to their surrounding contexts. We provide analytical justification for the practicality of Trojan<sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">LM</sup>, and further discuss potential countermeasures and their challenges, which lead to several promising research directions.",2020,2020,,European Symposium on Security and Privacy,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/EuroSP51992.2021.00022,10.1109/EuroSP51992.2021.00022,https://doi.org/10.1109/EuroSP51992.2021.00022,120,"Recent years have witnessed the emergence of a new paradigm of building natural language processing (NLP) systems: general-purpose, pre-trained language models (LMs) are composed with simple downstream models and fine-tuned for a variety of NLP tasks. This paradigm shift significantly simplifies the system development cycles. However, as many LMs are provided by untrusted third parties, their lack of standardization or regulation entails profound security implications, which are largely unexplored. To bridge this gap, this work studies the security threats posed by malicious LMs to NLP systems. Specifically, we present Trojan<sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">LM</sup>, a new class of trojaning attacks in which maliciously crafted LMs trigger host NLP systems to malfunction in a highly predictable manner. By empirically studying three state-of-the-art LMs (BERT, GPT-2, XLNet) in a range of security-critical NLP tasks (toxic comment detection, question answering, text completion) as well as user studies on crowdsourcing platforms, we demonstrate that Trojan<sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">LM</sup> possesses the following properties: (i) flexibility - the adversary is able to flexibly define logical combinations (e.g., ‘and’, ‘or’, ‘xor’) of arbitrary words as triggers, (ii) efficacy - the host systems misbehave as desired by the adversary with high probability when “trigger” -embedded inputs are present, (iii) specificity - the trojan LMs function indistinguishably from their benign counterparts on clean inputs, and (iv) fluency - the trigger-embedded inputs appear as fluent natural language and highly relevant to their surrounding contexts. We provide analytical justification for the practicality of Trojan<sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">LM</sup>, and further discuss potential countermeasures and their challenges, which lead to several promising research directions.",Document_96,Building organizational support for AI through education and communication,0.05224594473838806,"Education, Awareness, and Policy Strategies"
A Survey of the State of Explainable AI for Natural Language Processing,"Marina Danilevsky, Kun Qian, R. Aharonov, Yannis Katsis, B. Kawas, Prithviraj Sen","Recent years have seen important advances in the quality of state-of-the-art models, but this has come at the expense of models becoming less interpretable. This survey presents an overview of the current state of Explainable AI (XAI), considered within the domain of Natural Language Processing (NLP). We discuss the main categorization of explanations, as well as the various ways explanations can be arrived at and visualized. We detail the operations and explainability techniques currently available for generating explanations for NLP model predictions, to serve as a resource for model developers in the community. Finally, we point out the current gaps and encourage directions for future work in this important research area.",2020,2020,12.0,AACL,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.aacl-main.46,10.18653/v1/2020.aacl-main.46,https://doi.org/10.18653/v1/2020.aacl-main.46,334,"Recent years have seen important advances in the quality of state-of-the-art models, but this has come at the expense of models becoming less interpretable. This survey presents an overview of the current state of Explainable AI (XAI), considered within the domain of Natural Language Processing (NLP). We discuss the main categorization of explanations, as well as the various ways explanations can be arrived at and visualized. We detail the operations and explainability techniques currently available for generating explanations for NLP model predictions, to serve as a resource for model developers in the community. Finally, we point out the current gaps and encourage directions for future work in this important research area.",Document_97,Technical aspects or methods of AI or machine learning,0.1477595865726471,Other Categories
Interpreting Black-Box Models: A Review on Explainable Artificial Intelligence,"Vikas Hassija, V. Chamola, Atmesh Mahapatra, Abhinandan Singal, Divyansh Goel, Kaizhu Huang, Simone Scardapane, Indro Spinelli, Mufti Mahmud, Amir Hussain","Recent years have seen a tremendous growth in Artificial Intelligence (AI)-based methodological development in a broad range of domains. In this rapidly evolving field, large number of methods are being reported using machine learning (ML) and Deep Learning (DL) models. Majority of these models are inherently complex and lacks explanations of the decision making process causing these models to be termed as 'Black-Box'. One of the major bottlenecks to adopt such models in mission-critical application domains, such as banking, e-commerce, healthcare, and public services and safety, is the difficulty in interpreting them. Due to the rapid proleferation of these AI models, explaining their learning and decision making process are getting harder which require transparency and easy predictability. Aiming to collate the current state-of-the-art in interpreting the black-box models, this study provides a comprehensive analysis of the explainable AI (XAI) models. To reduce false negative and false positive outcomes of these back-box models, finding flaws in them is still difficult and inefficient. In this paper, the development of XAI is reviewed meticulously through careful selection and analysis of the current state-of-the-art of XAI research. It also provides a comprehensive and in-depth evaluation of the XAI frameworks and their efficacy to serve as a starting point of XAI for applied and theoretical researchers. Towards the end, it highlights emerging and critical issues pertaining to XAI research to showcase major, model-specific trends for better explanation, enhanced transparency, and improved prediction accuracy.",2023,2024,1.0,Cognitive Computation,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s12559-023-10179-8,10.1007/s12559-023-10179-8,https://doi.org/10.1007/s12559-023-10179-8,256,"Recent years have seen a tremendous growth in Artificial Intelligence (AI)-based methodological development in a broad range of domains. In this rapidly evolving field, large number of methods are being reported using machine learning (ML) and Deep Learning (DL) models. Majority of these models are inherently complex and lacks explanations of the decision making process causing these models to be termed as 'Black-Box'. One of the major bottlenecks to adopt such models in mission-critical application domains, such as banking, e-commerce, healthcare, and public services and safety, is the difficulty in interpreting them. Due to the rapid proleferation of these AI models, explaining their learning and decision making process are getting harder which require transparency and easy predictability. Aiming to collate the current state-of-the-art in interpreting the black-box models, this study provides a comprehensive analysis of the explainable AI (XAI) models. To reduce false negative and false positive outcomes of these back-box models, finding flaws in them is still difficult and inefficient. In this paper, the development of XAI is reviewed meticulously through careful selection and analysis of the current state-of-the-art of XAI research. It also provides a comprehensive and in-depth evaluation of the XAI frameworks and their efficacy to serve as a starting point of XAI for applied and theoretical researchers. Towards the end, it highlights emerging and critical issues pertaining to XAI research to showcase major, model-specific trends for better explanation, enhanced transparency, and improved prediction accuracy.",Document_98,Technical aspects or methods of AI or machine learning,0.2791500985622406,Other Categories
Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution,"Fanchao Qi, Yuan Yao, Sophia Xu, Zhiyuan Liu, Maosong Sun","Recent studies show that neural natural language processing (NLP) models are vulnerable to backdoor attacks. Injected with backdoors, models perform normally on benign examples but produce attacker-specified predictions when the backdoor is activated, presenting serious security threats to real-world applications. Since existing textual backdoor attacks pay little attention to the invisibility of backdoors, they can be easily detected and blocked. In this work, we present invisible backdoors that are activated by a learnable combination of word substitution. We show that NLP models can be injected with backdoors that lead to a nearly 100% attack success rate, whereas being highly invisible to existing defense strategies and even human inspections. The results raise a serious alarm to the security of NLP models, which requires further research to be resolved. All the data and code of this paper are released at https://github.com/thunlp/BkdAtk-LWS .",2021,2021,8.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2021.acl-long.377,10.18653/v1/2021.acl-long.377,https://doi.org/10.18653/v1/2021.acl-long.377,118,"Recent studies show that neural natural language processing (NLP) models are vulnerable to backdoor attacks. Injected with backdoors, models perform normally on benign examples but produce attacker-specified predictions when the backdoor is activated, presenting serious security threats to real-world applications. Since existing textual backdoor attacks pay little attention to the invisibility of backdoors, they can be easily detected and blocked. In this work, we present invisible backdoors that are activated by a learnable combination of word substitution. We show that NLP models can be injected with backdoors that lead to a nearly 100% attack success rate, whereas being highly invisible to existing defense strategies and even human inspections. The results raise a serious alarm to the security of NLP models, which requires further research to be resolved. All the data and code of this paper are released at https://github.com/thunlp/BkdAtk-LWS .",Document_99,Technical aspects or methods of AI or machine learning,0.1399490386247635,Other Categories
On Measures of Biases and Harms in NLP,"Sunipa Dev, Emily Sheng, Jieyu Zhao, Aubrie Amstutz, Jiao Sun, Yu Hou, M. Sanseverino, Jiin Kim, Akihiro Nishi, Nanyun Peng, Kai-Wei Chang","Recent studies show that Natural Language Processing (NLP) technologies propagate societal biases about demographic groups associated with attributes such as gender, race, and nationality. To create interventions and mitigate these biases and associated harms, it is vital to be able to detect and measure such biases. While existing works propose bias evaluation and mitigation methods for various tasks, there remains a need to cohesively understand the biases and the specific harms they measure, and how different measures compare with each other. To address this gap, this work presents a practical framework of harms and a series of questions that practitioners can answer to guide the development of bias measures. As a validation of our framework and documentation questions, we also present several case studies of how existing bias measures in NLP—both intrinsic measures of bias in representations and extrinsic measures of bias of downstream applications—can be aligned with different harms and how our proposed documentation questions facilitates more holistic understanding of what bias measures are measuring.",2021,2022,11.0,AACL/IJCNLP,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2022.findings-aacl.24,10.18653/v1/2022.findings-aacl.24,https://doi.org/10.18653/v1/2022.findings-aacl.24,75,"Recent studies show that Natural Language Processing (NLP) technologies propagate societal biases about demographic groups associated with attributes such as gender, race, and nationality. To create interventions and mitigate these biases and associated harms, it is vital to be able to detect and measure such biases. While existing works propose bias evaluation and mitigation methods for various tasks, there remains a need to cohesively understand the biases and the specific harms they measure, and how different measures compare with each other. To address this gap, this work presents a practical framework of harms and a series of questions that practitioners can answer to guide the development of bias measures. As a validation of our framework and documentation questions, we also present several case studies of how existing bias measures in NLP—both intrinsic measures of bias in representations and extrinsic measures of bias of downstream applications—can be aligned with different harms and how our proposed documentation questions facilitates more holistic understanding of what bias measures are measuring.",Document_100,Technical aspects or methods of AI or machine learning,0.08743837475776672,Other Categories
Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in NLP Models,"Wenkai Yang, Lei Li, Zhiyuan Zhang, Xuancheng Ren, Xu Sun, Bin He","Recent studies have revealed a security threat to natural language processing (NLP) models, called the Backdoor Attack. Victim models can maintain competitive performance on clean samples while behaving abnormally on samples with a specific trigger word inserted. Previous backdoor attacking methods usually assume that attackers have a certain degree of data knowledge, either the dataset which users would use or proxy datasets for a similar task, for implementing the data poisoning procedure. However, in this paper, we find that it is possible to hack the model in a data-free way by modifying one single word embedding vector, with almost no accuracy sacrificed on clean samples. Experimental results on sentiment analysis and sentence-pair classification tasks show that our method is more efficient and stealthier. We hope this work can raise the awareness of such a critical security risk hidden in the embedding layers of NLP models. Our code is available at https://github.com/lancopku/Embedding-Poisoning .",2021,2021,6.0,North American Chapter of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/V1/2021.NAACL-MAIN.165,10.18653/V1/2021.NAACL-MAIN.165,https://doi.org/10.18653/V1/2021.NAACL-MAIN.165,132,"Recent studies have revealed a security threat to natural language processing (NLP) models, called the Backdoor Attack. Victim models can maintain competitive performance on clean samples while behaving abnormally on samples with a specific trigger word inserted. Previous backdoor attacking methods usually assume that attackers have a certain degree of data knowledge, either the dataset which users would use or proxy datasets for a similar task, for implementing the data poisoning procedure. However, in this paper, we find that it is possible to hack the model in a data-free way by modifying one single word embedding vector, with almost no accuracy sacrificed on clean samples. Experimental results on sentiment analysis and sentence-pair classification tasks show that our method is more efficient and stealthier. We hope this work can raise the awareness of such a critical security risk hidden in the embedding layers of NLP models. Our code is available at https://github.com/lancopku/Embedding-Poisoning .",Document_101,Technical aspects or methods of AI or machine learning,0.08658759295940399,Other Categories
Energy and Policy Considerations for Deep Learning in NLP,"Emma Strubell, Ananya Ganesh, A. McCallum","Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.",2019,2019,7.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/P19-1355,10.18653/v1/P19-1355,https://doi.org/10.18653/v1/P19-1355,2442,"Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.",Document_102,Technical aspects or methods of AI or machine learning,0.11263727396726608,Other Categories
Named Entity Recognition Utilized to Enhance Text Classification While Preserving Privacy,Mohammed Kutbi,"Recent development in Natural Language Processing (NLP) techniques has encouraged NLP-based application in various field including business, legal and health. An important process for all NLP projects is text preprocessing which is a process that modifies text data before using them in a machine learning model. Usually text preprocessing process includes cleaning, filtering, removing and replacing some texts to increase model accuracy, robustness, reduce data size or preserve privacy. Named entities recognizer (NER) is an NLP tool which finds Named Entities in text such as: names, organization, addresses, numbers and date. In this work, we create a preproccessing approach that uses NER to find named entities and, then, replace them with their type i.e. location, person or organization name to improve accuracy and preserve privacy instead of removing them or letting them become noise to our data. Experiments for text classification task using our approach have been conducted on several datasets some of which were collected in-house. Experiments indicate that using this approach enhances classifier accuracy and reduces feature representation’s dimensionality while, also, preserve privacy.",2023,2023,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2023.3325895,10.1109/ACCESS.2023.3325895,https://doi.org/10.1109/ACCESS.2023.3325895,10,"Recent development in Natural Language Processing (NLP) techniques has encouraged NLP-based application in various field including business, legal and health. An important process for all NLP projects is text preprocessing which is a process that modifies text data before using them in a machine learning model. Usually text preprocessing process includes cleaning, filtering, removing and replacing some texts to increase model accuracy, robustness, reduce data size or preserve privacy. Named entities recognizer (NER) is an NLP tool which finds Named Entities in text such as: names, organization, addresses, numbers and date. In this work, we create a preproccessing approach that uses NER to find named entities and, then, replace them with their type i.e. location, person or organization name to improve accuracy and preserve privacy instead of removing them or letting them become noise to our data. Experiments for text classification task using our approach have been conducted on several datasets some of which were collected in-house. Experiments indicate that using this approach enhances classifier accuracy and reduces feature representation’s dimensionality while, also, preserve privacy.",Document_103,Technical aspects or methods of AI or machine learning,0.1362244039773941,Other Categories
Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks,"Daniel Kang, Xuechen Li, Ion Stoica, Carlos Guestrin, M. Zaharia, Tatsunori Hashimoto","Recent advances in instruction-following large language models (LLMs) have led to dramatic improvements in a range of NLP tasks. Unfortunately, we find that the same improved capabilities amplify the dual-use risks for malicious purposes of these models. Dual-use is difficult to prevent as instruction-following capabilities now enable standard attacks from computer security. The capabilities of these instruction-following LLMs provide strong economic incentives for dual-use by malicious actors. In particular, we show that instruction-following LLMs can produce targeted malicious content, including hate speech and scams, bypassing in-the-wild defenses implemented by LLM API vendors. Our analysis shows that this content can be generated economically and at cost of $125-500 \times$ cheaper than human effort alone. Together, our findings suggest that LLMs will increasingly attract more sophisticated adversaries and attacks, and addressing these attacks may require new approaches to mitigations.",2023,2023,,2024 IEEE Security and Privacy Workshops (SPW),"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/SPW63631.2024.00018,10.1109/SPW63631.2024.00018,https://doi.org/10.1109/SPW63631.2024.00018,197,"Recent advances in instruction-following large language models (LLMs) have led to dramatic improvements in a range of NLP tasks. Unfortunately, we find that the same improved capabilities amplify the dual-use risks for malicious purposes of these models. Dual-use is difficult to prevent as instruction-following capabilities now enable standard attacks from computer security. The capabilities of these instruction-following LLMs provide strong economic incentives for dual-use by malicious actors. In particular, we show that instruction-following LLMs can produce targeted malicious content, including hate speech and scams, bypassing in-the-wild defenses implemented by LLM API vendors. Our analysis shows that this content can be generated economically and at cost of $125-500 \times$ cheaper than human effort alone. Together, our findings suggest that LLMs will increasingly attract more sophisticated adversaries and attacks, and addressing these attacks may require new approaches to mitigations.",Document_104,Technical aspects or methods of AI or machine learning,0.08536911010742188,Other Categories
Natural language processing analysis of online reviews for small business: extracting insight from small corpora,"Benjamin J. McCloskey, Phillip M. LaCasse, Bruce A. Cox","Receiving and acting on customer input is essential to sustaining and growing any service organization, particularly a small family business whose livelihood depends on strong relationships with its customers. The competitive advantage offered by advanced analytical approaches for supporting decisions is not trivial, and enterprises across virtually all domains of society are investing heavily in this emerging discipline. Natural Language Processing (NLP) is a subset of computer science that employs computational approaches to analyze human language; it is effective at extracting insight from text data but frequently requires large corpora to train its models, in the scale of thousands or millions of documents. This restricts its accessibility to those large enterprises with the capability to capture, store, manage, and analyze such corpora. This research explores a pilot study that applies NLP approaches, specifically topic modeling and large language models (LLM), to assist a small, family-owned business in assessing its strengths and weaknesses based on customer reviews. The relevant corpora of online Facebook, Google Reviews, TripAdvisor, and Yelp reviews is far smaller than ideal, numbering only in the hundreds. Results demonstrate that coherent and actionable insights from big-data approaches are obtainable and that small organizations are not automatically excluded from the benefits of these advanced analytical approaches, with complementary employment of both topic modeling and LLM presenting the greatest potential for similarly-positioned organizations to exploit.",2024,2024,10.0,Annals of Operations Research,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10479-023-05816-2,10.1007/s10479-023-05816-2,https://doi.org/10.1007/s10479-023-05816-2,5,"Receiving and acting on customer input is essential to sustaining and growing any service organization, particularly a small family business whose livelihood depends on strong relationships with its customers. The competitive advantage offered by advanced analytical approaches for supporting decisions is not trivial, and enterprises across virtually all domains of society are investing heavily in this emerging discipline. Natural Language Processing (NLP) is a subset of computer science that employs computational approaches to analyze human language; it is effective at extracting insight from text data but frequently requires large corpora to train its models, in the scale of thousands or millions of documents. This restricts its accessibility to those large enterprises with the capability to capture, store, manage, and analyze such corpora. This research explores a pilot study that applies NLP approaches, specifically topic modeling and large language models (LLM), to assist a small, family-owned business in assessing its strengths and weaknesses based on customer reviews. The relevant corpora of online Facebook, Google Reviews, TripAdvisor, and Yelp reviews is far smaller than ideal, numbering only in the hundreds. Results demonstrate that coherent and actionable insights from big-data approaches are obtainable and that small organizations are not automatically excluded from the benefits of these advanced analytical approaches, with complementary employment of both topic modeling and LLM presenting the greatest potential for similarly-positioned organizations to exploit.",Document_105,Technical aspects or methods of AI or machine learning,0.12855570018291473,Other Categories
Ethically Responsible Machine Learning in Fintech,"Maryan Rizinski, Hristijan Peshov, Kostadin Mishev, Lubomir T. Chitkushev, I. Vodenska, D. Trajanov","Rapid technological developments in the last decade have contributed to using machine learning (ML) in various economic sectors. Financial institutions have embraced technology and have applied ML algorithms in trading, portfolio management, and investment advising. Large-scale automation capabilities and cost savings make the ML algorithms attractive for personal and corporate finance applications. Using ML applications in finance raises ethical issues that need to be carefully examined. We engage a group of experts in finance and ethics to evaluate the relationship between ethical principles of finance and ML. The paper compares the experts’ findings with the results obtained using natural language processing (NLP) transformer models, given their ability to capture the semantic text similarity. The results reveal that the finance principles of integrity and fairness have the most significant relationships with ML ethics. The study includes a use case with SHapley Additive exPlanations (SHAP) and Microsoft Responsible AI Widgets explainability tools for error analysis and visualization of ML models. It analyzes credit card approval data and demonstrates that the explainability tools can address ethical issues in fintech, and improve transparency, thereby increasing the overall trustworthiness of ML models. The results show that both humans and machines could err in approving credit card requests despite using their best judgment based on the available information. Hence, human-machine collaboration could contribute to improved decision-making in finance. We propose a conceptual framework for addressing ethical challenges in fintech such as bias, discrimination, differential pricing, conflict of interest, and data protection.",2022,2022,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2022.3202889,10.1109/ACCESS.2022.3202889,https://doi.org/10.1109/ACCESS.2022.3202889,16,"Rapid technological developments in the last decade have contributed to using machine learning (ML) in various economic sectors. Financial institutions have embraced technology and have applied ML algorithms in trading, portfolio management, and investment advising. Large-scale automation capabilities and cost savings make the ML algorithms attractive for personal and corporate finance applications. Using ML applications in finance raises ethical issues that need to be carefully examined. We engage a group of experts in finance and ethics to evaluate the relationship between ethical principles of finance and ML. The paper compares the experts’ findings with the results obtained using natural language processing (NLP) transformer models, given their ability to capture the semantic text similarity. The results reveal that the finance principles of integrity and fairness have the most significant relationships with ML ethics. The study includes a use case with SHapley Additive exPlanations (SHAP) and Microsoft Responsible AI Widgets explainability tools for error analysis and visualization of ML models. It analyzes credit card approval data and demonstrates that the explainability tools can address ethical issues in fintech, and improve transparency, thereby increasing the overall trustworthiness of ML models. The results show that both humans and machines could err in approving credit card requests despite using their best judgment based on the available information. Hence, human-machine collaboration could contribute to improved decision-making in finance. We propose a conceptual framework for addressing ethical challenges in fintech such as bias, discrimination, differential pricing, conflict of interest, and data protection.",Document_106,Transparency is a challenge for AI adoption in financial services,0.15096516907215118,Explainability and Transparency Barriers
Reliability Testing for Natural Language Processing Systems,"Samson Tan, Shafiq R. Joty, K. Baxter, Araz Taeihagh, G. Bennett, Min-Yen Kan","Questions of fairness, robustness, and transparency are paramount to address before deploying NLP systems. Central to these concerns is the question of reliability: Can NLP systems reliably treat different demographics fairly and function correctly in diverse and noisy environments? To address this, we argue for the need for reliability testing and contextualize it among existing work on improving accountability. We show how adversarial attacks can be reframed for this goal, via a framework for developing reliability tests. We argue that reliability testing — with an emphasis on interdisciplinary collaboration — will enable rigorous and targeted testing, and aid in the enactment and enforcement of industry standards.",2021,2021,8.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2021.acl-long.321,10.18653/v1/2021.acl-long.321,https://doi.org/10.18653/v1/2021.acl-long.321,34,"Questions of fairness, robustness, and transparency are paramount to address before deploying NLP systems. Central to these concerns is the question of reliability: Can NLP systems reliably treat different demographics fairly and function correctly in diverse and noisy environments? To address this, we argue for the need for reliability testing and contextualize it among existing work on improving accountability. We show how adversarial attacks can be reframed for this goal, via a framework for developing reliability tests. We argue that reliability testing — with an emphasis on interdisciplinary collaboration — will enable rigorous and targeted testing, and aid in the enactment and enforcement of industry standards.",Document_107,Demonstrating the value of AI for compliance and risk management,0.08615829050540924,Business Case and Value Demonstration Strategies
Literature Review of Qualitative Data with Natural Language Processing,Bukuroshe Elira Epoka,"Qualitative research techniques are frequently employed by scholars in the field of social sciences when investigating communities and their communication media. The proliferation of computer-mediated communications has resulted in a substantial volume of textual content. However, the process of coding this vast amount of information necessitates significant time and effort. This article examines the potential for automating specific elements of content analysis through the utilization of natural language processing (NLP) systems, which analyze text in human languages, with a focus on extracting theoretical evidence. In this study, we present a case analysis utilizing NLP to examine the effectiveness of NLP rules in qualitative analysis. Our findings indicate that the NLP rules demonstrated strong performance across multiple codes. The utilization of a NLP system in its current developmental stage has the potential to significantly minimize the text volume, which has to be evaluated using the human coder. This reduction could potentially result in a substantial increase in coding speed, potentially by a factor of ten or more. The research is considered groundbreaking as it pioneers the application of advanced NLP approach to evaluate qualitative data, making it one of the earliest studies in this domain.",2023,2023,,Journal of Robotics Spectrum,Heading+Sibling / Date Not Found (URL Source: DOI Link),https://doi.org/10.53759/9852/jrs202301006,10.53759/9852/jrs202301006,https://doi.org/10.53759/9852/jrs202301006,62,"Qualitative research techniques are frequently employed by scholars in the field of social sciences when investigating communities and their communication media. The proliferation of computer-mediated communications has resulted in a substantial volume of textual content. However, the process of coding this vast amount of information necessitates significant time and effort. This article examines the potential for automating specific elements of content analysis through the utilization of natural language processing (NLP) systems, which analyze text in human languages, with a focus on extracting theoretical evidence. In this study, we present a case analysis utilizing NLP to examine the effectiveness of NLP rules in qualitative analysis. Our findings indicate that the NLP rules demonstrated strong performance across multiple codes. The utilization of a NLP system in its current developmental stage has the potential to significantly minimize the text volume, which has to be evaluated using the human coder. This reduction could potentially result in a substantial increase in coding speed, potentially by a factor of ten or more. The research is considered groundbreaking as it pioneers the application of advanced NLP approach to evaluate qualitative data, making it one of the earliest studies in this domain.",Document_108,Technical aspects or methods of AI or machine learning,0.09309419244527817,Other Categories
Natural language processing and machine learning as practical toolsets for archival processing,T. Hutchinson,"This study aims to provide an overview of recent efforts relating to natural language processing (NLP) and machine learning applied to archival processing, particularly appraisal and sensitivity reviews, and propose functional requirements and workflow considerations for transitioning from experimental to operational use of these tools. Design/methodology/approach The paper has four main sections. 1) A short overview of the NLP and machine learning concepts referenced in the paper. 2) A review of the literature reporting on NLP and machine learning applied to archival processes. 3) An overview and commentary on key existing and developing tools that use NLP or machine learning techniques for archives. 4) This review and analysis will inform a discussion of functional requirements and workflow considerations for NLP and machine learning tools for archival processing. Findings Applications for processing e-mail have received the most attention so far, although most initiatives have been experimental or project based. It now seems feasible to branch out to develop more generalized tools for born-digital, unstructured records. Effective NLP and machine learning tools for archival processing should be usable, interoperable, flexible, iterative and configurable. Originality/value Most implementations of NLP for archives have been experimental or project based. The main exception that has moved into production is ePADD, which includes robust NLP features through its named entity recognition module. This paper takes a broader view, assessing the prospects and possible directions for integrating NLP tools and techniques into archival workflows.",2020,2020,,Records Management Journal,Selector (#abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1108/rmj-09-2019-0055,10.1108/rmj-09-2019-0055,https://doi.org/10.1108/rmj-09-2019-0055,18,"This study aims to provide an overview of recent efforts relating to natural language processing (NLP) and machine learning applied to archival processing, particularly appraisal and sensitivity reviews, and propose functional requirements and workflow considerations for transitioning from experimental to operational use of these tools. Design/methodology/approach The paper has four main sections. 1) A short overview of the NLP and machine learning concepts referenced in the paper. 2) A review of the literature reporting on NLP and machine learning applied to archival processes. 3) An overview and commentary on key existing and developing tools that use NLP or machine learning techniques for archives. 4) This review and analysis will inform a discussion of functional requirements and workflow considerations for NLP and machine learning tools for archival processing. Findings Applications for processing e-mail have received the most attention so far, although most initiatives have been experimental or project based. It now seems feasible to branch out to develop more generalized tools for born-digital, unstructured records. Effective NLP and machine learning tools for archival processing should be usable, interoperable, flexible, iterative and configurable. Originality/value Most implementations of NLP for archives have been experimental or project based. The main exception that has moved into production is ePADD, which includes robust NLP features through its named entity recognition module. This paper takes a broader view, assessing the prospects and possible directions for integrating NLP tools and techniques into archival workflows.",Document_109,Technical aspects or methods of AI or machine learning,0.13242554664611816,Other Categories
"Large language models for automated Q&A involving legal documents: a survey on algorithms, frameworks and applications","Xiaoxian Yang, Zhifeng Wang, Qi Wang, Ke Wei, Kaiqi Zhang, Jiangang Shi","This study aims to adopt a systematic review approach to examine the existing literature on law and LLMs.It involves analyzing and synthesizing relevant research papers, reports and scholarly articles that discuss the use of LLMs in the legal domain. The review encompasses various aspects, including an analysis of LLMs, legal natural language processing (NLP), model tuning techniques, data processing strategies and frameworks for addressing the challenges associated with legal question-and-answer (Q&A) systems. Additionally, the study explores potential applications and services that can benefit from the integration of LLMs in the field of intelligent justice. Design/methodology/approach This paper surveys the state-of-the-art research on law LLMs and their application in the field of intelligent justice. The study aims to identify the challenges associated with developing Q&A systems based on LLMs and explores potential directions for future research and development. The ultimate goal is to contribute to the advancement of intelligent justice by effectively leveraging LLMs. Findings To effectively apply a law LLM, systematic research on LLM, legal NLP and model adjustment technology is required. Originality/value This study contributes to the field of intelligent justice by providing a comprehensive review of the current state of research on law LLMs.",2024,2024,,International Journal of Web Information Systems,Selector (#abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1108/ijwis-12-2023-0256,10.1108/ijwis-12-2023-0256,https://doi.org/10.1108/ijwis-12-2023-0256,12,"This study aims to adopt a systematic review approach to examine the existing literature on law and LLMs.It involves analyzing and synthesizing relevant research papers, reports and scholarly articles that discuss the use of LLMs in the legal domain. The review encompasses various aspects, including an analysis of LLMs, legal natural language processing (NLP), model tuning techniques, data processing strategies and frameworks for addressing the challenges associated with legal question-and-answer (Q&A) systems. Additionally, the study explores potential applications and services that can benefit from the integration of LLMs in the field of intelligent justice. Design/methodology/approach This paper surveys the state-of-the-art research on law LLMs and their application in the field of intelligent justice. The study aims to identify the challenges associated with developing Q&A systems based on LLMs and explores potential directions for future research and development. The ultimate goal is to contribute to the advancement of intelligent justice by effectively leveraging LLMs. Findings To effectively apply a law LLM, systematic research on LLM, legal NLP and model adjustment technology is required. Originality/value This study contributes to the field of intelligent justice by providing a comprehensive review of the current state of research on law LLMs.",Document_110,Technical aspects or methods of AI or machine learning,0.07386355847120285,Other Categories
Rebuilding trust: sustainability and non-financial reporting and the European Union regulation,"Matteo La Torre, Svetlana Sabelfeld, Marita Blomkvist, John Dumay","This paper introduces the special issue “Rebuilding trust: Sustainability and non-financial reporting, and the European Union regulation”. Inspired by the studies published in the special issue, this study aims to examine the concept of accountability within the context of the European Union (EU) Directive on non-financial disclosure (hereafter the EU Directive) to offer a critique and a novel perspective for future research into mandatory non-financial reporting (NFR) and to advance future practice and policy. Design/methodology/approach The authors review the papers published in this special issue and other contemporary studies on the topic of NFR and the EU Directive. Findings Accountability is a fundamental concept for building trust in the corporate reporting context and emerges as a common topic linking contemporary studies on the EU Directive. While the EU Directive acknowledges the role of accountability in the reporting practice, this study argues that regulation and practice on NFR needs to move away from an accounting-based conception of accountability to promote accountability-based accounting practices (Dillard and Vinnari, 2019). By analysing the links between trust, accountability and accounting and reporting, the authors claim the need to examine and rethink the inscription of interests into non-financial information (NFI) and its materiality. Hence, this study encourages research and practice to broaden mandatory NFR practice over the traditional boundaries of accountability, reporting and formal accounting systems. Research limitations/implications Considering the challenges posed by the COVID-19 crisis, this study calls for further research to investigate the dialogical accountability underpinning NFR in practice to avoid the trap of focusing on accounting changes regardless of accountability. The authors advocate that what is needed is more timely NFI that develops a dialogue between companies, investors, national regulators, the EU and civil society, not more untimely standalone reporting that has most likely lost its relevance and materiality by the time it is issued to users. Originality/value By highlighting accountability issues in the context of mandatory NFR and its linkages with trust, this study lays out a case for moving the focus of research and practice from accounting-based regulations towards accountability-driven accounting change.",2020,2020,,Meditari Accountancy Research,Selector (#abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1108/medar-06-2020-0914,10.1108/medar-06-2020-0914,https://doi.org/10.1108/medar-06-2020-0914,98,"This paper introduces the special issue “Rebuilding trust: Sustainability and non-financial reporting, and the European Union regulation”. Inspired by the studies published in the special issue, this study aims to examine the concept of accountability within the context of the European Union (EU) Directive on non-financial disclosure (hereafter the EU Directive) to offer a critique and a novel perspective for future research into mandatory non-financial reporting (NFR) and to advance future practice and policy. Design/methodology/approach The authors review the papers published in this special issue and other contemporary studies on the topic of NFR and the EU Directive. Findings Accountability is a fundamental concept for building trust in the corporate reporting context and emerges as a common topic linking contemporary studies on the EU Directive. While the EU Directive acknowledges the role of accountability in the reporting practice, this study argues that regulation and practice on NFR needs to move away from an accounting-based conception of accountability to promote accountability-based accounting practices (Dillard and Vinnari, 2019). By analysing the links between trust, accountability and accounting and reporting, the authors claim the need to examine and rethink the inscription of interests into non-financial information (NFI) and its materiality. Hence, this study encourages research and practice to broaden mandatory NFR practice over the traditional boundaries of accountability, reporting and formal accounting systems. Research limitations/implications Considering the challenges posed by the COVID-19 crisis, this study calls for further research to investigate the dialogical accountability underpinning NFR in practice to avoid the trap of focusing on accounting changes regardless of accountability. The authors advocate that what is needed is more timely NFI that develops a dialogue between companies, investors, national regulators, the EU and civil society, not more untimely standalone reporting that has most likely lost its relevance and materiality by the time it is issued to users. Originality/value By highlighting accountability issues in the context of mandatory NFR and its linkages with trust, this study lays out a case for moving the focus of research and practice from accounting-based regulations towards accountability-driven accounting change.",Document_111,General discussion of financial or regulatory topics (non-AI focus),0.0610688142478466,Other Categories
An innovative RegTech approach to financial risk monitoring and supervisory reporting,"P. Kavassalis, Harald W. Stieber, W. Breymann, Keith Saxton, Francis Gross","The purpose of this study is to propose a bearer service, which generates and maintains a “digital doppelgänger” for every financial contract in the form of a dynamic transaction document that is a standardised “data facility” automatically making important contract data from the transaction counterparties available to relevant authorities mandated by law to request and process such data. This would be achieved by sharing certain elements of the dynamic transaction document on a bearer service, based on a federation of distribution ledgers; such a quasi-simultaneous sharing of risk data becomes possible because the dynamic transaction document maintain a record of state in semi-real time, and this state can be verified by anybody with access to the distribution ledgers, also in semi-real time. Design/methodology/approach In this paper, the authors propose a novel, regular technology (RegTech) cum automated legal text approach for financial transaction as well as financial risk reporting that is based on cutting-edge distributed computing and decentralised data management technologies such as distributed ledger (Swanson, 2015), distributed storage (Arner et al. , 2016; Chandra et al. , 2013; Caron et al. , 2014), algorithmic financial contract standards (Brammertz and Mendelowitz, 2014; Breymann and Mendelowitz, 2015; Braswell, 2016), automated legal text (Hazard and Haapio, 2017) and document engineering methods and techniques (Glushko and McGrath, 2005). This approach is equally inspired by the concept of the “bearer service” and its capacity to span over existing and future technological systems and substrates (Kavassalis et al. , 2000; Clark, 1988). Findings The result is a transformation of supervisors’ capacity to monitor risk in the financial system based on data which preserve informational content of financial instruments at the most granular level, in combination with a mathematically robust time stamping approach using blockchain technology. Practical implications The RegTech approach has the potential to contain operational risk linked to inadequate handling of risk data and to rein in compliance cost of supervisory reporting. Originality value The present RegTech approach to financial risk monitoring and supervisory reporting is the first integration of algorithmic financial data standards with blockchain functionality.",2017,2017,,-,Selector (#abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1108/JRF-07-2017-0111,10.1108/JRF-07-2017-0111,https://doi.org/10.1108/JRF-07-2017-0111,36,"The purpose of this study is to propose a bearer service, which generates and maintains a “digital doppelgänger” for every financial contract in the form of a dynamic transaction document that is a standardised “data facility” automatically making important contract data from the transaction counterparties available to relevant authorities mandated by law to request and process such data. This would be achieved by sharing certain elements of the dynamic transaction document on a bearer service, based on a federation of distribution ledgers; such a quasi-simultaneous sharing of risk data becomes possible because the dynamic transaction document maintain a record of state in semi-real time, and this state can be verified by anybody with access to the distribution ledgers, also in semi-real time. Design/methodology/approach In this paper, the authors propose a novel, regular technology (RegTech) cum automated legal text approach for financial transaction as well as financial risk reporting that is based on cutting-edge distributed computing and decentralised data management technologies such as distributed ledger (Swanson, 2015), distributed storage (Arner et al. , 2016; Chandra et al. , 2013; Caron et al. , 2014), algorithmic financial contract standards (Brammertz and Mendelowitz, 2014; Breymann and Mendelowitz, 2015; Braswell, 2016), automated legal text (Hazard and Haapio, 2017) and document engineering methods and techniques (Glushko and McGrath, 2005). This approach is equally inspired by the concept of the “bearer service” and its capacity to span over existing and future technological systems and substrates (Kavassalis et al. , 2000; Clark, 1988). Findings The result is a transformation of supervisors’ capacity to monitor risk in the financial system based on data which preserve informational content of financial instruments at the most granular level, in combination with a mathematically robust time stamping approach using blockchain technology. Practical implications The RegTech approach has the potential to contain operational risk linked to inadequate handling of risk data and to rein in compliance cost of supervisory reporting. Originality value The present RegTech approach to financial risk monitoring and supervisory reporting is the first integration of algorithmic financial data standards with blockchain functionality.",Document_112,General discussion of financial or regulatory topics (non-AI focus),0.08860625326633453,Other Categories
Legal and Sharīʿah non-compliance risks in Nigerian Islamic finance industry: a review of the literature,"Zakariya Mustapha, S. Kunhibava, Aishath Muneeza","The purpose of this paper is to review the literature on Islamic finance vis-à-vis legal and Sharīʿah non-compliance risks in its transactions and judicial dispute resolution in Nigeria. This is with a view to putting forward direction for future studies on the duo of legal and Sharīʿah non-compliance risks and their impact in Islamic finance. Design/methodology/approach This review is designed as an exploratory study and qualitative methodology is used in examining relevant literature comprising of primary and secondary data while identifying legal risk and Sharīʿah non-compliance risks of Nigeria’s Islamic finance industry. Using the doctrinal approach together with content analysis, relevant Nigerian laws and judicial precedents applicable to Islamic finance practice and related publications were examined in determining the identified risks. Findings Undeveloped laws, the uncertainty of Sharīʿah governance and enforceability issues are identified as legal gaps for Islamic finance under the Nigerian legal system. The gaps are inimical to and undermine investor confidence in Nigeria’s Islamic finance industry. The review reveals the necessity of tailor-made Sharīʿah-based regulations in addition to corresponding governance and oversight for a legally safe and Sharīʿah-compliant Islamic finance practice. It brings to light the imperative for mitigating the legal and Sharīʿah non-compliance risks associated with Islamic finance operations as crucial for Islamic finance businesses, Islamic finance institutions and their sustainable development. Research limitations/implications Based on content analysis, the review is wholly doctrinal and does not involve empirical data. Legal safety and Sharīʿah compliance are not to be compromised in Islamic finance operations. The review would assist relevant regulators and investors in Islamic financial enterprises to understand and determine the impact and potential ramifications of legal safety and Sharīʿah non-compliance on Islamic Finance Institutions. Practical implications This study provides an insight into the dimensions and ramifications of legal and Sharīʿah non-compliance risks of Nigeria’s Islamic finance industry. This study is premised on the imperative for research studies whose outcome would inform regulations that strike a balance between establishing Islamic financial institution/business and ensuring legal certainty and Sharīʿah compliance of their operations. This study paves way for this kind of research studies. Originality/value The findings and discussions provide a guide for regulators and researchers on the identification and mitigation of legal and Sharīʿah non-compliance risks in Islamic finance via a literature review. This study, the first of its kind in Nigeria, advances the idea that research into legal and Sharīʿah non-compliance risks of Islamic financial entities is key to mitigating the risks and fostering the entities and their businesses.",2020,2020,,-,Selector (#abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1108/ijlma-03-2020-0075,10.1108/ijlma-03-2020-0075,https://doi.org/10.1108/ijlma-03-2020-0075,14,"The purpose of this paper is to review the literature on Islamic finance vis-à-vis legal and Sharīʿah non-compliance risks in its transactions and judicial dispute resolution in Nigeria. This is with a view to putting forward direction for future studies on the duo of legal and Sharīʿah non-compliance risks and their impact in Islamic finance. Design/methodology/approach This review is designed as an exploratory study and qualitative methodology is used in examining relevant literature comprising of primary and secondary data while identifying legal risk and Sharīʿah non-compliance risks of Nigeria’s Islamic finance industry. Using the doctrinal approach together with content analysis, relevant Nigerian laws and judicial precedents applicable to Islamic finance practice and related publications were examined in determining the identified risks. Findings Undeveloped laws, the uncertainty of Sharīʿah governance and enforceability issues are identified as legal gaps for Islamic finance under the Nigerian legal system. The gaps are inimical to and undermine investor confidence in Nigeria’s Islamic finance industry. The review reveals the necessity of tailor-made Sharīʿah-based regulations in addition to corresponding governance and oversight for a legally safe and Sharīʿah-compliant Islamic finance practice. It brings to light the imperative for mitigating the legal and Sharīʿah non-compliance risks associated with Islamic finance operations as crucial for Islamic finance businesses, Islamic finance institutions and their sustainable development. Research limitations/implications Based on content analysis, the review is wholly doctrinal and does not involve empirical data. Legal safety and Sharīʿah compliance are not to be compromised in Islamic finance operations. The review would assist relevant regulators and investors in Islamic financial enterprises to understand and determine the impact and potential ramifications of legal safety and Sharīʿah non-compliance on Islamic Finance Institutions. Practical implications This study provides an insight into the dimensions and ramifications of legal and Sharīʿah non-compliance risks of Nigeria’s Islamic finance industry. This study is premised on the imperative for research studies whose outcome would inform regulations that strike a balance between establishing Islamic financial institution/business and ensuring legal certainty and Sharīʿah compliance of their operations. This study paves way for this kind of research studies. Originality/value The findings and discussions provide a guide for regulators and researchers on the identification and mitigation of legal and Sharīʿah non-compliance risks in Islamic finance via a literature review. This study, the first of its kind in Nigeria, advances the idea that research into legal and Sharīʿah non-compliance risks of Islamic financial entities is key to mitigating the risks and fostering the entities and their businesses.",Document_113,Proactively addressing regulatory concerns to enable AI in finance,0.06307131797075272,Regulatory Engagement and Proactive Compliance Strategies
The regulation of RegTech and SupTech in finance: ensuring consistency in principle and in practice,Jonathan McCarthy,"The paper’s aim is to consider how best to formulate sturdy regulatory frameworks for RegTech and SupTech. The paper appraises how key features of EU and UK regulatory and policy initiatives can contribute to a functional framework for RegTech and SupTech. Design/methodology/approach The paper refers to the most comprehensive empirical findings within the EU and the UK on RegTech and SupTech, including reports released by the European Banking Authority and the Bank of England. As data is only gradually becoming available about the true rate of adoption of RegTech and SupTech, the paper identifies salient areas that warrant analysis from emerging findings. In light of the relatively restricted sources of empirical data, the article’s methodological approach is directed towards the most wide-ranging and detailed sources that are currently available at EU and UK levels. Findings The paper reveals distinct variations in how the EU and UK have pursued regulatory approaches towards RegTech and SupTech growth. However, there are many shared features in the respective approaches. The paper argues that a regulatory framework should ideally be imbued with overarching strategies and policy objectives, as well as with practical measures through innovation facilitators, such as sandboxes. Yet, legislative (top-down) intervention will be the significant ingredient in guaranteeing legal clarity for RegTech and SupTech. Originality/value By understanding the nuances in EU and UK approaches, the paper advocates for pragmatic reasoning when formulating a regulatory response. The importance of the article is in its focus on the elements of EU and UK regulatory approaches that are most capable of guaranteeing clarity on standards relating to RegTech and SupTech. The paper makes a vital contribution to existing commentary by determining how a balance can be struck between “top-down” and “bottom-up” types of regulation (i.e. should regulation be entirely concerned with industry-driven standards, such as codes of conduct?).",2022,2022,,Journal of Financial Regulation and Compliance,Selector (#abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1108/jfrc-01-2022-0004,10.1108/jfrc-01-2022-0004,https://doi.org/10.1108/jfrc-01-2022-0004,8,"The paper’s aim is to consider how best to formulate sturdy regulatory frameworks for RegTech and SupTech. The paper appraises how key features of EU and UK regulatory and policy initiatives can contribute to a functional framework for RegTech and SupTech. Design/methodology/approach The paper refers to the most comprehensive empirical findings within the EU and the UK on RegTech and SupTech, including reports released by the European Banking Authority and the Bank of England. As data is only gradually becoming available about the true rate of adoption of RegTech and SupTech, the paper identifies salient areas that warrant analysis from emerging findings. In light of the relatively restricted sources of empirical data, the article’s methodological approach is directed towards the most wide-ranging and detailed sources that are currently available at EU and UK levels. Findings The paper reveals distinct variations in how the EU and UK have pursued regulatory approaches towards RegTech and SupTech growth. However, there are many shared features in the respective approaches. The paper argues that a regulatory framework should ideally be imbued with overarching strategies and policy objectives, as well as with practical measures through innovation facilitators, such as sandboxes. Yet, legislative (top-down) intervention will be the significant ingredient in guaranteeing legal clarity for RegTech and SupTech. Originality/value By understanding the nuances in EU and UK approaches, the paper advocates for pragmatic reasoning when formulating a regulatory response. The importance of the article is in its focus on the elements of EU and UK regulatory approaches that are most capable of guaranteeing clarity on standards relating to RegTech and SupTech. The paper makes a vital contribution to existing commentary by determining how a balance can be struck between “top-down” and “bottom-up” types of regulation (i.e. should regulation be entirely concerned with industry-driven standards, such as codes of conduct?).",Document_114,General discussion of financial or regulatory topics (non-AI focus),0.07648869603872299,Other Categories
Unpacking the black box of systemic risks in banking,C. Hoffmann,"Systemic risks affect financial market participants in many ways. However, the literature insists firmly that they are and, in fact, should be of little concern to (private) banks (as opposed to regulators). The purpose of this paper is to argue for the relevance of systemic risks for private banks as opposed to regulators only by making use of causal loop models as being traditionally used in the discipline of systems dynamics. In contrast to the starting point for all common risk-management frameworks in banks, which is the classification of risks into risk categories, the authors show that risk has been compartmentalized too much and provide a strong case for a really holistic approach. Design/methodology/approach Systems thinking, causal loop models and conceptual approach. Findings Relevance of systemic risks for private banks as opposed to regulators only. In contrast to the starting point for all common risk-management frameworks in banks, which is the classification of risks into risk categories, the authors show that risk has been compartmentalized too much and provide a strong case for a really holistic approach, which stems from using explanatory models such as causal loop diagrams. On top of that more explanatory models ought to be used for risk management purposes while banks currently rely too much on statistical-descriptive approaches. Originality/value Integration of systems thinking into risk management, which is novel: in contrast to the starting point for all common risk-management frameworks in banks, which is the classification of risks into risk categories, the authors show that risk has been compartmentalized too much and provide a strong case for a really holistic approach.",2019,2019,,Kybernetes,Selector (#abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1108/k-05-2019-0314,10.1108/k-05-2019-0314,https://doi.org/10.1108/k-05-2019-0314,4,"Systemic risks affect financial market participants in many ways. However, the literature insists firmly that they are and, in fact, should be of little concern to (private) banks (as opposed to regulators). The purpose of this paper is to argue for the relevance of systemic risks for private banks as opposed to regulators only by making use of causal loop models as being traditionally used in the discipline of systems dynamics. In contrast to the starting point for all common risk-management frameworks in banks, which is the classification of risks into risk categories, the authors show that risk has been compartmentalized too much and provide a strong case for a really holistic approach. Design/methodology/approach Systems thinking, causal loop models and conceptual approach. Findings Relevance of systemic risks for private banks as opposed to regulators only. In contrast to the starting point for all common risk-management frameworks in banks, which is the classification of risks into risk categories, the authors show that risk has been compartmentalized too much and provide a strong case for a really holistic approach, which stems from using explanatory models such as causal loop diagrams. On top of that more explanatory models ought to be used for risk management purposes while banks currently rely too much on statistical-descriptive approaches. Originality/value Integration of systems thinking into risk management, which is novel: in contrast to the starting point for all common risk-management frameworks in banks, which is the classification of risks into risk categories, the authors show that risk has been compartmentalized too much and provide a strong case for a really holistic approach.",Document_115,General discussion of financial or regulatory topics (non-AI focus),0.11590179800987244,Other Categories
Artificial intelligence and deep learning: considerations for financial institutions for compliance with the regulatory burden in the United Kingdom,C. Singh,"Artificial intelligence (AI), machine learning (ML) and deep learning (DL) are having a major impact on banking (FinTech), health (HealthTech), law (RegTech) and other sectors such as charitable fundraising (CharityTech). The pace of technological innovation and the ability of AI systems to think like human beings (simulate human intelligence), perform tasks independently, develop intelligence based on its own experiences and process layers of information to learn ever-complex representations of data (ML/DL) means that improvements in the rates at which this technology can undertake complex, technical and time-consuming tasks, identify people, objects, voices, patterns, etc., screen for ‘problems’ earlier, and provide solutions, provide astounding benefit in economic, political and social terms. The purpose of this paper is to explore advents in AI, ML and DL in the context of the regulatory compliance challenge faced by financial institutions in the United Kingdom (UK). Design/methodology/approach The subject is explored through the analysis of data and domestic and international published literature. The first part of the paper summarises the context of current regulatory issues, the advents in deep learning, how financial institutions are currently using AI, and how AI could provide further technological solutions to regulatory compliance as of February 2023. Findings It is suggested that UK financial institutions can further utilise AI, ML and DL as part of an armoury of solutions that ease the regulatory burden and achieve high levels of compliance success. Originality/value To the best of the author’s knowledge, this is the first study to specifically explore how AI, ML and DL can continue to assist UK financial institutions in meeting the regulatory compliance challenge and the opportunities provided for financial institutions by the metaverse.",2023,2023,,Journal of Financial Crime,Selector (#abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1108/jfc-01-2023-0011,10.1108/jfc-01-2023-0011,https://doi.org/10.1108/jfc-01-2023-0011,3,"Artificial intelligence (AI), machine learning (ML) and deep learning (DL) are having a major impact on banking (FinTech), health (HealthTech), law (RegTech) and other sectors such as charitable fundraising (CharityTech). The pace of technological innovation and the ability of AI systems to think like human beings (simulate human intelligence), perform tasks independently, develop intelligence based on its own experiences and process layers of information to learn ever-complex representations of data (ML/DL) means that improvements in the rates at which this technology can undertake complex, technical and time-consuming tasks, identify people, objects, voices, patterns, etc., screen for ‘problems’ earlier, and provide solutions, provide astounding benefit in economic, political and social terms. The purpose of this paper is to explore advents in AI, ML and DL in the context of the regulatory compliance challenge faced by financial institutions in the United Kingdom (UK). Design/methodology/approach The subject is explored through the analysis of data and domestic and international published literature. The first part of the paper summarises the context of current regulatory issues, the advents in deep learning, how financial institutions are currently using AI, and how AI could provide further technological solutions to regulatory compliance as of February 2023. Findings It is suggested that UK financial institutions can further utilise AI, ML and DL as part of an armoury of solutions that ease the regulatory burden and achieve high levels of compliance success. Originality/value To the best of the author’s knowledge, this is the first study to specifically explore how AI, ML and DL can continue to assist UK financial institutions in meeting the regulatory compliance challenge and the opportunities provided for financial institutions by the metaverse.",Document_116,Technical aspects or methods of AI or machine learning,0.1757349669933319,Other Categories
Progress in Natural Language Processing Technologies: Regulating Quality and Accessibility of Training Data,Ilya Ilyin,"Progress in natural language processing technologies (NLP) is a cardinal factor of major socioeconomic importance behind innovative digital products. However, inadequate legal regulation of quality and accessibility of training data is a major obstacle to this technological development. The paper is focused on regulatory issues affecting the quality and accessibility of data needed for language model training. In analyzing the normative barriers and proposing ways to remove them, the author of the paper argues for the need to develop a comprehensive regulatory system designed to ensure sustainable development of the technology.",2024,2024,,Legal Issues in the Digital Age,Selector (div.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.17323/2713-2749.2024.2.36.56,10.17323/2713-2749.2024.2.36.56,https://doi.org/10.17323/2713-2749.2024.2.36.56,3,"Progress in natural language processing technologies (NLP) is a cardinal factor of major socioeconomic importance behind innovative digital products. However, inadequate legal regulation of quality and accessibility of training data is a major obstacle to this technological development. The paper is focused on regulatory issues affecting the quality and accessibility of data needed for language model training. In analyzing the normative barriers and proposing ways to remove them, the author of the paper argues for the need to develop a comprehensive regulatory system designed to ensure sustainable development of the technology.",Document_117,Collaborating with regulators to create AI compliance frameworks,0.11238210648298264,Regulatory Engagement and Proactive Compliance Strategies
Natural Language Processing Applications in Case-Law Text Publishing,"Francesco Tarasconi, Milad Botros, Matteo Caserio, Gianpiero Sportelli, G. Giacalone, Carlotta Uttini, L. Vignati, Fabrizio Zanetta","Processing case-law contents for electronic publishing purposes is a time-consuming activity that encompasses several sub-tasks and usually involves adding annotations to the original text. On the other hand, recent trends in Artificial Intelligence and Natural Language Processing enable the automatic and efficient analysis of big textual data. In this paper we present our Machine Learning solution to three specific business problems, regularly met by a real world Italian publisher in their day-to-day work: recognition of legal references in text spans, new content ranking by relevance, and text classification according to a given tree of topics. Different approaches based on BERT language model were experimented with, together with alternatives, typically based on Bag-of-Words. The optimal solution, deployed in a controlled production environment, was in two out of three cases based on fine-tuned BERT (for the extraction of legal references and text classification), while, in the case of relevance ranking, a Random Forest model, with hand-crafted features, was preferred. We will conclude by discussing the concrete impact, as perceived by the publisher, of the developed prototypes.",2020,2020,4.0,International Conference on Legal Knowledge and Information Systems,Success (Selector (div.abstract)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.3233/faia200859,10.3233/faia200859,https://doi.org/10.3233/faia200859,2,"Processing case-law contents for electronic publishing purposes is a time-consuming activity that encompasses several sub-tasks and usually involves adding annotations to the original text. On the other hand, recent trends in Artificial Intelligence and Natural Language Processing enable the automatic and efficient analysis of big textual data. In this paper we present our Machine Learning solution to three specific business problems, regularly met by a real world Italian publisher in their day-to-day work: recognition of legal references in text spans, new content ranking by relevance, and text classification according to a given tree of topics. Different approaches based on BERT language model were experimented with, together with alternatives, typically based on Bag-of-Words. The optimal solution, deployed in a controlled production environment, was in two out of three cases based on fine-tuned BERT (for the extraction of legal references and text classification), while, in the case of relevance ranking, a Random Forest model, with hand-crafted features, was preferred. We will conclude by discussing the concrete impact, as perceived by the publisher, of the developed prototypes.",Document_118,Technical aspects or methods of AI or machine learning,0.424096941947937,Other Categories
Leveraging NLP Techniques for Privacy Requirements Engineering in User Stories,"Guntur Budi Herwanto, G. Quirchmayr, A. Tjoa, Guntur Budi Herwanto","Privacy requirements engineering acts as a role to systematically elicit privacy requirements from system requirements and legal requirements such as the GDPR. Many methodologies have been proposed, but the majority of them are focused on the waterfall approach, making adopting privacy engineering in agile software development difficult. The other major issue is that the process currently is to a high degree manual. This paper focuses on closing these gaps through the development of a machine learning-based approach for identifying privacy requirements in an agile software development environment, employing natural language processing (NLP) techniques. Our method aims to allow agile teams to focus on functional requirements while NLP tools assist them in generating privacy requirements. The main input for our method is a collection of user stories, which are typically used to identify functional requirements in agile software development. The NLP approach is then used to automate some human-intensive tasks such as identifying personal data and creating data flow diagrams from user stories. The data flow diagram forms the basis for the automatic creation of privacy requirements. Our evaluation shows that our NLP method achieves a fairly good performance in terms of F-Measure. We are also demonstrate the feasibility of our NLP approach in CamperPlus project. Lastly, we are developing a tool to integrate our NLP approach into the privacy requirements engineering pipeline, allowing for manual editing of results so that agile teams can maintain control over the automated approach.",2024,2024,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2024.3364533,10.1109/ACCESS.2024.3364533,https://doi.org/10.1109/ACCESS.2024.3364533,2,"Privacy requirements engineering acts as a role to systematically elicit privacy requirements from system requirements and legal requirements such as the GDPR. Many methodologies have been proposed, but the majority of them are focused on the waterfall approach, making adopting privacy engineering in agile software development difficult. The other major issue is that the process currently is to a high degree manual. This paper focuses on closing these gaps through the development of a machine learning-based approach for identifying privacy requirements in an agile software development environment, employing natural language processing (NLP) techniques. Our method aims to allow agile teams to focus on functional requirements while NLP tools assist them in generating privacy requirements. The main input for our method is a collection of user stories, which are typically used to identify functional requirements in agile software development. The NLP approach is then used to automate some human-intensive tasks such as identifying personal data and creating data flow diagrams from user stories. The data flow diagram forms the basis for the automatic creation of privacy requirements. Our evaluation shows that our NLP method achieves a fairly good performance in terms of F-Measure. We are also demonstrate the feasibility of our NLP approach in CamperPlus project. Lastly, we are developing a tool to integrate our NLP approach into the privacy requirements engineering pipeline, allowing for manual editing of results so that agile teams can maintain control over the automated approach.",Document_119,Technical aspects or methods of AI or machine learning,0.20334592461585999,Other Categories
Privacy-Preserving Deep Learning NLP Models for Cancer Registries,"M. Alawad, Hong-Jun Yoon, Shang Gao, B. Mumphrey, Xiao-Cheng Wu, E. Durbin, J. C. Jeong, I. Hands, D. Rust, Linda Coyle, Lynne Penberthy, G. Tourassi","Population cancer registries can benefit from Deep Learning (DL) to automatically extract cancer characteristics from the high volume of unstructured pathology text reports they process annually. The success of DL to tackle this and other real-world problems is proportional to the availability of large labeled datasets for model training. Although collaboration among cancer registries is essential to fully exploit the promise of DL, privacy and confidentiality concerns are main obstacles for data sharing across cancer registries. Moreover, DL for natural language processing (NLP) requires sharing a vocabulary dictionary for the embedding layer which may contain patient identifiers. Thus, even distributing the trained models across cancer registries causes a privacy violation issue. In this article, we propose DL NLP model distribution via privacy-preserving transfer learning approaches without sharing sensitive data. These approaches are used to distribute a multitask convolutional neural network (MT-CNN) NLP model among cancer registries. The model is trained to extract six key cancer characteristics – tumor site, subsite, laterality, behavior, histology, and grade – from cancer pathology reports. Using 410,064 pathology documents from two cancer registries, we compare our proposed approach to conventional transfer learning without privacy-preserving, single-registry models, and a model trained on centrally hosted data. The results show that transfer learning approaches including data sharing and model distribution outperform significantly the single-registry model. In addition, the best performing privacy-preserving model distribution approach achieves statistically indistinguishable average micro- and macro-F1 scores across all extraction tasks (0.823,0.580) as compared to the centralized model (0.827,0.585).",2020,2020,,IEEE Transactions on Emerging Topics in Computing,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/tetc.2020.2983404,10.1109/tetc.2020.2983404,https://doi.org/10.1109/tetc.2020.2983404,27,"Population cancer registries can benefit from Deep Learning (DL) to automatically extract cancer characteristics from the high volume of unstructured pathology text reports they process annually. The success of DL to tackle this and other real-world problems is proportional to the availability of large labeled datasets for model training. Although collaboration among cancer registries is essential to fully exploit the promise of DL, privacy and confidentiality concerns are main obstacles for data sharing across cancer registries. Moreover, DL for natural language processing (NLP) requires sharing a vocabulary dictionary for the embedding layer which may contain patient identifiers. Thus, even distributing the trained models across cancer registries causes a privacy violation issue. In this article, we propose DL NLP model distribution via privacy-preserving transfer learning approaches without sharing sensitive data. These approaches are used to distribute a multitask convolutional neural network (MT-CNN) NLP model among cancer registries. The model is trained to extract six key cancer characteristics – tumor site, subsite, laterality, behavior, histology, and grade – from cancer pathology reports. Using 410,064 pathology documents from two cancer registries, we compare our proposed approach to conventional transfer learning without privacy-preserving, single-registry models, and a model trained on centrally hosted data. The results show that transfer learning approaches including data sharing and model distribution outperform significantly the single-registry model. In addition, the best performing privacy-preserving model distribution approach achieves statistically indistinguishable average micro- and macro-F1 scores across all extraction tasks (0.823,0.580) as compared to the centralized model (0.827,0.585).",Document_120,Technical aspects or methods of AI or machine learning,0.16693176329135895,Other Categories
Efficient Combinatorial Optimization for Word-Level Adversarial Textual Attack,"Shengcai Liu, Ning Lu, Cheng Chen, Ke Tang","Over the past few years, various word-level textual attack approaches have been proposed to reveal the vulnerability of deep neural networks used in natural language processing. Typically, these approaches involve an important optimization step to determine which substitute to be used for each word in the original input. However, current research on this step is still rather limited, from the perspectives of both problem-understanding and problem-solving. In this paper, we address these issues by uncovering the theoretical properties of the problem and proposing an efficient local search algorithm (LS) to solve it. We establish the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">first</i> provable approximation guarantee on solving the problem in general cases. Extensive experiments involving 5 NLP tasks, 8 datasets and 26 NLP models show that LS can largely reduce the number of queries usually by an order of magnitude to achieve high attack success rates. Further experiments show that the adversarial examples crafted by LS usually have higher quality, exhibit better transferability, and can bring more robustness improvement to victim models by adversarial training.",2021,2021,,IEEE/ACM Transactions on Audio Speech and Language Processing,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/taslp.2021.3130970,10.1109/taslp.2021.3130970,https://doi.org/10.1109/taslp.2021.3130970,24,"Over the past few years, various word-level textual attack approaches have been proposed to reveal the vulnerability of deep neural networks used in natural language processing. Typically, these approaches involve an important optimization step to determine which substitute to be used for each word in the original input. However, current research on this step is still rather limited, from the perspectives of both problem-understanding and problem-solving. In this paper, we address these issues by uncovering the theoretical properties of the problem and proposing an efficient local search algorithm (LS) to solve it. We establish the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">first</i> provable approximation guarantee on solving the problem in general cases. Extensive experiments involving 5 NLP tasks, 8 datasets and 26 NLP models show that LS can largely reduce the number of queries usually by an order of magnitude to achieve high attack success rates. Further experiments show that the adversarial examples crafted by LS usually have higher quality, exhibit better transferability, and can bring more robustness improvement to victim models by adversarial training.",Document_121,Technical aspects or methods of AI or machine learning,0.09593725949525833,Other Categories
Extracting Keywords from Open-Ended Business Survey Questions,"Barbara McGillivray, Gard B. Jenset, D. Heil","Open-ended survey data constitute an important basis in research as well as for making business decisions. Collecting and manually analysing free-text survey data is generally more costly than collecting and analysing survey data consisting of answers to multiple-choice questions. Yet free-text data allow for new content to be expressed beyond predefined categories and are a very valuable source of new insights into people's opinions. At the same time, surveys always make ontological assumptions about the nature of the entities that are researched, and this has vital ethical consequences. Human interpretations and opinions can only be properly ascertained in their richness using textual data sources; if these sources are analyzed appropriately, the essential linguistic nature of humans and social entities is safeguarded. Natural Language Processing (NLP) offers possibilities for meeting this ethical business challenge by automating the analysis of natural language and thus allowing for insightful investigations of human judgements. We present a computational pipeline for analysing large amounts of responses to open-ended questions in surveys and extract keywords that appropriately represent people's opinions. This pipeline addresses the need to perform such tasks outside the scope of both commercial software and bespoke analysis, exceeds the performance to state-of-the-art systems, and performs this task in a transparent way that allows for scrutinising and exposing potential biases in the analysis. Following the principle of Open Data Science, our code is open-source and generalizable to other datasets.",2018,2020,3.0,Journal of Data Mining and Digital Humanities,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (Meta (citation_publication_date)) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.48) (URL Source: DOI Link)",https://doi.org/10.46298/jdmdh.5077,10.46298/jdmdh.5077,https://doi.org/10.46298/jdmdh.5077,2,"Open-ended survey data constitute an important basis in research as well as for making business decisions. Collecting and manually analysing free-text survey data is generally more costly than collecting and analysing survey data consisting of answers to multiple-choice questions. Yet free-text data allow for new content to be expressed beyond predefined categories and are a very valuable source of new insights into people's opinions. At the same time, surveys always make ontological assumptions about the nature of the entities that are researched, and this has vital ethical consequences. Human interpretations and opinions can only be properly ascertained in their richness using textual data sources; if these sources are analyzed appropriately, the essential linguistic nature of humans and social entities is safeguarded. Natural Language Processing (NLP) offers possibilities for meeting this ethical business challenge by automating the analysis of natural language and thus allowing for insightful investigations of human judgements. We present a computational pipeline for analysing large amounts of responses to open-ended questions in surveys and extract keywords that appropriately represent people's opinions. This pipeline addresses the need to perform such tasks outside the scope of both commercial software and bespoke analysis, exceeds the performance to state-of-the-art systems, and performs this task in a transparent way that allows for scrutinising and exposing potential biases in the analysis. Following the principle of Open Data Science, our code is open-source and generalizable to other datasets.",Document_122,Technical aspects or methods of AI or machine learning,0.05769882723689079,Other Categories
"Knowledge Representation and Management, It’s Time to Integrate!","F. Dhombres, J. Charlet","Objectives: To select, present, and summarize the best papers published in 2016 in the field of Knowledge Representation and Management (KRM). Methods: A comprehensive and standardized review of the medical informatics literature was performed based on a PubMed query. Results: Among the 1,421 retrieved papers, the review process resulted in the selection of four best papers focused on the integration of heterogeneous data via the development and the alignment of terminological resources. In the first article, the authors provide a curated and standardized version of the publicly available US FDA Adverse Event Reporting System. Such a resource will improve the quality of the underlying data, and enable standardized analyses using common vocabularies. The second article describes a project developed in order to facilitate heterogeneous data integration in the i2b2 framework. The originality is to allow users integrate the data described in different terminologies and to build a new repository, with a unique model able to support the representation of the various data. The third paper is dedicated to model the association between multiple phenotypic traits described within the Human Phenotype Ontology (HPO) and the corresponding genotype in the specific context of rare diseases (rare variants). Finally, the fourth paper presents solutions to annotation-ontology mapping in genome-scale data. Of particular interest in this work is the Experimental Factor Ontology (EFO) and its generic association model, the Ontology of Biomedical AssociatioN (OBAN). Conclusion: Ontologies have started to show their efficiency to integrate medical data for various tasks in medical informatics: electronic health records data management, clinical research, and knowledge-based systems development.",2017,2017,8.0,Yearbook of Medical Informatics,Success (Selector (#abstract)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.15265/IY-2017-030,10.15265/IY-2017-030,https://doi.org/10.15265/IY-2017-030,9,"Objectives: To select, present, and summarize the best papers published in 2016 in the field of Knowledge Representation and Management (KRM). Methods: A comprehensive and standardized review of the medical informatics literature was performed based on a PubMed query. Results: Among the 1,421 retrieved papers, the review process resulted in the selection of four best papers focused on the integration of heterogeneous data via the development and the alignment of terminological resources. In the first article, the authors provide a curated and standardized version of the publicly available US FDA Adverse Event Reporting System. Such a resource will improve the quality of the underlying data, and enable standardized analyses using common vocabularies. The second article describes a project developed in order to facilitate heterogeneous data integration in the i2b2 framework. The originality is to allow users integrate the data described in different terminologies and to build a new repository, with a unique model able to support the representation of the various data. The third paper is dedicated to model the association between multiple phenotypic traits described within the Human Phenotype Ontology (HPO) and the corresponding genotype in the specific context of rare diseases (rare variants). Finally, the fourth paper presents solutions to annotation-ontology mapping in genome-scale data. Of particular interest in this work is the Experimental Factor Ontology (EFO) and its generic association model, the Ontology of Biomedical AssociatioN (OBAN). Conclusion: Ontologies have started to show their efficiency to integrate medical data for various tasks in medical informatics: electronic health records data management, clinical research, and knowledge-based systems development.",Document_123,Building organizational support for AI through education and communication,0.055289894342422485,"Education, Awareness, and Policy Strategies"
Knowledge Representation and Management: Benefits and Challenges of the Semantic Web for the Fields of KRM and NLP,A. Rassinoux,"Objectives To summarize excellent current research in the field of knowledge representation and management (KRM). Method A synopsis of the articles selected for the IMIA Yearbook 2011 is provided and an attempt to highlight the current trends in the field is sketched. Results This last decade, with the extension of the text-based web towards a semantic-structured web, NLP techniques have experienced a renewed interest in knowledge extraction. This trend is corroborated through the five papers selected for the KRM section of the Yearbook 2011. They all depict outstanding studies that exploit NLP technologies whenever possible in order to accurately extract meaningful information from various biomedical textual sources. Conclusions Bringing semantic structure to the meaningful content of textual web pages affords the user with cooperative sharing and intelligent finding of electronic data. As exemplified by the best paper selection, more and more advanced biomedical applications aim at exploiting the meaningful richness of free-text documents in order to generate semantic metadata and recently to learn and populate domain ontologies. These later are becoming a key piece as they allow portraying the semantics of the Semantic Web content. Maintaining their consistency with documents and semantic annotations that refer to them is a crucial challenge of the Semantic Web for the coming years.",2011,2011,4.0,Yearbook of Medical Informatics,Success (Selector (#abstract)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1055/s-0038-1638749,10.1055/s-0038-1638749,https://doi.org/10.1055/s-0038-1638749,3,"Objectives To summarize excellent current research in the field of knowledge representation and management (KRM). Method A synopsis of the articles selected for the IMIA Yearbook 2011 is provided and an attempt to highlight the current trends in the field is sketched. Results This last decade, with the extension of the text-based web towards a semantic-structured web, NLP techniques have experienced a renewed interest in knowledge extraction. This trend is corroborated through the five papers selected for the KRM section of the Yearbook 2011. They all depict outstanding studies that exploit NLP technologies whenever possible in order to accurately extract meaningful information from various biomedical textual sources. Conclusions Bringing semantic structure to the meaningful content of textual web pages affords the user with cooperative sharing and intelligent finding of electronic data. As exemplified by the best paper selection, more and more advanced biomedical applications aim at exploiting the meaningful richness of free-text documents in order to generate semantic metadata and recently to learn and populate domain ontologies. These later are becoming a key piece as they allow portraying the semantics of the Semantic Web content. Maintaining their consistency with documents and semantic annotations that refer to them is a crucial challenge of the Semantic Web for the coming years.",Document_124,Building organizational support for AI through education and communication,0.07771484553813934,"Education, Awareness, and Policy Strategies"
GDPR Compliant Information Confidentiality Preservation in Big Data Processing,"Loredana Caruccio, Domenico Desiato, G. Polese, G. Tortora","Nowadays, new laws and regulations, such as the European General Data Protection Regulation (GDPR), require companies to define privacy policies complying with the preferences of their users. The regulation prescribes expensive penalties for those companies causing the disclosure of sensitive data of their users, even if this occurs accidentally. Thus, it is necessary to devise methods supporting companies in the identification of privacy threats during advanced data manipulation activities. To this end, in this paper, we propose a methodology exploiting relaxed functional dependencies (RFDs) to automatically identify data that could imply the values of sensitive ones, which permits to increase the confidentiality of a dataset while reducing the number of values to be obscured. An experimental evaluation demonstrates the effectiveness of the proposed methodology in increasing compliance to the GDPR data privacy, while reducing the set of values to be partially masked, hence enhancing data usage.",2020,2020,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2020.3036916,10.1109/ACCESS.2020.3036916,https://doi.org/10.1109/ACCESS.2020.3036916,15,"Nowadays, new laws and regulations, such as the European General Data Protection Regulation (GDPR), require companies to define privacy policies complying with the preferences of their users. The regulation prescribes expensive penalties for those companies causing the disclosure of sensitive data of their users, even if this occurs accidentally. Thus, it is necessary to devise methods supporting companies in the identification of privacy threats during advanced data manipulation activities. To this end, in this paper, we propose a methodology exploiting relaxed functional dependencies (RFDs) to automatically identify data that could imply the values of sensitive ones, which permits to increase the confidentiality of a dataset while reducing the number of values to be obscured. An experimental evaluation demonstrates the effectiveness of the proposed methodology in increasing compliance to the GDPR data privacy, while reducing the set of values to be partially masked, hence enhancing data usage.",Document_125,Demonstrating the value of AI for compliance and risk management,0.13055898249149323,Business Case and Value Demonstration Strategies
Protecting Intellectual Property of Language Generation APIs with Lexical Watermark,"Xuanli He, Qiongkai Xu, L. Lyu, Fangzhao Wu, Chenguang Wang","Nowadays, due to the breakthrough in natural language generation (NLG), including machine translation, document summarization, image captioning, etc NLG models have been encapsulated in cloud APIs to serve over half a billion people worldwide and process over one hundred billion word generations per day. Thus, NLG APIs have already become essential profitable services in many commercial companies. Due to the substantial financial and intellectual investments, service providers adopt a pay-as-you-use policy to promote sustainable market growth. However, recent works have shown that cloud platforms suffer from financial losses imposed by model extraction attacks, which aim to imitate the functionality and utility of the victim services, thus violating the intellectual property (IP) of cloud APIs. This work targets at protecting IP of NLG APIs by identifying the attackers who have utilized watermarked responses from the victim NLG APIs. However, most existing watermarking techniques are not directly amenable for IP protection of NLG APIs. To bridge this gap, we first present a novel watermarking method for text generation APIs by conducting lexical modification to the original outputs. Compared with the competitive baselines, our watermark approach achieves better identifiable performance in terms of p-value, with fewer semantic losses. In addition, our watermarks are more understandable and intuitive to humans than the baselines. Finally, the empirical studies show our approach is also applicable to queries from different domains, and is effective on the attacker trained on a mixture of the corpus which includes less than 10% watermarked samples.",2021,2021,,AAAI Conference on Artificial Intelligence,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1609/aaai.v36i10.21321,10.1609/aaai.v36i10.21321,https://doi.org/10.1609/aaai.v36i10.21321,85,"Nowadays, due to the breakthrough in natural language generation (NLG), including machine translation, document summarization, image captioning, etc NLG models have been encapsulated in cloud APIs to serve over half a billion people worldwide and process over one hundred billion word generations per day. Thus, NLG APIs have already become essential profitable services in many commercial companies. Due to the substantial financial and intellectual investments, service providers adopt a pay-as-you-use policy to promote sustainable market growth. However, recent works have shown that cloud platforms suffer from financial losses imposed by model extraction attacks, which aim to imitate the functionality and utility of the victim services, thus violating the intellectual property (IP) of cloud APIs. This work targets at protecting IP of NLG APIs by identifying the attackers who have utilized watermarked responses from the victim NLG APIs. However, most existing watermarking techniques are not directly amenable for IP protection of NLG APIs. To bridge this gap, we first present a novel watermarking method for text generation APIs by conducting lexical modification to the original outputs. Compared with the competitive baselines, our watermark approach achieves better identifiable performance in terms of p-value, with fewer semantic losses. In addition, our watermarks are more understandable and intuitive to humans than the baselines. Finally, the empirical studies show our approach is also applicable to queries from different domains, and is effective on the attacker trained on a mixture of the corpus which includes less than 10% watermarked samples.",Document_126,Security risks associated with AI are a concern in financial regulation,0.0548817440867424,Organizational and Human Barriers
Overview of the 2014 NLP Unshared Task in PoliInformatics,"Noah A. Smith, Claire Cardie, A. Washington, J. Wilkerson","Noah A. Smith, Claire Cardie, Anne Washington, John Wilkerson. Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science. 2014.",2014,2014,6.0,LTCSS@ACL,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (Meta (citation_publication_date)) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.11) (URL Source: DOI Link)",https://doi.org/10.3115/v1/W14-2505,10.3115/v1/W14-2505,https://doi.org/10.3115/v1/W14-2505,13,"Noah A. Smith, Claire Cardie, Anne Washington, John Wilkerson. Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science. 2014.",Document_127,Building organizational support for AI through education and communication,0.09585404396057129,"Education, Awareness, and Policy Strategies"
CAT-Gen: Improving Robustness in NLP Models via Controlled Adversarial Text Generation,"Tianlu Wang, Xuezhi Wang, Yao Qin, Ben Packer, Kang Li, Jilin Chen, Alex Beutel, Ed H. Chi","NLP models are shown to suffer from robustness issues, i.e., a model’s prediction can be easily changed under small perturbations to the input. In this work, we present a Controlled Adversarial Text Generation (CAT-Gen) model that, given an input text, generates adversarial texts through controllable attributes that are known to be invariant to task labels. For example, in order to attack a model for sentiment classification over product reviews, we can use the product categories as the controllable attribute which would not change the sentiment of the reviews. Experiments on real-world NLP datasets demonstrate that our method can generate more diverse and fluent adversarial texts, compared to many existing adversarial text generation approaches. We further use our generated adversarial examples to improve models through adversarial training, and we demonstrate that our generated attacks are more robust against model re-training and different model architectures.",2020,2020,11.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.emnlp-main.417,10.18653/v1/2020.emnlp-main.417,https://doi.org/10.18653/v1/2020.emnlp-main.417,79,"NLP models are shown to suffer from robustness issues, i.e., a model’s prediction can be easily changed under small perturbations to the input. In this work, we present a Controlled Adversarial Text Generation (CAT-Gen) model that, given an input text, generates adversarial texts through controllable attributes that are known to be invariant to task labels. For example, in order to attack a model for sentiment classification over product reviews, we can use the product categories as the controllable attribute which would not change the sentiment of the reviews. Experiments on real-world NLP datasets demonstrate that our method can generate more diverse and fluent adversarial texts, compared to many existing adversarial text generation approaches. We further use our generated adversarial examples to improve models through adversarial training, and we demonstrate that our generated attacks are more robust against model re-training and different model architectures.",Document_128,Technical aspects or methods of AI or machine learning,0.08457228541374207,Other Categories
NLP and Deep Learning-based Analysis of Building Regulations to Support Automated Rule Checking System,"Jaeyeol Song, Jinsung Kim, J. Lee","NLP and Deep Learning-based Analysis of Building Regulations to Support Automated Rule Checking System Jaeyeol Song, Jinsung Kim and Jin-Kook Lee Pages 586-592 (2018 Proceedings of the 35th ISARC, Berlin, Germany, ISBN 978-3-00-060855-1, ISSN 2413-5844) Abstract: This paper aims to describe a natural language processing (NLP) and deep learning-based approach for supporting automated rule checking system. Automated rule checking has been developed in various ways and enhanced the efficiency of building design review process. Converting human-readable building regulations to computer-readable format is, however, still time-consuming and error-prone due to the nature of human languages. Several domain-independent efforts have been made for NLP, and this paper focuses on how computers can be able to understand semantic meaning of building regulations to intelligently automate rule interpretation process. This paper proposes a semantic analysis process of regulatory sentences and its utilization for rule checking system. The proposed process is composed of following steps: 1) learning semantics of words and sentences, 2) utilization of semantic analysis. For semantic analysis, we use word embedding technique which converts meaning of words in numerical values. By using those values, computers can extract related words and classify the topic of sentences. The results of the semantic analysis can elaborate the interpretation with domain-specific knowledge. This paper also shows a demonstration of the proposed approach. Keywords: Automated rule checking, Natural language processing, Deep learning, Semantic analysis, Building information modeling (BIM) DOI: https://doi.org/10.22260/ISARC2018/0080 Download fulltext Download BibTex Download Endnote (RIS) TeX Import to Mendeley",2018,2018,7.0,Proceedings of the 35th International Symposium on Automation and Robotics in Construction (ISARC),"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.22260/isarc2018/0080,10.22260/isarc2018/0080,https://doi.org/10.22260/isarc2018/0080,21,"NLP and Deep Learning-based Analysis of Building Regulations to Support Automated Rule Checking System Jaeyeol Song, Jinsung Kim and Jin-Kook Lee Pages 586-592 (2018 Proceedings of the 35th ISARC, Berlin, Germany, ISBN 978-3-00-060855-1, ISSN 2413-5844) Abstract: This paper aims to describe a natural language processing (NLP) and deep learning-based approach for supporting automated rule checking system. Automated rule checking has been developed in various ways and enhanced the efficiency of building design review process. Converting human-readable building regulations to computer-readable format is, however, still time-consuming and error-prone due to the nature of human languages. Several domain-independent efforts have been made for NLP, and this paper focuses on how computers can be able to understand semantic meaning of building regulations to intelligently automate rule interpretation process. This paper proposes a semantic analysis process of regulatory sentences and its utilization for rule checking system. The proposed process is composed of following steps: 1) learning semantics of words and sentences, 2) utilization of semantic analysis. For semantic analysis, we use word embedding technique which converts meaning of words in numerical values. By using those values, computers can extract related words and classify the topic of sentences. The results of the semantic analysis can elaborate the interpretation with domain-specific knowledge. This paper also shows a demonstration of the proposed approach. Keywords: Automated rule checking, Natural language processing, Deep learning, Semantic analysis, Building information modeling (BIM) DOI: https://doi.org/10.22260/ISARC2018/0080 Download fulltext Download BibTex Download Endnote (RIS) TeX Import to Mendeley",Document_129,Technical aspects or methods of AI or machine learning,0.13731904327869415,Other Categories
Exposing the Vulnerabilities of Deep Learning Models in News Classification,"Ashish Bajaj, D. Vishwakarma","News websites need to divide their articles into categories that make it easier for readers to find news of their interest. Recent deep-learning models have excelled in this news classification task. Despite the tremendous success of deep learning models in NLP-related tasks, it is vulnerable to adversarial attacks, which lead to misclassification of the news category. An adversarial text is generated by changing a few words or characters in a way that retains the overall semantic similarity of news for a human reader but deceives the machine into giving inaccurate predictions. This paper presents the vulnerability in news classification by generating adversarial text using various state-of-the-art attack algorithms. We have compared and analyzed the behavior of different models, including the powerful transformer model, BERT, and the widely used Word-CNN and LSTM models trained on AG news classification dataset. We have evaluated the potential results by calculating Attack Success Rates (ASR) for each model. The results show that it is possible to automatically bypass News topic classification mechanisms, resulting in repercussions for current policy measures.",2023,2023,,2023 4th International Conference on Innovative Trends in Information Technology (ICITIIT),"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ICITIIT57246.2023.10068577,10.1109/ICITIIT57246.2023.10068577,https://doi.org/10.1109/ICITIIT57246.2023.10068577,7,"News websites need to divide their articles into categories that make it easier for readers to find news of their interest. Recent deep-learning models have excelled in this news classification task. Despite the tremendous success of deep learning models in NLP-related tasks, it is vulnerable to adversarial attacks, which lead to misclassification of the news category. An adversarial text is generated by changing a few words or characters in a way that retains the overall semantic similarity of news for a human reader but deceives the machine into giving inaccurate predictions. This paper presents the vulnerability in news classification by generating adversarial text using various state-of-the-art attack algorithms. We have compared and analyzed the behavior of different models, including the powerful transformer model, BERT, and the widely used Word-CNN and LSTM models trained on AG news classification dataset. We have evaluated the potential results by calculating Attack Success Rates (ASR) for each model. The results show that it is possible to automatically bypass News topic classification mechanisms, resulting in repercussions for current policy measures.",Document_130,Technical aspects or methods of AI or machine learning,0.13947758078575134,Other Categories
Building a Business Knowledge Base by a Supervised Learning and Rule-Based Method,"Sungho Shin, Hanmin Jung, M. Yi","Natural Language Question Answering (NLQA) and Prescriptive Analytics (PA) have been identified as innovative, emerging technologies in 2015 by the Gartner group. These technologies require knowledge bases that consist of data that has been extracted from unstructured texts. Every business requires a knowledge base for business analytics as it can enhance companies competitiveness in their industry. Most intelligent or analytic services depend a lot upon on knowledge bases. However, building a qualified knowledge base is very time consuming and requires a considerable amount of effort, especially if it is to be manually created. Another problem that occurs when creating a knowledge base is that it will be outdated by the time it is completed and will require constant updating even when it is ready in use. For these reason, it is more advisable to create a computerized knowledge base. This research focuses on building a computerized knowledge base for business using a supervised learning and rule-based method. The method proposed in this paper is based on information extraction, but it has been specialized and modified to extract information related only to a business. The business knowledge base created by our system can also be used for advanced functions such as presenting the hierarchy of technologies and products, and the relations between technologies and products. Using our method, these relations can be expanded and customized according to business requirements.",2015,2015,1.0,KSII Transactions on Internet and Information Systems,Success (Heading+Sibling) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.3837/tiis.2015.01.025,10.3837/tiis.2015.01.025,https://doi.org/10.3837/tiis.2015.01.025,4,"Natural Language Question Answering (NLQA) and Prescriptive Analytics (PA) have been identified as innovative, emerging technologies in 2015 by the Gartner group. These technologies require knowledge bases that consist of data that has been extracted from unstructured texts. Every business requires a knowledge base for business analytics as it can enhance companies competitiveness in their industry. Most intelligent or analytic services depend a lot upon on knowledge bases. However, building a qualified knowledge base is very time consuming and requires a considerable amount of effort, especially if it is to be manually created. Another problem that occurs when creating a knowledge base is that it will be outdated by the time it is completed and will require constant updating even when it is ready in use. For these reason, it is more advisable to create a computerized knowledge base. This research focuses on building a computerized knowledge base for business using a supervised learning and rule-based method. The method proposed in this paper is based on information extraction, but it has been specialized and modified to extract information related only to a business. The business knowledge base created by our system can also be used for advanced functions such as presenting the hierarchy of technologies and products, and the relations between technologies and products. Using our method, these relations can be expanded and customized according to business requirements.",Document_131,Technical aspects or methods of AI or machine learning,0.12541629374027252,Other Categories
Natural language based financial forecasting: a survey,"Frank Xing, E. Cambria, R. Welsch","Natural language processing (NLP), or the pragmatic research perspective of computational linguistics, has become increasingly powerful due to data availability and various techniques developed in the past decade. This increasing capability makes it possible to capture sentiments more accurately and semantics in a more nuanced way. Naturally, many applications are starting to seek improvements by adopting cutting-edge NLP techniques. Financial forecasting is no exception. As a result, articles that leverage NLP techniques to predict financial markets are fast accumulating, gradually establishing the research field of natural language based financial forecasting (NLFF), or from the application perspective, stock market prediction. This review article clarifies the scope of NLFF research by ordering and structuring techniques and applications from related work. The survey also aims to increase the understanding of progress and hotspots in NLFF, and bring about discussions across many different disciplines.",2017,2018,6.0,Artificial Intelligence Review,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10462-017-9588-9,10.1007/s10462-017-9588-9,https://doi.org/10.1007/s10462-017-9588-9,328,"Natural language processing (NLP), or the pragmatic research perspective of computational linguistics, has become increasingly powerful due to data availability and various techniques developed in the past decade. This increasing capability makes it possible to capture sentiments more accurately and semantics in a more nuanced way. Naturally, many applications are starting to seek improvements by adopting cutting-edge NLP techniques. Financial forecasting is no exception. As a result, articles that leverage NLP techniques to predict financial markets are fast accumulating, gradually establishing the research field of natural language based financial forecasting (NLFF), or from the application perspective, stock market prediction. This review article clarifies the scope of NLFF research by ordering and structuring techniques and applications from related work. The survey also aims to increase the understanding of progress and hotspots in NLFF, and bring about discussions across many different disciplines.",Document_132,Improving data quality is crucial for successful AI in finance,0.06649854779243469,Data Improvement and Availability Strategies
Ethical by Design: Ethics Best Practices for Natural Language Processing,"Jochen L. Leidner, Vassilis Plachouras","Natural language processing (NLP) systems analyze and/or generate human language, typically on users’ behalf. One natural and necessary question that needs to be addressed in this context, both in research projects and in production settings, is the question how ethical the work is, both regarding the process and its outcome. Towards this end, we articulate a set of issues, propose a set of best practices, notably a process featuring an ethics review board, and sketch and how they could be meaningfully applied. Our main argument is that ethical outcomes ought to be achieved by design, i.e. by following a process aligned by ethical values. We also offer some response options for those facing ethics issues. While a number of previous works exist that discuss ethical issues, in particular around big data and machine learning, to the authors’ knowledge this is the first account of NLP and ethics from the perspective of a principled process.",2017,2017,4.0,EthNLP@EACL,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/W17-1604,10.18653/v1/W17-1604,https://doi.org/10.18653/v1/W17-1604,71,"Natural language processing (NLP) systems analyze and/or generate human language, typically on users’ behalf. One natural and necessary question that needs to be addressed in this context, both in research projects and in production settings, is the question how ethical the work is, both regarding the process and its outcome. Towards this end, we articulate a set of issues, propose a set of best practices, notably a process featuring an ethics review board, and sketch and how they could be meaningfully applied. Our main argument is that ethical outcomes ought to be achieved by design, i.e. by following a process aligned by ethical values. We also offer some response options for those facing ethics issues. While a number of previous works exist that discuss ethical issues, in particular around big data and machine learning, to the authors’ knowledge this is the first account of NLP and ethics from the perspective of a principled process.",Document_133,Technical aspects or methods of AI or machine learning,0.20006240904331207,Other Categories
BAE: BERT-based Adversarial Examples for Text Classification,"Siddhant Garg, Goutham Ramakrishnan","Modern text classification models are susceptible to adversarial examples, perturbed versions of the original text indiscernible by humans which get misclassified by the model. Recent works in NLP use rule-based synonym replacement strategies to generate adversarial examples. These strategies can lead to out-of-context and unnaturally complex token replacements, which are easily identifiable by humans. We present BAE, a black box attack for generating adversarial examples using contextual perturbations from a BERT masked language model. BAE replaces and inserts tokens in the original text by masking a portion of the text and leveraging the BERT-MLM to generate alternatives for the masked tokens. Through automatic and human evaluations, we show that BAE performs a stronger attack, in addition to generating adversarial examples with improved grammaticality and semantic coherence as compared to prior work.",2020,2020,11.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.emnlp-main.498,10.18653/v1/2020.emnlp-main.498,https://doi.org/10.18653/v1/2020.emnlp-main.498,509,"Modern text classification models are susceptible to adversarial examples, perturbed versions of the original text indiscernible by humans which get misclassified by the model. Recent works in NLP use rule-based synonym replacement strategies to generate adversarial examples. These strategies can lead to out-of-context and unnaturally complex token replacements, which are easily identifiable by humans. We present BAE, a black box attack for generating adversarial examples using contextual perturbations from a BERT masked language model. BAE replaces and inserts tokens in the original text by masking a portion of the text and leveraging the BERT-MLM to generate alternatives for the masked tokens. Through automatic and human evaluations, we show that BAE performs a stronger attack, in addition to generating adversarial examples with improved grammaticality and semantic coherence as compared to prior work.",Document_134,Technical aspects or methods of AI or machine learning,0.14791461825370789,Other Categories
Facilitating Cancer Research using Natural Language Processing of Pathology Reports,"Huan Xu, K. Anderson, V. Grann, C. Friedman","Many ongoing clinical research projects, such as projects involving studies associated with cancer, involve manual capture of information in surgical pathology reports so that the information can be used to determine the eligibility of recruited patients for the study and to provide other information, such as cancer prognosis. Natural language processing (NLP) systems offer an alternative to automated coding, but pathology reports have certain features that are difficult for NLP systems. This paper describes how a preprocessor was integrated with an existing NLP system (MedLEE) in order to reduce modification to the NLP system and to improve performance. The work was done in conjunction with an ongoing clinical research project that assesses disparities and risks of developing breast cancer for minority women. An evaluation of the system was performed using manually coded data from the research project’s database as a gold standard. The evaluation outcome showed that the extended NLP system had a sensitivity of 90.6% and a precision of 91.6%. Results indicated that this system performed satisfactorily for capturing information for the cancer research project.",2004,2004,4.0,Medinfo,Success (Selector (div.abstract)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.3233/978-1-60750-949-3-565,10.3233/978-1-60750-949-3-565,https://doi.org/10.3233/978-1-60750-949-3-565,80,"Many ongoing clinical research projects, such as projects involving studies associated with cancer, involve manual capture of information in surgical pathology reports so that the information can be used to determine the eligibility of recruited patients for the study and to provide other information, such as cancer prognosis. Natural language processing (NLP) systems offer an alternative to automated coding, but pathology reports have certain features that are difficult for NLP systems. This paper describes how a preprocessor was integrated with an existing NLP system (MedLEE) in order to reduce modification to the NLP system and to improve performance. The work was done in conjunction with an ongoing clinical research project that assesses disparities and risks of developing breast cancer for minority women. An evaluation of the system was performed using manually coded data from the research project’s database as a gold standard. The evaluation outcome showed that the extended NLP system had a sensitivity of 90.6% and a precision of 91.6%. Results indicated that this system performed satisfactorily for capturing information for the cancer research project.",Document_135,Demonstrating the value of AI for compliance and risk management,0.05969209223985672,Business Case and Value Demonstration Strategies
Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment,"Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits","Machine learning algorithms are often vulnerable to adversarial examples that have imperceptible alterations from the original counterparts but can fool the state-of-the-art models. It is helpful to evaluate or even improve the robustness of these models by exposing the maliciously crafted adversarial examples. In this paper, we present TextFooler , a simple but strong baseline to generate adversarial text. By applying it to two fundamental natural language tasks, text classification and textual entailment, we successfully attacked three target models, including the powerful pre-trained BERT, and the widely used convolutional and recurrent neural networks. We demonstrate three advantages of this framework: (1) effective—it outperforms previous attacks by success rate and perturbation rate, (2) utility-preserving—it preserves semantic content, grammaticality, and correct types classified by humans, and (3) efficient—it generates adversarial text with computational complexity linear to the text length. 1",2019,2019,,AAAI Conference on Artificial Intelligence,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1609/AAAI.V34I05.6311,10.1609/AAAI.V34I05.6311,https://doi.org/10.1609/AAAI.V34I05.6311,965,"Machine learning algorithms are often vulnerable to adversarial examples that have imperceptible alterations from the original counterparts but can fool the state-of-the-art models. It is helpful to evaluate or even improve the robustness of these models by exposing the maliciously crafted adversarial examples. In this paper, we present TextFooler , a simple but strong baseline to generate adversarial text. By applying it to two fundamental natural language tasks, text classification and textual entailment, we successfully attacked three target models, including the powerful pre-trained BERT, and the widely used convolutional and recurrent neural networks. We demonstrate three advantages of this framework: (1) effective—it outperforms previous attacks by success rate and perturbation rate, (2) utility-preserving—it preserves semantic content, grammaticality, and correct types classified by humans, and (3) efficient—it generates adversarial text with computational complexity linear to the text length. 1",Document_136,Technical aspects or methods of AI or machine learning,0.14138692617416382,Other Categories
Sentiment Analysis in Finance: From Transformers Back to eXplainable Lexicons (XLex),"Maryan Rizinski, Hristijan Peshov, Kostadin Mishev, Milos Jovanovik, D. Trajanov","Lexicon-based sentiment analysis in finance leverages specialized, manually annotated lexicons created by human experts to extract sentiment from financial texts effectively. Although lexicon-based methods are simple to implement and fast to operate on textual data, they require considerable manual annotation efforts to create, maintain, and update the lexicons. These methods are also considered inferior to the deep learning-based approaches, such as transformer models, which have become dominant in various natural language processing (NLP) tasks due to their remarkable performance. However, their efficacy comes at a cost: these models require extensive data and computational resources for both training and testing. Additionally, they involve significant prediction times, making them unsuitable for real-time production environments or systems with limited processing capabilities. In this paper, we introduce a novel methodology named eXplainable Lexicons (XLex) that combines the advantages of both lexicon-based methods and transformer models. We propose an approach that utilizes transformers and SHapley Additive exPlanations (SHAP) for explainability to automatically learn financial lexicons. Our study presents four main contributions. Firstly, we demonstrate that transformer-aided explainable lexicons can enhance the vocabulary coverage of the benchmark Loughran-McDonald (LM) lexicon. This enhancement leads to a significant reduction in the need for human involvement in the process of annotating, maintaining, and updating the lexicons. Secondly, we show that the resulting lexicon outperforms the standard LM lexicon in sentiment analysis of financial datasets. Our experiments show that XLex outperforms LM when applied to general financial texts, resulting in enhanced word coverage and an overall increase in classification accuracy by 0.431. Furthermore, by employing XLex to extend LM, we create a combined dictionary, XLex+LM, which achieves an even higher accuracy improvement of 0.450. Thirdly, we illustrate that the lexicon-based approach is significantly more efficient in terms of model speed and size compared to transformers. Lastly, the proposed XLex approach is inherently more interpretable than transformer models. This interpretability is advantageous as lexicon models rely on predefined rules, unlike transformers, which have complex inner workings. The interpretability of the models allows for better understanding and insights into the results of sentiment analysis, making the XLex approach a valuable tool for financial decision-making.",2023,2023,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2024.3349970,10.1109/ACCESS.2024.3349970,https://doi.org/10.1109/ACCESS.2024.3349970,5,"Lexicon-based sentiment analysis in finance leverages specialized, manually annotated lexicons created by human experts to extract sentiment from financial texts effectively. Although lexicon-based methods are simple to implement and fast to operate on textual data, they require considerable manual annotation efforts to create, maintain, and update the lexicons. These methods are also considered inferior to the deep learning-based approaches, such as transformer models, which have become dominant in various natural language processing (NLP) tasks due to their remarkable performance. However, their efficacy comes at a cost: these models require extensive data and computational resources for both training and testing. Additionally, they involve significant prediction times, making them unsuitable for real-time production environments or systems with limited processing capabilities. In this paper, we introduce a novel methodology named eXplainable Lexicons (XLex) that combines the advantages of both lexicon-based methods and transformer models. We propose an approach that utilizes transformers and SHapley Additive exPlanations (SHAP) for explainability to automatically learn financial lexicons. Our study presents four main contributions. Firstly, we demonstrate that transformer-aided explainable lexicons can enhance the vocabulary coverage of the benchmark Loughran-McDonald (LM) lexicon. This enhancement leads to a significant reduction in the need for human involvement in the process of annotating, maintaining, and updating the lexicons. Secondly, we show that the resulting lexicon outperforms the standard LM lexicon in sentiment analysis of financial datasets. Our experiments show that XLex outperforms LM when applied to general financial texts, resulting in enhanced word coverage and an overall increase in classification accuracy by 0.431. Furthermore, by employing XLex to extend LM, we create a combined dictionary, XLex+LM, which achieves an even higher accuracy improvement of 0.450. Thirdly, we illustrate that the lexicon-based approach is significantly more efficient in terms of model speed and size compared to transformers. Lastly, the proposed XLex approach is inherently more interpretable than transformer models. This interpretability is advantageous as lexicon models rely on predefined rules, unlike transformers, which have complex inner workings. The interpretability of the models allows for better understanding and insights into the results of sentiment analysis, making the XLex approach a valuable tool for financial decision-making.",Document_137,Technical aspects or methods of AI or machine learning,0.11150255054235458,Other Categories
Unifying Large Language Models and Knowledge Graphs: A Roadmap,"Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, Xindong Wu","Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia, and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolve by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and, simultaneously, leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely: <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1) KG-enhanced LLMs,</i> which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2) LLM-augmented KGs,</i> that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">3) Synergized LLMs + KGs</i>, in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions.",2023,2023,,IEEE Transactions on Knowledge and Data Engineering,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/TKDE.2024.3352100,10.1109/TKDE.2024.3352100,https://doi.org/10.1109/TKDE.2024.3352100,540,"Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia, and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolve by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and, simultaneously, leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely: <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1) KG-enhanced LLMs,</i> which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2) LLM-augmented KGs,</i> that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">3) Synergized LLMs + KGs</i>, in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions.",Document_138,Technical aspects or methods of AI or machine learning,0.16797837615013123,Other Categories
A Survey of Large Language Models in Finance (FinLLMs),"Jean Lee, Nicholas Stevens, S. Han, Minseok Song","Large language models (LLMs) have demonstrated remarkable capabilities and have attracted significant attention across diverse domains, including financial services. Despite the extensive research into general-domain LLMs and their immense potential in finance, financial LLMs (FinLLMs) research remains limited. This survey provides a comprehensive overview of FinLLMs, including their history, techniques, downstream tasks associated with datasets, evaluations, and opportunities and challenges. Firstly, we present a chronological overview of general-domain language models (LMs) through to current FinLLMs, including the GPT-series, selected open-source LLMs, and financial LMs. Secondly, we compare five techniques used across eight financial LMs, including training methods, training data, and fine-tuning methods. Thirdly, we summarize the performance evaluations of six benchmark tasks and datasets and provide eight advanced financial NLP tasks and datasets for developing more sophisticated FinLLMs. Finally, we discuss the opportunities and the challenges facing FinLLMs, such as hallucination, privacy, and efficiency. To support AI research in finance, we compile a collection of accessible datasets and benchmarks on GitHub. ( https://github.com/adlnlp/FinLLMs )",2024,2025,1.0,Neural computing & applications (Print),Success (Selector (#Abs1-content)) / Date (Time Tag) (URL Source: DOI Link),https://doi.org/10.1007/s00521-024-10495-6,10.1007/s00521-024-10495-6,https://doi.org/10.1007/s00521-024-10495-6,30,"Large language models (LLMs) have demonstrated remarkable capabilities and have attracted significant attention across diverse domains, including financial services. Despite the extensive research into general-domain LLMs and their immense potential in finance, financial LLMs (FinLLMs) research remains limited. This survey provides a comprehensive overview of FinLLMs, including their history, techniques, downstream tasks associated with datasets, evaluations, and opportunities and challenges. Firstly, we present a chronological overview of general-domain language models (LMs) through to current FinLLMs, including the GPT-series, selected open-source LLMs, and financial LMs. Secondly, we compare five techniques used across eight financial LMs, including training methods, training data, and fine-tuning methods. Thirdly, we summarize the performance evaluations of six benchmark tasks and datasets and provide eight advanced financial NLP tasks and datasets for developing more sophisticated FinLLMs. Finally, we discuss the opportunities and the challenges facing FinLLMs, such as hallucination, privacy, and efficiency. To support AI research in finance, we compile a collection of accessible datasets and benchmarks on GitHub. ( https://github.com/adlnlp/FinLLMs )",Document_139,Technical aspects or methods of AI or machine learning,0.07717854529619217,Other Categories
Preserving Privacy in Arabic Judgments: AI-Powered Anonymization for Enhanced Legal Data Privacy,"Taoufiq El Moussaoui, Loqman Chakir, J. Boumhidi","Jurisprudence involves studying, interpreting, and applying the law to comprehend its societal impact. Judges annually review cases to ensure accurate law application, which raises privacy concerns when accessing files from other courts. While the legal field has garnered interest from the research community, the challenge of masking personal data, particularly in the Arabic language with limited resources, remains in its early stages. To address this research gap, we develop a two-component system for generating anonymous Arabic judgments. The first component, a personal data extractor model, utilizes Named Entity Recognition (NER) to identify key individual entities like names, addresses, birthdays, case numbers, and national identity codes. We train this model on a purpose-built Arabic legal corpus. The second component involves a Python module designed to mask the personal entities extracted by the first component. Together, these components enable the generation of anonymous judgments. Our model achieves an F1-score of 96.14% when detecting entities in the created Arabic Legal corpus. Additionally, experiments on the ANERCorp corpus, with training and testing splits of 70%-30% and 90%-10%, yield F1-scores of 93.78% and 95.77%, respectively. With these results, our proposed system demonstrates the promising potential for generating anonymous Arabic judgments. Furthermore, the built Arabic legal corpus provides a valuable resource for researchers aiming to enhance domain-specific NER models in Arabic text.",2023,2023,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2023.3324288,10.1109/ACCESS.2023.3324288,https://doi.org/10.1109/ACCESS.2023.3324288,2,"Jurisprudence involves studying, interpreting, and applying the law to comprehend its societal impact. Judges annually review cases to ensure accurate law application, which raises privacy concerns when accessing files from other courts. While the legal field has garnered interest from the research community, the challenge of masking personal data, particularly in the Arabic language with limited resources, remains in its early stages. To address this research gap, we develop a two-component system for generating anonymous Arabic judgments. The first component, a personal data extractor model, utilizes Named Entity Recognition (NER) to identify key individual entities like names, addresses, birthdays, case numbers, and national identity codes. We train this model on a purpose-built Arabic legal corpus. The second component involves a Python module designed to mask the personal entities extracted by the first component. Together, these components enable the generation of anonymous judgments. Our model achieves an F1-score of 96.14% when detecting entities in the created Arabic Legal corpus. Additionally, experiments on the ANERCorp corpus, with training and testing splits of 70%-30% and 90%-10%, yield F1-scores of 93.78% and 95.77%, respectively. With these results, our proposed system demonstrates the promising potential for generating anonymous Arabic judgments. Furthermore, the built Arabic legal corpus provides a valuable resource for researchers aiming to enhance domain-specific NER models in Arabic text.",Document_140,Technical aspects or methods of AI or machine learning,0.09181328862905502,Other Categories
A New Framework for Analyzing News in the Financial Markets to Enhance the Investor’s Perception,"Issam Aattouchi, M. A. Kerroum","JAIT is a scientific open access journal which focuses on empirical research results and critical analysis of technology development, use, management and impacts in information technology.",2022,2022,,Journal of Advances in Information Technology,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM (Filtered HTML) Failed (Answer too short, Score: 0.47) (URL Source: DOI Link)",https://doi.org/10.12720/jait.13.2.125-131,10.12720/jait.13.2.125-131,https://doi.org/10.12720/jait.13.2.125-131,1,"JAIT is a scientific open access journal which focuses on empirical research results and critical analysis of technology development, use, management and impacts in information technology.",Document_141,Other AI topic (not related to finance/regulation),0.07521677762269974,Other Categories
Case-based Reasoning for Natural Language Queries over Knowledge Bases,"Rajarshi Das, M. Zaheer, Dung Ngoc Thai, Ameya Godbole, Ethan Perez, Jay Yoon Lee, Lizhen Tan, L. Polymenakos, A. McCallum","It is often challenging to solve a complex problem from scratch, but much easier if we can access other similar problems with their solutions — a paradigm known as case-based reasoning (CBR). We propose a neuro-symbolic CBR approach (CBR-KBQA) for question answering over large knowledge bases. CBR-KBQA consists of a nonparametric memory that stores cases (question and logical forms) and a parametric model that can generate a logical form for a new question by retrieving cases that are relevant to it. On several KBQA datasets that contain complex questions, CBR-KBQA achieves competitive performance. For example, on the CWQ dataset, CBR-KBQA outperforms the current state of the art by 11% on accuracy. Furthermore, we show that CBR-KBQA is capable of using new cases without any further training: by incorporating a few human-labeled examples in the case memory, CBR-KBQA is able to successfully generate logical forms containing unseen KB entities as well as relations.",2021,2021,11.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2021.emnlp-main.755,10.18653/v1/2021.emnlp-main.755,https://doi.org/10.18653/v1/2021.emnlp-main.755,151,"It is often challenging to solve a complex problem from scratch, but much easier if we can access other similar problems with their solutions — a paradigm known as case-based reasoning (CBR). We propose a neuro-symbolic CBR approach (CBR-KBQA) for question answering over large knowledge bases. CBR-KBQA consists of a nonparametric memory that stores cases (question and logical forms) and a parametric model that can generate a logical form for a new question by retrieving cases that are relevant to it. On several KBQA datasets that contain complex questions, CBR-KBQA achieves competitive performance. For example, on the CWQ dataset, CBR-KBQA outperforms the current state of the art by 11% on accuracy. Furthermore, we show that CBR-KBQA is capable of using new cases without any further training: by incorporating a few human-labeled examples in the case memory, CBR-KBQA is able to successfully generate logical forms containing unseen KB entities as well as relations.",Document_142,Technical aspects or methods of AI or machine learning,0.05201268941164017,Other Categories
Perturbing Inputs for Fragile Interpretations in Deep Natural Language Processing,"Sanchit Sinha, Hanjie Chen, Arshdeep Sekhon, Yangfeng Ji, Yanjun Qi","Interpretability methods like Integrated Gradient and LIME are popular choices for explaining natural language model predictions with relative word importance scores. These interpretations need to be robust for trustworthy NLP applications in high-stake areas like medicine or finance. Our paper demonstrates how interpretations can be manipulated by making simple word perturbations on an input text. Via a small portion of word-level swaps, these adversarial perturbations aim to make the resulting text semantically and spatially similar to its seed input (therefore sharing similar interpretations). Simultaneously, the generated examples achieve the same prediction label as the seed yet are given a substantially different explanation by the interpretation methods. Our experiments generate fragile interpretations to attack two SOTA interpretation methods, across three popular Transformer models and on three different NLP datasets. We observe that the rank order correlation and top-K intersection score drops by over 20% when less than 10% of words are perturbed on average. Further, rank-order correlation keeps decreasing as more words get perturbed. Furthermore, we demonstrate that candidates generated from our method have good quality metrics.",2021,2021,11.0,BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2021.blackboxnlp-1.33,10.18653/v1/2021.blackboxnlp-1.33,https://doi.org/10.18653/v1/2021.blackboxnlp-1.33,39,"Interpretability methods like Integrated Gradient and LIME are popular choices for explaining natural language model predictions with relative word importance scores. These interpretations need to be robust for trustworthy NLP applications in high-stake areas like medicine or finance. Our paper demonstrates how interpretations can be manipulated by making simple word perturbations on an input text. Via a small portion of word-level swaps, these adversarial perturbations aim to make the resulting text semantically and spatially similar to its seed input (therefore sharing similar interpretations). Simultaneously, the generated examples achieve the same prediction label as the seed yet are given a substantially different explanation by the interpretation methods. Our experiments generate fragile interpretations to attack two SOTA interpretation methods, across three popular Transformer models and on three different NLP datasets. We observe that the rank order correlation and top-K intersection score drops by over 20% when less than 10% of words are perturbed on average. Further, rank-order correlation keeps decreasing as more words get perturbed. Furthermore, we demonstrate that candidates generated from our method have good quality metrics.",Document_143,Security risks associated with AI are a concern in financial regulation,0.07354816794395447,Organizational and Human Barriers
Automated Sequence Tagging: Applications in Financial Hybrid Systems,"Peter J. Hampton, Hui Wang, William Blackburn, Zhiwei Lin","Internal data published by a firm regarding their financial position, governance, people and reaction to market conditions are all believed to impact the underlying company’s valuation. An abundance of heterogeneous information coupled with the ever increasing processing power of machines, narrow AI applications are now managing investment positions and making decisions on behalf of humans. As unstructured data becomes more common, disambiguating structure from text-based documents remains an attractive research goal in the Finance and Investment industry. It has been found that statistical approaches are considered high risk in industrial applications and deterministic methods are typically preferred. In this paper we experiment with hybrid (ensemble) approaches for Named Entity Recognition to reduce implementation and run time risk involved with modern stochastic methods.",2016,2016,4.0,SGAI Conferences,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.40) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-319-47175-4_22,10.1007/978-3-319-47175-4_22,https://doi.org/10.1007/978-3-319-47175-4_22,2,"Internal data published by a firm regarding their financial position, governance, people and reaction to market conditions are all believed to impact the underlying company’s valuation. An abundance of heterogeneous information coupled with the ever increasing processing power of machines, narrow AI applications are now managing investment positions and making decisions on behalf of humans. As unstructured data becomes more common, disambiguating structure from text-based documents remains an attractive research goal in the Finance and Investment industry. It has been found that statistical approaches are considered high risk in industrial applications and deterministic methods are typically preferred. In this paper we experiment with hybrid (ensemble) approaches for Named Entity Recognition to reduce implementation and run time risk involved with modern stochastic methods.",Document_144,Difficulty in understanding AI decision-making is a barrier in finance,0.15596690773963928,Explainability and Transparency Barriers
Analyzing Regulatory Rules for Privacy and Security Requirements,"T. Breaux, A. Antón","Information practices that use personal, financial and health-related information are governed by U.S. laws and regulations to prevent unauthorized use and disclosure. To ensure compliance under the law, the security and privacy requirements of relevant software systems must be properly aligned with these regulations. However, these regulations describe stakeholder rules, called rights and obligations, in complex and sometimes ambiguous legal language. These ""rules"" are often precursors to software requirements that must undergo considerable refinement and analysis before they are implementable. To support the software engineering effort to derive security requirements from regulations, we present a methodology to extract access rights and obligations directly from regulation texts. The methodology provides statement-level coverage for an entire regulatory document to consistently identify and infer six types of data access constraints, handle complex cross-references, resolve ambiguities, and assign required priorities between access rights and obligations to avoid unlawful information disclosures. We present results from applying this methodology to the entire regulation text of the U.S. Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule.",2008,2008,,IEEE Transactions on Software Engineering,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/TSE.2007.70746,10.1109/TSE.2007.70746,https://doi.org/10.1109/TSE.2007.70746,376,"Information practices that use personal, financial and health-related information are governed by U.S. laws and regulations to prevent unauthorized use and disclosure. To ensure compliance under the law, the security and privacy requirements of relevant software systems must be properly aligned with these regulations. However, these regulations describe stakeholder rules, called rights and obligations, in complex and sometimes ambiguous legal language. These ""rules"" are often precursors to software requirements that must undergo considerable refinement and analysis before they are implementable. To support the software engineering effort to derive security requirements from regulations, we present a methodology to extract access rights and obligations directly from regulation texts. The methodology provides statement-level coverage for an entire regulatory document to consistently identify and infer six types of data access constraints, handle complex cross-references, resolve ambiguities, and assign required priorities between access rights and obligations to avoid unlawful information disclosures. We present results from applying this methodology to the entire regulation text of the U.S. Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule.",Document_145,General discussion of financial or regulatory topics (non-AI focus),0.058001961559057236,Other Categories
Strengthening corporate governance and financial compliance: Enhancing accountability and transparency,"Christianah Pelumi Efunniyi, Angela Omozele Abhulimen, Anwuli Nkemchor Obiki-Osafiele, Olajide Soji Osundare, Edith Ebele Agu, Ibrahim Adedeji Adeniran","In today's complex business landscape, robust corporate governance and financial compliance are essential for maintaining organizational integrity, accountability, and transparency. This review examines the key components and strategies necessary to enhance these frameworks, ensuring sustainable success and stakeholder trust. Corporate governance encompasses regulatory compliance, risk management, ethical conduct, and stakeholder engagement. Adherence to laws and regulations, such as the Sarbanes-Oxley Act (SOX) and the General Data Protection Regulation (GDPR), is foundational in minimizing legal risks and safeguarding reputation. Effective risk management involves identifying, assessing, and mitigating potential threats to an organization’s financial health and operational integrity through strong internal controls and regular audits. Promoting ethical conduct within organizations is crucial for maintaining trust and reputation. Establishing codes of conduct, ethical guidelines, and whistleblower protections fosters a culture of integrity. Transparent communication and stakeholder engagement ensure that organizational activities align with stakeholder interests and expectations. Enhancing accountability and transparency involves several key strategies. Strong board oversight and independence, characterized by diverse and skilled board members, ensure balanced and objective decision-making. Regular internal and external audits verify financial accuracy and compliance, identifying areas for improvement. Leveraging technology and data analytics is pivotal in modern compliance efforts. Technologies like blockchain, artificial intelligence (AI), and machine learning automate processes, improve accuracy, and provide real-time insights into financial performance and risk management. Transparent regulatory reporting and disclosure practices, adhering to standards such as the International Financial Reporting Standards (IFRS), further enhance stakeholder trust. Continuous training and education for employees and board members on corporate governance principles, regulatory requirements, and ethical standards are vital for fostering a culture of compliance and accountability. Strengthening corporate governance and financial compliance is fundamental for enhancing accountability and transparency. By adopting comprehensive regulatory frameworks, leveraging technology, and promoting ethical conduct, organizations can build trust, mitigate risks, and ensure sustainable growth in a dynamic business environment. Keywords : Corporate Governance, Global Corporations, Harmonization.",2024,2024,,Finance &amp; Accounting Research Journal,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.51594/farj.v6i8.1509,10.51594/farj.v6i8.1509,https://doi.org/10.51594/farj.v6i8.1509,18,"In today's complex business landscape, robust corporate governance and financial compliance are essential for maintaining organizational integrity, accountability, and transparency. This review examines the key components and strategies necessary to enhance these frameworks, ensuring sustainable success and stakeholder trust. Corporate governance encompasses regulatory compliance, risk management, ethical conduct, and stakeholder engagement. Adherence to laws and regulations, such as the Sarbanes-Oxley Act (SOX) and the General Data Protection Regulation (GDPR), is foundational in minimizing legal risks and safeguarding reputation. Effective risk management involves identifying, assessing, and mitigating potential threats to an organization’s financial health and operational integrity through strong internal controls and regular audits. Promoting ethical conduct within organizations is crucial for maintaining trust and reputation. Establishing codes of conduct, ethical guidelines, and whistleblower protections fosters a culture of integrity. Transparent communication and stakeholder engagement ensure that organizational activities align with stakeholder interests and expectations. Enhancing accountability and transparency involves several key strategies. Strong board oversight and independence, characterized by diverse and skilled board members, ensure balanced and objective decision-making. Regular internal and external audits verify financial accuracy and compliance, identifying areas for improvement. Leveraging technology and data analytics is pivotal in modern compliance efforts. Technologies like blockchain, artificial intelligence (AI), and machine learning automate processes, improve accuracy, and provide real-time insights into financial performance and risk management. Transparent regulatory reporting and disclosure practices, adhering to standards such as the International Financial Reporting Standards (IFRS), further enhance stakeholder trust. Continuous training and education for employees and board members on corporate governance principles, regulatory requirements, and ethical standards are vital for fostering a culture of compliance and accountability. Strengthening corporate governance and financial compliance is fundamental for enhancing accountability and transparency. By adopting comprehensive regulatory frameworks, leveraging technology, and promoting ethical conduct, organizations can build trust, mitigate risks, and ensure sustainable growth in a dynamic business environment. Keywords : Corporate Governance, Global Corporations, Harmonization.",Document_146,Technical aspects or methods of AI or machine learning,0.129372239112854,Other Categories
"A Systematic Literature Review of Natural Language Processing: Current State, Challenges and Risks","Eghbal Ghazizadeh, Peng Zhu","In this research paper, a comprehensive literature review was undertaken in order to analyze Natural Language Processing (NLP) application based in different domains. Also, by conducting qualitative research, we will try to analyze the development of the current state and the challenge of NLP technology as a key for Artificial Intelligence (AI) technology, pointing out some of the limitations, risks and opportunities. In our research, we rely on primary data from applicable legislation and secondary public domain data sources providing related information from case studies. By studying the structure and content of the published literature, the NLP-based applications have been clearly classified into different fields which include natural language understanding, natural language generation, voice or speech recognition, machine translation, spell correction and grammar check. The development trend, open issues and limitations have also been analyzed.",2020,2021,4.0,"Proceedings of the Future Technologies Conference (FTC) 2020, Volume 1","Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.17) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-030-63128-4_49,10.1007/978-3-030-63128-4_49,https://doi.org/10.1007/978-3-030-63128-4_49,9,"In this research paper, a comprehensive literature review was undertaken in order to analyze Natural Language Processing (NLP) application based in different domains. Also, by conducting qualitative research, we will try to analyze the development of the current state and the challenge of NLP technology as a key for Artificial Intelligence (AI) technology, pointing out some of the limitations, risks and opportunities. In our research, we rely on primary data from applicable legislation and secondary public domain data sources providing related information from case studies. By studying the structure and content of the published literature, the NLP-based applications have been clearly classified into different fields which include natural language understanding, natural language generation, voice or speech recognition, machine translation, spell correction and grammar check. The development trend, open issues and limitations have also been analyzed.",Document_147,Technical aspects or methods of AI or machine learning,0.10782209038734436,Other Categories
Understanding the landscape of Distributed Ledger Technologies/Blockchain,"A. Deshpande, Katherine Stewart, Louise Lepetit, S. Gunashekar","In this report, we present an overview of the current landscape of Distributed Ledger Technologies (DLT)/Blockchain developments and closely examine the issues that are central to the development of DLT/Blockchain. We articulate a set of areas for further consideration by the DLT/Blockchain community regarding the potential role of standardization. Rather than providing a definitive list of topics, the aim of the study is to provoke further discussion across the DLT/Blockchain community about the potential role of standards in supporting the development and adoption of the technology. The research has been carried out using a mixed methods approach involving a focused review of the literature, in-depth interviews with experts from public and private organizations, and an internal workshop.",2017,2017,10.0,-,Success (Selector (div.abstract > div > p)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.7249/rr2223,10.7249/rr2223,https://doi.org/10.7249/rr2223,27,"In this report, we present an overview of the current landscape of Distributed Ledger Technologies (DLT)/Blockchain developments and closely examine the issues that are central to the development of DLT/Blockchain. We articulate a set of areas for further consideration by the DLT/Blockchain community regarding the potential role of standardization. Rather than providing a definitive list of topics, the aim of the study is to provoke further discussion across the DLT/Blockchain community about the potential role of standards in supporting the development and adoption of the technology. The research has been carried out using a mixed methods approach involving a focused review of the literature, in-depth interviews with experts from public and private organizations, and an internal workshop.",Document_148,Difficulty in understanding AI decision-making is a barrier in finance,0.052905380725860596,Explainability and Transparency Barriers
Towards a Knowledge Base of Financial Relations: Overview and Project Description,"A. Jabbari, Olivier Sauvage, Nicolas Cabioch","In this paper, we present an overview of the existing knowledge bases of financial relations and a description of our ongoing research towards building one based on unstructured data. First, we aim to create a specialized ontology of financial relations which will allow to model information related to regulatory compliance monitoring tasks. Next, we plan to harness Natural Language Processing (NLP) methods to extract financial relations from text sources such as news, press releases, etc. and to organize the derived information according to our crafted ontology. In addition to an overview of the literature in these areas, we describe our vision of an automated knowledge system for the experts of financial domains.",2019,2019,,International Conference on Artificial Intelligence and Knowledge Engineering,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/AIKE.2019.00063,10.1109/AIKE.2019.00063,https://doi.org/10.1109/AIKE.2019.00063,3,"In this paper, we present an overview of the existing knowledge bases of financial relations and a description of our ongoing research towards building one based on unstructured data. First, we aim to create a specialized ontology of financial relations which will allow to model information related to regulatory compliance monitoring tasks. Next, we plan to harness Natural Language Processing (NLP) methods to extract financial relations from text sources such as news, press releases, etc. and to organize the derived information according to our crafted ontology. In addition to an overview of the literature in these areas, we describe our vision of an automated knowledge system for the experts of financial domains.",Document_149,Technical aspects or methods of AI or machine learning,0.07336553186178207,Other Categories
Natural Language to SQL: Automated Query Formation Using NLP Techniques,"S. Y., Prashanthi G., Sravani Puranam, Sheethal Reddy Vemula, Preethi Doulathbaji, Anusha Bellamkonda","In this era of information world, given any topic, we are able to get relevant data or documents at a mouse click. The flexibility that internet provides is the user friendly language or Natural Language to search for required topic. Natural Language Querying and Retrieval has made internet popular. It is implicit for business user to understand what the business data is indicating to find better business opportunities. Querying for required data the business users are using SQL. To effectively Query such systems, the Business users has to master the Language. But many business users may not be aware of the SQL language or may not be aware of the databases and some users feel difficulty to write the long SQL Queries. Therefore, it is equally important to query the database very easily. The work here presents a case study to help the business users to type a query in Natural Language, which then converts into SQL statement and process this SQL query against the Databases and get the expected result. This work proposes QCNER approach to extract SQL properties from Natural Language Query. The proposed approach after the application of SMOTE technique depicts 92.31 accuracy over the existing models.<sup>1<sup/>",2023,2023,4.0,E3S Web of Conferences,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (Meta (citation_publication_date)) / LLM Found Similar/Shorter (LLM (Filtered HTML) - Short, Score: 0.21) (URL Source: DOI Link)",https://doi.org/10.1051/e3sconf/202339101115,10.1051/e3sconf/202339101115,https://doi.org/10.1051/e3sconf/202339101115,4,"In this era of information world, given any topic, we are able to get relevant data or documents at a mouse click. The flexibility that internet provides is the user friendly language or Natural Language to search for required topic. Natural Language Querying and Retrieval has made internet popular. It is implicit for business user to understand what the business data is indicating to find better business opportunities. Querying for required data the business users are using SQL. To effectively Query such systems, the Business users has to master the Language. But many business users may not be aware of the SQL language or may not be aware of the databases and some users feel difficulty to write the long SQL Queries. Therefore, it is equally important to query the database very easily. The work here presents a case study to help the business users to type a query in Natural Language, which then converts into SQL statement and process this SQL query against the Databases and get the expected result. This work proposes QCNER approach to extract SQL properties from Natural Language Query. The proposed approach after the application of SMOTE technique depicts 92.31 accuracy over the existing models.<sup>1<sup/>",Document_150,Building internal AI expertise is key for financial institutions,0.041411880403757095,Expertise and Training Strategies
Improving Data Governance in Large Organizations through Ontology and Linked Data,"Richard DeStefano, Lixin Tao, Keke Gai","In the past decade, the role of data has increased exponentially from something that is queried or reported on, to becoming a true corporate asset. The same time period has also seen marked growth in corporate structural complexity. This combination has lead to information management challenges, as the data moving across a multitude of systems lends itself to a higher likelihood of impacting dependent processes and systems, should something go wrong or be changed. Many enterprise data projects are faced with low success rates and consequently subject to high amounts of scrutiny as senior leadership struggles to identify return on investment. While there are many tools and methods to increase a companies' ability to govern data, this research is based on the premise that you can not govern what you do not know. This lack of awareness of the corporate data landscape impacts the ability to govern data, which in turn impacts overall data quality within organizations. This paper seeks to propose a tools and techniques for companies to better gain an awareness of the landscape of their data, processes, and organizational attributes through the use of linked data, via the Resource Description Framework (RDF) and ontology. The outcome of adopting such techniques is an increased level of data awareness within the organization, resulting in improved ability to govern corporate data assets, and in turn increased data quality.",2016,2016,,International Conference on Cyber Security and Cloud Computing,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/CSCloud.2016.47,10.1109/CSCloud.2016.47,https://doi.org/10.1109/CSCloud.2016.47,33,"In the past decade, the role of data has increased exponentially from something that is queried or reported on, to becoming a true corporate asset. The same time period has also seen marked growth in corporate structural complexity. This combination has lead to information management challenges, as the data moving across a multitude of systems lends itself to a higher likelihood of impacting dependent processes and systems, should something go wrong or be changed. Many enterprise data projects are faced with low success rates and consequently subject to high amounts of scrutiny as senior leadership struggles to identify return on investment. While there are many tools and methods to increase a companies' ability to govern data, this research is based on the premise that you can not govern what you do not know. This lack of awareness of the corporate data landscape impacts the ability to govern data, which in turn impacts overall data quality within organizations. This paper seeks to propose a tools and techniques for companies to better gain an awareness of the landscape of their data, processes, and organizational attributes through the use of linked data, via the Resource Description Framework (RDF) and ontology. The outcome of adopting such techniques is an increased level of data awareness within the organization, resulting in improved ability to govern corporate data assets, and in turn increased data quality.",Document_151,General discussion of financial or regulatory topics (non-AI focus),0.05651309713721275,Other Categories
Negative Review or Complaint? Exploring Interpretability in Financial Complaints,"Sarmistha Das, A. Singh, Sriparna Saha, Alka Maurya","In the financial service sector, customer service is the most critical tool for long-term business growth. A financial complaint detection (CD) system could aid in the identification of shortcomings in product features and service delivery. This could further ensure faster resolution of customer complaints and thereby help retain existing clients and attract new ones. Prior research has prioritized only complaint identification and prediction of the corresponding severity levels; the first aim is to categorize a textual element as a complaint or a noncompliant. The other attempts to classify complaints into several severity levels based on the degree of risk the complainant is willing to endure. Identifying the reason or source of a complaint in a text is a significant but underexplored area in natural language processing study. We propose an explainable complaint cause identification approach with a dyadic attention mechanism at the sentence and word levels, enabling it to give varying amounts of emphasis to more and less important information. As the first subtask, the model simultaneously trains CD, sentiment detection, and emotion recognition tasks. Afterwards, we identify the complaint's cause and its severity level. To do this, the causal span annotations for complaint tweets are added to an existing financial complaints corpus. The findings suggest that conventional computing techniques can be adapted to solve extremely relevant new problems, generating novel opportunities for research<xref ref-type=""fn"" rid=""fn1"" xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""><sup>1</sup></xref><fn id=""fn1"" xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""><label><sup>1</sup></label>The code and dataset are available at <uri>https://github.com/sarmistha-D/Complaint-HaN</uri></p></fn>.",2024,2024,,IEEE Transactions on Computational Social Systems,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/TCSS.2023.3338357,10.1109/TCSS.2023.3338357,https://doi.org/10.1109/TCSS.2023.3338357,1,"In the financial service sector, customer service is the most critical tool for long-term business growth. A financial complaint detection (CD) system could aid in the identification of shortcomings in product features and service delivery. This could further ensure faster resolution of customer complaints and thereby help retain existing clients and attract new ones. Prior research has prioritized only complaint identification and prediction of the corresponding severity levels; the first aim is to categorize a textual element as a complaint or a noncompliant. The other attempts to classify complaints into several severity levels based on the degree of risk the complainant is willing to endure. Identifying the reason or source of a complaint in a text is a significant but underexplored area in natural language processing study. We propose an explainable complaint cause identification approach with a dyadic attention mechanism at the sentence and word levels, enabling it to give varying amounts of emphasis to more and less important information. As the first subtask, the model simultaneously trains CD, sentiment detection, and emotion recognition tasks. Afterwards, we identify the complaint's cause and its severity level. To do this, the causal span annotations for complaint tweets are added to an existing financial complaints corpus. The findings suggest that conventional computing techniques can be adapted to solve extremely relevant new problems, generating novel opportunities for research<xref ref-type=""fn"" rid=""fn1"" xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""><sup>1</sup></xref><fn id=""fn1"" xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""><label><sup>1</sup></label>The code and dataset are available at <uri>https://github.com/sarmistha-D/Complaint-HaN</uri></p></fn>.",Document_152,Highlighting the benefits of AI for customer insights in finance,0.08775182068347931,Business Case and Value Demonstration Strategies
NLP for Enterprise Asset Management: An Emerging Paradigm,"Pedro Santos, Nuno Datia, Matilde Pato, José Sobral, Nuno Gomes, Noel Leitão, Manuel R. Ferreira","In the field of asset management, a Work Order refers to a document that outlines the necessary steps to carry out a maintenance operation on a specific physical asset. The text on this Work orders providing details about the problem and the actions required are open-ended, not normalized, and Technician’ dependant, presenting challenges for automating asset management Work Order processing. To address the issue of automating the analysis of Work Orders, Natural Language Processing techniques are employed to process the content of these documents. The aim is to identify and extract relevant information related to actions and components within the sentences. This paper presents the Reliability Centred Maintenance for Assets solution, which utilizes a semi-automatic, human-in-the-loop approach to determine a standardised and condensed set of actions and components. The results indicate a significant increase in the number of annotations, reaching a ratio of 1:14. By implementing this solution, the manual workload associated with analysing Work Orders can be reduced, thereby improving decision support and analytical processing of the data contained within these documents.",2023,2023,,International Conference on Information Visualisation,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/IV60283.2023.00049,10.1109/IV60283.2023.00049,https://doi.org/10.1109/IV60283.2023.00049,1,"In the field of asset management, a Work Order refers to a document that outlines the necessary steps to carry out a maintenance operation on a specific physical asset. The text on this Work orders providing details about the problem and the actions required are open-ended, not normalized, and Technician’ dependant, presenting challenges for automating asset management Work Order processing. To address the issue of automating the analysis of Work Orders, Natural Language Processing techniques are employed to process the content of these documents. The aim is to identify and extract relevant information related to actions and components within the sentences. This paper presents the Reliability Centred Maintenance for Assets solution, which utilizes a semi-automatic, human-in-the-loop approach to determine a standardised and condensed set of actions and components. The results indicate a significant increase in the number of annotations, reaching a ratio of 1:14. By implementing this solution, the manual workload associated with analysing Work Orders can be reduced, thereby improving decision support and analytical processing of the data contained within these documents.",Document_153,Difficulty in understanding AI decision-making is a barrier in finance,0.05431636422872543,Explainability and Transparency Barriers
Automating financial reporting with natural language processing: A review and case analysis,"Adedoyin Tolulope Oyewole, Omotayo Bukola Adeoye, Wilhelmina Afua Addy, Chinwe Chinazo Okoye, Onyeka Chrisanctus Ofodile, Chinonye Esther Ugochukwu","In the evolving landscape of financial reporting, the integration of Natural Language Processing (NLP) emerges as a beacon of innovation, promising to redefine the paradigms of accuracy, efficiency, and compliance. This paper embarks on a scholarly expedition to explore the transformative potential of NLP within the realm of financial disclosures, navigating through the intricate interplay of technological advancements and regulatory frameworks. The study meticulously analyzes the application of NLP techniques in automating financial reporting, unraveling the complexities of implementation and the multifaceted challenges therein through a qualitative research design. Through a comprehensive review of the literature and empirical data, the paper illuminates the efficacy of NLP in enhancing the precision and reliability of financial reports while also delving into stakeholders' perceptions regarding its adoption. The findings reveal a significant improvement in reporting efficiency and accuracy, underscored by the strategic importance of addressing implementation hurdles and regulatory considerations. The study culminates in a set of cogent recommendations, advocating for the development of a robust framework for NLP applications in financial reporting, alongside a clarion call for ongoing research into sophisticated NLP models and scalable solutions. In essence, this paper not only charts a course for the future integration of NLP in financial reporting but also stands as a testament to the indelible impact of technological innovation on the financial industry. It beckons the academic and professional communities to forge a collaborative path towards realizing the full potential of NLP, thereby ushering in a new era of transparency and insight in financial disclosures.",2024,2024,4.0,World Journal of Advanced Research and Reviews,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.30574/wjarr.2024.21.3.0688,10.30574/wjarr.2024.21.3.0688,https://doi.org/10.30574/wjarr.2024.21.3.0688,12,"In the evolving landscape of financial reporting, the integration of Natural Language Processing (NLP) emerges as a beacon of innovation, promising to redefine the paradigms of accuracy, efficiency, and compliance. This paper embarks on a scholarly expedition to explore the transformative potential of NLP within the realm of financial disclosures, navigating through the intricate interplay of technological advancements and regulatory frameworks. The study meticulously analyzes the application of NLP techniques in automating financial reporting, unraveling the complexities of implementation and the multifaceted challenges therein through a qualitative research design. Through a comprehensive review of the literature and empirical data, the paper illuminates the efficacy of NLP in enhancing the precision and reliability of financial reports while also delving into stakeholders' perceptions regarding its adoption. The findings reveal a significant improvement in reporting efficiency and accuracy, underscored by the strategic importance of addressing implementation hurdles and regulatory considerations. The study culminates in a set of cogent recommendations, advocating for the development of a robust framework for NLP applications in financial reporting, alongside a clarion call for ongoing research into sophisticated NLP models and scalable solutions. In essence, this paper not only charts a course for the future integration of NLP in financial reporting but also stands as a testament to the indelible impact of technological innovation on the financial industry. It beckons the academic and professional communities to forge a collaborative path towards realizing the full potential of NLP, thereby ushering in a new era of transparency and insight in financial disclosures.",Document_154,Proactively addressing regulatory concerns to enable AI in finance,0.057231903076171875,Regulatory Engagement and Proactive Compliance Strategies
"Enhancing data quality through comprehensive governance: Methodologies, tools, and continuous improvement techniques","Courage Idemudia, Adebimpe Bolatito Ige, Victor Ibukun Adebayo, Osemeike Gloria Eyieyien","In the era of data-driven decision-making, ensuring data quality is paramount for organizations seeking to leverage their data assets effectively. This paper explores comprehensive strategies for enhancing data quality through robust governance, methodologies, tools, and continuous improvement techniques. It highlights the critical dimensions of data quality, including accuracy, completeness, consistency, timeliness, validity, and uniqueness. It discusses various assessment techniques, such as data profiling, auditing, and quality metrics. The paper also examines the role of data cleansing, enrichment, integration, and interoperability in maintaining high data quality. Additionally, it provides an overview of leading data quality management tools, their evaluation criteria, and best practices for implementation. Finally, it underscores the importance of continuous monitoring, feedback loops, root cause analysis, and fostering an organization's data quality culture. By adopting these strategies, organizations can ensure the reliability and integrity of their data, leading to improved business outcomes. Keywords : Data Quality, Data Governance, Data Profiling, Data Cleansing, Continuous Improvement.",2024,2024,,Computer Science &amp; IT Research Journal,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.51594/csitrj.v5i7.1352,10.51594/csitrj.v5i7.1352,https://doi.org/10.51594/csitrj.v5i7.1352,6,"In the era of data-driven decision-making, ensuring data quality is paramount for organizations seeking to leverage their data assets effectively. This paper explores comprehensive strategies for enhancing data quality through robust governance, methodologies, tools, and continuous improvement techniques. It highlights the critical dimensions of data quality, including accuracy, completeness, consistency, timeliness, validity, and uniqueness. It discusses various assessment techniques, such as data profiling, auditing, and quality metrics. The paper also examines the role of data cleansing, enrichment, integration, and interoperability in maintaining high data quality. Additionally, it provides an overview of leading data quality management tools, their evaluation criteria, and best practices for implementation. Finally, it underscores the importance of continuous monitoring, feedback loops, root cause analysis, and fostering an organization's data quality culture. By adopting these strategies, organizations can ensure the reliability and integrity of their data, leading to improved business outcomes. Keywords : Data Quality, Data Governance, Data Profiling, Data Cleansing, Continuous Improvement.",Document_155,General discussion of financial or regulatory topics (non-AI focus),0.044397223740816116,Other Categories
An ontology based framework to support multi-standard compliance for an enterprise,"Danny C. Cheng, Nathalie Rose Lim-Cheng","In recent years, the complexity and scale of governance, risk and compliance has grown significantly due to globalization and there is a need for institutions to consult multiple standards and frameworks to address a heterogeneous and highly regulated environment. Even with the advent of Governance Risk and Compliance (GRC) systems, there is a need to reduce redundancy and amount of work to the organization and thus the need for semantic interoperability in a multi-faceted compliance management environment. In this paper, we present the enhancement and population of a compliance ontology thru the use of information extraction where the information is acquired from an existing GRC system (Eramba) to facilitate semantic interoperability to reduce the complexity and redundant activities performed in compliance monitoring for an enterprise.",2017,2017,,International Conference on Research and Innovation in Information Systems,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ICRIIS.2017.8002514,10.1109/ICRIIS.2017.8002514,https://doi.org/10.1109/ICRIIS.2017.8002514,8,"In recent years, the complexity and scale of governance, risk and compliance has grown significantly due to globalization and there is a need for institutions to consult multiple standards and frameworks to address a heterogeneous and highly regulated environment. Even with the advent of Governance Risk and Compliance (GRC) systems, there is a need to reduce redundancy and amount of work to the organization and thus the need for semantic interoperability in a multi-faceted compliance management environment. In this paper, we present the enhancement and population of a compliance ontology thru the use of information extraction where the information is acquired from an existing GRC system (Eramba) to facilitate semantic interoperability to reduce the complexity and redundant activities performed in compliance monitoring for an enterprise.",Document_156,Difficulty in understanding AI decision-making is a barrier in finance,0.06110299006104469,Explainability and Transparency Barriers
The NLP Cookbook: Modern Recipes for Transformer Based Deep Learning Architectures,"Sushant Singh, A. Mahmood","In recent years, Natural Language Processing (NLP) models have achieved phenomenal success in linguistic and semantic tasks like text classification, machine translation, cognitive dialogue systems, information retrieval via Natural Language Understanding (NLU), and Natural Language Generation (NLG). This feat is primarily attributed due to the seminal Transformer architecture, leading to designs such as BERT, GPT (I, II, III), etc. Although these large-size models have achieved unprecedented performances, they come at high computational costs. Consequently, some of the recent NLP architectures have utilized concepts of transfer learning, pruning, quantization, and knowledge distillation to achieve moderate model sizes while keeping nearly similar performances as achieved by their predecessors. Additionally, to mitigate the data size challenge raised by language models from a knowledge extraction perspective, Knowledge Retrievers have been built to extricate explicit data documents from a large corpus of databases with greater efficiency and accuracy. Recent research has also focused on superior inference by providing efficient attention to longer input sequences. In this paper, we summarize and examine the current state-of-the-art (SOTA) NLP models that have been employed for numerous NLP tasks for optimal performance and efficiency. We provide a detailed understanding and functioning of the different architectures, a taxonomy of NLP designs, comparative evaluations, and future directions in NLP.",2021,2021,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2021.3077350,10.1109/ACCESS.2021.3077350,https://doi.org/10.1109/ACCESS.2021.3077350,76,"In recent years, Natural Language Processing (NLP) models have achieved phenomenal success in linguistic and semantic tasks like text classification, machine translation, cognitive dialogue systems, information retrieval via Natural Language Understanding (NLU), and Natural Language Generation (NLG). This feat is primarily attributed due to the seminal Transformer architecture, leading to designs such as BERT, GPT (I, II, III), etc. Although these large-size models have achieved unprecedented performances, they come at high computational costs. Consequently, some of the recent NLP architectures have utilized concepts of transfer learning, pruning, quantization, and knowledge distillation to achieve moderate model sizes while keeping nearly similar performances as achieved by their predecessors. Additionally, to mitigate the data size challenge raised by language models from a knowledge extraction perspective, Knowledge Retrievers have been built to extricate explicit data documents from a large corpus of databases with greater efficiency and accuracy. Recent research has also focused on superior inference by providing efficient attention to longer input sequences. In this paper, we summarize and examine the current state-of-the-art (SOTA) NLP models that have been employed for numerous NLP tasks for optimal performance and efficiency. We provide a detailed understanding and functioning of the different architectures, a taxonomy of NLP designs, comparative evaluations, and future directions in NLP.",Document_157,Technical aspects or methods of AI or machine learning,0.09399615973234177,Other Categories
Gender Bias in Machine Translation Systems,Stefanie Ullmann,"In recent years, headlines such as ‘Is Google Translate Sexist?’ (Mail Online, Is Google translate sexist? Users report biased results when translating gender-neutral languages into English in 2017) or ‘The Algorithm that Helped Google Translate Become Sexist’ (Olson, The Algorithm that Helped Google Translate Become Sexist in 2018) have appeared in the technology sections of the world’s news providers. The nature of our highly interconnected world has made online translators indispensable tools in our daily lives. However, their output has the potential to cause great social harm. Due to the continuous pursuit to create ever larger language models and, as a consequence thereof, the opaque nature of unsupervised training datasets, language-based AI systems, such as online translators, can easily produce biased content. If left unchecked, this will inevitable have detrimental consequences. This chapter addresses the nature, impact and risks of bias in training data by looking at the concrete example of gender bias in machine translation (MT). The first section will provide an introduction to recent proposals for ethical AI guidelines in different sectors and the field of natural language processing (NLP) will be presented. Next, I will explain different types of bias in machine learning and how they can manifest themselves in language models. This is followed by presenting the results of a corpus-linguistic analysis I performed of a sample dataset that was later used to train a MT system. I will explore the gender-related imbalances in the corpus that are likely to give rise to biased results. In the final section of this chapter, I will discuss different approaches to reduce gender bias in MT and present findings from a set of experiments my colleagues and I conducted ourselves to mitigate bias in MT. The research presented in this chapter takes a highly interdisciplinary approach, as it takes expertise from linguistics, philosophy, computer science and engineering in order to successfully dismantle and solve the complex problem of bias in NLP.",2022,2022,4.0,Artificial Intelligence and Its Discontents,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.29) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-030-88615-8_7,10.1007/978-3-030-88615-8_7,https://doi.org/10.1007/978-3-030-88615-8_7,4,"In recent years, headlines such as ‘Is Google Translate Sexist?’ (Mail Online, Is Google translate sexist? Users report biased results when translating gender-neutral languages into English in 2017) or ‘The Algorithm that Helped Google Translate Become Sexist’ (Olson, The Algorithm that Helped Google Translate Become Sexist in 2018) have appeared in the technology sections of the world’s news providers. The nature of our highly interconnected world has made online translators indispensable tools in our daily lives. However, their output has the potential to cause great social harm. Due to the continuous pursuit to create ever larger language models and, as a consequence thereof, the opaque nature of unsupervised training datasets, language-based AI systems, such as online translators, can easily produce biased content. If left unchecked, this will inevitable have detrimental consequences. This chapter addresses the nature, impact and risks of bias in training data by looking at the concrete example of gender bias in machine translation (MT). The first section will provide an introduction to recent proposals for ethical AI guidelines in different sectors and the field of natural language processing (NLP) will be presented. Next, I will explain different types of bias in machine learning and how they can manifest themselves in language models. This is followed by presenting the results of a corpus-linguistic analysis I performed of a sample dataset that was later used to train a MT system. I will explore the gender-related imbalances in the corpus that are likely to give rise to biased results. In the final section of this chapter, I will discuss different approaches to reduce gender bias in MT and present findings from a set of experiments my colleagues and I conducted ourselves to mitigate bias in MT. The research presented in this chapter takes a highly interdisciplinary approach, as it takes expertise from linguistics, philosophy, computer science and engineering in order to successfully dismantle and solve the complex problem of bias in NLP.",Document_158,Technical aspects or methods of AI or machine learning,0.2764640748500824,Other Categories
Extraction and Representation of Financial Entities from Text,"Tim Repke, Ralf Krestel","In our modern society, almost all events, processes, and decisions in a corporation are documented by internal written communication, legal filings, or business and financial news. The valuable knowledge in such collections is not directly accessible by computers as they mostly consist of unstructured text. This chapter provides an overview of corpora commonly used in research and highlights related work and state-of-the-art approaches to extract and represent financial entities and relations.The second part of this chapter considers applications based on knowledge graphs of automatically extracted facts. Traditional information retrieval systems typically require the user to have prior knowledge of the data. Suitable visualization techniques can overcome this requirement and enable users to explore large sets of documents. Furthermore, data mining techniques can be used to enrich or filter knowledge graphs. This information can augment source documents and guide exploration processes. Systems for document exploration are tailored to specific tasks, such as investigative work in audits or legal discovery, monitoring compliance, or providing information in a retrieval system to support decisions.",2021,2021,4.0,Data Science for Economics and Finance,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.45) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-030-66891-4_11,10.1007/978-3-030-66891-4_11,https://doi.org/10.1007/978-3-030-66891-4_11,6,"In our modern society, almost all events, processes, and decisions in a corporation are documented by internal written communication, legal filings, or business and financial news. The valuable knowledge in such collections is not directly accessible by computers as they mostly consist of unstructured text. This chapter provides an overview of corpora commonly used in research and highlights related work and state-of-the-art approaches to extract and represent financial entities and relations.The second part of this chapter considers applications based on knowledge graphs of automatically extracted facts. Traditional information retrieval systems typically require the user to have prior knowledge of the data. Suitable visualization techniques can overcome this requirement and enable users to explore large sets of documents. Furthermore, data mining techniques can be used to enrich or filter knowledge graphs. This information can augment source documents and guide exploration processes. Systems for document exploration are tailored to specific tasks, such as investigative work in audits or legal discovery, monitoring compliance, or providing information in a retrieval system to support decisions.",Document_159,Technical aspects or methods of AI or machine learning,0.06662070751190186,Other Categories
Proceedings of the Second Workshop on Economics and Natural Language Processing,-,"In order to automate banking processes (e.g. payments, money transfers, foreign trade), we need to extract banking transactions from different types of mediums such as faxes, e-mails, and scanners. Banking orders may be considered as complex documents since they contain quite complex relations compared to traditional datasets used in relation extraction research. In this paper, we present our method to extract intersentential, nested and complex relations from banking orders, and introduce a relation extraction method based on maximal clique factorization technique. We demonstrate 11% error reduction over previous methods.",2019,2019,,-,"Selector (div[class*=""abstract""] / Date Not Found (URL Source: DOI Link)",https://doi.org/10.18653/v1/d19-51,10.18653/v1/d19-51,https://doi.org/10.18653/v1/d19-51,4,"In order to automate banking processes (e.g. payments, money transfers, foreign trade), we need to extract banking transactions from different types of mediums such as faxes, e-mails, and scanners. Banking orders may be considered as complex documents since they contain quite complex relations compared to traditional datasets used in relation extraction research. In this paper, we present our method to extract intersentential, nested and complex relations from banking orders, and introduce a relation extraction method based on maximal clique factorization technique. We demonstrate 11% error reduction over previous methods.",Document_160,General discussion of financial or regulatory topics (non-AI focus),0.06614982336759567,Other Categories
Natural Language Processing in Biomedicine: A Unified System Architecture Overview,"S. Doan, Mike Conway, Tu Minh Phuong, L. Ohno-Machado","In contemporary electronic medical records much of the clinically important data—signs and symptoms, symptom severity, disease status, etc.—are not provided in structured data fields but rather are encoded in clinician-generated narrative text. Natural language processing (NLP) provides a means of unlocking this important data source for applications in clinical decision support, quality assurance, and public health. This chapter provides an overview of representative NLP systems in biomedicine based on a unified architectural view. A general architecture in an NLP system consists of two main components: background knowledge that includes biomedical knowledge resources and a framework that integrates NLP tools to process text. Systems differ in both components, which we review briefly. Additionally, the challenge facing current research efforts in biomedical NLP includes the paucity of large, publicly available annotated corpora, although initiatives that facilitate data sharing, system evaluation, and collaborative work between researchers in clinical NLP are starting to emerge.",2014,2014,4.0,Methods in molecular biology,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.34) (URL Source: DOI Link)",https://doi.org/10.1007/978-1-4939-0847-9_16,10.1007/978-1-4939-0847-9_16,https://doi.org/10.1007/978-1-4939-0847-9_16,77,"In contemporary electronic medical records much of the clinically important data—signs and symptoms, symptom severity, disease status, etc.—are not provided in structured data fields but rather are encoded in clinician-generated narrative text. Natural language processing (NLP) provides a means of unlocking this important data source for applications in clinical decision support, quality assurance, and public health. This chapter provides an overview of representative NLP systems in biomedicine based on a unified architectural view. A general architecture in an NLP system consists of two main components: background knowledge that includes biomedical knowledge resources and a framework that integrates NLP tools to process text. Systems differ in both components, which we review briefly. Additionally, the challenge facing current research efforts in biomedical NLP includes the paucity of large, publicly available annotated corpora, although initiatives that facilitate data sharing, system evaluation, and collaborative work between researchers in clinical NLP are starting to emerge.",Document_161,Building organizational support for AI through education and communication,0.08266662806272507,"Education, Awareness, and Policy Strategies"
Scaling Web API Integrations,"Guido Chari, Brandon Sheffer, S. Branavan, Nicol´as D’ippolito Asapp","In ASAPP, a company that offers AI solutions to enterprise customers, internal services consume data from our customers’ web APIs. Implementing and maintaining integrations between our customers’ APIs and internal services is a major effort for the company. In this paper, we present a scalable approach for integrating web APIs in enterprise software that is lightweight and semi-automatic. It leverages a combination of Ontology-Based Data Access architectures (OBDA), a Domain Specific Language (DSL) called IBL, Natural Language Processing (NLP) models, and Automated Planning techniques. The OBDA architecture decouples our platform from our customers’ APIs via an ontology that acts as a single internal data access point. IBL is a functional and graphical DSL that enables domain experts to implement integrations, even if they don’t have software development expertise. To reduce the effort of manually writing the IBL code, an NLP model suggests correspondences from each web API to the ontology. Given the API, ontology, and selected mappings for a set of desired fields from the ontology, we define an Automated Planning problem. The resulting policy is finally fed to a code synthesizer that generates the appropriate IBL method implementing the desired integration.This approach has been in production in ASAPP for 2 years with more than 300 integrations already implemented. Results indicate a ≈ 50% reduction in effort due to implementing integrations with IBL. Preliminary results on the IBL automatic code generation show an encouraging further ≈ 25% reduction so far.",2023,2023,,2023 IEEE/ACM 45th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP),"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ICSE-SEIP58684.2023.00007,10.1109/ICSE-SEIP58684.2023.00007,https://doi.org/10.1109/ICSE-SEIP58684.2023.00007,2,"In ASAPP, a company that offers AI solutions to enterprise customers, internal services consume data from our customers’ web APIs. Implementing and maintaining integrations between our customers’ APIs and internal services is a major effort for the company. In this paper, we present a scalable approach for integrating web APIs in enterprise software that is lightweight and semi-automatic. It leverages a combination of Ontology-Based Data Access architectures (OBDA), a Domain Specific Language (DSL) called IBL, Natural Language Processing (NLP) models, and Automated Planning techniques. The OBDA architecture decouples our platform from our customers’ APIs via an ontology that acts as a single internal data access point. IBL is a functional and graphical DSL that enables domain experts to implement integrations, even if they don’t have software development expertise. To reduce the effort of manually writing the IBL code, an NLP model suggests correspondences from each web API to the ontology. Given the API, ontology, and selected mappings for a set of desired fields from the ontology, we define an Automated Planning problem. The resulting policy is finally fed to a code synthesizer that generates the appropriate IBL method implementing the desired integration.This approach has been in production in ASAPP for 2 years with more than 300 integrations already implemented. Results indicate a ≈ 50% reduction in effort due to implementing integrations with IBL. Preliminary results on the IBL automatic code generation show an encouraging further ≈ 25% reduction so far.",Document_162,Difficulty in understanding AI decision-making is a barrier in finance,0.08459841459989548,Explainability and Transparency Barriers
Applied Data Science in Financial Industry - Natural Language Processing Techniques for Bank Policies,"M. Spruit, D. Ferati","In a time when the employment of Natural Language Processing techniques in domains such as biomedicine, national security, finance and law, is flourishing, this study takes a deep look in its application in policy documents. Besides providing an overview of the current state of the literature that treats these concepts, the study at hand implements a set of unprecedented Natural Language Processing techniques on internal bank policies. The implementation of these techniques, together with the results that derive from the experiment and the experts’ evaluation, introduce a Meta-Algorithmic Modelling framework for processing internal business policies. This framework relies on three Natural Language Processing techniques, namely information extraction, automatic summarization and automatic keyword extraction. For the reference extraction and keyword extraction tasks we calculated Precision, Recall and F-scores. For the former we obtained 0.99, 0.84, and 0.89; for the latter we obtained 0.79, 0.87 and 0.83, respectively. Finally, our summary extraction approach was positively evaluated using a qualitative assessment.",2019,2019,4.0,Research & Innovation Forum,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.78) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-030-30809-4_32,10.1007/978-3-030-30809-4_32,https://doi.org/10.1007/978-3-030-30809-4_32,1,"In a time when the employment of Natural Language Processing techniques in domains such as biomedicine, national security, finance and law, is flourishing, this study takes a deep look in its application in policy documents. Besides providing an overview of the current state of the literature that treats these concepts, the study at hand implements a set of unprecedented Natural Language Processing techniques on internal bank policies. The implementation of these techniques, together with the results that derive from the experiment and the experts’ evaluation, introduce a Meta-Algorithmic Modelling framework for processing internal business policies. This framework relies on three Natural Language Processing techniques, namely information extraction, automatic summarization and automatic keyword extraction. For the reference extraction and keyword extraction tasks we calculated Precision, Recall and F-scores. For the former we obtained 0.99, 0.84, and 0.89; for the latter we obtained 0.79, 0.87 and 0.83, respectively. Finally, our summary extraction approach was positively evaluated using a qualitative assessment.",Document_163,Technical aspects or methods of AI or machine learning,0.07282230257987976,Other Categories
Measuring the model risk-adjusted performance of machine learning algorithms in credit default prediction,"Andrés Alonso Robisco, José Manuel Carbó Martínez","Implementing new machine learning (ML) algorithms for credit default prediction is associated with better predictive performance; however, it also generates new model risks, particularly concerning the supervisory validation process. Recent industry surveys often mention that uncertainty about how supervisors might assess these risks could be a barrier to innovation. In this study, we propose a new framework to quantify model risk-adjustments to compare the performance of several ML methods. To address this challenge, we first harness the internal ratings-based approach to identify up to 13 risk components that we classify into 3 main categories—statistics, technology, and market conduct. Second, to evaluate the importance of each risk category, we collect a series of regulatory documents related to three potential use cases—regulatory capital, credit scoring, or provisioning—and we compute the weight of each category according to the intensity of their mentions, using natural language processing and a risk terminology based on expert knowledge. Finally, we test our framework using popular ML models in credit risk, and a publicly available database, to quantify some proxies of a subset of risk factors that we deem representative. We measure the statistical risk according to the number of hyperparameters and the stability of the predictions. The technological risk is assessed through the transparency of the algorithm and the latency of the ML training method, while the market conduct risk is quantified by the time it takes to run a post hoc technique (SHapley Additive exPlanations) to interpret the output.",2022,2022,12.0,Financial Innovation,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1186/s40854-022-00366-1,10.1186/s40854-022-00366-1,https://doi.org/10.1186/s40854-022-00366-1,36,"Implementing new machine learning (ML) algorithms for credit default prediction is associated with better predictive performance; however, it also generates new model risks, particularly concerning the supervisory validation process. Recent industry surveys often mention that uncertainty about how supervisors might assess these risks could be a barrier to innovation. In this study, we propose a new framework to quantify model risk-adjustments to compare the performance of several ML methods. To address this challenge, we first harness the internal ratings-based approach to identify up to 13 risk components that we classify into 3 main categories—statistics, technology, and market conduct. Second, to evaluate the importance of each risk category, we collect a series of regulatory documents related to three potential use cases—regulatory capital, credit scoring, or provisioning—and we compute the weight of each category according to the intensity of their mentions, using natural language processing and a risk terminology based on expert knowledge. Finally, we test our framework using popular ML models in credit risk, and a publicly available database, to quantify some proxies of a subset of risk factors that we deem representative. We measure the statistical risk according to the number of hyperparameters and the stability of the predictions. The technological risk is assessed through the transparency of the algorithm and the latency of the ML training method, while the market conduct risk is quantified by the time it takes to run a post hoc technique (SHapley Additive exPlanations) to interpret the output.",Document_164,Technical aspects or methods of AI or machine learning,0.08268174529075623,Other Categories
Data Cleaning Tools for Token Classification Tasks,"K. Muthuraman, Frederick Reiss, Hong Xu, Bryan Cutler, Zachary Eichenberger","Human-in-the-loop systems for cleaning NLP training data rely on automated sieves to isolate potentially-incorrect labels for manual review. We have developed a novel technique for flagging potentially-incorrect labels with high sensitivity in named entity recognition corpora. We incorporated our sieve into an end-to-end system for cleaning NLP corpora, implemented as a modular collection of Jupyter notebooks built on extensions to the Pandas DataFrame library. We used this system to identify incorrect labels in the CoNLL-2003 corpus for English-language named entity recognition (NER), one of the most influential corpora for NER model research. Unlike previous work that only looked at a subset of the corpus’s validation fold, our automated sieve enabled us to examine the entire corpus in depth. Across the entire CoNLL-2003 corpus, we identified over 1300 incorrect labels (out of 35089 in the corpus). We have published our corrections, along with the code we used in our experiments. We are developing a repeatable version of the process we used on the CoNLL-2003 corpus as an open-source library.",2021,2021,6.0,DASH,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/V1/2021.DASH-1.10,10.18653/V1/2021.DASH-1.10,https://doi.org/10.18653/V1/2021.DASH-1.10,7,"Human-in-the-loop systems for cleaning NLP training data rely on automated sieves to isolate potentially-incorrect labels for manual review. We have developed a novel technique for flagging potentially-incorrect labels with high sensitivity in named entity recognition corpora. We incorporated our sieve into an end-to-end system for cleaning NLP corpora, implemented as a modular collection of Jupyter notebooks built on extensions to the Pandas DataFrame library. We used this system to identify incorrect labels in the CoNLL-2003 corpus for English-language named entity recognition (NER), one of the most influential corpora for NER model research. Unlike previous work that only looked at a subset of the corpus’s validation fold, our automated sieve enabled us to examine the entire corpus in depth. Across the entire CoNLL-2003 corpus, we identified over 1300 incorrect labels (out of 35089 in the corpus). We have published our corrections, along with the code we used in our experiments. We are developing a repeatable version of the process we used on the CoNLL-2003 corpus as an open-source library.",Document_165,Technical aspects or methods of AI or machine learning,0.07489179074764252,Other Categories
"RegTech in public and private sectors: the nexus between data, technology and regulation","Laura Grassi, Davide Lanfranchi","Higher regulatory compliance requirements, fast and continuous changes in regulations and high digital dynamics in the financial markets are powering RegTech (regulatory technology), defined as technology‐enabled innovation applied to the world of regulation, compliance, risk management, reporting and supervision. This work builds on a systematic literature review and a bibliometric analysis of the literature on RegTech, its influential papers and authors, its main areas of research, its past and its future. The resulting multi-dimensional framework bridges across four main dimensions, starting with regulation and technology, where one or more regulations, not necessarily financial ones, are addressed with the support of technologies (e.g. artificial intelligence, DLT, blockchain, smart contracts, API). Data play a central role, as sharing them enables data ecosystems, where additional value can be attained by each market participant, while data automation and machine-readable regulations empower regulators to pull data directly from the banks’ systems and combine these data with data obtained directly from customers or other external sources. Several applications emerge, both for regulated entities, covering matters of compliance, monitoring, risk management, reporting and operations, as well as for authorities, which can leverage on RegTech (SupTech) solutions to make policies, to undertake their authorising, supervising and enforcement operations, for monitoring and controlling purposes, and even to issue fines automatically. As a consequence, stakeholders can reap a series of benefits, such as higher efficiency and effectiveness, accuracy, transparency and lower compliance costs but also risks, such as cyber risk, algorithmic biases, and dehumanization.",2022,2022,9.0,Journal of Industrial and Business Economics,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s40812-022-00226-0,10.1007/s40812-022-00226-0,https://doi.org/10.1007/s40812-022-00226-0,15,"Higher regulatory compliance requirements, fast and continuous changes in regulations and high digital dynamics in the financial markets are powering RegTech (regulatory technology), defined as technology‐enabled innovation applied to the world of regulation, compliance, risk management, reporting and supervision. This work builds on a systematic literature review and a bibliometric analysis of the literature on RegTech, its influential papers and authors, its main areas of research, its past and its future. The resulting multi-dimensional framework bridges across four main dimensions, starting with regulation and technology, where one or more regulations, not necessarily financial ones, are addressed with the support of technologies (e.g. artificial intelligence, DLT, blockchain, smart contracts, API). Data play a central role, as sharing them enables data ecosystems, where additional value can be attained by each market participant, while data automation and machine-readable regulations empower regulators to pull data directly from the banks’ systems and combine these data with data obtained directly from customers or other external sources. Several applications emerge, both for regulated entities, covering matters of compliance, monitoring, risk management, reporting and operations, as well as for authorities, which can leverage on RegTech (SupTech) solutions to make policies, to undertake their authorising, supervising and enforcement operations, for monitoring and controlling purposes, and even to issue fines automatically. As a consequence, stakeholders can reap a series of benefits, such as higher efficiency and effectiveness, accuracy, transparency and lower compliance costs but also risks, such as cyber risk, algorithmic biases, and dehumanization.",Document_166,Technical aspects or methods of AI or machine learning,0.1721828579902649,Other Categories
Gradient-based Analysis of NLP Models is Manipulable,"Junlin Wang, Jens Tuyls, Eric Wallace, Sameer Singh","Gradient-based analysis methods, such as saliency map visualizations and adversarial input perturbations, have found widespread use in interpreting neural NLP models due to their simplicity, flexibility, and most importantly, the fact that they directly reflect the model internals. In this paper, however, we demonstrate that the gradients of a model are easily manipulable, and thus bring into question the reliability of gradient-based analyses. In particular, we merge the layers of a target model with a Facade Model that overwhelms the gradients without affecting the predictions. This Facade Model can be trained to have gradients that are misleading and irrelevant to the task, such as focusing only on the stop words in the input. On a variety of NLP tasks (sentiment analysis, NLI, and QA), we show that the merged model effectively fools different analysis tools: saliency maps differ significantly from the original model’s, input reduction keeps more irrelevant input tokens, and adversarial perturbations identify unimportant tokens as being highly important.",2020,2020,11.0,Findings,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.findings-emnlp.24,10.18653/v1/2020.findings-emnlp.24,https://doi.org/10.18653/v1/2020.findings-emnlp.24,58,"Gradient-based analysis methods, such as saliency map visualizations and adversarial input perturbations, have found widespread use in interpreting neural NLP models due to their simplicity, flexibility, and most importantly, the fact that they directly reflect the model internals. In this paper, however, we demonstrate that the gradients of a model are easily manipulable, and thus bring into question the reliability of gradient-based analyses. In particular, we merge the layers of a target model with a Facade Model that overwhelms the gradients without affecting the predictions. This Facade Model can be trained to have gradients that are misleading and irrelevant to the task, such as focusing only on the stop words in the input. On a variety of NLP tasks (sentiment analysis, NLI, and QA), we show that the merged model effectively fools different analysis tools: saliency maps differ significantly from the original model’s, input reduction keeps more irrelevant input tokens, and adversarial perturbations identify unimportant tokens as being highly important.",Document_167,Technical aspects or methods of AI or machine learning,0.075840525329113,Other Categories
A linguistics approach to solving financial services standardization,R. Robinson,"Global regulators in the financial industry have increasingly referred to the need for a universal “common financial language” to solve issues of perceived nonstandardization and to simplify the tasks of oversight and properly functioning markets. The author cautions, however, that there can be no common financial language for practical reasons, examples of which are presented. Language-related issues are better explained and examined through the lens of applied linguistics, intertwined with current and evolving standards, advanced work in ontologies and already-established dictionaries. It needs to be recognized that real language differences exist which can- not be reconciled or standardized across the entire financial domain; instead, there should be a focus on defining financial language geographies (ie, bounded communities that speak the same language) and points of interoperability (ie, translation). A shared understanding of meaning does not translate to a single, shared definition, for it may be recognized in various contexts or by multiple views. This requires multiple tools and approaches, which cannot be provided by the regulatory mandating of specific data standards. Based on referenced industry and academic work over the past twenty-five-plus years, the author proposes steps to be taken that would better serve regulators and industry in reaching their goals, while also providing the industry with a foundation for better interoperability, communication and standardization.",2018,2018,11.0,-,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (Possible Paywall/Login Page Detected) (URL Source: DOI Link)",https://doi.org/10.21314/jfmi.2018.104,10.21314/jfmi.2018.104,https://doi.org/10.21314/jfmi.2018.104,3,"Global regulators in the financial industry have increasingly referred to the need for a universal “common financial language” to solve issues of perceived nonstandardization and to simplify the tasks of oversight and properly functioning markets. The author cautions, however, that there can be no common financial language for practical reasons, examples of which are presented. Language-related issues are better explained and examined through the lens of applied linguistics, intertwined with current and evolving standards, advanced work in ontologies and already-established dictionaries. It needs to be recognized that real language differences exist which can- not be reconciled or standardized across the entire financial domain; instead, there should be a focus on defining financial language geographies (ie, bounded communities that speak the same language) and points of interoperability (ie, translation). A shared understanding of meaning does not translate to a single, shared definition, for it may be recognized in various contexts or by multiple views. This requires multiple tools and approaches, which cannot be provided by the regulatory mandating of specific data standards. Based on referenced industry and academic work over the past twenty-five-plus years, the author proposes steps to be taken that would better serve regulators and industry in reaching their goals, while also providing the industry with a foundation for better interoperability, communication and standardization.",Document_168,General discussion of financial or regulatory topics (non-AI focus),0.18731097877025604,Other Categories
Impact of Gender Debiased Word Embeddings in Language Modeling,"Christine Basta, M. Costa-jussà","Gender, race and social biases have recently been detected as evident examples of unfairness in applications of Natural Language Processing. A key path towards fairness is to understand, analyse and interpret our data and algorithms. Recent studies have shown that the human-generated data used in training is an apparent factor of getting biases. In addition, current algorithms have also been proven to amplify biases from data. To further address these concerns, in this paper, we study how an state-of-the-art recurrent neural language model behaves when trained on data, which under-represents females, using pre-trained standard and debiased word embeddings. Results show that language models inherit higher bias when trained on unbalanced data when using pre-trained embeddings, in comparison with using embeddings trained within the task. Moreover, results show that, on the same data, language models inherit lower bias when using debiased pre-trained emdeddings, compared to using standard pre-trained embeddings.",2021,2023,4.0,Conference on Intelligent Text Processing and Computational Linguistics,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.27) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-031-24337-0_25,10.1007/978-3-031-24337-0_25,https://doi.org/10.1007/978-3-031-24337-0_25,4,"Gender, race and social biases have recently been detected as evident examples of unfairness in applications of Natural Language Processing. A key path towards fairness is to understand, analyse and interpret our data and algorithms. Recent studies have shown that the human-generated data used in training is an apparent factor of getting biases. In addition, current algorithms have also been proven to amplify biases from data. To further address these concerns, in this paper, we study how an state-of-the-art recurrent neural language model behaves when trained on data, which under-represents females, using pre-trained standard and debiased word embeddings. Results show that language models inherit higher bias when trained on unbalanced data when using pre-trained embeddings, in comparison with using embeddings trained within the task. Moreover, results show that, on the same data, language models inherit lower bias when using debiased pre-trained emdeddings, compared to using standard pre-trained embeddings.",Document_169,Technical aspects or methods of AI or machine learning,0.1109703779220581,Other Categories
Visual Surveillance Within the EU General Data Protection Regulation: A Technology Perspective,"M. Asghar, N. Kanwal, Brian A. Lee, M. Fleury, Marco Herbst, Yuansong Qiao","From an individual's perspective, technological advancement has merits and demerits. Video captured by surveillance cameras while a person goes about their daily life may improve their personal safety but the images collected may also represent an invasion of their privacy. Because of the ease of digital information sharing, there exists a need to protect that visual information from illegal utilization by untrusted parties. The European parliament has ratified the General Data Protection Regulation (GDPR), which has been effective since May 2018 with a view to ensuring the privacy of European Union (EU) citizens' and visitors' personal data. The regulation has introduced data safeguards through Pseudonymisation, Encryption, and Data protection-by-design. However, the regulation does not assist with technical and implementation procedures, such as video redaction, to establish those safeguards. This paper refers to the GDPR term “personal data” as “visual personal data” and aims to discuss regulatory safeguards of visual privacy, such as reversible protection, from the technological point-of-view. In the context of GDPR, the roles of machine learning (i.e. within computer vision), image processing, cryptography, and blockchain are explored as a way of deploying Data Protection-by-Design solutions for visual surveillance data. The paper surveys the existing market-based data protection solutions and provides suggestions for the development of GDPR-compliant Data Protection-by-Design video surveillance systems. The paper is also relevant for those entities interacting with EU citizens from outside the EU and for those regions not currently covered by such regulation that may soon implement similar provisions.",2019,2019,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2019.2934226,10.1109/ACCESS.2019.2934226,https://doi.org/10.1109/ACCESS.2019.2934226,43,"From an individual's perspective, technological advancement has merits and demerits. Video captured by surveillance cameras while a person goes about their daily life may improve their personal safety but the images collected may also represent an invasion of their privacy. Because of the ease of digital information sharing, there exists a need to protect that visual information from illegal utilization by untrusted parties. The European parliament has ratified the General Data Protection Regulation (GDPR), which has been effective since May 2018 with a view to ensuring the privacy of European Union (EU) citizens' and visitors' personal data. The regulation has introduced data safeguards through Pseudonymisation, Encryption, and Data protection-by-design. However, the regulation does not assist with technical and implementation procedures, such as video redaction, to establish those safeguards. This paper refers to the GDPR term “personal data” as “visual personal data” and aims to discuss regulatory safeguards of visual privacy, such as reversible protection, from the technological point-of-view. In the context of GDPR, the roles of machine learning (i.e. within computer vision), image processing, cryptography, and blockchain are explored as a way of deploying Data Protection-by-Design solutions for visual surveillance data. The paper surveys the existing market-based data protection solutions and provides suggestions for the development of GDPR-compliant Data Protection-by-Design video surveillance systems. The paper is also relevant for those entities interacting with EU citizens from outside the EU and for those regions not currently covered by such regulation that may soon implement similar provisions.",Document_170,Technical aspects or methods of AI or machine learning,0.49137213826179504,Other Categories
Regulations impacting corporate actions and best practices for implementation,Deborah Culhane,"Financial services firms continue to grapple with increasing levels of risk and growing regulatory challenges, forcing these firms to fundamentally rethink their data management, information sourcing and validation strategies. Firms are required to adopt more rigorous risk assessment and reporting capabilities, meaning they must also adopt more strategic data management and data quality programs. For example, The Basel Committee on Banking Supervision (BCBS) proposed the BCBS 239 ‘Principles for effective risk data aggregation and risk reporting’, which encourages firms to address these processes from a more consistent and aggregated view of risk. Another is the Legal Entity Identifier (LEI), which addresses the lack of a global standard for financial transaction identification at the entity/counterparty level. The benefits of complying with BCBS and broader leverage of the LEI are clear. And while some firms may be able to develop the internal infrastructure to address these regulations, other firms may choose to outsource the integration of new data management and workflow systems to a third party provider for the best result.",2014,2014,,Journal of Securities Operations &amp; Custody,Selector (div.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.69554/ytwa1105,10.69554/ytwa1105,https://doi.org/10.69554/ytwa1105,1,"Financial services firms continue to grapple with increasing levels of risk and growing regulatory challenges, forcing these firms to fundamentally rethink their data management, information sourcing and validation strategies. Firms are required to adopt more rigorous risk assessment and reporting capabilities, meaning they must also adopt more strategic data management and data quality programs. For example, The Basel Committee on Banking Supervision (BCBS) proposed the BCBS 239 ‘Principles for effective risk data aggregation and risk reporting’, which encourages firms to address these processes from a more consistent and aggregated view of risk. Another is the Legal Entity Identifier (LEI), which addresses the lack of a global standard for financial transaction identification at the entity/counterparty level. The benefits of complying with BCBS and broader leverage of the LEI are clear. And while some firms may be able to develop the internal infrastructure to address these regulations, other firms may choose to outsource the integration of new data management and workflow systems to a third party provider for the best result.",Document_171,General discussion of financial or regulatory topics (non-AI focus),0.1677929162979126,Other Categories
"Automatic detection of relevant information, predictions and forecasts in financial news through topic modelling with Latent Dirichlet Allocation","Silvia García-Méndez, Francisco de Arriba-Pérez, Ana Barros-Vila, F. González-Castaño, E. Costa-Montenegro","Financial news items are unstructured sources of information that can be mined to extract knowledge for market screening applications. They are typically written by market experts who describe stock market events within the context of social, economic and political change. Manual extraction of relevant information from the continuous stream of finance-related news is cumbersome and beyond the skills of many investors, who, at most, can follow a few sources and authors. Accordingly, we focus on the analysis of financial news to identify relevant text and, within that text, forecasts and predictions. We propose a novel Natural Language Processing ( nlp ) system to assist investors in the detection of relevant financial events in unstructured textual sources by considering both relevance and temporality at the discursive level. Firstly, we segment the text to group together closely related text. Secondly, we apply co-reference resolution to discover internal dependencies within segments. Finally, we perform relevant topic modelling with Latent Dirichlet Allocation ( lda ) to separate relevant from less relevant text and then analyse the relevant text using a Machine Learning-oriented temporal approach to identify predictions and speculative statements. Our solution outperformed a rule-based baseline system. We created an experimental data set composed of 2,158 financial news items that were manually labelled by nlp researchers to evaluate our solution. Inter-agreement Alpha-reliability and accuracy values, and rouge-l results endorse its potential as a valuable tool for busy investors. The rouge-l values for the identification of relevant text and predictions/forecasts were 0.662 and 0.982, respectively. To our knowledge, this is the first work to jointly consider relevance and temporality at the discursive level. It contributes to the transfer of human associative discourse capabilities to expert systems through the combination of multi-paragraph topic segmentation and co-reference resolution to separate author expression patterns, topic modelling with lda to detect relevant text, and discursive temporality analysis to identify forecasts and predictions within this text. Our solution may have compelling applications in the financial field, including the possibility of extracting relevant statements on investment strategies to analyse authors’ reputations.",2023,2023,8.0,Applied intelligence (Boston),Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10489-023-04452-4,10.1007/s10489-023-04452-4,https://doi.org/10.1007/s10489-023-04452-4,14,"Financial news items are unstructured sources of information that can be mined to extract knowledge for market screening applications. They are typically written by market experts who describe stock market events within the context of social, economic and political change. Manual extraction of relevant information from the continuous stream of finance-related news is cumbersome and beyond the skills of many investors, who, at most, can follow a few sources and authors. Accordingly, we focus on the analysis of financial news to identify relevant text and, within that text, forecasts and predictions. We propose a novel Natural Language Processing ( nlp ) system to assist investors in the detection of relevant financial events in unstructured textual sources by considering both relevance and temporality at the discursive level. Firstly, we segment the text to group together closely related text. Secondly, we apply co-reference resolution to discover internal dependencies within segments. Finally, we perform relevant topic modelling with Latent Dirichlet Allocation ( lda ) to separate relevant from less relevant text and then analyse the relevant text using a Machine Learning-oriented temporal approach to identify predictions and speculative statements. Our solution outperformed a rule-based baseline system. We created an experimental data set composed of 2,158 financial news items that were manually labelled by nlp researchers to evaluate our solution. Inter-agreement Alpha-reliability and accuracy values, and rouge-l results endorse its potential as a valuable tool for busy investors. The rouge-l values for the identification of relevant text and predictions/forecasts were 0.662 and 0.982, respectively. To our knowledge, this is the first work to jointly consider relevance and temporality at the discursive level. It contributes to the transfer of human associative discourse capabilities to expert systems through the combination of multi-paragraph topic segmentation and co-reference resolution to separate author expression patterns, topic modelling with lda to detect relevant text, and discursive temporality analysis to identify forecasts and predictions within this text. Our solution may have compelling applications in the financial field, including the possibility of extracting relevant statements on investment strategies to analyse authors’ reputations.",Document_172,Technical aspects or methods of AI or machine learning,0.11343064159154892,Other Categories
Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers,"Kostadin Mishev, Ana Gjorgjevikj, I. Vodenska, Lubomir T. Chitkushev, D. Trajanov","Financial and economic news is continuously monitored by financial market participants. According to the efficient market hypothesis, all past information is reflected in stock prices and new information is instantaneously absorbed in determining future stock prices. Hence, prompt extraction of positive or negative sentiments from news is very important for investment decision-making by traders, portfolio managers and investors. Sentiment analysis models can provide an efficient method for extracting actionable signals from the news. However, financial sentiment analysis is challenging due to domain-specific language and unavailability of large labeled datasets. General sentiment analysis models are ineffective when applied to specific domains such as finance. To overcome these challenges, we design an evaluation platform which we use to assess the effectiveness and performance of various sentiment analysis approaches, based on combinations of text representation methods and machine-learning classifiers. We perform more than one hundred experiments using publicly available datasets, labeled by financial experts. We start the evaluation with specific lexicons for sentiment analysis in finance and gradually build the study to include word and sentence encoders, up to the latest available NLP transformers. The results show improved efficiency of contextual embeddings in sentiment analysis compared to lexicons and fixed word and sentence encoders, even when large datasets are not available. Furthermore, distilled versions of NLP transformers produce comparable results to their larger teacher models, which makes them suitable for use in production environments.",2020,2020,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2020.3009626,10.1109/ACCESS.2020.3009626,https://doi.org/10.1109/ACCESS.2020.3009626,160,"Financial and economic news is continuously monitored by financial market participants. According to the efficient market hypothesis, all past information is reflected in stock prices and new information is instantaneously absorbed in determining future stock prices. Hence, prompt extraction of positive or negative sentiments from news is very important for investment decision-making by traders, portfolio managers and investors. Sentiment analysis models can provide an efficient method for extracting actionable signals from the news. However, financial sentiment analysis is challenging due to domain-specific language and unavailability of large labeled datasets. General sentiment analysis models are ineffective when applied to specific domains such as finance. To overcome these challenges, we design an evaluation platform which we use to assess the effectiveness and performance of various sentiment analysis approaches, based on combinations of text representation methods and machine-learning classifiers. We perform more than one hundred experiments using publicly available datasets, labeled by financial experts. We start the evaluation with specific lexicons for sentiment analysis in finance and gradually build the study to include word and sentence encoders, up to the latest available NLP transformers. The results show improved efficiency of contextual embeddings in sentiment analysis compared to lexicons and fixed word and sentence encoders, even when large datasets are not available. Furthermore, distilled versions of NLP transformers produce comparable results to their larger teacher models, which makes them suitable for use in production environments.",Document_173,Technical aspects or methods of AI or machine learning,0.0706653892993927,Other Categories
Detecting Constraints and Their Relations from Regulatory Documents Using NLP Techniques,"Karolin Winter, S. Rinderle-Ma","Extracting constraints and process models from natural language text is an ongoing challenge. While the focus of current research is merely on the extraction itself, this paper presents a three step approach to group constraints as well as to detect and display relations between constraints in order to ease their implementation. For this, the approach uses NLP techniques to extract sentences containing constraints, group them by, e.g., stakeholders or topics, and detect redundant, subsuming, and conflicting pairs of constraints. These relations are displayed using network maps. The approach is prototypically implemented and evaluated based on regulatory documents from the financial sector as well as expert interviews.",2018,2018,4.0,OTM Conferences,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.21) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-030-02610-3_15,10.1007/978-3-030-02610-3_15,https://doi.org/10.1007/978-3-030-02610-3_15,25,"Extracting constraints and process models from natural language text is an ongoing challenge. While the focus of current research is merely on the extraction itself, this paper presents a three step approach to group constraints as well as to detect and display relations between constraints in order to ease their implementation. For this, the approach uses NLP techniques to extract sentences containing constraints, group them by, e.g., stakeholders or topics, and detect redundant, subsuming, and conflicting pairs of constraints. These relations are displayed using network maps. The approach is prototypically implemented and evaluated based on regulatory documents from the financial sector as well as expert interviews.",Document_174,Improving data quality is crucial for successful AI in finance,0.0621742382645607,Data Improvement and Availability Strategies
Semi-automatic knowledge population in a legal document management system,"G. Boella, Luigi Di Caro, Valentina Leone","Every organization has to deal with operational risks, arising from the execution of a company’s primary business functions. In this paper, we describe a legal knowledge management system which helps users understand the meaning of legislative text and the relationship between norms. While much of the knowledge requires the input of legal experts, we focus in this article on NLP applications that semi-automate essential time-consuming and lower-skill tasks—classifying legal documents, identifying cross-references and legislative amendments, linking legal terms to the most relevant definitions, and extracting key elements of legal provisions to facilitate clarity and advanced search options. The use of Natural Language Processing tools to semi-automate such tasks makes the proposal a realistic commercial prospect as it helps keep costs down while allowing greater coverage.",2018,2019,6.0,Artificial Intelligence and Law,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10506-018-9239-8,10.1007/s10506-018-9239-8,https://doi.org/10.1007/s10506-018-9239-8,20,"Every organization has to deal with operational risks, arising from the execution of a company’s primary business functions. In this paper, we describe a legal knowledge management system which helps users understand the meaning of legislative text and the relationship between norms. While much of the knowledge requires the input of legal experts, we focus in this article on NLP applications that semi-automate essential time-consuming and lower-skill tasks—classifying legal documents, identifying cross-references and legislative amendments, linking legal terms to the most relevant definitions, and extracting key elements of legal provisions to facilitate clarity and advanced search options. The use of Natural Language Processing tools to semi-automate such tasks makes the proposal a realistic commercial prospect as it helps keep costs down while allowing greater coverage.",Document_175,Demonstrating the value of AI for compliance and risk management,0.13809743523597717,Business Case and Value Demonstration Strategies
Measuring Fairness with Biased Data: A Case Study on the Effects of Unsupervised Data in Fairness Evaluation,"Sarah Schröder, Alexander Schulz, Ivan Tarakanov, Robert Feldhans, Barbara Hammer","Evaluating fairness in language models has become an important topic, including different types of measurements for specific models, but also fundamental questions such as the impact of pre-training biases in fine-tuned models. Ultimately, many rely on a data based evaluation using one of the few larger datasets for this purpose. We investigate one of them, the BIOS dataset [1], that has been employed in several studies. It is an entirely unsupervised dataset, in the sense that it is scraped from the web and automatically labeled. We investigate this dataset in depth and expose a variety of flaws such as out-of-domain samples or falsely labeled samples, which particularly affect the biases measured on this dataset. We consider a subset that we review, relabel and clean, then reproduce fairness experiments from the literature both on the original and cleaned subset and demonstrate, that biases are strongly affected by the mentioned problems.",2023,2023,4.0,International Work-Conference on Artificial and Natural Neural Networks,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.26) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-031-43085-5_11,10.1007/978-3-031-43085-5_11,https://doi.org/10.1007/978-3-031-43085-5_11,2,"Evaluating fairness in language models has become an important topic, including different types of measurements for specific models, but also fundamental questions such as the impact of pre-training biases in fine-tuned models. Ultimately, many rely on a data based evaluation using one of the few larger datasets for this purpose. We investigate one of them, the BIOS dataset [1], that has been employed in several studies. It is an entirely unsupervised dataset, in the sense that it is scraped from the web and automatically labeled. We investigate this dataset in depth and expose a variety of flaws such as out-of-domain samples or falsely labeled samples, which particularly affect the biases measured on this dataset. We consider a subset that we review, relabel and clean, then reproduce fairness experiments from the literature both on the original and cleaned subset and demonstrate, that biases are strongly affected by the mentioned problems.",Document_176,Building organizational support for AI through education and communication,0.05427540838718414,"Education, Awareness, and Policy Strategies"
NLP for Responsible Finance: Fine-Tuning Transformer-Based Models for ESG,"Stefan Pasch, D. Ehnes","Evaluating companies’ performances according to environmental, social, and governance (ESG) standards has become a central task in the financial industry. We show a novel solution to fine-tune transformer-based models for the ESG domain. By combining ESG ratings with text documents from annual reports, we were able to train an ESG sentiment model that outperforms traditional text classifiers at predicting the ESG behavior of companies by up to 11 percentage points. Moreover, we show practical applications of our ESG sentiment models by predicting individual sentences and by tracking ESG-related news coverage over time.",2022,2022,,2022 IEEE International Conference on Big Data (Big Data),"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/BigData55660.2022.10020755,10.1109/BigData55660.2022.10020755,https://doi.org/10.1109/BigData55660.2022.10020755,12,"Evaluating companies’ performances according to environmental, social, and governance (ESG) standards has become a central task in the financial industry. We show a novel solution to fine-tune transformer-based models for the ESG domain. By combining ESG ratings with text documents from annual reports, we were able to train an ESG sentiment model that outperforms traditional text classifiers at predicting the ESG behavior of companies by up to 11 percentage points. Moreover, we show practical applications of our ESG sentiment models by predicting individual sentences and by tracking ESG-related news coverage over time.",Document_177,Improving data quality is crucial for successful AI in finance,0.06306932121515274,Data Improvement and Availability Strategies
Integrated Data Mapping Engine (DaME) for Financial Services,"Shubhi Asthana, R. Mahindru","Enterprise organizations have vast datasets that need comprehensive analysis on a frequent basis, in order to manage data and take business decisions based on it. However, we observe that there can be a lack of industry standards for definitions of key terms. Additionally, there is a lack of governance for maintaining business processes. This typically leads to disconnected siloed datasets generated from disintegrated systems. To address these challenges, we developed a novel, integrated methodology DaME (Data Mapping Engine) that performs data mapping using ensemble of NLP techniques.The results from the industrial application and evaluation of DaME on a financial services dataset are encouraging that it can help reduce manual effort by automating data mapping and reusing the learning. The accuracy from our dataset in the application is much higher at 69% compared to the existing state-of-the-art with an accuracy of 34%. It has also helped improve the productivity of the industry practitioners, by saving them 14,000 hours of time spent manually mapping vast data stores over a period of ten months.",2022,2022,,2022 IEEE International Conference on Big Data (Big Data),"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/BigData55660.2022.10020358,10.1109/BigData55660.2022.10020358,https://doi.org/10.1109/BigData55660.2022.10020358,1,"Enterprise organizations have vast datasets that need comprehensive analysis on a frequent basis, in order to manage data and take business decisions based on it. However, we observe that there can be a lack of industry standards for definitions of key terms. Additionally, there is a lack of governance for maintaining business processes. This typically leads to disconnected siloed datasets generated from disintegrated systems. To address these challenges, we developed a novel, integrated methodology DaME (Data Mapping Engine) that performs data mapping using ensemble of NLP techniques.The results from the industrial application and evaluation of DaME on a financial services dataset are encouraging that it can help reduce manual effort by automating data mapping and reusing the learning. The accuracy from our dataset in the application is much higher at 69% compared to the existing state-of-the-art with an accuracy of 34%. It has also helped improve the productivity of the industry practitioners, by saving them 14,000 hours of time spent manually mapping vast data stores over a period of ten months.",Document_178,General discussion of AI in finance (neutral focus),0.07578667998313904,Other Categories
A Data-Centric Framework for Composable NLP Workflows,"Zhengzhong Liu, Guanxiong Ding, Avinash Bukkittu, Mansi Gupta, Pengzhi Gao, Atif Ahmed, Shikun Zhang, Xin Gao, Swapnil Singhavi, Linwei Li, Wei Wei, Zecong Hu, Haoran Shi, Xiaodan Liang, T. Mitamura, E. Xing, Zhiting Hu","Empirical natural language processing (NLP) systems in application domains (e.g., healthcare, finance, education) involve interoperation among multiple components, ranging from data ingestion, human annotation, to text retrieval, analysis, generation, and visualization. We establish a unified open-source framework to support fast development of such sophisticated NLP workflows in a composable manner. The framework introduces a uniform data representation to encode heterogeneous results by a wide range of NLP tasks. It offers a large repository of processors for NLP tasks, visualization, and annotation, which can be easily assembled with full interoperability under the unified representation. The highly extensible framework allows plugging in custom processors from external off-the-shelf NLP and deep learning libraries. The whole framework is delivered through two modularized yet integratable open-source projects, namely Forte (for workflow infrastructure and NLP function processors) and Stave (for user interaction, visualization, and annotation).",2020,2020,10.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.emnlp-demos.26,10.18653/v1/2020.emnlp-demos.26,https://doi.org/10.18653/v1/2020.emnlp-demos.26,6,"Empirical natural language processing (NLP) systems in application domains (e.g., healthcare, finance, education) involve interoperation among multiple components, ranging from data ingestion, human annotation, to text retrieval, analysis, generation, and visualization. We establish a unified open-source framework to support fast development of such sophisticated NLP workflows in a composable manner. The framework introduces a uniform data representation to encode heterogeneous results by a wide range of NLP tasks. It offers a large repository of processors for NLP tasks, visualization, and annotation, which can be easily assembled with full interoperability under the unified representation. The highly extensible framework allows plugging in custom processors from external off-the-shelf NLP and deep learning libraries. The whole framework is delivered through two modularized yet integratable open-source projects, namely Forte (for workflow infrastructure and NLP function processors) and Stave (for user interaction, visualization, and annotation).",Document_179,Building organizational support for AI through education and communication,0.08124475181102753,"Education, Awareness, and Policy Strategies"
Scholarly Data Mining: Making Sense of Scientific Literature,"Horacio Saggion, Francesco Ronzano","During the last decade the amount of scientific information available on-line increased at an unprecedented rate and this situation is unlikely to change. As a consequence, nowadays researchers are overwhelmed by an enormous and continuously growing number of publications to consider when they perform research activities like the exploration of advances in specific topics, peer reviewing, writing and evaluation of proposals. Natural Language Processing technology plays a key role in enabling intelligent access to the content of scientific publications. By mining the contents of scientific papers, for example, rich scientific knowledge bases can be built, thus supporting more effective information discovery and question answering approaches. Moreover, text summarization technology can help condense long papers to their essential contents so as to speed up the selection of scientific articles of interest or to assist in the manual or automatic generation of state of the art reports. Paraphrase and textual entailment techniques can contribute to the identification of relations across different scientific textual sources, thus, for instance, identifying implicit links between publications. This tutorial provides an overview of approaches to the extraction of knowledge from scientific literature, including the in-depth analysis of the structure of the scientific articles, their semantic interpretation, content extraction, summarization, and visualization.",2017,2017,,ACM/IEEE Joint Conference on Digital Libraries,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/JCDL.2017.7991622,10.1109/JCDL.2017.7991622,https://doi.org/10.1109/JCDL.2017.7991622,15,"During the last decade the amount of scientific information available on-line increased at an unprecedented rate and this situation is unlikely to change. As a consequence, nowadays researchers are overwhelmed by an enormous and continuously growing number of publications to consider when they perform research activities like the exploration of advances in specific topics, peer reviewing, writing and evaluation of proposals. Natural Language Processing technology plays a key role in enabling intelligent access to the content of scientific publications. By mining the contents of scientific papers, for example, rich scientific knowledge bases can be built, thus supporting more effective information discovery and question answering approaches. Moreover, text summarization technology can help condense long papers to their essential contents so as to speed up the selection of scientific articles of interest or to assist in the manual or automatic generation of state of the art reports. Paraphrase and textual entailment techniques can contribute to the identification of relations across different scientific textual sources, thus, for instance, identifying implicit links between publications. This tutorial provides an overview of approaches to the extraction of knowledge from scientific literature, including the in-depth analysis of the structure of the scientific articles, their semantic interpretation, content extraction, summarization, and visualization.",Document_180,Technical aspects or methods of AI or machine learning,0.08777203410863876,Other Categories
"Applications of Explainable Artificial Intelligence in Finance—a systematic review of Finance, Information Systems, and Computer Science literature","P. Weber, K. V. Carl, O. Hinz","Digitalization and technologization affect numerous domains, promising advantages but also entailing risks. Hence, when decision-makers in highly-regulated domains like Finance implement these technological advances—especially Artificial Intelligence—regulators prescribe high levels of transparency, assuring the traceability of decisions for third parties. Explainable Artificial Intelligence (XAI) is of tremendous importance in this context. We provide an overview of current research on XAI in Finance with a systematic literature review screening 2,022 articles from leading Finance, Information Systems, and Computer Science outlets. We identify a set of 60 relevant articles, classify them according to the used XAI methods and goals that they aim to achieve, and provide an overview of XAI methods used in different Finance areas. Areas like risk management, portfolio optimization, and applications around the stock market are well-researched, while anti-money laundering is understudied. Researchers implement both transparent models and post-hoc explainability, while they recently favored the latter.",2023,2024,6.0,Management Review Quarterly,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (Possible Paywall/Login Page Detected) (URL Source: DOI Link),https://doi.org/10.1007/s11301-023-00320-0,10.1007/s11301-023-00320-0,https://doi.org/10.1007/s11301-023-00320-0,71,"Digitalization and technologization affect numerous domains, promising advantages but also entailing risks. Hence, when decision-makers in highly-regulated domains like Finance implement these technological advances—especially Artificial Intelligence—regulators prescribe high levels of transparency, assuring the traceability of decisions for third parties. Explainable Artificial Intelligence (XAI) is of tremendous importance in this context. We provide an overview of current research on XAI in Finance with a systematic literature review screening 2,022 articles from leading Finance, Information Systems, and Computer Science outlets. We identify a set of 60 relevant articles, classify them according to the used XAI methods and goals that they aim to achieve, and provide an overview of XAI methods used in different Finance areas. Areas like risk management, portfolio optimization, and applications around the stock market are well-researched, while anti-money laundering is understudied. Researchers implement both transparent models and post-hoc explainability, while they recently favored the latter.",Document_181,Aligning AI implementation with financial regulatory requirements,0.1783839762210846,Regulatory Engagement and Proactive Compliance Strategies
Trusting deep learning natural-language models via local and global explanations,"F. Ventura, Salvatore Greco, D. Apiletti, T. Cerquitelli","Despite the high accuracy offered by state-of-the-art deep natural-language models (e.g., LSTM, BERT), their application in real-life settings is still widely limited, as they behave like a black-box to the end-user. Hence, explainability is rapidly becoming a fundamental requirement of future-generation data-driven systems based on deep-learning approaches. Several attempts to fulfill the existing gap between accuracy and interpretability have been made. However, robust and specialized eXplainable Artificial Intelligence solutions, tailored to deep natural-language models, are still missing. We propose a new framework, named T-EBAnO , which provides innovative prediction-local and class-based model-global explanation strategies tailored to deep learning natural-language models. Given a deep NLP model and the textual input data, T-EBAnO provides an objective, human-readable, domain-specific assessment of the reasons behind the automatic decision-making process. Specifically, the framework extracts sets of interpretable features mining the inner knowledge of the model. Then, it quantifies the influence of each feature during the prediction process by exploiting the normalized Perturbation Influence Relation index at the local level and the novel Global Absolute Influence and Global Relative Influence indexes at the global level. The effectiveness and the quality of the local and global explanations obtained with T-EBAnO are proved on an extensive set of experiments addressing different tasks, such as a sentiment-analysis task performed by a fine-tuned BERT model and a toxic-comment classification task performed by an LSTM model. The quality of the explanations proposed by T-EBAnO , and, specifically, the correlation between the influence index and human judgment, has been evaluated by humans in a survey with more than 4000 judgments. To prove the generality of T-EBAnO and its model/task-independent methodology, experiments with other models (ALBERT, ULMFit) on popular public datasets (Ag News and Cola) are also discussed in detail.",2022,2022,7.0,Knowledge and Information Systems,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10115-022-01690-9,10.1007/s10115-022-01690-9,https://doi.org/10.1007/s10115-022-01690-9,12,"Despite the high accuracy offered by state-of-the-art deep natural-language models (e.g., LSTM, BERT), their application in real-life settings is still widely limited, as they behave like a black-box to the end-user. Hence, explainability is rapidly becoming a fundamental requirement of future-generation data-driven systems based on deep-learning approaches. Several attempts to fulfill the existing gap between accuracy and interpretability have been made. However, robust and specialized eXplainable Artificial Intelligence solutions, tailored to deep natural-language models, are still missing. We propose a new framework, named T-EBAnO , which provides innovative prediction-local and class-based model-global explanation strategies tailored to deep learning natural-language models. Given a deep NLP model and the textual input data, T-EBAnO provides an objective, human-readable, domain-specific assessment of the reasons behind the automatic decision-making process. Specifically, the framework extracts sets of interpretable features mining the inner knowledge of the model. Then, it quantifies the influence of each feature during the prediction process by exploiting the normalized Perturbation Influence Relation index at the local level and the novel Global Absolute Influence and Global Relative Influence indexes at the global level. The effectiveness and the quality of the local and global explanations obtained with T-EBAnO are proved on an extensive set of experiments addressing different tasks, such as a sentiment-analysis task performed by a fine-tuned BERT model and a toxic-comment classification task performed by an LSTM model. The quality of the explanations proposed by T-EBAnO , and, specifically, the correlation between the influence index and human judgment, has been evaluated by humans in a survey with more than 4000 judgments. To prove the generality of T-EBAnO and its model/task-independent methodology, experiments with other models (ALBERT, ULMFit) on popular public datasets (Ag News and Cola) are also discussed in detail.",Document_182,Technical aspects or methods of AI or machine learning,0.2083374708890915,Other Categories
"Detecting Environmental, Social and Governance (ESG) Topics Using Domain-Specific Language Models and Data Augmentation","Timothy Nugent, N. Stelea, Jochen L. Leidner","Despite recent advances in deep learning-based language modelling, many natural language processing (NLP) tasks in the financial domain remain challenging due to the paucity of appropriately labelled data. Other issues that can limit task performance are differences in word distribution between the general corpora – typically used to pre-train language models – and financial corpora, which often exhibit specialized language and symbology. Here, we investigate two approaches that can help to mitigate these issues. Firstly, we experiment with further language model pre-training using large amounts of in-domain data from business and financial news. We then apply augmentation approaches to increase the size of our data-set for model fine-tuning. We report our findings on an Environmental, Social and Governance (ESG) controversies data-set and demonstrate that both approaches are beneficial to accuracy in classification tasks.",2021,2021,4.0,International Conference on Flexible Query Answering Systems,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.32) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-030-86967-0_12,10.1007/978-3-030-86967-0_12,https://doi.org/10.1007/978-3-030-86967-0_12,16,"Despite recent advances in deep learning-based language modelling, many natural language processing (NLP) tasks in the financial domain remain challenging due to the paucity of appropriately labelled data. Other issues that can limit task performance are differences in word distribution between the general corpora – typically used to pre-train language models – and financial corpora, which often exhibit specialized language and symbology. Here, we investigate two approaches that can help to mitigate these issues. Firstly, we experiment with further language model pre-training using large amounts of in-domain data from business and financial news. We then apply augmentation approaches to increase the size of our data-set for model fine-tuning. We report our findings on an Environmental, Social and Governance (ESG) controversies data-set and demonstrate that both approaches are beneficial to accuracy in classification tasks.",Document_183,Improving data quality is crucial for successful AI in finance,0.12176131457090378,Data Improvement and Availability Strategies
Developments in Practice XVII: A Framework for KM Evaluation,"H. Smith, J. McKeen","Demonstrating the value of knowledge management (KM) to the organization represents an elusive challenge. In part, this challenge is due to the nature of knowledge management itself and the difficulty in creating direct linkages between knowledge sharing and sales growth or productivity. But it is also undoubtedly due to misaligned KM activities. This paper first reviews the current state of metrics in KM and presents six principles of measurement immediately applicable to the practice of KM. It then outlines a framework for KM evaluation using four key approaches: balanced scorecard; strategic imperatives; capabilities assessment; and measurement matrix. The paper concludes by presenting a number of strategies for improving KM metrics.",2005,2005,,Communications of the Association for Information Systems,Selector (div#abstract > p / Date Not Found (URL Source: DOI Link),https://doi.org/10.17705/1cais.01609,10.17705/1cais.01609,https://doi.org/10.17705/1cais.01609,13,"Demonstrating the value of knowledge management (KM) to the organization represents an elusive challenge. In part, this challenge is due to the nature of knowledge management itself and the difficulty in creating direct linkages between knowledge sharing and sales growth or productivity. But it is also undoubtedly due to misaligned KM activities. This paper first reviews the current state of metrics in KM and presents six principles of measurement immediately applicable to the practice of KM. It then outlines a framework for KM evaluation using four key approaches: balanced scorecard; strategic imperatives; capabilities assessment; and measurement matrix. The paper concludes by presenting a number of strategies for improving KM metrics.",Document_184,AI systems in finance lack sufficient explainability,0.051292505115270615,Explainability and Transparency Barriers
Linguistically inspired roadmap for building biologically reliable protein language models,"Mai Ha Vu, R. Akbar, Philippe A. Robert, Bartlomiej Swiatczak, G. K. Sandve, V. Greiff, Dag Trygve Tryslew Haug","Deep neural-network-based language models (LMs) are increasingly applied to large-scale protein sequence data to predict protein function. However, being largely black-box models and thus challenging to interpret, current protein LM approaches do not contribute to a fundamental understanding of sequence–function mappings, hindering rule-based biotherapeutic drug development. We argue that guidance drawn from linguistics, a field specialized in analytical rule extraction from natural language data, can aid with building more interpretable protein LMs that are more likely to learn relevant domain-specific rules. Differences between protein sequence data and linguistic sequence data require the integration of more domain-specific knowledge in protein LMs compared with natural language LMs. Here, we provide a linguistics-based roadmap for protein LM pipeline choices with regard to training data, tokenization, token embedding, sequence embedding and model interpretation. Incorporating linguistic ideas into protein LMs enables the development of next-generation interpretable machine learning models with the potential of uncovering the biological mechanisms underlying sequence–function relationships.",2022,2023,5.0,Nature Machine Intelligence,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1038/s42256-023-00637-1,10.1038/s42256-023-00637-1,https://doi.org/10.1038/s42256-023-00637-1,29,"Deep neural-network-based language models (LMs) are increasingly applied to large-scale protein sequence data to predict protein function. However, being largely black-box models and thus challenging to interpret, current protein LM approaches do not contribute to a fundamental understanding of sequence–function mappings, hindering rule-based biotherapeutic drug development. We argue that guidance drawn from linguistics, a field specialized in analytical rule extraction from natural language data, can aid with building more interpretable protein LMs that are more likely to learn relevant domain-specific rules. Differences between protein sequence data and linguistic sequence data require the integration of more domain-specific knowledge in protein LMs compared with natural language LMs. Here, we provide a linguistics-based roadmap for protein LM pipeline choices with regard to training data, tokenization, token embedding, sequence embedding and model interpretation. Incorporating linguistic ideas into protein LMs enables the development of next-generation interpretable machine learning models with the potential of uncovering the biological mechanisms underlying sequence–function relationships.",Document_185,Technical aspects or methods of AI or machine learning,0.089642234146595,Other Categories
Adversarial Attacks and defenses on Deep Learning Models in Natural Language Processing,"Yu Zhang, Kun Shao, Jun-an Yang, Hui Liu","Deep neural networks (DNNs) have achieved remarkable success in various tasks such as image classification, speech recognition, and natural language processing. However, DNNs have proven to be vulnerable to attacks from adversarial examples. These samples are generated by adding some imperceptible disturbances, which are used to mislead the output decision of the deep learning model and bring significant security risks to the system. However, previous research mainly focused on computer vision, thus neglecting the security issues of natural language processing models. Since the text data is discrete, the existing methods in the image field cannot directly use the text. This article summarized the research on adversarial attacks and defenses in natural language processing and looked forward to future research directions.",2021,2021,,"2021 IEEE 5th Information Technology,Networking,Electronic and Automation Control Conference (ITNEC)","Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ITNEC52019.2021.9587104,10.1109/ITNEC52019.2021.9587104,https://doi.org/10.1109/ITNEC52019.2021.9587104,3,"Deep neural networks (DNNs) have achieved remarkable success in various tasks such as image classification, speech recognition, and natural language processing. However, DNNs have proven to be vulnerable to attacks from adversarial examples. These samples are generated by adding some imperceptible disturbances, which are used to mislead the output decision of the deep learning model and bring significant security risks to the system. However, previous research mainly focused on computer vision, thus neglecting the security issues of natural language processing models. Since the text data is discrete, the existing methods in the image field cannot directly use the text. This article summarized the research on adversarial attacks and defenses in natural language processing and looked forward to future research directions.",Document_186,Technical aspects or methods of AI or machine learning,0.12694957852363586,Other Categories
Generating Natural Language Adversarial Examples,"M. Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, M. Srivastava, Kai-Wei Chang","Deep neural networks (DNNs) are vulnerable to adversarial examples, perturbations to correctly classified examples which can cause the model to misclassify. In the image domain, these perturbations can often be made virtually indistinguishable to human perception, causing humans and state-of-the-art models to disagree. However, in the natural language domain, small perturbations are clearly perceptible, and the replacement of a single word can drastically alter the semantics of the document. Given these challenges, we use a black-box population-based optimization algorithm to generate semantically and syntactically similar adversarial examples that fool well-trained sentiment analysis and textual entailment models with success rates of 97% and 70%, respectively. We additionally demonstrate that 92.3% of the successful sentiment analysis adversarial examples are classified to their original label by 20 human annotators, and that the examples are perceptibly quite similar. Finally, we discuss an attempt to use adversarial training as a defense, but fail to yield improvement, demonstrating the strength and diversity of our adversarial examples. We hope our findings encourage researchers to pursue improving the robustness of DNNs in the natural language domain.",2018,2018,4.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/D18-1316,10.18653/v1/D18-1316,https://doi.org/10.18653/v1/D18-1316,890,"Deep neural networks (DNNs) are vulnerable to adversarial examples, perturbations to correctly classified examples which can cause the model to misclassify. In the image domain, these perturbations can often be made virtually indistinguishable to human perception, causing humans and state-of-the-art models to disagree. However, in the natural language domain, small perturbations are clearly perceptible, and the replacement of a single word can drastically alter the semantics of the document. Given these challenges, we use a black-box population-based optimization algorithm to generate semantically and syntactically similar adversarial examples that fool well-trained sentiment analysis and textual entailment models with success rates of 97% and 70%, respectively. We additionally demonstrate that 92.3% of the successful sentiment analysis adversarial examples are classified to their original label by 20 human annotators, and that the examples are perceptibly quite similar. Finally, we discuss an attempt to use adversarial training as a defense, but fail to yield improvement, demonstrating the strength and diversity of our adversarial examples. We hope our findings encourage researchers to pursue improving the robustness of DNNs in the natural language domain.",Document_187,Technical aspects or methods of AI or machine learning,0.10995029658079147,Other Categories
A Review on Natural Language Processing: Back to Basics,"P. Dinesh, V. Sujitha, C. Salma, B. Srijayapriya","Deep learning models have made incredible progress in tackling an assortment of natural language processing (NLP) issues. An ever-developing assortment of research, in any case, outlines the dependence of deep neural systems (DNNs) to ill-disposed models—inputs adjusted by acquainting little irritations with knowingly fooling an objective model into yielding mistaken outcomes. The powerlessness to aggressive models has gotten one of the fundamental obstacles blocking neural system organization into security basic conditions. This paper talks about the contemporary utilization of ill-disposed guides to thwart DNNs and presents an extensive audit of their utilization to improve the robustness of DNNs in NLP applications.",2021,2021,4.0,-,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.15) (URL Source: DOI Link)",https://doi.org/10.1007/978-981-15-9651-3_54,10.1007/978-981-15-9651-3_54,https://doi.org/10.1007/978-981-15-9651-3_54,6,"Deep learning models have made incredible progress in tackling an assortment of natural language processing (NLP) issues. An ever-developing assortment of research, in any case, outlines the dependence of deep neural systems (DNNs) to ill-disposed models—inputs adjusted by acquainting little irritations with knowingly fooling an objective model into yielding mistaken outcomes. The powerlessness to aggressive models has gotten one of the fundamental obstacles blocking neural system organization into security basic conditions. This paper talks about the contemporary utilization of ill-disposed guides to thwart DNNs and presents an extensive audit of their utilization to improve the robustness of DNNs in NLP applications.",Document_188,Technical aspects or methods of AI or machine learning,0.15871745347976685,Other Categories
Saliency Learning: Teaching the Model Where to Pay Attention,"Reza Ghaeini, Xiaoli Z. Fern, Hamed Shahbazi, Prasad Tadepalli","Deep learning has emerged as a compelling solution to many NLP tasks with remarkable performances. However, due to their opacity, such models are hard to interpret and trust. Recent work on explaining deep models has introduced approaches to provide insights toward the model’s behaviour and predictions, which are helpful for assessing the reliability of the model’s predictions. However, such methods do not improve the model’s reliability. In this paper, we aim to teach the model to make the right prediction for the right reason by providing explanation training and ensuring the alignment of the model’s explanation with the ground truth explanation. Our experimental results on multiple tasks and datasets demonstrate the effectiveness of the proposed method, which produces more reliable predictions while delivering better results compared to traditionally trained models.",2019,2019,6.0,North American Chapter of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/N19-1404,10.18653/v1/N19-1404,https://doi.org/10.18653/v1/N19-1404,28,"Deep learning has emerged as a compelling solution to many NLP tasks with remarkable performances. However, due to their opacity, such models are hard to interpret and trust. Recent work on explaining deep models has introduced approaches to provide insights toward the model’s behaviour and predictions, which are helpful for assessing the reliability of the model’s predictions. However, such methods do not improve the model’s reliability. In this paper, we aim to teach the model to make the right prediction for the right reason by providing explanation training and ensuring the alignment of the model’s explanation with the ground truth explanation. Our experimental results on multiple tasks and datasets demonstrate the effectiveness of the proposed method, which produces more reliable predictions while delivering better results compared to traditionally trained models.",Document_189,Technical aspects or methods of AI or machine learning,0.12301129102706909,Other Categories
Residue-Based Natural Language Adversarial Attack Detection,"Vyas Raina, M. Gales","Deep learning based systems are susceptible to adversarial attacks, where a small, imperceptible change at the input alters the model prediction. However, to date the majority of the approaches to detect these attacks have been designed for image processing systems. Many popular image adversarial detection approaches are able to identify adversarial examples from embedding feature spaces, whilst in the NLP domain existing state of the art detection approaches solely focus on input text features, without consideration of model embedding spaces. This work examines what differences result when porting these image designed strategies to Natural Language Processing (NLP) tasks - these detectors are found to not port over well. This is expected as NLP systems have a very different form of input: discrete and sequential in nature, rather than the continuous and fixed size inputs for images. As an equivalent model-focused NLP detection approach, this work proposes a simple sentence-embedding “residue” based detector to identify adversarial examples. On many tasks, it out-performs ported image domain detectors and recent state of the art NLP specific detectors.",2022,2022,7.0,North American Chapter of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2022.naacl-main.281,10.18653/v1/2022.naacl-main.281,https://doi.org/10.18653/v1/2022.naacl-main.281,10,"Deep learning based systems are susceptible to adversarial attacks, where a small, imperceptible change at the input alters the model prediction. However, to date the majority of the approaches to detect these attacks have been designed for image processing systems. Many popular image adversarial detection approaches are able to identify adversarial examples from embedding feature spaces, whilst in the NLP domain existing state of the art detection approaches solely focus on input text features, without consideration of model embedding spaces. This work examines what differences result when porting these image designed strategies to Natural Language Processing (NLP) tasks - these detectors are found to not port over well. This is expected as NLP systems have a very different form of input: discrete and sequential in nature, rather than the continuous and fixed size inputs for images. As an equivalent model-focused NLP detection approach, this work proposes a simple sentence-embedding “residue” based detector to identify adversarial examples. On many tasks, it out-performs ported image domain detectors and recent state of the art NLP specific detectors.",Document_190,Technical aspects or methods of AI or machine learning,0.14504969120025635,Other Categories
How to keep text private? A systematic review of deep learning methods for privacy-preserving natural language processing,"S. Sousa, Roman Kern","Deep learning (DL) models for natural language processing (NLP) tasks often handle private data, demanding protection against breaches and disclosures. Data protection laws, such as the European Union’s General Data Protection Regulation (GDPR), thereby enforce the need for privacy. Although many privacy-preserving NLP methods have been proposed in recent years, no categories to organize them have been introduced yet, making it hard to follow the progress of the literature. To close this gap, this article systematically reviews over sixty DL methods for privacy-preserving NLP published between 2016 and 2020, covering theoretical foundations, privacy-enhancing technologies, and analysis of their suitability for real-world scenarios. First, we introduce a novel taxonomy for classifying the existing methods into three categories: data safeguarding methods, trusted methods, and verification methods. Second, we present an extensive summary of privacy threats, datasets for applications, and metrics for privacy evaluation. Third, throughout the review, we describe privacy issues in the NLP pipeline in a holistic view. Further, we discuss open challenges in privacy-preserving NLP regarding data traceability, computation overhead, dataset size, the prevalence of human biases in embeddings, and the privacy-utility tradeoff. Finally, this review presents future research directions to guide successive research and development of privacy-preserving NLP models.",2022,2023,2.0,Artificial Intelligence Review,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10462-022-10204-6,10.1007/s10462-022-10204-6,https://doi.org/10.1007/s10462-022-10204-6,34,"Deep learning (DL) models for natural language processing (NLP) tasks often handle private data, demanding protection against breaches and disclosures. Data protection laws, such as the European Union’s General Data Protection Regulation (GDPR), thereby enforce the need for privacy. Although many privacy-preserving NLP methods have been proposed in recent years, no categories to organize them have been introduced yet, making it hard to follow the progress of the literature. To close this gap, this article systematically reviews over sixty DL methods for privacy-preserving NLP published between 2016 and 2020, covering theoretical foundations, privacy-enhancing technologies, and analysis of their suitability for real-world scenarios. First, we introduce a novel taxonomy for classifying the existing methods into three categories: data safeguarding methods, trusted methods, and verification methods. Second, we present an extensive summary of privacy threats, datasets for applications, and metrics for privacy evaluation. Third, throughout the review, we describe privacy issues in the NLP pipeline in a holistic view. Further, we discuss open challenges in privacy-preserving NLP regarding data traceability, computation overhead, dataset size, the prevalence of human biases in embeddings, and the privacy-utility tradeoff. Finally, this review presents future research directions to guide successive research and development of privacy-preserving NLP models.",Document_191,Technical aspects or methods of AI or machine learning,0.12115145474672318,Other Categories
Perturbation Sensitivity Analysis to Detect Unintended Model Biases,"Vinodkumar Prabhakaran, Ben Hutchinson, Margaret Mitchell","Data-driven statistical Natural Language Processing (NLP) techniques leverage large amounts of language data to build models that can understand language. However, most language data reflect the public discourse at the time the data was produced, and hence NLP models are susceptible to learning incidental associations around named referents at a particular point in time, in addition to general linguistic meaning. An NLP system designed to model notions such as sentiment and toxicity should ideally produce scores that are independent of the identity of such entities mentioned in text and their social associations. For example, in a general purpose sentiment analysis system, a phrase such as I hate Katy Perry should be interpreted as having the same sentiment as I hate Taylor Swift. Based on this idea, we propose a generic evaluation framework, Perturbation Sensitivity Analysis, which detects unintended model biases related to named entities, and requires no new annotations or corpora. We demonstrate the utility of this analysis by employing it on two different NLP models — a sentiment model and a toxicity model — applied on online comments in English language from four different genres.",2019,2019,11.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/D19-1578,10.18653/v1/D19-1578,https://doi.org/10.18653/v1/D19-1578,116,"Data-driven statistical Natural Language Processing (NLP) techniques leverage large amounts of language data to build models that can understand language. However, most language data reflect the public discourse at the time the data was produced, and hence NLP models are susceptible to learning incidental associations around named referents at a particular point in time, in addition to general linguistic meaning. An NLP system designed to model notions such as sentiment and toxicity should ideally produce scores that are independent of the identity of such entities mentioned in text and their social associations. For example, in a general purpose sentiment analysis system, a phrase such as I hate Katy Perry should be interpreted as having the same sentiment as I hate Taylor Swift. Based on this idea, we propose a generic evaluation framework, Perturbation Sensitivity Analysis, which detects unintended model biases related to named entities, and requires no new annotations or corpora. We demonstrate the utility of this analysis by employing it on two different NLP models — a sentiment model and a toxicity model — applied on online comments in English language from four different genres.",Document_192,Technical aspects or methods of AI or machine learning,0.05919312313199043,Other Categories
“Just-in-time” generation of datasets by considering structured representations of given consent for GDPR compliance,"C. Debruyne, H. Pandit, D. Lewis, D. O’Sullivan","Data processing is increasingly becoming the subject of various policies and regulations, such as the European General Data Protection Regulation (GDPR) that came into effect in May 2018. One important aspect of GDPR is informed consent, which captures one’s permission for using one’s personal information for specific data processing purposes. Organizations must demonstrate that they comply with these policies. The fines that come with non-compliance are of such importance that it has driven research in facilitating compliance verification. The state-of-the-art primarily focuses on, for instance, the analysis of prescriptive models and posthoc analysis on logs to check whether data processing is compliant to GDPR. We argue that GDPR compliance can be facilitated by ensuring datasets used in processing activities are compliant with consent from the very start. The problem addressed in this paper is how we can generate datasets that comply with given consent “just-in-time”. We propose RDF and OWL ontologies to represent the consent that an organization has collected and its relationship with data processing purposes. We use this ontology to annotate schemas, allowing us to generate declarative mappings that transform (relational) data into RDF driven by the annotations. We furthermore demonstrate how we can create compliant datasets by altering the results of the mapping. The use of RDF and OWL allows us to implement the entire process in a declarative manner using SPARQL. We have integrated all components in a service that furthermore captures provenance information for each step, further contributing to the transparency that is needed towards facilitating compliance verification. We demonstrate the approach with a synthetic dataset simulating users (re-)giving, withdrawing, and rejecting their consent on data processing purposes of systems. In summary, it is argued that the approach facilitates transparency and compliance verification from the start, reducing the need for posthoc compliance analysis common in the state-of-the-art.",2020,2020,9.0,Knowledge and Information Systems,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s10115-020-01468-x,10.1007/s10115-020-01468-x,https://doi.org/10.1007/s10115-020-01468-x,14,"Data processing is increasingly becoming the subject of various policies and regulations, such as the European General Data Protection Regulation (GDPR) that came into effect in May 2018. One important aspect of GDPR is informed consent, which captures one’s permission for using one’s personal information for specific data processing purposes. Organizations must demonstrate that they comply with these policies. The fines that come with non-compliance are of such importance that it has driven research in facilitating compliance verification. The state-of-the-art primarily focuses on, for instance, the analysis of prescriptive models and posthoc analysis on logs to check whether data processing is compliant to GDPR. We argue that GDPR compliance can be facilitated by ensuring datasets used in processing activities are compliant with consent from the very start. The problem addressed in this paper is how we can generate datasets that comply with given consent “just-in-time”. We propose RDF and OWL ontologies to represent the consent that an organization has collected and its relationship with data processing purposes. We use this ontology to annotate schemas, allowing us to generate declarative mappings that transform (relational) data into RDF driven by the annotations. We furthermore demonstrate how we can create compliant datasets by altering the results of the mapping. The use of RDF and OWL allows us to implement the entire process in a declarative manner using SPARQL. We have integrated all components in a service that furthermore captures provenance information for each step, further contributing to the transparency that is needed towards facilitating compliance verification. We demonstrate the approach with a synthetic dataset simulating users (re-)giving, withdrawing, and rejecting their consent on data processing purposes of systems. In summary, it is argued that the approach facilitates transparency and compliance verification from the start, reducing the need for posthoc compliance analysis common in the state-of-the-art.",Document_193,Technical aspects or methods of AI or machine learning,0.04484104365110397,Other Categories
Review: Privacy-preservation in the context of Natural Language Processing,"D. Mahendran, Changqing Luo, Bridget T. McInnes","Data privacy is one of the highly discussed issues in recent years as we encounter data breaches and privacy scandals often. This raises a lot of concerns about the ways the data is acquired and the potential information leaks. Especially in the field of Artificial Intelligence (AI), the widely using of AI models aggravates the vulnerability of user privacy because a considerable portion of user data that AI models used is represented in natural language. In the past few years, many researchers have proposed NLP-based methods to address these data privacy challenges. To the best of our knowledge, this is the first interdisciplinary review discussing privacy preservation in the context of NLP. In this paper, we present a comprehensive review of previous research conducted to gather techniques and challenges of building and testing privacy-preserving systems in the context of Natural Language Processing (NLP). We group the different works under four categories: 1) Data privacy in the medical domain, 2) Privacy preservation in the technology domain, 3) Analysis of privacy policies, and 4) Privacy leaks detection in the text representation. This review compares the contributions and pitfalls of the various privacy violation detection and prevention works done using NLP techniques to help guide a path ahead.",2021,2021,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2021.3124163,10.1109/ACCESS.2021.3124163,https://doi.org/10.1109/ACCESS.2021.3124163,11,"Data privacy is one of the highly discussed issues in recent years as we encounter data breaches and privacy scandals often. This raises a lot of concerns about the ways the data is acquired and the potential information leaks. Especially in the field of Artificial Intelligence (AI), the widely using of AI models aggravates the vulnerability of user privacy because a considerable portion of user data that AI models used is represented in natural language. In the past few years, many researchers have proposed NLP-based methods to address these data privacy challenges. To the best of our knowledge, this is the first interdisciplinary review discussing privacy preservation in the context of NLP. In this paper, we present a comprehensive review of previous research conducted to gather techniques and challenges of building and testing privacy-preserving systems in the context of Natural Language Processing (NLP). We group the different works under four categories: 1) Data privacy in the medical domain, 2) Privacy preservation in the technology domain, 3) Analysis of privacy policies, and 4) Privacy leaks detection in the text representation. This review compares the contributions and pitfalls of the various privacy violation detection and prevention works done using NLP techniques to help guide a path ahead.",Document_194,Technical aspects or methods of AI or machine learning,0.15742281079292297,Other Categories
A BERT Based Approach to Measure Web Services Policies Compliance with GDPR,"Lavanya Elluri, Sai Sree Laya Chukkapalli, K. Joshi, Timothy W. Finin, A. Joshi","Data confidentiality is an issue of increasing importance. Several authorities and regulatory bodies are creating new laws that control how web services data is handled and shared. With the rapid increase of such regulations, web service providers face challenges in complying with these evolving regulations across jurisdictions. Providers must update their service policies regularly to address the new regulations. The challenge is that regulatory documents are large text documents and require substantial human effort to comprehend and enforce. On the other hand, web service provider privacy policies are relatively short compared to the regulatory texts, so it is hard to determine if an organization’s policy document addresses the regulation’s essential elements. We have developed a framework to automatically compare web service policies with regulatory policies to measure how closely the web service provider complies with a regulation. In this paper, we present our framework’s details along with the results of analyzing a corpus of 3,000 privacy policies against GDPR. Our framework uses BiLSTM multi-class classification and a BERT extractive summarizer. We evaluate the framework’s efficacy by checking the context similarity score between summarized GDPR and web service provider privacy policies.",2021,2021,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2021.3123950,10.1109/ACCESS.2021.3123950,https://doi.org/10.1109/ACCESS.2021.3123950,15,"Data confidentiality is an issue of increasing importance. Several authorities and regulatory bodies are creating new laws that control how web services data is handled and shared. With the rapid increase of such regulations, web service providers face challenges in complying with these evolving regulations across jurisdictions. Providers must update their service policies regularly to address the new regulations. The challenge is that regulatory documents are large text documents and require substantial human effort to comprehend and enforce. On the other hand, web service provider privacy policies are relatively short compared to the regulatory texts, so it is hard to determine if an organization’s policy document addresses the regulation’s essential elements. We have developed a framework to automatically compare web service policies with regulatory policies to measure how closely the web service provider complies with a regulation. In this paper, we present our framework’s details along with the results of analyzing a corpus of 3,000 privacy policies against GDPR. Our framework uses BiLSTM multi-class classification and a BERT extractive summarizer. We evaluate the framework’s efficacy by checking the context similarity score between summarized GDPR and web service provider privacy policies.",Document_195,Technical aspects or methods of AI or machine learning,0.08597546070814133,Other Categories
Clean or Annotate: How to Spend a Limited Data Collection Budget,"Derek Chen, Zhou Yu, Samuel R. Bowman","Crowdsourcing platforms are often used to collect datasets for training machine learning models, despite higher levels of inaccurate labeling compared to expert labeling. There are two common strategies to manage the impact of such noise: The first involves aggregating redundant annotations, but comes at the expense of labeling substantially fewer examples. Secondly, prior works have also considered using the entire annotation budget to label as many examples as possible and subsequently apply denoising algorithms to implicitly clean the dataset. We find a middle ground and propose an approach which reserves a fraction of annotations to explicitly clean up highly probable error samples to optimize the annotation process. In particular, we allocate a large portion of the labeling budget to form an initial dataset used to train a model. This model is then used to identify specific examples that appear most likely to be incorrect, which we spend the remaining budget to relabel. Experiments across three model variations and four natural language processing tasks show our approach outperforms or matches both label aggregation and advanced denoising methods designed to handle noisy labels when allocated the same finite annotation budget.",2021,2022,7.0,Workshop on Deep Learning Approaches for Low-Resource Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2022.deeplo-1.17,10.18653/v1/2022.deeplo-1.17,https://doi.org/10.18653/v1/2022.deeplo-1.17,11,"Crowdsourcing platforms are often used to collect datasets for training machine learning models, despite higher levels of inaccurate labeling compared to expert labeling. There are two common strategies to manage the impact of such noise: The first involves aggregating redundant annotations, but comes at the expense of labeling substantially fewer examples. Secondly, prior works have also considered using the entire annotation budget to label as many examples as possible and subsequently apply denoising algorithms to implicitly clean the dataset. We find a middle ground and propose an approach which reserves a fraction of annotations to explicitly clean up highly probable error samples to optimize the annotation process. In particular, we allocate a large portion of the labeling budget to form an initial dataset used to train a model. This model is then used to identify specific examples that appear most likely to be incorrect, which we spend the remaining budget to relabel. Experiments across three model variations and four natural language processing tasks show our approach outperforms or matches both label aggregation and advanced denoising methods designed to handle noisy labels when allocated the same finite annotation budget.",Document_196,Technical aspects or methods of AI or machine learning,0.1474592685699463,Other Categories
Measuring Bias in Contextualized Word Representations,"Keita Kurita, Nidhi Vyas, Ayush Pareek, A. Black, Yulia Tsvetkov","Contextual word embeddings such as BERT have achieved state of the art performance in numerous NLP tasks. Since they are optimized to capture the statistical properties of training data, they tend to pick up on and amplify social stereotypes present in the data as well. In this study, we (1) propose a template-based method to quantify bias in BERT; (2) show that this method obtains more consistent results in capturing social biases than the traditional cosine based method; and (3) conduct a case study, evaluating gender bias in a downstream task of Gender Pronoun Resolution. Although our case study focuses on gender bias, the proposed technique is generalizable to unveiling other biases, including in multiclass settings, such as racial and religious biases.",2019,2019,8.0,Proceedings of the First Workshop on Gender Bias in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/W19-3823,10.18653/v1/W19-3823,https://doi.org/10.18653/v1/W19-3823,417,"Contextual word embeddings such as BERT have achieved state of the art performance in numerous NLP tasks. Since they are optimized to capture the statistical properties of training data, they tend to pick up on and amplify social stereotypes present in the data as well. In this study, we (1) propose a template-based method to quantify bias in BERT; (2) show that this method obtains more consistent results in capturing social biases than the traditional cosine based method; and (3) conduct a case study, evaluating gender bias in a downstream task of Gender Pronoun Resolution. Although our case study focuses on gender bias, the proposed technique is generalizable to unveiling other biases, including in multiclass settings, such as racial and religious biases.",Document_197,Technical aspects or methods of AI or machine learning,0.08548391610383987,Other Categories
Protecting Citizens’ Personal Data and Privacy: Joint Effort from GDPR EU Cluster Research Projects,"Renata M. de Carvalho, Camillo Del Prete, Y. Martín, Rosa M. Araujo Rivero, Melek Önen, Francesco Paolo Schiavo, Ángel Cuevas Rumín, H. Mouratidis, J. Yelmo, Maria N. Koukovini","Confidence in information and communication technology services and systems is crucial for the digital society which we live in, but this confidence is not possible without privacy-enhancing tools and technologies, nor without risks management frameworks that guarantee privacy, data protection, and secure digital identities. This paper provides information on ongoing and recent developments in this area in the European Union (EU) space. We start by providing an overview of EU’s General Data Protection Regulation (GDPR) and proceed by identifying challenges concerning GDPR implementation, either technical or organizational. For this, we consider the work currently being done by a set of EU projects on the H2020 DS-08-2017 topic, namely BPR4GDPR, DEFeND, SMOOTH, PDP4E, PAPAYA and PoSeID-on, which address and aim at providing specific, operational solutions for the identified challenges. We briefly present these solutions and discuss the ways in which the projects cooperate and complement each other. Finally, we identify guidelines for further research.",2020,2020,7.0,SN Computer Science,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s42979-020-00218-8,10.1007/s42979-020-00218-8,https://doi.org/10.1007/s42979-020-00218-8,17,"Confidence in information and communication technology services and systems is crucial for the digital society which we live in, but this confidence is not possible without privacy-enhancing tools and technologies, nor without risks management frameworks that guarantee privacy, data protection, and secure digital identities. This paper provides information on ongoing and recent developments in this area in the European Union (EU) space. We start by providing an overview of EU’s General Data Protection Regulation (GDPR) and proceed by identifying challenges concerning GDPR implementation, either technical or organizational. For this, we consider the work currently being done by a set of EU projects on the H2020 DS-08-2017 topic, namely BPR4GDPR, DEFeND, SMOOTH, PDP4E, PAPAYA and PoSeID-on, which address and aim at providing specific, operational solutions for the identified challenges. We briefly present these solutions and discuss the ways in which the projects cooperate and complement each other. Finally, we identify guidelines for further research.",Document_198,General discussion of financial or regulatory topics (non-AI focus),0.051841795444488525,Other Categories
Wide range screening of algorithmic bias in word embedding models using large sentiment lexicons reveals underreported bias types,David Rozado,"Concerns about gender bias in word embedding models have captured substantial attention in the algorithmic bias research literature. Other bias types however have received lesser amounts of scrutiny. This work describes a large-scale analysis of sentiment associations in popular word embedding models along the lines of gender and ethnicity but also along the less frequently studied dimensions of socioeconomic status, age, physical appearance, sexual orientation, religious sentiment and political leanings. Consistent with previous scholarly literature, this work has found systemic bias against given names popular among African-Americans in most embedding models examined. Gender bias in embedding models however appears to be multifaceted and often reversed in polarity to what has been regularly reported. Interestingly, using the common operationalization of the term bias in the fairness literature, novel types of so far unreported bias types in word embedding models have also been identified. Specifically, the popular embedding models analyzed here display negative biases against middle and working-class socioeconomic status, male children, senior citizens, plain physical appearance and intellectual phenomena such as Islamic religious faith, non-religiosity and conservative political orientation. Reasons for the paradoxical underreporting of these bias types in the relevant literature are probably manifold but widely held blind spots when searching for algorithmic bias and a lack of widespread technical jargon to unambiguously describe a variety of algorithmic associations could conceivably be playing a role. The causal origins for the multiplicity of loaded associations attached to distinct demographic groups within embedding models are often unclear but the heterogeneity of said associations and their potential multifactorial roots raises doubts about the validity of grouping them all under the umbrella term bias . Richer and more fine-grained terminology as well as a more comprehensive exploration of the bias landscape could help the fairness epistemic community to characterize and neutralize algorithmic discrimination more efficiently.",2020,2020,,PLoS ONE,Selector (div.abstract > div > p / Date Not Found (URL Source: DOI Link),https://doi.org/10.1371/journal.pone.0231189,10.1371/journal.pone.0231189,https://doi.org/10.1371/journal.pone.0231189,38,"Concerns about gender bias in word embedding models have captured substantial attention in the algorithmic bias research literature. Other bias types however have received lesser amounts of scrutiny. This work describes a large-scale analysis of sentiment associations in popular word embedding models along the lines of gender and ethnicity but also along the less frequently studied dimensions of socioeconomic status, age, physical appearance, sexual orientation, religious sentiment and political leanings. Consistent with previous scholarly literature, this work has found systemic bias against given names popular among African-Americans in most embedding models examined. Gender bias in embedding models however appears to be multifaceted and often reversed in polarity to what has been regularly reported. Interestingly, using the common operationalization of the term bias in the fairness literature, novel types of so far unreported bias types in word embedding models have also been identified. Specifically, the popular embedding models analyzed here display negative biases against middle and working-class socioeconomic status, male children, senior citizens, plain physical appearance and intellectual phenomena such as Islamic religious faith, non-religiosity and conservative political orientation. Reasons for the paradoxical underreporting of these bias types in the relevant literature are probably manifold but widely held blind spots when searching for algorithmic bias and a lack of widespread technical jargon to unambiguously describe a variety of algorithmic associations could conceivably be playing a role. The causal origins for the multiplicity of loaded associations attached to distinct demographic groups within embedding models are often unclear but the heterogeneity of said associations and their potential multifactorial roots raises doubts about the validity of grouping them all under the umbrella term bias . Richer and more fine-grained terminology as well as a more comprehensive exploration of the bias landscape could help the fairness epistemic community to characterize and neutralize algorithmic discrimination more efficiently.",Document_199,Difficulty in understanding AI decision-making is a barrier in finance,0.046537838876247406,Explainability and Transparency Barriers
Knowledge-Driven Approaches for Financial News Analytics,"B. Upreti, Philipp Back, P. Malo, Oskar Ahlgren, Ankur Sinha","Computational finance is one of the fastest-growing application areas for natural language processing technologies. Already today, algorithmic trading funds are successfully using robo readers and sentiment analysis techniques to support adaptive algorithms that are capable of making automated decisions with little or no human intervention. However, these technologies are still in a nascent state and the competition to improve approaches within the industry is fierce. In this chapter, we discuss financial news analytics and learning strategies that help machines combine domain knowledge with other linguistic information that is extracted from text sources. We provide an overview of existing linguistic resources and methodological approaches that can be readily utilized to develop knowledge-driven solutions for financial news analysis.",2019,2019,4.0,Network Theory and Agent-Based Modeling in Economics and Finance,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML) - Short, Score: 0.33) (URL Source: DOI Link)",https://doi.org/10.1007/978-981-13-8319-9_19,10.1007/978-981-13-8319-9_19,https://doi.org/10.1007/978-981-13-8319-9_19,3,"Computational finance is one of the fastest-growing application areas for natural language processing technologies. Already today, algorithmic trading funds are successfully using robo readers and sentiment analysis techniques to support adaptive algorithms that are capable of making automated decisions with little or no human intervention. However, these technologies are still in a nascent state and the competition to improve approaches within the industry is fierce. In this chapter, we discuss financial news analytics and learning strategies that help machines combine domain knowledge with other linguistic information that is extracted from text sources. We provide an overview of existing linguistic resources and methodological approaches that can be readily utilized to develop knowledge-driven solutions for financial news analysis.",Document_200,Building internal AI expertise is key for financial institutions,0.08991573005914688,Expertise and Training Strategies
Backdoors Against Natural Language Processing: A Review,"Shaofeng Li, Tian Dong, Benjamin Zi Hao Zhao, Minhui Xue, Suguo Du, Haojin Zhu","Change Username/Password Update Address Payment Options Order History View Purchased Documents Communications Preferences Profession and Education Technical Interests US & Canada: +1 800 678 4333 Worldwide: +1 732 981 0060 Contact & Support About IEEE Xplore Contact Us Help Accessibility Terms of Use Nondiscrimination Policy Sitemap Privacy & Opting Out of Cookies A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2025",2022,2022,,IEEE Security and Privacy,"Success (LLM (Filtered HTML), Score: 0.08) / Date Not Found (URL Source: DOI Link)",https://doi.org/10.1109/MSEC.2022.3181001,10.1109/MSEC.2022.3181001,https://doi.org/10.1109/MSEC.2022.3181001,25,"Change Username/Password Update Address Payment Options Order History View Purchased Documents Communications Preferences Profession and Education Technical Interests US & Canada: +1 800 678 4333 Worldwide: +1 732 981 0060 Contact & Support About IEEE Xplore Contact Us Help Accessibility Terms of Use Nondiscrimination Policy Sitemap Privacy & Opting Out of Cookies A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2025",Document_201,Aligning AI implementation with financial regulatory requirements,0.04466317594051361,Regulatory Engagement and Proactive Compliance Strategies
Fair automated assessment of noncompliance in cargo ship networks,"Gerrit Jan de Bruin, Antonio Pereira Barata, H. J. van den Herik, Frank W. Takes, C. Veenman","Cargo ships navigating global waters are required to be sufficiently safe and compliant with international treaties. Governmental inspectorates currently assess in a rule-based manner whether a ship is potentially noncompliant and thus needs inspection. One of the dominant ship characteristics in this assessment is the ‘colour’ of the flag a ship is flying, where countries with a positive reputation have a so-called ‘white flag’. The colour of a flag may disproportionately influence the inspector, causing more frequent and stricter inspections of ships flying a non-white flag, resulting in confirmation bias in historical inspection data. In this paper, we propose an automated approach for the assessment of ship noncompliance, realising two important contributions. First, we reduce confirmation bias by using fair classifiers that decorrelate the flag from the risk classification returned by the model. Second, we extract mobility patterns from a cargo ship network, allowing us to derive meaningful features for ship classification. Crucially, these features model the behaviour of a ship, rather than its static properties. Our approach shows both a higher overall prediction performance and improved fairness with respect to the flag. Ultimately, this work enables inspectorates to better target noncompliant ships, thereby improving overall maritime safety and environmental protection.",2022,2022,12.0,EPJ Data Science,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1140/epjds/s13688-022-00326-w,10.1140/epjds/s13688-022-00326-w,https://doi.org/10.1140/epjds/s13688-022-00326-w,3,"Cargo ships navigating global waters are required to be sufficiently safe and compliant with international treaties. Governmental inspectorates currently assess in a rule-based manner whether a ship is potentially noncompliant and thus needs inspection. One of the dominant ship characteristics in this assessment is the ‘colour’ of the flag a ship is flying, where countries with a positive reputation have a so-called ‘white flag’. The colour of a flag may disproportionately influence the inspector, causing more frequent and stricter inspections of ships flying a non-white flag, resulting in confirmation bias in historical inspection data. In this paper, we propose an automated approach for the assessment of ship noncompliance, realising two important contributions. First, we reduce confirmation bias by using fair classifiers that decorrelate the flag from the risk classification returned by the model. Second, we extract mobility patterns from a cargo ship network, allowing us to derive meaningful features for ship classification. Crucially, these features model the behaviour of a ship, rather than its static properties. Our approach shows both a higher overall prediction performance and improved fairness with respect to the flag. Ultimately, this work enables inspectorates to better target noncompliant ships, thereby improving overall maritime safety and environmental protection.",Document_202,Demonstrating the value of AI for compliance and risk management,0.1033795103430748,Business Case and Value Demonstration Strategies
Bridging the Gap Between AI and Explainability in the GDPR: Towards Trustworthiness-by-Design in Automated Decision-Making,"Ronan Hamon, H. Junklewitz, Ignacio Sanchez, Gianclaudio Malgieri, P. De Hert","Can satisfactory explanations for complex machine learning models be achieved in high-risk automated decision-making? How can such explanations be integrated into a data protection framework safeguarding a right to explanation? This article explores from an interdisciplinary point of view the connection between existing legal requirements for the explainability of AI systems set out in the General Data Protection Regulation (GDPR) and the current state of the art in the field of explainable AI. It studies the challenges of providing human legible explanations for current and future AI-based decision-making systems in practice, based on two scenarios of automated decision-making in credit scoring risks and medical diagnosis of COVID-19. These scenarios exemplify the trend towards increasingly complex machine learning algorithms in automated decision-making, both in terms of data and models. Current machine learning techniques, in particular those based on deep learning, are unable to make clear causal links between input data and final decisions. This represents a limitation for providing exact, human-legible reasons behind specific decisions, and presents a serious challenge to the provision of satisfactory, fair and transparent explanations. Therefore, the conclusion is that the quality of explanations might not be considered as an adequate safeguard for automated decision-making processes under the GDPR. Accordingly, additional tools should be considered to complement explanations. These could include algorithmic impact assessments, other forms of algorithmic justifications based on broader AI principles, and new technical developments in trustworthy AI. This suggests that eventually all of these approaches would need to be considered as a whole.",2022,2022,,IEEE Computational Intelligence Magazine,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/MCI.2021.3129960,10.1109/MCI.2021.3129960,https://doi.org/10.1109/MCI.2021.3129960,48,"Can satisfactory explanations for complex machine learning models be achieved in high-risk automated decision-making? How can such explanations be integrated into a data protection framework safeguarding a right to explanation? This article explores from an interdisciplinary point of view the connection between existing legal requirements for the explainability of AI systems set out in the General Data Protection Regulation (GDPR) and the current state of the art in the field of explainable AI. It studies the challenges of providing human legible explanations for current and future AI-based decision-making systems in practice, based on two scenarios of automated decision-making in credit scoring risks and medical diagnosis of COVID-19. These scenarios exemplify the trend towards increasingly complex machine learning algorithms in automated decision-making, both in terms of data and models. Current machine learning techniques, in particular those based on deep learning, are unable to make clear causal links between input data and final decisions. This represents a limitation for providing exact, human-legible reasons behind specific decisions, and presents a serious challenge to the provision of satisfactory, fair and transparent explanations. Therefore, the conclusion is that the quality of explanations might not be considered as an adequate safeguard for automated decision-making processes under the GDPR. Accordingly, additional tools should be considered to complement explanations. These could include algorithmic impact assessments, other forms of algorithmic justifications based on broader AI principles, and new technical developments in trustworthy AI. This suggests that eventually all of these approaches would need to be considered as a whole.",Document_203,Technical aspects or methods of AI or machine learning,0.23578336834907532,Other Categories
Integrating Legal-URN and Eunomos: Towards a Comprehensive Compliance Management Solution,"G. Boella, S. C. Tosatto, S. Ghanavati, J. Hulstijn, Llio Humphreys, Robert Muthuri, André Rifaut, Leendert van der Torre","Business process compliance with regulations has been a topic of many research areas in Computer Science such as Requirements Engineering (RE), Artificial Intelligence (AI), Logic and Natural Language Processing (NLP). This work aims to provide a systematic way of establishing and managing compliance to assist decision-making and reporting. Despite many notable advances, few systems deal adequately with legal interpretation and modeling norms in an expressive way that is well-integrated with business modeling practices. In this paper, we bring together two leading systems, Legal-URN and Eunomos, for a comprehensive compliance management solution.",2013,2014,4.0,International Workshop on AI Approaches to the Complexity of Legal Systems,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML) - Short, Score: 0.16) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-662-45960-7_10,10.1007/978-3-662-45960-7_10,https://doi.org/10.1007/978-3-662-45960-7_10,17,"Business process compliance with regulations has been a topic of many research areas in Computer Science such as Requirements Engineering (RE), Artificial Intelligence (AI), Logic and Natural Language Processing (NLP). This work aims to provide a systematic way of establishing and managing compliance to assist decision-making and reporting. Despite many notable advances, few systems deal adequately with legal interpretation and modeling norms in an expressive way that is well-integrated with business modeling practices. In this paper, we bring together two leading systems, Legal-URN and Eunomos, for a comprehensive compliance management solution.",Document_204,Technical aspects or methods of AI or machine learning,0.3600028455257416,Other Categories
Natural Language Technology for Information Integration in Business Intelligence,"D. Maynard, Horacio Saggion, Milena Yankova, Kalina Bontcheva, Wim Peters","Business intelligence requires the collecting and merging of information from many different sources, both structured and unstructured, in order to analyse for example financial risk, operational risk factors, follow trends and perform credit risk management. While traditional data mining tools make use of numerical data and cannot easily be applied to knowledge extracted from free text, traditional information extraction is either not adapted for the financial domain, or does not address the issue of information integration: the merging of information from different kinds of sources. We describe here the development of a system for content mining using domain ontologies, which enables the extraction of relevant information to be fed into models for analysis of financial and operational risk and other business intelligence applications such as company intelligence, by means of the XBRL standard. The results so far are of extremely high quality, due to the implementation of primarily high-precision rules.",2007,2007,4.0,Business Information Systems,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.51) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-540-72035-5_28,10.1007/978-3-540-72035-5_28,https://doi.org/10.1007/978-3-540-72035-5_28,33,"Business intelligence requires the collecting and merging of information from many different sources, both structured and unstructured, in order to analyse for example financial risk, operational risk factors, follow trends and perform credit risk management. While traditional data mining tools make use of numerical data and cannot easily be applied to knowledge extracted from free text, traditional information extraction is either not adapted for the financial domain, or does not address the issue of information integration: the merging of information from different kinds of sources. We describe here the development of a system for content mining using domain ontologies, which enables the extraction of relevant information to be fed into models for analysis of financial and operational risk and other business intelligence applications such as company intelligence, by means of the XBRL standard. The results so far are of extremely high quality, due to the implementation of primarily high-precision rules.",Document_205,Improving data quality is crucial for successful AI in finance,0.057616401463747025,Data Improvement and Availability Strategies
Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead,C. Rudin,"Black box machine learning models are currently being used for high-stakes decision making throughout society, causing problems in healthcare, criminal justice and other domains. Some people hope that creating methods for explaining these black box models will alleviate some of the problems, but trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practice and can potentially cause great harm to society. The way forward is to design models that are inherently interpretable. This Perspective clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare and computer vision.",2018,2019,5.0,Nature Machine Intelligence,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1038/s42256-019-0048-x,10.1038/s42256-019-0048-x,https://doi.org/10.1038/s42256-019-0048-x,5388,"Black box machine learning models are currently being used for high-stakes decision making throughout society, causing problems in healthcare, criminal justice and other domains. Some people hope that creating methods for explaining these black box models will alleviate some of the problems, but trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practice and can potentially cause great harm to society. The way forward is to design models that are inherently interpretable. This Perspective clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare and computer vision.",Document_206,Technical aspects or methods of AI or machine learning,0.10208522528409958,Other Categories
Privacy–Enhancing Face Biometrics: A Comprehensive Survey,"Blaž Meden, Peter Rot, Philipp Terhörst, N. Damer, Arjan Kuijper, W. Scheirer, A. Ross, Peter, Peer, Vitomir Štruc","Biometric recognition technology has made significant advances over the last decade and is now used across a number of services and applications. However, this widespread deployment has also resulted in privacy concerns and evolving societal expectations about the appropriate use of the technology. For example, the ability to automatically extract age, gender, race, and health cues from biometric data has heightened concerns about privacy leakage. Face recognition technology, in particular, has been in the spotlight, and is now seen by many as posing a considerable risk to personal privacy. In response to these and similar concerns, researchers have intensified efforts towards developing techniques and computational models capable of ensuring privacy to individuals, while still facilitating the utility of face recognition technology in several application scenarios. These efforts have resulted in a multitude of privacy-enhancing techniques that aim at addressing privacy risks originating from biometric systems and providing technological solutions for legislative requirements set forth in privacy laws and regulations, such as GDPR. The goal of this overview paper is to provide a comprehensive introduction into privacy-related research in the area of biometrics and review existing work on Biometric Privacy-Enhancing Techniques (B-PETs) applied to face biometrics. To make this work useful for as wide of an audience as possible, several key topics are covered as well, including evaluation strategies used with B-PETs, existing datasets, relevant standards, and regulations and critical open issues that will have to be addressed in the future.",2021,2021,,IEEE Transactions on Information Forensics and Security,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/tifs.2021.3096024,10.1109/tifs.2021.3096024,https://doi.org/10.1109/tifs.2021.3096024,115,"Biometric recognition technology has made significant advances over the last decade and is now used across a number of services and applications. However, this widespread deployment has also resulted in privacy concerns and evolving societal expectations about the appropriate use of the technology. For example, the ability to automatically extract age, gender, race, and health cues from biometric data has heightened concerns about privacy leakage. Face recognition technology, in particular, has been in the spotlight, and is now seen by many as posing a considerable risk to personal privacy. In response to these and similar concerns, researchers have intensified efforts towards developing techniques and computational models capable of ensuring privacy to individuals, while still facilitating the utility of face recognition technology in several application scenarios. These efforts have resulted in a multitude of privacy-enhancing techniques that aim at addressing privacy risks originating from biometric systems and providing technological solutions for legislative requirements set forth in privacy laws and regulations, such as GDPR. The goal of this overview paper is to provide a comprehensive introduction into privacy-related research in the area of biometrics and review existing work on Biometric Privacy-Enhancing Techniques (B-PETs) applied to face biometrics. To make this work useful for as wide of an audience as possible, several key topics are covered as well, including evaluation strategies used with B-PETs, existing datasets, relevant standards, and regulations and critical open issues that will have to be addressed in the future.",Document_207,Technical aspects or methods of AI or machine learning,0.04968505725264549,Other Categories
Evaluation of Bias in Sensitive Personal Information Used to Train Financial Models,"R. Bryant, C. Cintas, Isaac Wambugu, Andrew Kinai, Abdigani Diriye, Komminist Weldemariam","Bias in data can have unintended consequences which propagate to the design, development, and deployment of machine learning models. In the financial services sector, this can result in discrimination from certain financial instruments and services. At the same time, data privacy is of paramount importance, and recent data breaches have seen reputational damage for large institutions. Presented in this paper is a trusted model-lifecycle management platform that attempts to ensure consumer data protection, anonymization, and fairness. Specifically, we examine how datasets can be reproduced using deep learning techniques to effectively retain important statistical features in datasets whilst simultaneously protecting data privacy and enabling safe and secure sharing of sensitive personal information beyond the current state-of-practice.",2019,2019,,IEEE Global Conference on Signal and Information Processing,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/GlobalSIP45357.2019.8969527,10.1109/GlobalSIP45357.2019.8969527,https://doi.org/10.1109/GlobalSIP45357.2019.8969527,3,"Bias in data can have unintended consequences which propagate to the design, development, and deployment of machine learning models. In the financial services sector, this can result in discrimination from certain financial instruments and services. At the same time, data privacy is of paramount importance, and recent data breaches have seen reputational damage for large institutions. Presented in this paper is a trusted model-lifecycle management platform that attempts to ensure consumer data protection, anonymization, and fairness. Specifically, we examine how datasets can be reproduced using deep learning techniques to effectively retain important statistical features in datasets whilst simultaneously protecting data privacy and enabling safe and secure sharing of sensitive personal information beyond the current state-of-practice.",Document_208,Establishing clear policies for ethical and secure AI usage in finance,0.1759290099143982,"Education, Awareness, and Policy Strategies"
Synthetic Disinformation Attacks on Automated Fact Verification Systems,"Y. Du, Antoine Bosselut, Christopher D. Manning","Automated fact-checking is a needed technology to curtail the spread of online misinformation. One current framework for such solutions proposes to verify claims by retrieving supporting or refuting evidence from related textual sources. However, the realistic use cases for fact-checkers will require verifying claims against evidence sources that could be affected by the same misinformation. Furthermore, the development of modern NLP tools that can produce coherent, fabricated content would allow malicious actors to systematically generate adversarial disinformation for fact-checkers.
  
In this work, we explore the sensitivity of automated fact-checkers to synthetic adversarial evidence in two simulated settings: ADVERSARIAL ADDITION, where we fabricate documents and add them to the evidence repository available to the fact-checking system, and ADVERSARIAL MODIFICATION, where existing evidence source documents in the repository are automatically altered. Our study across multiple models on three benchmarks demonstrates that these systems suffer significant performance drops against these attacks. Finally, we discuss the growing threat of modern NLG systems as generators of disinformation in the context of the challenges they pose to automated fact-checkers.",2022,2022,,AAAI Conference on Artificial Intelligence,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1609/aaai.v36i10.21302,10.1609/aaai.v36i10.21302,https://doi.org/10.1609/aaai.v36i10.21302,25,"Automated fact-checking is a needed technology to curtail the spread of online misinformation. One current framework for such solutions proposes to verify claims by retrieving supporting or refuting evidence from related textual sources. However, the realistic use cases for fact-checkers will require verifying claims against evidence sources that could be affected by the same misinformation. Furthermore, the development of modern NLP tools that can produce coherent, fabricated content would allow malicious actors to systematically generate adversarial disinformation for fact-checkers.
  
In this work, we explore the sensitivity of automated fact-checkers to synthetic adversarial evidence in two simulated settings: ADVERSARIAL ADDITION, where we fabricate documents and add them to the evidence repository available to the fact-checking system, and ADVERSARIAL MODIFICATION, where existing evidence source documents in the repository are automatically altered. Our study across multiple models on three benchmarks demonstrates that these systems suffer significant performance drops against these attacks. Finally, we discuss the growing threat of modern NLG systems as generators of disinformation in the context of the challenges they pose to automated fact-checkers.",Document_209,Technical aspects or methods of AI or machine learning,0.051064327359199524,Other Categories
InfoLM: A New Metric to Evaluate Summarization & Data2Text Generation,"Pierre Colombo, Chloe Clave, P. Piantanida","Assessing the quality of natural language generation (NLG) systems through human annotation is very expensive. Additionally, human annotation campaigns are time-consuming and include non-reusable human labour. In practice, researchers rely on automatic metrics as a proxy of quality. In the last decade, many string-based metrics (e.g., BLEU or ROUGE) have been introduced. However, such metrics usually rely on exact matches and thus, do not robustly handle synonyms. In this paper, we introduce InfoLM a family of untrained metrics that can be viewed as a string-based metric that addresses the aforementioned flaws thanks to a pre-trained masked language model. This family of metrics also makes use of information measures allowing the possibility to adapt InfoLM to different evaluation criteria. Using direct assessment, we demonstrate that InfoLM achieves statistically significant improvement and two figure correlation gains in many configurations compared to existing metrics on both summarization and data2text generation tasks.",2021,2021,,AAAI Conference on Artificial Intelligence,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.1609/aaai.v36i10.21299,10.1609/aaai.v36i10.21299,https://doi.org/10.1609/aaai.v36i10.21299,38,"Assessing the quality of natural language generation (NLG) systems through human annotation is very expensive. Additionally, human annotation campaigns are time-consuming and include non-reusable human labour. In practice, researchers rely on automatic metrics as a proxy of quality. In the last decade, many string-based metrics (e.g., BLEU or ROUGE) have been introduced. However, such metrics usually rely on exact matches and thus, do not robustly handle synonyms. In this paper, we introduce InfoLM a family of untrained metrics that can be viewed as a string-based metric that addresses the aforementioned flaws thanks to a pre-trained masked language model. This family of metrics also makes use of information measures allowing the possibility to adapt InfoLM to different evaluation criteria. Using direct assessment, we demonstrate that InfoLM achieves statistically significant improvement and two figure correlation gains in many configurations compared to existing metrics on both summarization and data2text generation tasks.",Document_210,Building organizational support for AI through education and communication,0.0672706812620163,"Education, Awareness, and Policy Strategies"
Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models,Emilio Ferrara,"As generative language models, exemplified by ChatGPT, continue to advance in their capabilities, the spotlight on biases inherent in these models intensifies. This paper delves into the distinctive challenges and risks associated with biases specifically in large-scale language models. We explore the origins of biases, stemming from factors such as training data, model specifications, algorithmic constraints, product design, and policy decisions. Our examination extends to the ethical implications arising from the unintended consequences of biased model outputs. In addition, we analyze the intricacies of mitigating biases, acknowledging the inevitable persistence of some biases, and consider the consequences of deploying these models across diverse applications, including virtual assistants, content generation, and chatbots. Finally, we provide an overview of current approaches for identifying, quantifying, and mitigating biases in language models, underscoring the need for a collaborative, multidisciplinary effort to craft AI systems that embody equity, transparency, and responsibility. This article aims to catalyze a thoughtful discourse within the AI community, prompting researchers and developers to consider the unique role of biases in the domain of generative language models and the ongoing quest for ethical AI.",2023,2023,,First Monday,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.5210/fm.v28i11.13346,10.5210/fm.v28i11.13346,https://doi.org/10.5210/fm.v28i11.13346,203,"As generative language models, exemplified by ChatGPT, continue to advance in their capabilities, the spotlight on biases inherent in these models intensifies. This paper delves into the distinctive challenges and risks associated with biases specifically in large-scale language models. We explore the origins of biases, stemming from factors such as training data, model specifications, algorithmic constraints, product design, and policy decisions. Our examination extends to the ethical implications arising from the unintended consequences of biased model outputs. In addition, we analyze the intricacies of mitigating biases, acknowledging the inevitable persistence of some biases, and consider the consequences of deploying these models across diverse applications, including virtual assistants, content generation, and chatbots. Finally, we provide an overview of current approaches for identifying, quantifying, and mitigating biases in language models, underscoring the need for a collaborative, multidisciplinary effort to craft AI systems that embody equity, transparency, and responsibility. This article aims to catalyze a thoughtful discourse within the AI community, prompting researchers and developers to consider the unique role of biases in the domain of generative language models and the ongoing quest for ethical AI.",Document_211,Technical aspects or methods of AI or machine learning,0.2127813994884491,Other Categories
Ethical AI: Addressing bias in machine learning models and software applications,"Oyekunle Claudius Oyeniran, Adebunmi Okechukwu Adewusi, Adams Gbolahan Adeleke, Lucy Anthony Akwawa, Chidimma Francisca Azubuko","As artificial intelligence (AI) increasingly integrates into various aspects of society, addressing bias in machine learning models and software applications has become crucial. Bias in AI systems can originate from various sources, including unrepresentative datasets, algorithmic assumptions, and human factors. These biases can perpetuate discrimination and inequity, leading to significant social and ethical consequences. This paper explores the nature of bias in AI, emphasizing the need for ethical AI practices to ensure fairness and accountability. We first define and categorize the different types of bias—data bias, algorithmic bias, and human-induced bias—highlighting real-world examples and their impacts. The discussion then shifts to methods for mitigating bias, including strategies for improving data quality, developing fairness-aware algorithms, and implementing robust auditing processes. We also review existing ethical guidelines and frameworks, such as those proposed by IEEE and the European Union, which provide a foundation for ethical AI development. Challenges in identifying and addressing bias are examined, such as the trade-offs between fairness and model accuracy, and the complexities of legal and regulatory requirements. Future directions are considered, including emerging trends in ethical AI, the importance of interdisciplinary collaboration, and innovations in bias detection and mitigation. In conclusion, ongoing vigilance and commitment to ethical practices are essential for developing AI systems that are equitable and just. This paper calls for continuous improvement and proactive measures from developers, researchers, and policymakers to create AI technologies that serve all individuals fairly and without bias. Keywords: Ethical AI, Bias, Machine Learning, Models, Software Applications.",2022,2022,,Computer Science &amp; IT Research Journal,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.51594/csitrj.v3i3.1559,10.51594/csitrj.v3i3.1559,https://doi.org/10.51594/csitrj.v3i3.1559,23,"As artificial intelligence (AI) increasingly integrates into various aspects of society, addressing bias in machine learning models and software applications has become crucial. Bias in AI systems can originate from various sources, including unrepresentative datasets, algorithmic assumptions, and human factors. These biases can perpetuate discrimination and inequity, leading to significant social and ethical consequences. This paper explores the nature of bias in AI, emphasizing the need for ethical AI practices to ensure fairness and accountability. We first define and categorize the different types of bias—data bias, algorithmic bias, and human-induced bias—highlighting real-world examples and their impacts. The discussion then shifts to methods for mitigating bias, including strategies for improving data quality, developing fairness-aware algorithms, and implementing robust auditing processes. We also review existing ethical guidelines and frameworks, such as those proposed by IEEE and the European Union, which provide a foundation for ethical AI development. Challenges in identifying and addressing bias are examined, such as the trade-offs between fairness and model accuracy, and the complexities of legal and regulatory requirements. Future directions are considered, including emerging trends in ethical AI, the importance of interdisciplinary collaboration, and innovations in bias detection and mitigation. In conclusion, ongoing vigilance and commitment to ethical practices are essential for developing AI systems that are equitable and just. This paper calls for continuous improvement and proactive measures from developers, researchers, and policymakers to create AI technologies that serve all individuals fairly and without bias. Keywords: Ethical AI, Bias, Machine Learning, Models, Software Applications.",Document_212,Technical aspects or methods of AI or machine learning,0.2896641194820404,Other Categories
Large pre-trained language models contain human-like biases of what is right and wrong to do,"P. Schramowski, Cigdem Turan, Nico Andersen, C. Rothkopf, K. Kersting","Artificial writing is permeating our lives due to recent advances in large-scale, transformer-based language models (LMs) such as BERT, GPT-2 and GPT-3. Using them as pre-trained models and fine-tuning them for specific tasks, researchers have extended the state of the art for many natural language processing tasks and shown that they capture not only linguistic knowledge but also retain general knowledge implicitly present in the data. Unfortunately, LMs trained on unfiltered text corpora suffer from degenerated and biased behaviour. While this is well established, we show here that recent LMs also contain human-like biases of what is right and wrong to do, reflecting existing ethical and moral norms of society. We show that these norms can be captured geometrically by a ‘moral direction’ which can be computed, for example, by a PCA, in the embedding space. The computed ‘moral direction’ can rate the normativity (or non-normativity) of arbitrary phrases without explicitly training the LM for this task, reflecting social norms well. We demonstrate that computing the ’moral direction’ can provide a path for attenuating or even preventing toxic degeneration in LMs, showcasing this capability on the RealToxicityPrompts testbed.",2021,2022,3.0,Nature Machine Intelligence,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1038/s42256-022-00458-8,10.1038/s42256-022-00458-8,https://doi.org/10.1038/s42256-022-00458-8,239,"Artificial writing is permeating our lives due to recent advances in large-scale, transformer-based language models (LMs) such as BERT, GPT-2 and GPT-3. Using them as pre-trained models and fine-tuning them for specific tasks, researchers have extended the state of the art for many natural language processing tasks and shown that they capture not only linguistic knowledge but also retain general knowledge implicitly present in the data. Unfortunately, LMs trained on unfiltered text corpora suffer from degenerated and biased behaviour. While this is well established, we show here that recent LMs also contain human-like biases of what is right and wrong to do, reflecting existing ethical and moral norms of society. We show that these norms can be captured geometrically by a ‘moral direction’ which can be computed, for example, by a PCA, in the embedding space. The computed ‘moral direction’ can rate the normativity (or non-normativity) of arbitrary phrases without explicitly training the LM for this task, reflecting social norms well. We demonstrate that computing the ’moral direction’ can provide a path for attenuating or even preventing toxic degeneration in LMs, showcasing this capability on the RealToxicityPrompts testbed.",Document_213,Technical aspects or methods of AI or machine learning,0.10351020097732544,Other Categories
A Review on Explainability in Multimodal Deep Neural Nets,"Gargi Joshi, Rahee Walambe, K. Kotecha","Artificial Intelligence techniques powered by deep neural nets have achieved much success in several application domains, most significantly and notably in the Computer Vision applications and Natural Language Processing tasks. Surpassing human-level performance propelled the research in the applications where different modalities amongst language, vision, sensory, text play an important role in accurate predictions and identification. Several multimodal fusion methods employing deep learning models are proposed in the literature. Despite their outstanding performance, the complex, opaque and black-box nature of the deep neural nets limits their social acceptance and usability. This has given rise to the quest for model interpretability and explainability, more so in the complex tasks involving multimodal AI methods. This paper extensively reviews the present literature to present a comprehensive survey and commentary on the explainability in multimodal deep neural nets, especially for the vision and language tasks. Several topics on multimodal AI and its applications for generic domains have been covered in this paper, including the significance, datasets, fundamental building blocks of the methods and techniques, challenges, applications, and future trends in this domain.",2021,2021,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2021.3070212,10.1109/ACCESS.2021.3070212,https://doi.org/10.1109/ACCESS.2021.3070212,118,"Artificial Intelligence techniques powered by deep neural nets have achieved much success in several application domains, most significantly and notably in the Computer Vision applications and Natural Language Processing tasks. Surpassing human-level performance propelled the research in the applications where different modalities amongst language, vision, sensory, text play an important role in accurate predictions and identification. Several multimodal fusion methods employing deep learning models are proposed in the literature. Despite their outstanding performance, the complex, opaque and black-box nature of the deep neural nets limits their social acceptance and usability. This has given rise to the quest for model interpretability and explainability, more so in the complex tasks involving multimodal AI methods. This paper extensively reviews the present literature to present a comprehensive survey and commentary on the explainability in multimodal deep neural nets, especially for the vision and language tasks. Several topics on multimodal AI and its applications for generic domains have been covered in this paper, including the significance, datasets, fundamental building blocks of the methods and techniques, challenges, applications, and future trends in this domain.",Document_214,Technical aspects or methods of AI or machine learning,0.24826595187187195,Other Categories
Bayesian learning models to measure the relative impact of ESG factors on credit ratings,"Arianna Agosto, Paola Cerchiello, Paolo Giudici","Artificial intelligence methods, based on machine learning models, are rapidly changing financial services, and credit lending in particular, complementing traditional bank lending with platform lending. While financial technologies improve user experience and possibly lower costs, they may increase risks and, in particular, the model risks that derive from inaccurate credit rating assessments. In this paper, we will show how to reduce such model risks, using a S.A.F.E. statistical learning model, which improves: Sustainability, taking environmental, social and governance factors into account; Accuracy, building a model which maximises predictive accuracy; Fairness, merging ESG scores from different data providers, improving their representativeness; Explainability, clarifying the relative contribution of each ESG score to predictive accuracy.",2023,2023,7.0,International Journal of Data Science and Analysis,Success (Selector (#Abs1-content)) / Date (Time Tag) (URL Source: DOI Link),https://doi.org/10.1007/s41060-023-00405-9,10.1007/s41060-023-00405-9,https://doi.org/10.1007/s41060-023-00405-9,12,"Artificial intelligence methods, based on machine learning models, are rapidly changing financial services, and credit lending in particular, complementing traditional bank lending with platform lending. While financial technologies improve user experience and possibly lower costs, they may increase risks and, in particular, the model risks that derive from inaccurate credit rating assessments. In this paper, we will show how to reduce such model risks, using a S.A.F.E. statistical learning model, which improves: Sustainability, taking environmental, social and governance factors into account; Accuracy, building a model which maximises predictive accuracy; Fairness, merging ESG scores from different data providers, improving their representativeness; Explainability, clarifying the relative contribution of each ESG score to predictive accuracy.",Document_215,Technical aspects or methods of AI or machine learning,0.1752302497625351,Other Categories
How to Streamline AI Application in Government? A Case Study on Citizen Participation in Germany,"Dian Balta, Peter Kuhn, Mahdi Sellami, Daniel Kulus, Claudius Lieven, H. Krcmar","Artificial intelligence (AI) technologies are on the rise in almost every aspect of society, business and government. Especially in government, it is of interest how the application of AI can be streamlined: at least, in a controlled environment, in order to be able to evaluate potential (positive and negative) impact. Unfortunately, reuse in development of AI applications and their evaluation results lack interoperability and transferability. One potential remedy to this challenge would be to apply standardized artefacts: not only on a technical level, but also on an organization or semantic level. This paper presents findings from a qualitative explorative case study on online citizen participation in Germany that reveal insights on the current standardization level of AI applications. In order to provide an in-depth analysis, the research involves evaluation of two particular AI approaches to natural language processing. Our findings suggest that standardization artefacts for streamlining AI application exist predominantly on a technical level and are still limited.",2019,2019,4.0,International Conference on Electronic Government,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.33) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-030-27325-5_18,10.1007/978-3-030-27325-5_18,https://doi.org/10.1007/978-3-030-27325-5_18,5,"Artificial intelligence (AI) technologies are on the rise in almost every aspect of society, business and government. Especially in government, it is of interest how the application of AI can be streamlined: at least, in a controlled environment, in order to be able to evaluate potential (positive and negative) impact. Unfortunately, reuse in development of AI applications and their evaluation results lack interoperability and transferability. One potential remedy to this challenge would be to apply standardized artefacts: not only on a technical level, but also on an organization or semantic level. This paper presents findings from a qualitative explorative case study on online citizen participation in Germany that reveal insights on the current standardization level of AI applications. In order to provide an in-depth analysis, the research involves evaluation of two particular AI approaches to natural language processing. Our findings suggest that standardization artefacts for streamlining AI application exist predominantly on a technical level and are still limited.",Document_216,Technical aspects or methods of AI or machine learning,0.3042964041233063,Other Categories
Natürliche Sprachverarbeitung und Künstliche Intelligenz – ein wachsender Markt mit vielen Chancen,Stefan Geissler,"Article Natürliche Sprachverarbeitung und Künstliche Intelligenz – ein wachsender Markt mit vielen Chancen was published on April 20, 2020 in the journal Information – Wissenschaft & Praxis (volume 71, issue 2-3).",2020,2020,4.0,"Information, Wissenschaft und Praxis","Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.39) (URL Source: DOI Link)",https://doi.org/10.1515/iwp-2020-2079,10.1515/iwp-2020-2079,https://doi.org/10.1515/iwp-2020-2079,2,"Article Natürliche Sprachverarbeitung und Künstliche Intelligenz – ein wachsender Markt mit vielen Chancen was published on April 20, 2020 in the journal Information – Wissenschaft & Praxis (volume 71, issue 2-3).",Document_217,Building organizational support for AI through education and communication,0.4189005196094513,"Education, Awareness, and Policy Strategies"
Using Continuous Integration to organize and monitor the annotation process of domain specific corpora,"Marc Schreiber, Kai Barkschat, B. Kraft","Applications in the World Wide Web aggregate vast amounts of information from different data sources. The aggregation process is often implemented with Extract, Transform and Load (ETL) processes. Usually ETL processes require information for aggregation available in structured formats, e. g. XML or JSON. In many cases the information is provided in natural language text which makes the application of ETL processes impractical. Due to the fact that information is provided in natural language, Information Extraction (IE) systems have been evolved. They make use of Natural Language Processing (NLP) tools to derive meaning from natural language text. State-of-the-art NLP tools apply Machine Learning methods. These NLP tools perform on newspapers with good quality, but they drop accuracy in other domains. However, to improve the quality for IE systems in specific domains often NLP tools are trained on domain specific text which is a time consuming process. This paper introduces an approach using a Continuous Integration pipeline for organizing and monitoring the annotation process on domain specific corpora.",2014,2014,,"International Conference on Information, Communications and Signal Processing","Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/IACS.2014.6841958,10.1109/IACS.2014.6841958,https://doi.org/10.1109/IACS.2014.6841958,4,"Applications in the World Wide Web aggregate vast amounts of information from different data sources. The aggregation process is often implemented with Extract, Transform and Load (ETL) processes. Usually ETL processes require information for aggregation available in structured formats, e. g. XML or JSON. In many cases the information is provided in natural language text which makes the application of ETL processes impractical. Due to the fact that information is provided in natural language, Information Extraction (IE) systems have been evolved. They make use of Natural Language Processing (NLP) tools to derive meaning from natural language text. State-of-the-art NLP tools apply Machine Learning methods. These NLP tools perform on newspapers with good quality, but they drop accuracy in other domains. However, to improve the quality for IE systems in specific domains often NLP tools are trained on domain specific text which is a time consuming process. This paper introduces an approach using a Continuous Integration pipeline for organizing and monitoring the annotation process on domain specific corpora.",Document_218,Technical aspects or methods of AI or machine learning,0.22389142215251923,Other Categories
The Current Status and progress of Adversarial Examples Attacks,"Chaoran Yuan, Xiaobin Liu, Zhengyuan Zhang","Applications based on deep learning are prevailing in many real-world scenarios. However, due to the interpretability of deep learning and the emergence of adversarial examples attacks, their reliability has been put into doubt. As for Natural Language Processing, adversarial samples that can be semantically similar to the original ones can also be generated so that NLP classification can be fooled without human observers' attention. In this paper, we give an overview of the existing method in implementing adversarial examples attacks. Firstly, we introduce the implementation of these methods and the damage they impose on the security, integrity, and robustness of NLP systems. Secondly, we discuss problems like the limited attention on the logic of defense, the curse of dimensionality, and the difficulty of implementing white-box adversaries. Finally, to present our opinion on ML security's structure, our discussion upon the standardization of both attack and defense is also included.",2021,2021,,"2021 International Conference on Communications, Information System and Computer Engineering (CISCE)","Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/cisce52179.2021.9445917,10.1109/cisce52179.2021.9445917,https://doi.org/10.1109/cisce52179.2021.9445917,9,"Applications based on deep learning are prevailing in many real-world scenarios. However, due to the interpretability of deep learning and the emergence of adversarial examples attacks, their reliability has been put into doubt. As for Natural Language Processing, adversarial samples that can be semantically similar to the original ones can also be generated so that NLP classification can be fooled without human observers' attention. In this paper, we give an overview of the existing method in implementing adversarial examples attacks. Firstly, we introduce the implementation of these methods and the damage they impose on the security, integrity, and robustness of NLP systems. Secondly, we discuss problems like the limited attention on the logic of defense, the curse of dimensionality, and the difficulty of implementing white-box adversaries. Finally, to present our opinion on ML security's structure, our discussion upon the standardization of both attack and defense is also included.",Document_219,Technical aspects or methods of AI or machine learning,0.3139387369155884,Other Categories
Anonymization Techniques for Privacy Preserving Data Publishing: A Comprehensive Survey,"Abdul Majeed, Sungchang Lee","Anonymization is a practical solution for preserving user’s privacy in data publishing. Data owners such as hospitals, banks, social network (SN) service providers, and insurance companies anonymize their user’s data before publishing it to protect the privacy of users whereas anonymous data remains useful for legitimate information consumers. Many anonymization models, algorithms, frameworks, and prototypes have been proposed/developed for privacy preserving data publishing (PPDP). These models/algorithms anonymize users’ data which is mainly in the form of tables or graphs depending upon the data owners. It is of paramount importance to provide good perspectives of the whole information privacy area involving both tabular and SN data, and recent anonymization researches. In this paper, we presents a comprehensive survey about SN (i.e., graphs) and relational (i.e., tabular) data anonymization techniques used in the PPDP. We systematically categorize the existing anonymization techniques into relational and structural anonymization, and present an up to date thorough review on existing anonymization techniques and metrics used for their evaluation. Our aim is to provide deeper insights about the PPDP problem involving both graphs and tabular data, possible attacks that can be launched on the sanitized published data, different actors involved in the anonymization scenario, and major differences in amount of private information contained in graphs and relational data, respectively. We present various representative anonymization methods that have been proposed to solve privacy problems in application-specific scenarios of the SNs. Furthermore, we highlight the user’s re-identification methods used by malevolent adversaries to re-identify people uniquely from the privacy preserved published data. Additionally, we discuss the challenges of anonymizing both graphs and tabular data, and elaborate promising research directions. To the best of our knowledge, this is the first work to systematically cover recent PPDP techniques involving both SN and relational data, and it provides a solid foundation for future studies in the PPDP field.",2021,2021,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2020.3045700,10.1109/ACCESS.2020.3045700,https://doi.org/10.1109/ACCESS.2020.3045700,124,"Anonymization is a practical solution for preserving user’s privacy in data publishing. Data owners such as hospitals, banks, social network (SN) service providers, and insurance companies anonymize their user’s data before publishing it to protect the privacy of users whereas anonymous data remains useful for legitimate information consumers. Many anonymization models, algorithms, frameworks, and prototypes have been proposed/developed for privacy preserving data publishing (PPDP). These models/algorithms anonymize users’ data which is mainly in the form of tables or graphs depending upon the data owners. It is of paramount importance to provide good perspectives of the whole information privacy area involving both tabular and SN data, and recent anonymization researches. In this paper, we presents a comprehensive survey about SN (i.e., graphs) and relational (i.e., tabular) data anonymization techniques used in the PPDP. We systematically categorize the existing anonymization techniques into relational and structural anonymization, and present an up to date thorough review on existing anonymization techniques and metrics used for their evaluation. Our aim is to provide deeper insights about the PPDP problem involving both graphs and tabular data, possible attacks that can be launched on the sanitized published data, different actors involved in the anonymization scenario, and major differences in amount of private information contained in graphs and relational data, respectively. We present various representative anonymization methods that have been proposed to solve privacy problems in application-specific scenarios of the SNs. Furthermore, we highlight the user’s re-identification methods used by malevolent adversaries to re-identify people uniquely from the privacy preserved published data. Additionally, we discuss the challenges of anonymizing both graphs and tabular data, and elaborate promising research directions. To the best of our knowledge, this is the first work to systematically cover recent PPDP techniques involving both SN and relational data, and it provides a solid foundation for future studies in the PPDP field.",Document_220,Building organizational support for AI through education and communication,0.05193588510155678,"Education, Awareness, and Policy Strategies"
Global reconstruction of language models with linguistic rules – Explainable AI for online consumer reviews,"Markus Binder, Bernd Heinrich, Marcus Hopf, Alexander Schiller","Analyzing textual data by means of AI models has been recognized as highly relevant in information systems research and practice, since a vast amount of data on eCommerce platforms, review portals or social media is given in textual form. Here, language models such as BERT, which are deep learning AI models, constitute a breakthrough and achieve leading-edge results in many applications of text analytics such as sentiment analysis in online consumer reviews. However, these language models are “black boxes”: It is unclear how they arrive at their predictions. Yet, applications of language models, for instance, in eCommerce require checks and justifications by means of global reconstruction of their predictions, since the decisions based thereon can have large impacts or are even mandatory due to regulations such as the GDPR. To this end, we propose a novel XAI approach for global reconstructions of language model predictions for token-level classifications (e.g., aspect term detection) by means of linguistic rules based on NLP building blocks (e.g., part-of-speech). The approach is analyzed on different datasets of online consumer reviews and NLP tasks. Since our approach allows for different setups, we further are the first to analyze the trade-off between comprehensibility and fidelity of global reconstructions of language model predictions. With respect to this trade-off, we find that our approach indeed allows for balanced setups for global reconstructions of BERT’s predictions. Thus, our approach paves the way for a thorough understanding of language model predictions in text analytics. In practice, our approach can assist businesses in their decision-making and supports compliance with regulatory requirements.",2022,2022,12.0,Electronic Markets,Success (Selector (#Abs1-content)) / Date (Meta (citation_publication_date)) (URL Source: DOI Link),https://doi.org/10.1007/s12525-022-00612-5,10.1007/s12525-022-00612-5,https://doi.org/10.1007/s12525-022-00612-5,8,"Analyzing textual data by means of AI models has been recognized as highly relevant in information systems research and practice, since a vast amount of data on eCommerce platforms, review portals or social media is given in textual form. Here, language models such as BERT, which are deep learning AI models, constitute a breakthrough and achieve leading-edge results in many applications of text analytics such as sentiment analysis in online consumer reviews. However, these language models are “black boxes”: It is unclear how they arrive at their predictions. Yet, applications of language models, for instance, in eCommerce require checks and justifications by means of global reconstruction of their predictions, since the decisions based thereon can have large impacts or are even mandatory due to regulations such as the GDPR. To this end, we propose a novel XAI approach for global reconstructions of language model predictions for token-level classifications (e.g., aspect term detection) by means of linguistic rules based on NLP building blocks (e.g., part-of-speech). The approach is analyzed on different datasets of online consumer reviews and NLP tasks. Since our approach allows for different setups, we further are the first to analyze the trade-off between comprehensibility and fidelity of global reconstructions of language model predictions. With respect to this trade-off, we find that our approach indeed allows for balanced setups for global reconstructions of BERT’s predictions. Thus, our approach paves the way for a thorough understanding of language model predictions in text analytics. In practice, our approach can assist businesses in their decision-making and supports compliance with regulatory requirements.",Document_221,Technical aspects or methods of AI or machine learning,0.2236025333404541,Other Categories
Text Mining For Information Systems Researchers: An Annotated Topic Modeling Tutorial,"Stefan Debortoli, Oliver Müller, I. Junglas, J. Brocke","Analysts have estimated that more than 80 percent of today’s data is stored in unstructured form (e.g., text, audio, image, video)—much of it expressed in rich and ambiguous natural language. Traditionally, to analyze natural language, one has used qualitative data-analysis approaches, such as manual coding. Yet, the size of text data sets obtained from the Internet makes manual analysis virtually impossible. In this tutorial, we discuss the challenges encountered when applying automated text-mining techniques in information systems research. In particular, we showcase how to use probabilistic topic modeling via Latent Dirichlet allocation, an unsupervised text-mining technique, with a LASSO multinomial logistic regression to explain user satisfaction with an IT artifact by automatically analyzing more than 12,000 online customer reviews. For fellow information systems researchers, this tutorial provides guidance for conducting text-mining studies on their own and for evaluating the quality of others.",2016,2016,,Communications of the Association for Information Systems,Selector (div#abstract > p / Date Not Found (URL Source: DOI Link),https://doi.org/10.17705/1cais.03907,10.17705/1cais.03907,https://doi.org/10.17705/1cais.03907,195,"Analysts have estimated that more than 80 percent of today’s data is stored in unstructured form (e.g., text, audio, image, video)—much of it expressed in rich and ambiguous natural language. Traditionally, to analyze natural language, one has used qualitative data-analysis approaches, such as manual coding. Yet, the size of text data sets obtained from the Internet makes manual analysis virtually impossible. In this tutorial, we discuss the challenges encountered when applying automated text-mining techniques in information systems research. In particular, we showcase how to use probabilistic topic modeling via Latent Dirichlet allocation, an unsupervised text-mining technique, with a LASSO multinomial logistic regression to explain user satisfaction with an IT artifact by automatically analyzing more than 12,000 online customer reviews. For fellow information systems researchers, this tutorial provides guidance for conducting text-mining studies on their own and for evaluating the quality of others.",Document_222,Technical aspects or methods of AI or machine learning,0.13417035341262817,Other Categories
Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview,"Deven Santosh Shah, H. A. Schwartz, Dirk Hovy","An increasing number of natural language processing papers address the effect of bias on predictions, introducing mitigation techniques at different parts of the standard NLP pipeline (data and models). However, these works have been conducted individually, without a unifying framework to organize efforts within the field. This situation leads to repetitive approaches, and focuses overly on bias symptoms/effects, rather than on their origins, which could limit the development of effective countermeasures. In this paper, we propose a unifying predictive bias framework for NLP. We summarize the NLP literature and suggest general mathematical definitions of predictive bias. We differentiate two consequences of bias: outcome disparities and error disparities, as well as four potential origins of biases: label bias, selection bias, model overamplification, and semantic bias. Our framework serves as an overview of predictive bias in NLP, integrating existing work into a single structure, and providing a conceptual baseline for improved frameworks.",2019,2020,7.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.acl-main.468,10.18653/v1/2020.acl-main.468,https://doi.org/10.18653/v1/2020.acl-main.468,234,"An increasing number of natural language processing papers address the effect of bias on predictions, introducing mitigation techniques at different parts of the standard NLP pipeline (data and models). However, these works have been conducted individually, without a unifying framework to organize efforts within the field. This situation leads to repetitive approaches, and focuses overly on bias symptoms/effects, rather than on their origins, which could limit the development of effective countermeasures. In this paper, we propose a unifying predictive bias framework for NLP. We summarize the NLP literature and suggest general mathematical definitions of predictive bias. We differentiate two consequences of bias: outcome disparities and error disparities, as well as four potential origins of biases: label bias, selection bias, model overamplification, and semantic bias. Our framework serves as an overview of predictive bias in NLP, integrating existing work into a single structure, and providing a conceptual baseline for improved frameworks.",Document_223,Building organizational support for AI through education and communication,0.056545741856098175,"Education, Awareness, and Policy Strategies"
Named Entity Extraction for Knowledge Graphs: A Literature Overview,"Tareq Al-Moslmi, Marc Gallofré Ocaña, Andreas L. Opdahl, Csaba Veres","An enormous amount of digital information is expressed as natural-language (NL) text that is not easily processable by computers. Knowledge Graphs (KG) offer a widely used format for representing information in computer-processable form. Natural Language Processing (NLP) is therefore needed for mining (or lifting) knowledge graphs from NL texts. A central part of the problem is to extract the named entities in the text. The paper presents an overview of recent advances in this area, covering: Named Entity Recognition (NER), Named Entity Disambiguation (NED), and Named Entity Linking (NEL). We comment that many approaches to NED and NEL are based on older approaches to NER and need to leverage the outputs of state-of-the-art NER systems. There is also a need for standard methods to evaluate and compare named-entity extraction approaches. We observe that NEL has recently moved from being stepwise and isolated into an integrated process along two dimensions: the first is that previously sequential steps are now being integrated into end-to-end processes, and the second is that entities that were previously analysed in isolation are now being lifted in each other's context. The current culmination of these trends are the deep-learning approaches that have recently reported promising results.",2020,2020,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2020.2973928,10.1109/ACCESS.2020.2973928,https://doi.org/10.1109/ACCESS.2020.2973928,142,"An enormous amount of digital information is expressed as natural-language (NL) text that is not easily processable by computers. Knowledge Graphs (KG) offer a widely used format for representing information in computer-processable form. Natural Language Processing (NLP) is therefore needed for mining (or lifting) knowledge graphs from NL texts. A central part of the problem is to extract the named entities in the text. The paper presents an overview of recent advances in this area, covering: Named Entity Recognition (NER), Named Entity Disambiguation (NED), and Named Entity Linking (NEL). We comment that many approaches to NED and NEL are based on older approaches to NER and need to leverage the outputs of state-of-the-art NER systems. There is also a need for standard methods to evaluate and compare named-entity extraction approaches. We observe that NEL has recently moved from being stepwise and isolated into an integrated process along two dimensions: the first is that previously sequential steps are now being integrated into end-to-end processes, and the second is that entities that were previously analysed in isolation are now being lifted in each other's context. The current culmination of these trends are the deep-learning approaches that have recently reported promising results.",Document_224,Technical aspects or methods of AI or machine learning,0.112896628677845,Other Categories
Beyond Accuracy: Behavioral Testing of NLP Models with CheckList,"Marco Tulio Ribeiro, Tongshuang Sherry Wu, Carlos Guestrin, Sameer Singh","Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of NLP models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce CheckList, a task-agnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of CheckList with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, NLP practitioners with CheckList created twice as many tests, and found almost three times as many bugs as users without it.",2020,2020,7.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.acl-main.442,10.18653/v1/2020.acl-main.442,https://doi.org/10.18653/v1/2020.acl-main.442,1021,"Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of NLP models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce CheckList, a task-agnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of CheckList with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, NLP practitioners with CheckList created twice as many tests, and found almost three times as many bugs as users without it.",Document_225,Building organizational support for AI through education and communication,0.07512664794921875,"Education, Awareness, and Policy Strategies"
Leveraging legacy system dollars for e-business,L. Erlikh,"Although many firms have rapidly and enthusiastically adopted distributed architectures, many more are stuck with mainframe based mission-critical systems that continue to isolate them from their partner, supplier, and customer systems. Most companies want to transform their applications to meet new business demands, but because legacy systems tend to be unwieldy, monolithic, and inflexible, many firms regard modernization as somewhere between improbable and impossible. Reeling from the Y2K debacle and saddled with years of application backlog, the most these companies can hope for is to keep their legacy system alive. And keeping it alive is getting more expensive. It is also becoming harder to find qualified personnel to do the maintenance. All of this makes it difficult to add new functionality and keep up with business requirements. The ideal solution is to transform legacy systems to newer, more productive platforms so that companies can exploit faster and cheaper development technologies, like Java and XML (Extensible Markup Language). The focus then shifts to functionality, not the infrastructure, which means a company can respond more quickly to its changing business requirements and technology enhancements. RescueWare, legacy transformation software from Relativity Technologies, breaks business knowledge into stand-alone pieces, or e-components. The e-components are basically collections of objects that perform specific business services, have clearly defined application program interfaces (APIs), and are accessible through modern industry-standard protocols.",2000,2000,,-,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/6294.846201,10.1109/6294.846201,https://doi.org/10.1109/6294.846201,458,"Although many firms have rapidly and enthusiastically adopted distributed architectures, many more are stuck with mainframe based mission-critical systems that continue to isolate them from their partner, supplier, and customer systems. Most companies want to transform their applications to meet new business demands, but because legacy systems tend to be unwieldy, monolithic, and inflexible, many firms regard modernization as somewhere between improbable and impossible. Reeling from the Y2K debacle and saddled with years of application backlog, the most these companies can hope for is to keep their legacy system alive. And keeping it alive is getting more expensive. It is also becoming harder to find qualified personnel to do the maintenance. All of this makes it difficult to add new functionality and keep up with business requirements. The ideal solution is to transform legacy systems to newer, more productive platforms so that companies can exploit faster and cheaper development technologies, like Java and XML (Extensible Markup Language). The focus then shifts to functionality, not the infrastructure, which means a company can respond more quickly to its changing business requirements and technology enhancements. RescueWare, legacy transformation software from Relativity Technologies, breaks business knowledge into stand-alone pieces, or e-components. The e-components are basically collections of objects that perform specific business services, have clearly defined application program interfaces (APIs), and are accessible through modern industry-standard protocols.",Document_226,General discussion of AI in finance (neutral focus),0.04639054462313652,Other Categories
On the Vulnerabilities of Text-to-SQL Models,"Xutan Peng, Yipeng Zhang, Jingfeng Yang, Mark Stevenson","Although it has been demonstrated that Natural Language Processing (NLP) algorithms are vulnerable to deliberate attacks, the question of whether such weaknesses can lead to software security threats is under-explored. To bridge this gap, we conducted vulnerability tests on Text-to-SQL systems that are commonly used to create natural language interfaces to databases. We showed that the Text-to-SQL modules within six commercial applications can be manipulated to produce malicious code, potentially leading to data breaches and Denial of Service attacks. <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup> This is the first demonstration that NLP models can be exploited as attack vectors in the wild. In addition, experiments using four open-source language models verified that straightforward backdoor attacks on Text-to-SQL systems achieve a 100% success rate without affecting their performance. The aim of this work is to draw the community’s attention to potential software security issues associated with NLP algorithms and encourage exploration of methods to mitigate against them.",2022,2022,,IEEE International Symposium on Software Reliability Engineering,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ISSRE59848.2023.00047,10.1109/ISSRE59848.2023.00047,https://doi.org/10.1109/ISSRE59848.2023.00047,8,"Although it has been demonstrated that Natural Language Processing (NLP) algorithms are vulnerable to deliberate attacks, the question of whether such weaknesses can lead to software security threats is under-explored. To bridge this gap, we conducted vulnerability tests on Text-to-SQL systems that are commonly used to create natural language interfaces to databases. We showed that the Text-to-SQL modules within six commercial applications can be manipulated to produce malicious code, potentially leading to data breaches and Denial of Service attacks. <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup> This is the first demonstration that NLP models can be exploited as attack vectors in the wild. In addition, experiments using four open-source language models verified that straightforward backdoor attacks on Text-to-SQL systems achieve a 100% success rate without affecting their performance. The aim of this work is to draw the community’s attention to potential software security issues associated with NLP algorithms and encourage exploration of methods to mitigate against them.",Document_227,Difficulty in understanding AI decision-making is a barrier in finance,0.0639449954032898,Explainability and Transparency Barriers
Knowledge-Intensive Language Understanding for Explainable AI,"A. Sheth, Manas Gaur, Kaushik Roy, Keyur Faldu","AI systems have seen significant adoption in various domains. At the same time, further adoption in some domains is hindered by the inability to fully trust an AI system that it will not harm a human. Besides, fairness, privacy, transparency, and explainability are vital to developing trust in AI systems. As stated in Describing Trustworthy AI,aa.https://www.ibm.com/watson/trustworthy-ai. “Trust comes through understanding. How AI-led decisions are made and what determining factors were included are crucial to understand.” The subarea of explaining AI systems has come to be known as XAI. Multiple aspects of an AI system can be explained; these include biases that the data might have, lack of data points in a particular region of the example space, fairness of gathering the data, feature importances, etc. However, besides these, it is critical to have human-centered explanations directly related to decision-making, similar to how a domain expert makes decisions based on “domain knowledge,” including well-established, peer-validated explicit guidelines. To understand and validate an AI system's outcomes (such as classification, recommendations, predictions) that lead to developing trust in the AI system, it is necessary to involve explicit domain knowledge that humans understand and use. Contemporary XAI methods are yet addressed explanations that enable decision-making similar to an expert. Figure 1 shows the stages of adoption of an AI system into the real world.",2021,2021,,IEEE Internet Computing,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/mic.2021.3101919,10.1109/mic.2021.3101919,https://doi.org/10.1109/mic.2021.3101919,45,"AI systems have seen significant adoption in various domains. At the same time, further adoption in some domains is hindered by the inability to fully trust an AI system that it will not harm a human. Besides, fairness, privacy, transparency, and explainability are vital to developing trust in AI systems. As stated in Describing Trustworthy AI,aa.https://www.ibm.com/watson/trustworthy-ai. “Trust comes through understanding. How AI-led decisions are made and what determining factors were included are crucial to understand.” The subarea of explaining AI systems has come to be known as XAI. Multiple aspects of an AI system can be explained; these include biases that the data might have, lack of data points in a particular region of the example space, fairness of gathering the data, feature importances, etc. However, besides these, it is critical to have human-centered explanations directly related to decision-making, similar to how a domain expert makes decisions based on “domain knowledge,” including well-established, peer-validated explicit guidelines. To understand and validate an AI system's outcomes (such as classification, recommendations, predictions) that lead to developing trust in the AI system, it is necessary to involve explicit domain knowledge that humans understand and use. Contemporary XAI methods are yet addressed explanations that enable decision-making similar to an expert. Figure 1 shows the stages of adoption of an AI system into the real world.",Document_228,Technical aspects or methods of AI or machine learning,0.12215656787157059,Other Categories
Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data,"Antonio De Santis, Marco Balduini, F. D. Santis, Andrea Proia, Arsenio Leo, Marco Brambilla, Emanuele Della Valle","Aerospace manufacturing companies, such as Thales Alenia Space, design, develop, integrate, verify, and validate products characterized by high complexity and low volume. They carefully document all phases for each product but analyses across products are challenging due to the heterogeneity and unstructured nature of the data in documents. In this paper, we propose a hybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with Large Language Models (LLMs) to extract and validate data contained in these documents. We consider a case study focused on test data related to electronic boards for satellites. To do so, we extend the Semantic Sensor Network ontology. We store the metadata of the reports in a KG, while the actual test results are stored in parquet accessible via a Virtual Knowledge Graph. The validation process is managed using an LLM-based approach. We also conduct a benchmarking study to evaluate the performance of state-of-the-art LLMs in executing this task. Finally, we analyze the costs and benefits of automating preexisting processes of manual data extraction and validation for subsequent cross-report analyses.",2024,2025,4.0,International Workshop on the Semantic Web,"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.21) (URL Source: DOI Link)",https://doi.org/10.1007/978-3-031-77847-6_17,10.1007/978-3-031-77847-6_17,https://doi.org/10.1007/978-3-031-77847-6_17,1,"Aerospace manufacturing companies, such as Thales Alenia Space, design, develop, integrate, verify, and validate products characterized by high complexity and low volume. They carefully document all phases for each product but analyses across products are challenging due to the heterogeneity and unstructured nature of the data in documents. In this paper, we propose a hybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with Large Language Models (LLMs) to extract and validate data contained in these documents. We consider a case study focused on test data related to electronic boards for satellites. To do so, we extend the Semantic Sensor Network ontology. We store the metadata of the reports in a KG, while the actual test results are stored in parquet accessible via a Virtual Knowledge Graph. The validation process is managed using an LLM-based approach. We also conduct a benchmarking study to evaluate the performance of state-of-the-art LLMs in executing this task. Finally, we analyze the costs and benefits of automating preexisting processes of manual data extraction and validation for subsequent cross-report analyses.",Document_229,Technical aspects or methods of AI or machine learning,0.07761126011610031,Other Categories
Towards Improving Adversarial Training of NLP Models,"Jin Yong Yoo, Yanjun Qi","Adversarial training, a method for learning robust deep neural networks, constructs adversarial examples during training. However, recent methods for generating NLP adversarial examples involve combinatorial search and expensive sentence encoders for constraining the generated instances. As a result, it remains challenging to use vanilla adversarial training to improve NLP models’ performance, and the benefits are mainly uninvestigated. This paper proposes a simple and improved vanilla adversarial training process for NLP models, which we name Attacking to Training (A2T). The core part of A2T is a new and cheaper word substitution attack optimized for vanilla adversarial training. We use A2T to train BERT and RoBERTa models on IMDB, Rotten Tomatoes, Yelp, and SNLI datasets. Our results empirically show that it is possible to train robust NLP models using a much cheaper adversary. We demonstrate that vanilla adversarial training with A2T can improve an NLP model’s robustness to the attack it was originally trained with and also defend the model against other types of word substitution attacks. Furthermore, we show that A2T can improve NLP models’ standard accuracy, cross-domain generalization, and interpretability.",2021,2021,11.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2021.findings-emnlp.81,10.18653/v1/2021.findings-emnlp.81,https://doi.org/10.18653/v1/2021.findings-emnlp.81,117,"Adversarial training, a method for learning robust deep neural networks, constructs adversarial examples during training. However, recent methods for generating NLP adversarial examples involve combinatorial search and expensive sentence encoders for constraining the generated instances. As a result, it remains challenging to use vanilla adversarial training to improve NLP models’ performance, and the benefits are mainly uninvestigated. This paper proposes a simple and improved vanilla adversarial training process for NLP models, which we name Attacking to Training (A2T). The core part of A2T is a new and cheaper word substitution attack optimized for vanilla adversarial training. We use A2T to train BERT and RoBERTa models on IMDB, Rotten Tomatoes, Yelp, and SNLI datasets. Our results empirically show that it is possible to train robust NLP models using a much cheaper adversary. We demonstrate that vanilla adversarial training with A2T can improve an NLP model’s robustness to the attack it was originally trained with and also defend the model against other types of word substitution attacks. Furthermore, we show that A2T can improve NLP models’ standard accuracy, cross-domain generalization, and interpretability.",Document_230,Technical aspects or methods of AI or machine learning,0.12814979255199432,Other Categories
Diverse Adversaries for Mitigating Bias in Training,"Xudong Han, Timothy Baldwin, Trevor Cohn","Adversarial learning can learn fairer and less biased models of language processing than standard training. However, current adversarial techniques only partially mitigate the problem of model bias, added to which their training procedures are often unstable. In this paper, we propose a novel approach to adversarial learning based on the use of multiple diverse discriminators, whereby discriminators are encouraged to learn orthogonal hidden representations from one another. Experimental results show that our method substantially improves over standard adversarial removal methods, in terms of reducing bias and stability of training.",2021,2021,4.0,Conference of the European Chapter of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2021.eacl-main.239,10.18653/v1/2021.eacl-main.239,https://doi.org/10.18653/v1/2021.eacl-main.239,57,"Adversarial learning can learn fairer and less biased models of language processing than standard training. However, current adversarial techniques only partially mitigate the problem of model bias, added to which their training procedures are often unstable. In this paper, we propose a novel approach to adversarial learning based on the use of multiple diverse discriminators, whereby discriminators are encouraged to learn orthogonal hidden representations from one another. Experimental results show that our method substantially improves over standard adversarial removal methods, in terms of reducing bias and stability of training.",Document_231,Technical aspects or methods of AI or machine learning,0.0998394787311554,Other Categories
Universal Adversarial Triggers for Attacking and Analyzing NLP,"Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, Sameer Singh","Adversarial examples highlight model vulnerabilities and are useful for evaluation and interpretation. We define universal adversarial triggers: input-agnostic sequences of tokens that trigger a model to produce a specific prediction when concatenated to any input from a dataset. We propose a gradient-guided search over tokens which finds short trigger sequences (e.g., one word for classification and four words for language modeling) that successfully trigger the target prediction. For example, triggers cause SNLI entailment accuracy to drop from 89.94% to 0.55%, 72% of “why” questions in SQuAD to be answered “to kill american people”, and the GPT-2 language model to spew racist output even when conditioned on non-racial contexts. Furthermore, although the triggers are optimized using white-box access to a specific model, they transfer to other models for all tasks we consider. Finally, since triggers are input-agnostic, they provide an analysis of global model behavior. For instance, they confirm that SNLI models exploit dataset biases and help to diagnose heuristics learned by reading comprehension models.",2019,2019,11.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/D19-1221,10.18653/v1/D19-1221,https://doi.org/10.18653/v1/D19-1221,771,"Adversarial examples highlight model vulnerabilities and are useful for evaluation and interpretation. We define universal adversarial triggers: input-agnostic sequences of tokens that trigger a model to produce a specific prediction when concatenated to any input from a dataset. We propose a gradient-guided search over tokens which finds short trigger sequences (e.g., one word for classification and four words for language modeling) that successfully trigger the target prediction. For example, triggers cause SNLI entailment accuracy to drop from 89.94% to 0.55%, 72% of “why” questions in SQuAD to be answered “to kill american people”, and the GPT-2 language model to spew racist output even when conditioned on non-racial contexts. Furthermore, although the triggers are optimized using white-box access to a specific model, they transfer to other models for all tasks we consider. Finally, since triggers are input-agnostic, they provide an analysis of global model behavior. For instance, they confirm that SNLI models exploit dataset biases and help to diagnose heuristics learned by reading comprehension models.",Document_232,Technical aspects or methods of AI or machine learning,0.12162163853645325,Other Categories
Contextualized Perturbation for Textual Adversarial Attack,"Dianqi Li, Yizhe Zhang, Hao Peng, Liqun Chen, Chris Brockett, Ming-Ting Sun, Bill Dolan","Adversarial examples expose the vulnerabilities of natural language processing (NLP) models, and can be used to evaluate and improve their robustness. Existing techniques of generating such examples are typically driven by local heuristic rules that are agnostic to the context, often resulting in unnatural and ungrammatical outputs. This paper presents CLARE, a ContextuaLized AdversaRial Example generation model that produces fluent and grammatical outputs through a mask-then-infill procedure. CLARE builds on a pre-trained masked language model and modifies the inputs in a context-aware manner. We propose three contextualized perturbations, Replace, Insert and Merge, that allow for generating outputs of varied lengths. CLARE can flexibly combine these perturbations and apply them at any position in the inputs, and is thus able to attack the victim model more effectively with fewer edits. Extensive experiments and human evaluation demonstrate that CLARE outperforms the baselines in terms of attack success rate, textual similarity, fluency and grammaticality.",2020,2021,6.0,North American Chapter of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/V1/2021.NAACL-MAIN.400,10.18653/V1/2021.NAACL-MAIN.400,https://doi.org/10.18653/V1/2021.NAACL-MAIN.400,222,"Adversarial examples expose the vulnerabilities of natural language processing (NLP) models, and can be used to evaluate and improve their robustness. Existing techniques of generating such examples are typically driven by local heuristic rules that are agnostic to the context, often resulting in unnatural and ungrammatical outputs. This paper presents CLARE, a ContextuaLized AdversaRial Example generation model that produces fluent and grammatical outputs through a mask-then-infill procedure. CLARE builds on a pre-trained masked language model and modifies the inputs in a context-aware manner. We propose three contextualized perturbations, Replace, Insert and Merge, that allow for generating outputs of varied lengths. CLARE can flexibly combine these perturbations and apply them at any position in the inputs, and is thus able to attack the victim model more effectively with fewer edits. Extensive experiments and human evaluation demonstrate that CLARE outperforms the baselines in terms of attack success rate, textual similarity, fluency and grammaticality.",Document_233,Technical aspects or methods of AI or machine learning,0.10269898921251297,Other Categories
“That Is a Suspicious Reaction!”: Interpreting Logits Variation to Detect NLP Adversarial Attacks,"E. Mosca, Shreyash Agarwal, Javier Rando, G. Groh","Adversarial attacks are a major challenge faced by current machine learning research. These purposely crafted inputs fool even the most advanced models, precluding their deployment in safety-critical applications. Extensive research in computer vision has been carried to develop reliable defense strategies. However, the same issue remains less explored in natural language processing. Our work presents a model-agnostic detector of adversarial text examples. The approach identifies patterns in the logits of the target classifier when perturbing the input text. The proposed detector improves the current state-of-the-art performance in recognizing adversarial inputs and exhibits strong generalization capabilities across different NLP models, datasets, and word-level attacks.",2022,2022,5.0,Annual Meeting of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2022.acl-long.538,10.18653/v1/2022.acl-long.538,https://doi.org/10.18653/v1/2022.acl-long.538,26,"Adversarial attacks are a major challenge faced by current machine learning research. These purposely crafted inputs fool even the most advanced models, precluding their deployment in safety-critical applications. Extensive research in computer vision has been carried to develop reliable defense strategies. However, the same issue remains less explored in natural language processing. Our work presents a model-agnostic detector of adversarial text examples. The approach identifies patterns in the logits of the target classifier when perturbing the input text. The proposed detector improves the current state-of-the-art performance in recognizing adversarial inputs and exhibits strong generalization capabilities across different NLP models, datasets, and word-level attacks.",Document_234,Technical aspects or methods of AI or machine learning,0.202085942029953,Other Categories
Concealed Data Poisoning Attacks on NLP Models,"Eric Wallace, Tony Zhao, Shi Feng, Sameer Singh","Adversarial attacks alter NLP model predictions by perturbing test-time inputs. However, it is much less understood whether, and how, predictions can be manipulated with small, concealed changes to the training data. In this work, we develop a new data poisoning attack that allows an adversary to control model predictions whenever a desired trigger phrase is present in the input. For instance, we insert 50 poison examples into a sentiment model’s training set that causes the model to frequently predict Positive whenever the input contains “James Bond”. Crucially, we craft these poison examples using a gradient-based procedure so that they do not mention the trigger phrase. We also apply our poison attack to language modeling (“Apple iPhone” triggers negative generations) and machine translation (“iced coffee” mistranslated as “hot coffee”). We conclude by proposing three defenses that can mitigate our attack at some cost in prediction accuracy or extra human annotation.",2021,2021,6.0,North American Chapter of the Association for Computational Linguistics,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/V1/2021.NAACL-MAIN.13,10.18653/V1/2021.NAACL-MAIN.13,https://doi.org/10.18653/V1/2021.NAACL-MAIN.13,153,"Adversarial attacks alter NLP model predictions by perturbing test-time inputs. However, it is much less understood whether, and how, predictions can be manipulated with small, concealed changes to the training data. In this work, we develop a new data poisoning attack that allows an adversary to control model predictions whenever a desired trigger phrase is present in the input. For instance, we insert 50 poison examples into a sentiment model’s training set that causes the model to frequently predict Positive whenever the input contains “James Bond”. Crucially, we craft these poison examples using a gradient-based procedure so that they do not mention the trigger phrase. We also apply our poison attack to language modeling (“Apple iPhone” triggers negative generations) and machine translation (“iced coffee” mistranslated as “hot coffee”). We conclude by proposing three defenses that can mitigate our attack at some cost in prediction accuracy or extra human annotation.",Document_235,Technical aspects or methods of AI or machine learning,0.11670469492673874,Other Categories
T3: Tree-Autoencoder Constrained Adversarial Text Generation for Targeted Attack,"Boxin Wang, Hengzhi Pei, Boyuan Pan, Qiang Chen, Shuohang Wang, Bo Li","Adversarial attacks against natural language processing systems, which perform seemingly innocuous modifications to inputs, can induce arbitrary mistakes to the target models. Though raised great concerns, such adversarial attacks can be leveraged to estimate the robustness of NLP models. Compared with the adversarial example generation in continuous data domain (e.g., image), generating adversarial text that preserves the original meaning is challenging since the text space is discrete and non-differentiable. To handle these challenges, we propose a target-controllable adversarial attack framework T3, which is applicable to a range of NLP tasks. In particular, we propose a tree-based autoencoder to embed the discrete text data into a continuous representation space, upon which we optimize the adversarial perturbation. A novel tree-based decoder is then applied to regularize the syntactic correctness of the generated text and manipulate it on either sentence (T3(Sent)) or word (T3(Word)) level. We consider two most representative NLP tasks: sentiment analysis and question answering (QA). Extensive experimental results and human studies show that T3 generated adversarial texts can successfully manipulate the NLP models to output the targeted incorrect answer without misleading the human. Moreover, we show that the generated adversarial texts have high transferability which enables the black-box attacks in practice. Our work sheds light on an effective and general way to examine the robustness of NLP models. Our code is publicly available at https://github.com/AI-secure/T3/ .",2020,2020,11.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2020.emnlp-main.495,10.18653/v1/2020.emnlp-main.495,https://doi.org/10.18653/v1/2020.emnlp-main.495,66,"Adversarial attacks against natural language processing systems, which perform seemingly innocuous modifications to inputs, can induce arbitrary mistakes to the target models. Though raised great concerns, such adversarial attacks can be leveraged to estimate the robustness of NLP models. Compared with the adversarial example generation in continuous data domain (e.g., image), generating adversarial text that preserves the original meaning is challenging since the text space is discrete and non-differentiable. To handle these challenges, we propose a target-controllable adversarial attack framework T3, which is applicable to a range of NLP tasks. In particular, we propose a tree-based autoencoder to embed the discrete text data into a continuous representation space, upon which we optimize the adversarial perturbation. A novel tree-based decoder is then applied to regularize the syntactic correctness of the generated text and manipulate it on either sentence (T3(Sent)) or word (T3(Word)) level. We consider two most representative NLP tasks: sentiment analysis and question answering (QA). Extensive experimental results and human studies show that T3 generated adversarial texts can successfully manipulate the NLP models to output the targeted incorrect answer without misleading the human. Moreover, we show that the generated adversarial texts have high transferability which enables the black-box attacks in practice. Our work sheds light on an effective and general way to examine the robustness of NLP models. Our code is publicly available at https://github.com/AI-secure/T3/ .",Document_236,Technical aspects or methods of AI or machine learning,0.0996900424361229,Other Categories
Bias Dilemma,"Oisín Deery, Katherine Bailey","Addressing biases in natural-language processing (NLP) systems presents an underappreciated ethical dilemma, which we think underlies recent debates about bias in NLP models. In brief, even if we could eliminate bias from language models or their outputs, we would thereby often withhold descriptively or ethically useful information, despite avoiding perpetuating or amplifying bias. Yet if we do not debias, we can perpetuate or amplify bias, even if we retain relevant descriptively or ethically useful information. Understanding this dilemma provides for a useful way of rethinking the ethics of algorithmic bias in NLP.",2022,2022,,Feminist Philosophy Quarterly,Selector (section.abstract / Date Not Found (URL Source: DOI Link),https://doi.org/10.5206/fpq/2022.3/4.14292,10.5206/fpq/2022.3/4.14292,https://doi.org/10.5206/fpq/2022.3/4.14292,1,"Addressing biases in natural-language processing (NLP) systems presents an underappreciated ethical dilemma, which we think underlies recent debates about bias in NLP models. In brief, even if we could eliminate bias from language models or their outputs, we would thereby often withhold descriptively or ethically useful information, despite avoiding perpetuating or amplifying bias. Yet if we do not debias, we can perpetuate or amplify bias, even if we retain relevant descriptively or ethically useful information. Understanding this dilemma provides for a useful way of rethinking the ethics of algorithmic bias in NLP.",Document_237,Technical aspects or methods of AI or machine learning,0.0732189491391182,Other Categories
"Just What do You Think You're Doing, Dave?' A Checklist for Responsible Data Use in NLP","Anna Rogers, Timothy Baldwin, Kobi Leins","A key part of the NLP ethics movement is responsible use of data, but exactly what that means or how it can be best achieved remain unclear. This position paper discusses the core legal and ethical principles for collection and sharing of textual data, and the tensions between them. We propose a potential checklist for responsible data (re-)use that could both standardise the peer review of conference submissions, as well as enable a more in-depth view of published research across the community. Our proposal aims to contribute to the development of a consistent standard for data (re-)use, embraced across NLP conferences.",2021,2021,11.0,Conference on Empirical Methods in Natural Language Processing,"Success (Selector (div[class*=""abstract""])) / Date (Meta (citation_publication_date)) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2021.findings-emnlp.414,10.18653/v1/2021.findings-emnlp.414,https://doi.org/10.18653/v1/2021.findings-emnlp.414,60,"A key part of the NLP ethics movement is responsible use of data, but exactly what that means or how it can be best achieved remain unclear. This position paper discusses the core legal and ethical principles for collection and sharing of textual data, and the tensions between them. We propose a potential checklist for responsible data (re-)use that could both standardise the peer review of conference submissions, as well as enable a more in-depth view of published research across the community. Our proposal aims to contribute to the development of a consistent standard for data (re-)use, embraced across NLP conferences.",Document_238,Building organizational support for AI through education and communication,0.07363829761743546,"Education, Awareness, and Policy Strategies"
Effective Integration of Knowledge Management into the Business Starts with a Top-down Knowledge Strategy,J. Hofer-Alfeis,"A cornerstone in the integration of Knowledge Management (KM) in the business is the extension of the business strategy with a knowledge strategy. The Knowledge Strategy Process (KSP) at Siemens follows a top-down approach and helps the management to integrate knowledge strategy effectively in their business strategy. Furthermore, it brings the decision makers of a business unit on one table to draw up an action plan for their respective business unit. In six consequent steps, this action plan is generated to improve the way of working and learning by focusing on knowledge areas with highest impact on the major business ambitions. With a knowledge strategy, the pressure on impact measurements for KM is released, since sense and need for the KM program is understood and it is driven by the management. Only very reasonable cost-benefit checks will be required for larger investment plans by the business owner. An overview on diagnostics and mesurements for knowledge and KM as well as a list of open KM research issues is given for the full integration of KM into the business.",2003,2003,7.0,Journal of universal computer science (Online),"Success (JSON-LD - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.20) (URL Source: DOI Link)",https://doi.org/10.3217/jucs-009-07-0719,10.3217/jucs-009-07-0719,https://doi.org/10.3217/jucs-009-07-0719,26,"A cornerstone in the integration of Knowledge Management (KM) in the business is the extension of the business strategy with a knowledge strategy. The Knowledge Strategy Process (KSP) at Siemens follows a top-down approach and helps the management to integrate knowledge strategy effectively in their business strategy. Furthermore, it brings the decision makers of a business unit on one table to draw up an action plan for their respective business unit. In six consequent steps, this action plan is generated to improve the way of working and learning by focusing on knowledge areas with highest impact on the major business ambitions. With a knowledge strategy, the pressure on impact measurements for KM is released, since sense and need for the KM program is understood and it is driven by the management. Only very reasonable cost-benefit checks will be required for larger investment plans by the business owner. An overview on diagnostics and mesurements for knowledge and KM as well as a list of open KM research issues is given for the full integration of KM into the business.",Document_239,General discussion of AI in finance (neutral focus),0.06657591462135315,Other Categories
Neural Text Classification for Digital Transformation in the Financial Regulatory Domain,"Nelson Correa, Antonio Correa","A core use case in artificial intelligence and natural language processing (NLP) is automatic text classification of documents, for the efficient, transparent and reliable handling of the billions of documents generated each year as part of business and government operation. Our application for document analysis uses deep learning for Neural Text Classification, with recurrent (Bi-LSTM) and transformer neural networks (DistilBERT and FinBERT). We compare the new models against traditional TF-IDF bag-of-words machine learning models, and evaluate text classification on a corpus of over 2,600,000 consumer financial complaints from the U.S. Consumer Financial Protection Bureau (CFPB), an agency of the U.S. Federal government created as a result of the 2008 financial crisis. Our analysis shows the superiority of the transformer models, with a classification accuracy of 88.05% on the task formulated.",2022,2022,,IEEE ANDESCON,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ANDESCON56260.2022.9989638,10.1109/ANDESCON56260.2022.9989638,https://doi.org/10.1109/ANDESCON56260.2022.9989638,5,"A core use case in artificial intelligence and natural language processing (NLP) is automatic text classification of documents, for the efficient, transparent and reliable handling of the billions of documents generated each year as part of business and government operation. Our application for document analysis uses deep learning for Neural Text Classification, with recurrent (Bi-LSTM) and transformer neural networks (DistilBERT and FinBERT). We compare the new models against traditional TF-IDF bag-of-words machine learning models, and evaluate text classification on a corpus of over 2,600,000 consumer financial complaints from the U.S. Consumer Financial Protection Bureau (CFPB), an agency of the U.S. Federal government created as a result of the 2008 financial crisis. Our analysis shows the superiority of the transformer models, with a classification accuracy of 88.05% on the task formulated.",Document_240,Aligning AI implementation with financial regulatory requirements,0.1946823000907898,Regulatory Engagement and Proactive Compliance Strategies
The application of natural language processing for the extraction of mechanistic information in toxicology,"Marie Corradi, Thomas Luechtefeld, Alyanne M. de Haan, R. Pieters, Jonathan H. Freedman, T. Vanhaecke, Mathieu Vinken, M. Teunis","To study the ways in which compounds can induce adverse effects, toxicologists have been constructing Adverse Outcome Pathways (AOPs). An AOP can be considered as a pragmatic tool to capture and visualize mechanisms underlying different types of toxicity inflicted by any kind of stressor, and describes the interactions between key entities that lead to the adverse outcome on multiple biological levels of organization. The construction or optimization of an AOP is a labor intensive process, which currently depends on the manual search, collection, reviewing and synthesis of available scientific literature. This process could however be largely facilitated using Natural Language Processing (NLP) to extract information contained in scientific literature in a systematic, objective, and rapid manner that would lead to greater accuracy and reproducibility. This would support researchers to invest their expertise in the substantive assessment of the AOPs by replacing the time spent on evidence gathering by a critical review of the data extracted by NLP. As case examples, we selected two frequent adversities observed in the liver: namely, cholestasis and steatosis denoting accumulation of bile and lipid, respectively. We used deep learning language models to recognize entities of interest in text and establish causal relationships between them. We demonstrate how an NLP pipeline combining Named Entity Recognition and a simple rules-based relationship extraction model helps screen compounds related to liver adversities in the literature, but also extract mechanistic information for how such adversities develop, from the molecular to the organismal level. Finally, we provide some perspectives opened by the recent progress in Large Language Models and how these could be used in the future. We propose this work brings two main contributions: 1) a proof-of-concept that NLP can support the extraction of information from text for modern toxicology and 2) a template open-source model for recognition of toxicological entities and extraction of their relationships. All resources are openly accessible via GitHub (<ext-link ext-link-type=""uri"" xlink:href=""https://github.com/ontox-project/en-tox"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/ontox-project/en-tox</ext-link>).</p>",2024,2024,5.0,Frontiers in Toxicology,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.52) (URL Source: DOI Link)",https://doi.org/10.3389/ftox.2024.1393662,10.3389/ftox.2024.1393662,https://doi.org/10.3389/ftox.2024.1393662,1,"To study the ways in which compounds can induce adverse effects, toxicologists have been constructing Adverse Outcome Pathways (AOPs). An AOP can be considered as a pragmatic tool to capture and visualize mechanisms underlying different types of toxicity inflicted by any kind of stressor, and describes the interactions between key entities that lead to the adverse outcome on multiple biological levels of organization. The construction or optimization of an AOP is a labor intensive process, which currently depends on the manual search, collection, reviewing and synthesis of available scientific literature. This process could however be largely facilitated using Natural Language Processing (NLP) to extract information contained in scientific literature in a systematic, objective, and rapid manner that would lead to greater accuracy and reproducibility. This would support researchers to invest their expertise in the substantive assessment of the AOPs by replacing the time spent on evidence gathering by a critical review of the data extracted by NLP. As case examples, we selected two frequent adversities observed in the liver: namely, cholestasis and steatosis denoting accumulation of bile and lipid, respectively. We used deep learning language models to recognize entities of interest in text and establish causal relationships between them. We demonstrate how an NLP pipeline combining Named Entity Recognition and a simple rules-based relationship extraction model helps screen compounds related to liver adversities in the literature, but also extract mechanistic information for how such adversities develop, from the molecular to the organismal level. Finally, we provide some perspectives opened by the recent progress in Large Language Models and how these could be used in the future. We propose this work brings two main contributions: 1) a proof-of-concept that NLP can support the extraction of information from text for modern toxicology and 2) a template open-source model for recognition of toxicological entities and extraction of their relationships. All resources are openly accessible via GitHub (<ext-link ext-link-type=""uri"" xlink:href=""https://github.com/ontox-project/en-tox"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/ontox-project/en-tox</ext-link>).</p>",Document_241,Technical aspects or methods of AI or machine learning,0.13994036614894867,Other Categories
"Financial Risk Management and Explainable, Trustworthy, Responsible AI","Sebastian G. Fritz-Morgenthal, Bernhard Hein, Jochen Papenbrock","This perspective paper is based on several sessions by the members of the Round Table AI at FIRM<xref ref-type=""fn"" rid=""fn0001""><sup>1</sup></xref>, with input from a number of external and international speakers. Its particular focus lies on the management of the model risk of productive models in banks and other financial institutions. The models in view range from simple rules-based approaches to Artificial Intelligence (AI) or Machine learning (ML) models with a high level of sophistication. The typical applications of those models are related to predictions and decision making around the value chain of credit risk (including accounting side under IFRS9 or related national GAAP approaches), insurance risk or other financial risk types. We expect more models of higher complexity in the space of anti-money laundering, fraud detection and transaction monitoring as well as a rise of AI/ML models as alternatives to current methods in solving some of the more intricate stochastic differential equations needed for the pricing and/or valuation of derivatives. The same type of model is also successful in areas unrelated to risk management, such as sales optimization, customer lifetime value considerations, robo-advisory, and other fields of applications. The paper refers to recent related publications from central banks, financial supervisors and regulators as well as other relevant sources and working groups. It aims to give practical advice for establishing a risk-based governance and testing framework for the mentioned model types and discusses the use of recent technologies, approaches, and platforms to support the establishment of responsible, trustworthy, explainable, auditable, and manageable AI/ML in production. In view of the recent EU publication on AI, also referred to as the EU Artificial Intelligence Act (AIA), we also see a certain added value for this paper as an instigator of further thinking outside of the financial services sector, in particular where “High Risk” models according to the mentioned EU consultation are concerned.</p>",2021,2022,2.0,Frontiers in Artificial Intelligence,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.18) (URL Source: DOI Link)",https://doi.org/10.3389/frai.2022.779799,10.3389/frai.2022.779799,https://doi.org/10.3389/frai.2022.779799,38,"This perspective paper is based on several sessions by the members of the Round Table AI at FIRM<xref ref-type=""fn"" rid=""fn0001""><sup>1</sup></xref>, with input from a number of external and international speakers. Its particular focus lies on the management of the model risk of productive models in banks and other financial institutions. The models in view range from simple rules-based approaches to Artificial Intelligence (AI) or Machine learning (ML) models with a high level of sophistication. The typical applications of those models are related to predictions and decision making around the value chain of credit risk (including accounting side under IFRS9 or related national GAAP approaches), insurance risk or other financial risk types. We expect more models of higher complexity in the space of anti-money laundering, fraud detection and transaction monitoring as well as a rise of AI/ML models as alternatives to current methods in solving some of the more intricate stochastic differential equations needed for the pricing and/or valuation of derivatives. The same type of model is also successful in areas unrelated to risk management, such as sales optimization, customer lifetime value considerations, robo-advisory, and other fields of applications. The paper refers to recent related publications from central banks, financial supervisors and regulators as well as other relevant sources and working groups. It aims to give practical advice for establishing a risk-based governance and testing framework for the mentioned model types and discusses the use of recent technologies, approaches, and platforms to support the establishment of responsible, trustworthy, explainable, auditable, and manageable AI/ML in production. In view of the recent EU publication on AI, also referred to as the EU Artificial Intelligence Act (AIA), we also see a certain added value for this paper as an instigator of further thinking outside of the financial services sector, in particular where “High Risk” models according to the mentioned EU consultation are concerned.</p>",Document_242,Aligning AI implementation with financial regulatory requirements,0.11716444790363312,Regulatory Engagement and Proactive Compliance Strategies
A United States Fair Lending Perspective on Machine Learning,"Patrick Hall, Benjamin G. Cox, Steven N. Dickerson, Arjun Ravi Kannan, Raghu Kulkarni, N. Schmidt","The use of machine learning (ML) has become more widespread in many areas of consumer financial services, including credit underwriting and pricing of loans. ML’s ability to automatically learn nonlinearities and interactions in training data is perceived to facilitate faster and more accurate credit decisions, and ML is now a viable challenger to traditional credit modeling methodologies. In this mini review, we further the discussion of ML in consumer finance by proposing uniform definitions of key ML and legal concepts related to discrimination and interpretability. We use the United States legal and regulatory environment as a foundation to add critical context to the broader discussion of relevant, substantial, and novel ML methodologies in credit underwriting, and we review numerous strategies to mitigate the many potential adverse implications of ML in consumer finance.</p>",2021,2021,6.0,Frontiers in Artificial Intelligence,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.30) (URL Source: DOI Link)",https://doi.org/10.3389/frai.2021.695301,10.3389/frai.2021.695301,https://doi.org/10.3389/frai.2021.695301,15,"The use of machine learning (ML) has become more widespread in many areas of consumer financial services, including credit underwriting and pricing of loans. ML’s ability to automatically learn nonlinearities and interactions in training data is perceived to facilitate faster and more accurate credit decisions, and ML is now a viable challenger to traditional credit modeling methodologies. In this mini review, we further the discussion of ML in consumer finance by proposing uniform definitions of key ML and legal concepts related to discrimination and interpretability. We use the United States legal and regulatory environment as a foundation to add critical context to the broader discussion of relevant, substantial, and novel ML methodologies in credit underwriting, and we review numerous strategies to mitigate the many potential adverse implications of ML in consumer finance.</p>",Document_243,Technical aspects or methods of AI or machine learning,0.08001600205898285,Other Categories
Considerations on the regulation of AI systems in the financial sector by the AI Act,"Gabriele Mazzini, Filippo Bagni","The proposal for the Artificial Intelligence regulation in the EU (AI Act) is a horizontal legal instrument that aims to regulate, according to a tailored risk-based approach, the development and use of AI systems across a plurality of sectors, including the financial sector. In particular, AI systems intended to be used to evaluate the creditworthiness or establish the credit score of natural persons are classified as “high-risk AI systems”. The proposal, tabled by the Commission in April 2021, is currently at the center of intense interinstitutional negotiations between the two branches of the European legislature, the European Parliament and the Council. Without prejudice to the ongoing legislative deliberations, the paper aims to provide an overview of the main elements and choices made by the Commission in respect of the regulation of AI in the financial sector, as well as of the position taken in that regard by the European Parliament and Council.</p>",2023,2023,11.0,Frontiers Artif. Intell.,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.49) (URL Source: DOI Link)",https://doi.org/10.3389/frai.2023.1277544,10.3389/frai.2023.1277544,https://doi.org/10.3389/frai.2023.1277544,4,"The proposal for the Artificial Intelligence regulation in the EU (AI Act) is a horizontal legal instrument that aims to regulate, according to a tailored risk-based approach, the development and use of AI systems across a plurality of sectors, including the financial sector. In particular, AI systems intended to be used to evaluate the creditworthiness or establish the credit score of natural persons are classified as “high-risk AI systems”. The proposal, tabled by the Commission in April 2021, is currently at the center of intense interinstitutional negotiations between the two branches of the European legislature, the European Parliament and the Council. Without prejudice to the ongoing legislative deliberations, the paper aims to provide an overview of the main elements and choices made by the Commission in respect of the regulation of AI in the financial sector, as well as of the position taken in that regard by the European Parliament and Council.</p>",Document_244,AI-specific regulations pose challenges for financial institutions,0.11419471353292465,Regulatory and Ethical Barriers
Explainable AI in Fintech Risk Management,"N. Bussmann, Paolo Giudici, D. Marinelli, Jochen Papenbrock","The paper proposes an explainable AI model that can be used in fintech risk management and, in particular, in measuring the risks that arise when credit is borrowed employing peer to peer lending platforms. The model employs Shapley values, so that AI predictions are interpreted according to the underlying explanatory variables. The empirical analysis of 15,000 small and medium companies asking for peer to peer lending credit reveals that both risky and not risky borrowers can be grouped according to a set of similar financial characteristics, which can be employed to explain and understand their credit score and, therefore, to predict their future behavior.</p>",2020,2020,4.0,Frontiers in Artificial Intelligence,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.18) (URL Source: DOI Link)",https://doi.org/10.3389/frai.2020.00026,10.3389/frai.2020.00026,https://doi.org/10.3389/frai.2020.00026,112,"The paper proposes an explainable AI model that can be used in fintech risk management and, in particular, in measuring the risks that arise when credit is borrowed employing peer to peer lending platforms. The model employs Shapley values, so that AI predictions are interpreted according to the underlying explanatory variables. The empirical analysis of 15,000 small and medium companies asking for peer to peer lending credit reveals that both risky and not risky borrowers can be grouped according to a set of similar financial characteristics, which can be employed to explain and understand their credit score and, therefore, to predict their future behavior.</p>",Document_245,Demonstrating the value of AI for compliance and risk management,0.1647156924009323,Business Case and Value Demonstration Strategies
Responsible A.I.-based Credit Scoring – A Legal Framework,K. Langenbucher,"The paper proposes a legal framework to evaluate emerging FinTech methodology based on alternative data and machine learning to score borrowers. Instead of conventional variables, novel methods rely on information gathered from social networks, “digital footprints”, mobile phones or GPS data. Correlating these with repayment of loans is promoted as triggering precise predictions of probability of default. Borrowers profit if their profile falls outside of classic scoring checks but performs well under the new regime. Borrowers are disadvantaged if the new methods entail disparate impact for groups which are protected under anti-discrimination laws. Additionally, data may be collected without their consent or used in a way they don’t understand.&nbsp;<br></p>Two contributions to the debate are submitted. Firstly, a comparative assessment of EU and U.S. data protection and anti-discrimination laws suggests what might qualify as responsible A.I.-based scoring. Secondly, public and private enforcement mechanisms are explained</p>",2020,2020,8.0,European Business Law Review,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (Meta (citation_publication_date)) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.58) (URL Source: DOI Link)",https://doi.org/10.54648/eulr2020022,10.54648/eulr2020022,https://doi.org/10.54648/eulr2020022,14,"The paper proposes a legal framework to evaluate emerging FinTech methodology based on alternative data and machine learning to score borrowers. Instead of conventional variables, novel methods rely on information gathered from social networks, “digital footprints”, mobile phones or GPS data. Correlating these with repayment of loans is promoted as triggering precise predictions of probability of default. Borrowers profit if their profile falls outside of classic scoring checks but performs well under the new regime. Borrowers are disadvantaged if the new methods entail disparate impact for groups which are protected under anti-discrimination laws. Additionally, data may be collected without their consent or used in a way they don’t understand.&nbsp;<br></p>Two contributions to the debate are submitted. Firstly, a comparative assessment of EU and U.S. data protection and anti-discrimination laws suggests what might qualify as responsible A.I.-based scoring. Secondly, public and private enforcement mechanisms are explained</p>",Document_246,Technical aspects or methods of AI or machine learning,0.11893338710069656,Other Categories
Rationalization for explainable NLP: a survey,"Sai Gurrapu, Ajay Kulkarni, Lifu Huang, Ismini Lourentzou, Laura J. Freeman, Feras A. Batarseh","Recent advances in deep learning have improved the performance of many Natural Language Processing (NLP) tasks such as translation, question-answering, and text classification. However, this improvement comes at the expense of model explainability. Black-box models make it difficult to understand the internals of a system and the process it takes to arrive at an output. Numerical (LIME, Shapley) and visualization (saliency heatmap) explainability techniques are helpful; however, they are insufficient because they require specialized knowledge. These factors led rationalization to emerge as a more accessible explainable technique in NLP. Rationalization justifies a model's output by providing a natural language explanation (rationale). Recent improvements in natural language generation have made rationalization an attractive technique because it is intuitive, human-comprehensible, and accessible to non-technical users. Since rationalization is a relatively new field, it is disorganized. As the first survey, rationalization literature in NLP from 2007 to 2022 is analyzed. This survey presents available methods, explainable evaluations, code, and datasets used across various NLP tasks that use rationalization. Further, a new subfield in Explainable AI (XAI), namely, Rational AI (RAI), is introduced to advance the current state of rationalization. A discussion on observed insights, challenges, and future directions is provided to point to promising research opportunities.</p>",2023,2023,9.0,Frontiers Artif. Intell.,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.33) (URL Source: DOI Link)",https://doi.org/10.3389/frai.2023.1225093,10.3389/frai.2023.1225093,https://doi.org/10.3389/frai.2023.1225093,25,"Recent advances in deep learning have improved the performance of many Natural Language Processing (NLP) tasks such as translation, question-answering, and text classification. However, this improvement comes at the expense of model explainability. Black-box models make it difficult to understand the internals of a system and the process it takes to arrive at an output. Numerical (LIME, Shapley) and visualization (saliency heatmap) explainability techniques are helpful; however, they are insufficient because they require specialized knowledge. These factors led rationalization to emerge as a more accessible explainable technique in NLP. Rationalization justifies a model's output by providing a natural language explanation (rationale). Recent improvements in natural language generation have made rationalization an attractive technique because it is intuitive, human-comprehensible, and accessible to non-technical users. Since rationalization is a relatively new field, it is disorganized. As the first survey, rationalization literature in NLP from 2007 to 2022 is analyzed. This survey presents available methods, explainable evaluations, code, and datasets used across various NLP tasks that use rationalization. Further, a new subfield in Explainable AI (XAI), namely, Rational AI (RAI), is introduced to advance the current state of rationalization. A discussion on observed insights, challenges, and future directions is provided to point to promising research opportunities.</p>",Document_247,Technical aspects or methods of AI or machine learning,0.10158297419548035,Other Categories
"Natural language processing for humanitarian action: Opportunities, challenges, and the path toward humanitarian NLP","R. Rocca, Nicolò Tamagnone, Selim Fekih, Ximena Contla, Navid Rekabsaz","Natural language processing (NLP) is a rapidly evolving field at the intersection of linguistics, computer science, and artificial intelligence, which is concerned with developing methods to process and generate language at scale. Modern NLP tools have the potential to support humanitarian action at multiple stages of the humanitarian response cycle. Both internal reports, secondary text data (e.g., social media data, news media articles, or interviews with affected individuals), and external-facing documents like Humanitarian Needs Overviews (HNOs) encode information relevant to monitoring, anticipating, or responding to humanitarian crises. Yet, lack of awareness of the concrete opportunities offered by state-of-the-art techniques, as well as constraints posed by resource scarcity, limit adoption of NLP tools in the humanitarian sector. This paper provides a pragmatically-minded primer to the emerging field of humanitarian NLP, reviewing existing initiatives in the space of humanitarian NLP, highlighting potentially impactful applications of NLP in the humanitarian sector, and describing criteria, challenges, and potential solutions for large-scale adoption. In addition, as one of the main bottlenecks is the lack of data and standards for this domain, we present recent initiatives (the <sc>DEEP</sc> and <sc>HumSet</sc>) which are directly aimed at addressing these gaps. With this work, we hope to motivate humanitarians and NLP experts to create long-term impact-driven synergies and to co-develop an ambitious roadmap for the field.</p>",2023,2023,3.0,Frontiers in Big Data,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML) - Short, Score: 0.21) (URL Source: DOI Link)",https://doi.org/10.3389/fdata.2023.1082787,10.3389/fdata.2023.1082787,https://doi.org/10.3389/fdata.2023.1082787,6,"Natural language processing (NLP) is a rapidly evolving field at the intersection of linguistics, computer science, and artificial intelligence, which is concerned with developing methods to process and generate language at scale. Modern NLP tools have the potential to support humanitarian action at multiple stages of the humanitarian response cycle. Both internal reports, secondary text data (e.g., social media data, news media articles, or interviews with affected individuals), and external-facing documents like Humanitarian Needs Overviews (HNOs) encode information relevant to monitoring, anticipating, or responding to humanitarian crises. Yet, lack of awareness of the concrete opportunities offered by state-of-the-art techniques, as well as constraints posed by resource scarcity, limit adoption of NLP tools in the humanitarian sector. This paper provides a pragmatically-minded primer to the emerging field of humanitarian NLP, reviewing existing initiatives in the space of humanitarian NLP, highlighting potentially impactful applications of NLP in the humanitarian sector, and describing criteria, challenges, and potential solutions for large-scale adoption. In addition, as one of the main bottlenecks is the lack of data and standards for this domain, we present recent initiatives (the <sc>DEEP</sc> and <sc>HumSet</sc>) which are directly aimed at addressing these gaps. With this work, we hope to motivate humanitarians and NLP experts to create long-term impact-driven synergies and to co-develop an ambitious roadmap for the field.</p>",Document_248,Technical aspects or methods of AI or machine learning,0.27567189931869507,Other Categories
AI Applications and Regulation: Mapping the Regulatory Strata,"M. Viljanen, Henni Parviainen","Many accounts suggest that artificial intelligence (AI) law is still in its infancy with few statutes and other regulatory instruments regulating AI development and use. In this paper, we argue that such accounts are misguided. AI applications exist in a rich regulatory landscape, subject to multiple rules. To demonstrate our claim, we conduct two semi-fictional case studies under Finnish law. In the first case study, we chart the rules that currently would govern and impact AI tool use in recruitment. In the second case study, we map the legal framework for the Finnish COVID-19 contact tracing app. The article makes three contributions to the literature. First, the case studies provide ample evidence that the prevailing orthodoxy misstates the state of AI law. There is AI law on the books and existing laws have a profound impact on AI application design. Second, the mappings provide building material for developing a grounded theory framework for categorizing AI law and its types and modalities, allowing us to formulate a heuristic for understanding AI regulation. We argue that developers and AI application stakeholders should construe AI law as a complex stratigraphy consisting of five layers: data rules that regulate data use, application-specific AI rules that target specific AI applications or application domains, general AI rules that apply to a wide range of AI applications, application-specific non-AI rules that apply to specific activities but not to AI specifically and general non-AI rules that apply generically and across domains. Third, we provide guidance for practitioners for structuring AI compliance processes. We argue that practitioners should keep in mind that the rules and standards differ in their scopes, targets, certainty, and regulatory modalities. Consequently, understanding the AI regulatory landscape requires developing an understanding of multiple rule complexes, their dynamics, and regulatory modalities.</p>",2022,2022,1.0,Frontiers of Computer Science,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.21) (URL Source: DOI Link)",https://doi.org/10.3389/fcomp.2021.779957,10.3389/fcomp.2021.779957,https://doi.org/10.3389/fcomp.2021.779957,12,"Many accounts suggest that artificial intelligence (AI) law is still in its infancy with few statutes and other regulatory instruments regulating AI development and use. In this paper, we argue that such accounts are misguided. AI applications exist in a rich regulatory landscape, subject to multiple rules. To demonstrate our claim, we conduct two semi-fictional case studies under Finnish law. In the first case study, we chart the rules that currently would govern and impact AI tool use in recruitment. In the second case study, we map the legal framework for the Finnish COVID-19 contact tracing app. The article makes three contributions to the literature. First, the case studies provide ample evidence that the prevailing orthodoxy misstates the state of AI law. There is AI law on the books and existing laws have a profound impact on AI application design. Second, the mappings provide building material for developing a grounded theory framework for categorizing AI law and its types and modalities, allowing us to formulate a heuristic for understanding AI regulation. We argue that developers and AI application stakeholders should construe AI law as a complex stratigraphy consisting of five layers: data rules that regulate data use, application-specific AI rules that target specific AI applications or application domains, general AI rules that apply to a wide range of AI applications, application-specific non-AI rules that apply to specific activities but not to AI specifically and general non-AI rules that apply generically and across domains. Third, we provide guidance for practitioners for structuring AI compliance processes. We argue that practitioners should keep in mind that the rules and standards differ in their scopes, targets, certainty, and regulatory modalities. Consequently, understanding the AI regulatory landscape requires developing an understanding of multiple rule complexes, their dynamics, and regulatory modalities.</p>",Document_249,Technical aspects or methods of AI or machine learning,0.06676223874092102,Other Categories
Employing Explainable AI to Optimize the Return Target Function of a Loan Portfolio,"T. Gramespacher, Jan-Alexander Posth","In the recent years, data science methods have been developed considerably and have consequently found their way into many business processes in banking and finance. One example is the review and approval process of credit applications where they are employed with the aim to reduce rare but costly credit defaults in portfolios of loans. But there are challenges. Since defaults are rare events, it is—even with machine learning (ML) techniques—difficult to improve prediction accuracy and improvements are often marginal. Furthermore, while from an event prediction point of view, a non-default is the same as a default, from an economic point of view much more relevant to the end user it is not due to the high asymmetry in cost. Last, there are regulatory constraints when it comes to the adoption of advanced ML, hence the call for explainable artificial intelligence (XAI) issued by regulatory bodies like FINMA and BaFin. In our study, we will address these challenges. In particular, based on an exemplary use case, we show how ML methods can be adapted to the specific needs of credit assessment and how, in the case of strongly asymmetric costs of wrong forecasts, it makes sense to optimize not for accuracy but for an economic target function. We showcase this for two simple and ad hoc explainable ML algorithms, finding that in the case of credit approval, surprisingly high rejection rates contribute to maximizing profit.</p>",2021,2021,6.0,Frontiers in Artificial Intelligence,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.18) (URL Source: DOI Link)",https://doi.org/10.3389/frai.2021.693022,10.3389/frai.2021.693022,https://doi.org/10.3389/frai.2021.693022,14,"In the recent years, data science methods have been developed considerably and have consequently found their way into many business processes in banking and finance. One example is the review and approval process of credit applications where they are employed with the aim to reduce rare but costly credit defaults in portfolios of loans. But there are challenges. Since defaults are rare events, it is—even with machine learning (ML) techniques—difficult to improve prediction accuracy and improvements are often marginal. Furthermore, while from an event prediction point of view, a non-default is the same as a default, from an economic point of view much more relevant to the end user it is not due to the high asymmetry in cost. Last, there are regulatory constraints when it comes to the adoption of advanced ML, hence the call for explainable artificial intelligence (XAI) issued by regulatory bodies like FINMA and BaFin. In our study, we will address these challenges. In particular, based on an exemplary use case, we show how ML methods can be adapted to the specific needs of credit assessment and how, in the case of strongly asymmetric costs of wrong forecasts, it makes sense to optimize not for accuracy but for an economic target function. We showcase this for two simple and ad hoc explainable ML algorithms, finding that in the case of credit approval, surprisingly high rejection rates contribute to maximizing profit.</p>",Document_250,Aligning AI implementation with financial regulatory requirements,0.24198436737060547,Regulatory Engagement and Proactive Compliance Strategies
The assessment list for trustworthy artificial intelligence: A review and recommendations,"C. Radclyffe, Mafalda Ribeiro, R. Wortham","In July 2020, the European Commission's High-Level Expert Group on AI (HLEG-AI) published the Assessment List for Trustworthy Artificial Intelligence (ALTAI) tool, enabling organizations to perform self-assessments of the fit of their AI systems and surrounding governance to the “7 Principles for Trustworthy AI.” Prior research on ALTAI has focused primarily on specific application areas, but there has yet to be a comprehensive analysis and broader recommendations aimed at proto-regulators and industry practitioners. This paper therefore starts with an overview of this tool, including an assessment of its strengths and limitations. The authors then consider the success by which the ALTAI tool is likely to be of utility to industry in improving understanding of the risks inherent in AI systems and best practices to mitigate such risks. It is highlighted how research and practices from fields such as <italic>Environmental Sustainability, Social Justice, and Corporate Governance</italic> (ESG) can be of benefit for addressing similar challenges in ethical AI development and deployment. Also explored is the extent to which the tool is likely to be successful in being taken up by industry, considering various factors pertaining to its likely adoption. Finally, the authors also propose recommendations applicable internationally to similar bodies to the HLEG-AI regarding the gaps needing to be addressed between high-level principles and practical support for those on the front-line developing or commercializing AI tools. In all, this work provides a comprehensive analysis of the ALTAI tool, as well as recommendations to relevant stakeholders, with the broader aim of promoting more widespread adoption of such a tool in industry.</p>",2023,2023,3.0,Frontiers in Artificial Intelligence,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.54) (URL Source: DOI Link)",https://doi.org/10.3389/frai.2023.1020592,10.3389/frai.2023.1020592,https://doi.org/10.3389/frai.2023.1020592,27,"In July 2020, the European Commission's High-Level Expert Group on AI (HLEG-AI) published the Assessment List for Trustworthy Artificial Intelligence (ALTAI) tool, enabling organizations to perform self-assessments of the fit of their AI systems and surrounding governance to the “7 Principles for Trustworthy AI.” Prior research on ALTAI has focused primarily on specific application areas, but there has yet to be a comprehensive analysis and broader recommendations aimed at proto-regulators and industry practitioners. This paper therefore starts with an overview of this tool, including an assessment of its strengths and limitations. The authors then consider the success by which the ALTAI tool is likely to be of utility to industry in improving understanding of the risks inherent in AI systems and best practices to mitigate such risks. It is highlighted how research and practices from fields such as <italic>Environmental Sustainability, Social Justice, and Corporate Governance</italic> (ESG) can be of benefit for addressing similar challenges in ethical AI development and deployment. Also explored is the extent to which the tool is likely to be successful in being taken up by industry, considering various factors pertaining to its likely adoption. Finally, the authors also propose recommendations applicable internationally to similar bodies to the HLEG-AI regarding the gaps needing to be addressed between high-level principles and practical support for those on the front-line developing or commercializing AI tools. In all, this work provides a comprehensive analysis of the ALTAI tool, as well as recommendations to relevant stakeholders, with the broader aim of promoting more widespread adoption of such a tool in industry.</p>",Document_251,Demonstrating the value of AI for compliance and risk management,0.11883440613746643,Business Case and Value Demonstration Strategies
SHAP and LIME: An Evaluation of Discriminative Power in Credit Risk,"Alex Gramegna, Paolo Giudici","In credit risk estimation, the most important element is obtaining a probability of default as close as possible to the effective risk. This effort quickly prompted new, powerful algorithms that reach a far higher accuracy, but at the cost of losing intelligibility, such as Gradient Boosting or ensemble methods. These models are usually referred to as “black-boxes”, implying that you know the inputs and the output, but there is little way to understand what is going on under the hood. As a response to that, we have seen several different Explainable AI models flourish in recent years, with the aim of letting the user see why the black-box gave a certain output. In this context, we evaluate two very popular eXplainable AI (XAI) models in their ability to discriminate observations into groups, through the application of both unsupervised and predictive modeling to the weights these XAI models assign to features locally. The evaluation is carried out on real Small and Medium Enterprises data, obtained from official italian repositories, and may form the basis for the employment of such XAI models for post-processing features extraction.</p>",2021,2021,9.0,Frontiers in Artificial Intelligence,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.23) (URL Source: DOI Link)",https://doi.org/10.3389/frai.2021.752558,10.3389/frai.2021.752558,https://doi.org/10.3389/frai.2021.752558,138,"In credit risk estimation, the most important element is obtaining a probability of default as close as possible to the effective risk. This effort quickly prompted new, powerful algorithms that reach a far higher accuracy, but at the cost of losing intelligibility, such as Gradient Boosting or ensemble methods. These models are usually referred to as “black-boxes”, implying that you know the inputs and the output, but there is little way to understand what is going on under the hood. As a response to that, we have seen several different Explainable AI models flourish in recent years, with the aim of letting the user see why the black-box gave a certain output. In this context, we evaluate two very popular eXplainable AI (XAI) models in their ability to discriminate observations into groups, through the application of both unsupervised and predictive modeling to the weights these XAI models assign to features locally. The evaluation is carried out on real Small and Medium Enterprises data, obtained from official italian repositories, and may form the basis for the employment of such XAI models for post-processing features extraction.</p>",Document_252,Difficulty in understanding AI decision-making is a barrier in finance,0.1415066123008728,Explainability and Transparency Barriers
Principles and Practice of Explainable Machine Learning,"Vaishak Belle, I. Papantonis","Artificial intelligence (AI) provides many opportunities to improve private and public life. Discovering patterns and structures in large troves of data in an automated manner is a core component of data science, and currently drives applications in diverse areas such as computational biology, law and finance. However, such a highly positive impact is coupled with a significant challenge: how do we understand the decisions suggested by these systems in order that we can trust them? In this report, we focus specifically on data-driven methods—machine learning (ML) and pattern recognition models in particular—so as to survey and distill the results and observations from the literature. The purpose of this report can be especially appreciated by noting that ML models are increasingly deployed in a wide range of businesses. However, with the increasing prevalence and complexity of methods, business stakeholders in the very least have a growing number of concerns about the drawbacks of models, data-specific biases, and so on. Analogously, data science practitioners are often not aware about approaches emerging from the academic literature or may struggle to appreciate the differences between different methods, so end up using industry standards such as SHAP. Here, we have undertaken a survey to help industry practitioners (but also data scientists more broadly) understand the field of explainable machine learning better and apply the right tools. Our latter sections build a narrative around a putative data scientist, and discuss how she might go about explaining her models by asking the right questions. From an organization viewpoint, after motivating the area broadly, we discuss the main developments, including the principles that allow us to study transparent models vs. opaque models, as well as model-specific or model-agnostic post-hoc explainability approaches. We also briefly reflect on deep learning models, and conclude with a discussion about future research directions.</p>",2020,2021,7.0,Frontiers in Big Data,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.29) (URL Source: DOI Link)",https://doi.org/10.3389/fdata.2021.688969,10.3389/fdata.2021.688969,https://doi.org/10.3389/fdata.2021.688969,386,"Artificial intelligence (AI) provides many opportunities to improve private and public life. Discovering patterns and structures in large troves of data in an automated manner is a core component of data science, and currently drives applications in diverse areas such as computational biology, law and finance. However, such a highly positive impact is coupled with a significant challenge: how do we understand the decisions suggested by these systems in order that we can trust them? In this report, we focus specifically on data-driven methods—machine learning (ML) and pattern recognition models in particular—so as to survey and distill the results and observations from the literature. The purpose of this report can be especially appreciated by noting that ML models are increasingly deployed in a wide range of businesses. However, with the increasing prevalence and complexity of methods, business stakeholders in the very least have a growing number of concerns about the drawbacks of models, data-specific biases, and so on. Analogously, data science practitioners are often not aware about approaches emerging from the academic literature or may struggle to appreciate the differences between different methods, so end up using industry standards such as SHAP. Here, we have undertaken a survey to help industry practitioners (but also data scientists more broadly) understand the field of explainable machine learning better and apply the right tools. Our latter sections build a narrative around a putative data scientist, and discuss how she might go about explaining her models by asking the right questions. From an organization viewpoint, after motivating the area broadly, we discuss the main developments, including the principles that allow us to study transparent models vs. opaque models, as well as model-specific or model-agnostic post-hoc explainability approaches. We also briefly reflect on deep learning models, and conclude with a discussion about future research directions.</p>",Document_253,Difficulty in understanding AI decision-making is a barrier in finance,0.3451140820980072,Explainability and Transparency Barriers
BERT-Based Natural Language Processing of Drug Labeling Documents: A Case Study for Classifying Drug-Induced Liver Injury Risk,"Yue Wu, Zhichao Liu, Leihong Wu, Minjun Chen, W. Tong","<bold>Background & Aims:</bold> The United States Food and Drug Administration (FDA) regulates a broad range of consumer products, which account for about 25% of the United States market. The FDA regulatory activities often involve producing and reading of a large number of documents, which is time consuming and labor intensive. To support regulatory science at FDA, we evaluated artificial intelligence (AI)-based natural language processing (NLP) of regulatory documents for text classification and compared deep learning-based models with a conventional keywords-based model.</p><bold>Methods:</bold> FDA drug labeling documents were used as a representative regulatory data source to classify drug-induced liver injury (DILI) risk by employing the state-of-the-art language model BERT. The resulting NLP-DILI classification model was statistically validated with both internal and external validation procedures and applied to the labeling data from the European Medicines Agency (EMA) for cross-agency application.</p><bold>Results:</bold> The NLP-DILI model developed using FDA labeling documents and evaluated by cross-validations in this study showed remarkable performance in DILI classification with a recall of 1 and a precision of 0.78. When cross-agency data were used to validate the model, the performance remained comparable, demonstrating that the model was portable across agencies. Results also suggested that the model was able to capture the semantic meanings of sentences in drug labeling.</p><bold>Conclusion:</bold> Deep learning-based NLP models performed well in DILI classification of drug labeling documents and learned the meanings of complex text in drug labeling. This proof-of-concept work demonstrated that using AI technologies to assist regulatory activities is a promising approach to modernize and advance regulatory science.</p>",2021,2021,12.0,Frontiers in Artificial Intelligence,"Success (Meta (General) - Truncation Suspected, Retry Failed) / Date (JSON-LD) / LLM Found Similar/Shorter (LLM (Filtered HTML) - Short, Score: 0.13) (URL Source: DOI Link)",https://doi.org/10.3389/frai.2021.729834,10.3389/frai.2021.729834,https://doi.org/10.3389/frai.2021.729834,14,"<bold>Background & Aims:</bold> The United States Food and Drug Administration (FDA) regulates a broad range of consumer products, which account for about 25% of the United States market. The FDA regulatory activities often involve producing and reading of a large number of documents, which is time consuming and labor intensive. To support regulatory science at FDA, we evaluated artificial intelligence (AI)-based natural language processing (NLP) of regulatory documents for text classification and compared deep learning-based models with a conventional keywords-based model.</p><bold>Methods:</bold> FDA drug labeling documents were used as a representative regulatory data source to classify drug-induced liver injury (DILI) risk by employing the state-of-the-art language model BERT. The resulting NLP-DILI classification model was statistically validated with both internal and external validation procedures and applied to the labeling data from the European Medicines Agency (EMA) for cross-agency application.</p><bold>Results:</bold> The NLP-DILI model developed using FDA labeling documents and evaluated by cross-validations in this study showed remarkable performance in DILI classification with a recall of 1 and a precision of 0.78. When cross-agency data were used to validate the model, the performance remained comparable, demonstrating that the model was portable across agencies. Results also suggested that the model was able to capture the semantic meanings of sentences in drug labeling.</p><bold>Conclusion:</bold> Deep learning-based NLP models performed well in DILI classification of drug labeling documents and learned the meanings of complex text in drug labeling. This proof-of-concept work demonstrated that using AI technologies to assist regulatory activities is a promising approach to modernize and advance regulatory science.</p>",Document_254,Demonstrating the value of AI for compliance and risk management,0.2902679741382599,Business Case and Value Demonstration Strategies
User Stories and Natural Language Processing: A Systematic Literature Review,"I. K. Raharjana, D. Siahaan, Chastine Fatichah","<italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Context:</i> User stories have been widely accepted as artifacts to capture the user requirements in agile software development. They are short pieces of texts in a semi-structured format that express requirements. Natural language processing (NLP) techniques offer a potential advantage in user story applications. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Objective:</i> Conduct a systematic literature review to capture the current state-of-the-art of NLP research on user stories. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Method:</i> The search strategy is used to obtain relevant papers from SCOPUS, ScienceDirect, IEEE Xplore, ACM Digital Library, SpringerLink, and Google Scholar. Inclusion and exclusion criteria are applied to filter the search results. We also use the forward and backward snowballing techniques to obtain more comprehensive results. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Results:</i> The search results identified 718 papers published between January 2009 to December 2020. After applying the inclusion/exclusion criteria and the snowballing technique, we identified 38 primary studies that discuss NLP techniques in user stories. Most studies used NLP techniques to extract aspects of who, what, and why from user stories. The purpose of NLP studies in user stories is broad, ranging from discovering defects, generating software artifacts, identifying the key abstraction of user stories, and tracing links between model and user stories. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Conclusion:</i> NLP can help system analysts manage user stories. Implementing NLP in user stories has many opportunities and challenges. Considering the exploration of NLP techniques and rigorous evaluation methods is required to obtain quality research. As with NLP research in general, the ability to understand a sentence’s context continues to be a challenge.",2021,2021,,IEEE Access,"Meta (General - Truncation Suspected, Retry Failed / Date Not Found / LLM Found Similar/Shorter (LLM (Filtered HTML), Score: 0.08) (URL Source: DOI Link)",https://doi.org/10.1109/ACCESS.2021.3070606,10.1109/ACCESS.2021.3070606,https://doi.org/10.1109/ACCESS.2021.3070606,72,"<italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Context:</i> User stories have been widely accepted as artifacts to capture the user requirements in agile software development. They are short pieces of texts in a semi-structured format that express requirements. Natural language processing (NLP) techniques offer a potential advantage in user story applications. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Objective:</i> Conduct a systematic literature review to capture the current state-of-the-art of NLP research on user stories. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Method:</i> The search strategy is used to obtain relevant papers from SCOPUS, ScienceDirect, IEEE Xplore, ACM Digital Library, SpringerLink, and Google Scholar. Inclusion and exclusion criteria are applied to filter the search results. We also use the forward and backward snowballing techniques to obtain more comprehensive results. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Results:</i> The search results identified 718 papers published between January 2009 to December 2020. After applying the inclusion/exclusion criteria and the snowballing technique, we identified 38 primary studies that discuss NLP techniques in user stories. Most studies used NLP techniques to extract aspects of who, what, and why from user stories. The purpose of NLP studies in user stories is broad, ranging from discovering defects, generating software artifacts, identifying the key abstraction of user stories, and tracing links between model and user stories. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Conclusion:</i> NLP can help system analysts manage user stories. Implementing NLP in user stories has many opportunities and challenges. Considering the exploration of NLP techniques and rigorous evaluation methods is required to obtain quality research. As with NLP research in general, the ability to understand a sentence’s context continues to be a challenge.",Document_255,Building organizational support for AI through education and communication,0.058516714721918106,"Education, Awareness, and Policy Strategies"
Regulation and NLP (RegNLP): Taming Large Language Models,"Catalina Goanta, Nikolaos Aletras, Ilias Chalkidis, S. Ranchordas, Gerasimos Spanakis","The scientific innovation in Natural Language Processing (NLP) and more broadly in artificial intelligence (AI) is at its fastest pace to date. As large language models (LLMs) unleash a new era of automation, important debates emerge regarding the benefits and risks of their development, deployment and use. Currently, these debates have been dominated by often polarized narratives mainly led by the AI Safety and AI Ethics movements. This polarization, often amplified by social media, is swaying political agendas on AI regulation and governance and posing issues of regulatory capture. Capture occurs when the regulator advances the interests of the industry it is supposed to regulate, or of special interest groups rather than pursuing the general public interest. Meanwhile in NLP research, attention has been increasingly paid to the discussion of regulating risks and harms. This often happens without systematic methodologies or sufficient rooting in the disciplines that inspire an extended scope of NLP research, jeopardizing the scientific integrity of these endeavors. Regulation studies are a rich source of knowledge on how to systematically deal with risk and uncertainty, as well as with scientific evidence, to evaluate and compare regulatory options. This resource has largely remained untapped so far. In this paper, we argue how NLP research on these topics can benefit from proximity to regulatory studies and adjacent fields. We do so by discussing basic tenets of regulation, and risk and uncertainty, and by highlighting the shortcomings of current NLP discussions dealing with risk assessment. Finally, we advocate for the development of a new multidisciplinary research space on regulation and NLP (RegNLP), focused on connecting scientific knowledge to regulatory processes based on systematic methodologies. ",2023,2023,,Conference on Empirical Methods in Natural Language Processing,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2310.05553,10.48550/arXiv.2310.05553,https://doi.org/10.48550/arXiv.2310.05553,2,"The scientific innovation in Natural Language Processing (NLP) and more broadly in artificial intelligence (AI) is at its fastest pace to date. As large language models (LLMs) unleash a new era of automation, important debates emerge regarding the benefits and risks of their development, deployment and use. Currently, these debates have been dominated by often polarized narratives mainly led by the AI Safety and AI Ethics movements. This polarization, often amplified by social media, is swaying political agendas on AI regulation and governance and posing issues of regulatory capture. Capture occurs when the regulator advances the interests of the industry it is supposed to regulate, or of special interest groups rather than pursuing the general public interest. Meanwhile in NLP research, attention has been increasingly paid to the discussion of regulating risks and harms. This often happens without systematic methodologies or sufficient rooting in the disciplines that inspire an extended scope of NLP research, jeopardizing the scientific integrity of these endeavors. Regulation studies are a rich source of knowledge on how to systematically deal with risk and uncertainty, as well as with scientific evidence, to evaluate and compare regulatory options. This resource has largely remained untapped so far. In this paper, we argue how NLP research on these topics can benefit from proximity to regulatory studies and adjacent fields. We do so by discussing basic tenets of regulation, and risk and uncertainty, and by highlighting the shortcomings of current NLP discussions dealing with risk assessment. Finally, we advocate for the development of a new multidisciplinary research space on regulation and NLP (RegNLP), focused on connecting scientific knowledge to regulatory processes based on systematic methodologies. ",Document_256,Technical aspects or methods of AI or machine learning,0.19551138579845428,Other Categories
Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks,"Fatemehsadat Mireshghallah, Kartik Goyal, Archit Uniyal, Taylor Berg-Kirkpatrick, R. Shokri","The wide adoption and application of Masked language models~(MLMs) on sensitive data (from legal to medical) necessitates a thorough quantitative investigation into their privacy vulnerabilities -- to what extent do MLMs leak information about their training data? Prior attempts at measuring leakage of MLMs via membership inference attacks have been inconclusive, implying the potential robustness of MLMs to privacy attacks. In this work, we posit that prior attempts were inconclusive because they based their attack solely on the MLM's model score. We devise a stronger membership inference attack based on likelihood ratio hypothesis testing that involves an additional reference MLM to more accurately quantify the privacy risks of memorization in MLMs. We show that masked language models are extremely susceptible to likelihood ratio membership inference attacks: Our empirical results, on models trained on medical notes, show that our attack improves the AUC of prior membership inference attacks from 0.66 to an alarmingly high 0.90 level, with a significant improvement in the low-error region: at 1% false positive rate, our attack is 51X more powerful than prior work.",2022,2022,,Conference on Empirical Methods in Natural Language Processing,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2203.03929,10.48550/arXiv.2203.03929,https://doi.org/10.48550/arXiv.2203.03929,127,"The wide adoption and application of Masked language models~(MLMs) on sensitive data (from legal to medical) necessitates a thorough quantitative investigation into their privacy vulnerabilities -- to what extent do MLMs leak information about their training data? Prior attempts at measuring leakage of MLMs via membership inference attacks have been inconclusive, implying the potential robustness of MLMs to privacy attacks. In this work, we posit that prior attempts were inconclusive because they based their attack solely on the MLM's model score. We devise a stronger membership inference attack based on likelihood ratio hypothesis testing that involves an additional reference MLM to more accurately quantify the privacy risks of memorization in MLMs. We show that masked language models are extremely susceptible to likelihood ratio membership inference attacks: Our empirical results, on models trained on medical notes, show that our attack improves the AUC of prior membership inference attacks from 0.66 to an alarmingly high 0.90 level, with a significant improvement in the low-error region: at 1% false positive rate, our attack is 51X more powerful than prior work.",Document_257,Difficulty in understanding AI decision-making is a barrier in finance,0.06856586784124374,Explainability and Transparency Barriers
Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models,"Esma Balkir, S. Kiritchenko, Isar Nejadgholi, Kathleen C. Fraser","The wide adoption and application of Masked language models~(MLMs) on sensitive data (from legal to medical) necessitates a thorough quantitative investigation into their privacy vulnerabilities -- to what extent do MLMs leak information about their training data? Prior attempts at measuring leakage of MLMs via membership inference attacks have been inconclusive, implying the potential robustness of MLMs to privacy attacks. In this work, we posit that prior attempts were inconclusive because they based their attack solely on the MLM's model score. We devise a stronger membership inference attack based on likelihood ratio hypothesis testing that involves an additional reference MLM to more accurately quantify the privacy risks of memorization in MLMs. We show that masked language models are extremely susceptible to likelihood ratio membership inference attacks: Our empirical results, on models trained on medical notes, show that our attack improves the AUC of prior membership inference attacks from 0.66 to an alarmingly high 0.90 level, with a significant improvement in the low-error region: at 1% false positive rate, our attack is 51X more powerful than prior work. Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR) Cite as: arXiv:2203.03929 [cs.LG] (or arXiv:2203.03929v2 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2203.03929 Focus to learn more arXiv-issued DOI via DataCite[Submitted on 8 Jun 2022] Title: Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models Authors: Esma Balkir , Svetlana Kiritchenko , Isar Nejadgholi , Kathleen C. Fraser View a PDF of the paper titled Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models, by Esma Balkir and 3 other authors View PDF Abstract: Motivations for methods in explainable artificial intelligence (XAI) often include detecting, quantifying and mitigating bias, and contributing to making machine learning models fairer. However, exactly how an XAI method can help in combating biases is often left unspecified. In this paper, we briefly review trends in explainability and fairness in NLP research, identify the current practices in which explainability methods are applied to detect and mitigate bias, and investigate the barriers preventing XAI methods from being used more widely in tackling fairness issues.",2022,2022,,TRUSTNLP,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2206.03945,10.48550/arXiv.2206.03945,https://doi.org/10.48550/arXiv.2206.03945,32,"The wide adoption and application of Masked language models~(MLMs) on sensitive data (from legal to medical) necessitates a thorough quantitative investigation into their privacy vulnerabilities -- to what extent do MLMs leak information about their training data? Prior attempts at measuring leakage of MLMs via membership inference attacks have been inconclusive, implying the potential robustness of MLMs to privacy attacks. In this work, we posit that prior attempts were inconclusive because they based their attack solely on the MLM's model score. We devise a stronger membership inference attack based on likelihood ratio hypothesis testing that involves an additional reference MLM to more accurately quantify the privacy risks of memorization in MLMs. We show that masked language models are extremely susceptible to likelihood ratio membership inference attacks: Our empirical results, on models trained on medical notes, show that our attack improves the AUC of prior membership inference attacks from 0.66 to an alarmingly high 0.90 level, with a significant improvement in the low-error region: at 1% false positive rate, our attack is 51X more powerful than prior work. Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR) Cite as: arXiv:2203.03929 [cs.LG] (or arXiv:2203.03929v2 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2203.03929 Focus to learn more arXiv-issued DOI via DataCite[Submitted on 8 Jun 2022] Title: Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models Authors: Esma Balkir , Svetlana Kiritchenko , Isar Nejadgholi , Kathleen C. Fraser View a PDF of the paper titled Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models, by Esma Balkir and 3 other authors View PDF Abstract: Motivations for methods in explainable artificial intelligence (XAI) often include detecting, quantifying and mitigating bias, and contributing to making machine learning models fairer. However, exactly how an XAI method can help in combating biases is often left unspecified. In this paper, we briefly review trends in explainability and fairness in NLP research, identify the current practices in which explainability methods are applied to detect and mitigate bias, and investigate the barriers preventing XAI methods from being used more widely in tackling fairness issues.",Document_258,Technical aspects or methods of AI or machine learning,0.457193523645401,Other Categories
Ethical and social risks of harm from Language Models,"Laura Weidinger, John F. J. Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, Zachary Kenton, S. Brown, W. Hawkins, T. Stepleton, Courtney Biles, Abeba Birhane, Julia Haas, Laura Rimell, Lisa Anne Hendricks, William S. Isaac, Sean Legassick, G. Irving, Iason Gabriel","This paper aims to help structure the risk landscape associated with large-scale Language Models (LMs). In order to foster advances in responsible innovation, an in-depth understanding of the potential risks posed by these models is needed. A wide range of established and anticipated risks are analysed in detail, drawing on multidisciplinary expertise and literature from computer science, linguistics, and social sciences. We outline six specific risk areas: I. Discrimination, Exclusion and Toxicity, II. Information Hazards, III. Misinformation Harms, V. Malicious Uses, V. Human-Computer Interaction Harms, VI. Automation, Access, and Environmental Harms. The first area concerns the perpetuation of stereotypes, unfair discrimination, exclusionary norms, toxic language, and lower performance by social group for LMs. The second focuses on risks from private data leaks or LMs correctly inferring sensitive information. The third addresses risks arising from poor, false or misleading information including in sensitive domains, and knock-on risks such as the erosion of trust in shared information. The fourth considers risks from actors who try to use LMs to cause harm. The fifth focuses on risks specific to LLMs used to underpin conversational agents that interact with human users, including unsafe use, manipulation or deception. The sixth discusses the risk of environmental harm, job automation, and other challenges that may have a disparate effect on different social groups or communities. In total, we review 21 risks in-depth. We discuss the points of origin of different risks and point to potential mitigation approaches. Lastly, we discuss organisational responsibilities in implementing mitigations, and the role of collaboration and participation. We highlight directions for further research, particularly on expanding the toolkit for assessing and evaluating the outlined risks in LMs.",2021,2021,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2112.04359,-,https://doi.org/10.48550/arXiv.2112.04359,835,"This paper aims to help structure the risk landscape associated with large-scale Language Models (LMs). In order to foster advances in responsible innovation, an in-depth understanding of the potential risks posed by these models is needed. A wide range of established and anticipated risks are analysed in detail, drawing on multidisciplinary expertise and literature from computer science, linguistics, and social sciences. We outline six specific risk areas: I. Discrimination, Exclusion and Toxicity, II. Information Hazards, III. Misinformation Harms, V. Malicious Uses, V. Human-Computer Interaction Harms, VI. Automation, Access, and Environmental Harms. The first area concerns the perpetuation of stereotypes, unfair discrimination, exclusionary norms, toxic language, and lower performance by social group for LMs. The second focuses on risks from private data leaks or LMs correctly inferring sensitive information. The third addresses risks arising from poor, false or misleading information including in sensitive domains, and knock-on risks such as the erosion of trust in shared information. The fourth considers risks from actors who try to use LMs to cause harm. The fifth focuses on risks specific to LLMs used to underpin conversational agents that interact with human users, including unsafe use, manipulation or deception. The sixth discusses the risk of environmental harm, job automation, and other challenges that may have a disparate effect on different social groups or communities. In total, we review 21 risks in-depth. We discuss the points of origin of different risks and point to potential mitigation approaches. Lastly, we discuss organisational responsibilities in implementing mitigations, and the role of collaboration and participation. We highlight directions for further research, particularly on expanding the toolkit for assessing and evaluating the outlined risks in LMs.",Document_259,Demonstrating the value of AI for compliance and risk management,0.07788724452257156,Business Case and Value Demonstration Strategies
Fixing Model Bugs with Natural Language Patches,"Shikhar Murty, Christopher D. Manning, Scott M. Lundberg, Marco Tulio Ribeiro","Current approaches for fixing systematic problems in NLP models (e.g. regex patches, finetuning on more data) are either brittle, or labor-intensive and liable to shortcuts. In contrast, humans often provide corrections to each other through natural language. Taking inspiration from this, we explore natural language patches -- declarative statements that allow developers to provide corrective feedback at the right level of abstraction, either overriding the model (``if a review gives 2 stars, the sentiment is negative'') or providing additional information the model may lack (``if something is described as the bomb, then it is good''). We model the task of determining if a patch applies separately from the task of integrating patch information, and show that with a small amount of synthetic data, we can teach models to effectively use real patches on real data -- 1 to 7 patches improve accuracy by ~1-4 accuracy points on different slices of a sentiment analysis dataset, and F1 by 7 points on a relation extraction dataset. Finally, we show that finetuning on as many as 100 labeled examples may be needed to match the performance of a small set of language patches. Comments: Accepted at EMNLP 2022 [Fixed fig-1]",2022,2022,,Conference on Empirical Methods in Natural Language Processing,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2211.03318,10.48550/arXiv.2211.03318,https://doi.org/10.48550/arXiv.2211.03318,38,"Current approaches for fixing systematic problems in NLP models (e.g. regex patches, finetuning on more data) are either brittle, or labor-intensive and liable to shortcuts. In contrast, humans often provide corrections to each other through natural language. Taking inspiration from this, we explore natural language patches -- declarative statements that allow developers to provide corrective feedback at the right level of abstraction, either overriding the model (``if a review gives 2 stars, the sentiment is negative'') or providing additional information the model may lack (``if something is described as the bomb, then it is good''). We model the task of determining if a patch applies separately from the task of integrating patch information, and show that with a small amount of synthetic data, we can teach models to effectively use real patches on real data -- 1 to 7 patches improve accuracy by ~1-4 accuracy points on different slices of a sentiment analysis dataset, and F1 by 7 points on a relation extraction dataset. Finally, we show that finetuning on as many as 100 labeled examples may be needed to match the performance of a small set of language patches. Comments: Accepted at EMNLP 2022 [Fixed fig-1]",Document_260,Technical aspects or methods of AI or machine learning,0.0839935913681984,Other Categories
Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples,"Hezekiah J. Branch, Jonathan Rodriguez Cefalu, Jeremy McHugh, Leyla Hujer, Aditya Bahl, Daniel del Castillo Iglesias, Ron Heichman, Ramesh Darwishi","Recent advances in the development of large language models have resulted in public access to state-of-the-art pre-trained language models (PLMs), including Generative Pre-trained Transformer 3 (GPT-3) and Bidirectional Encoder Representations from Transformers (BERT). However, evaluations of PLMs, in practice, have shown their susceptibility to adversarial attacks during the training and fine-tuning stages of development. Such attacks can result in erroneous outputs, model-generated hate speech, and the exposure of users' sensitive information. While existing research has focused on adversarial attacks during either the training or the fine-tuning of PLMs, there is a deficit of information on attacks made between these two development phases. In this work, we highlight a major security vulnerability in the public release of GPT-3 and further investigate this vulnerability in other state-of-the-art PLMs. We restrict our work to pre-trained models that have not undergone fine-tuning. Further, we underscore token distance-minimized perturbations as an effective adversarial approach, bypassing both supervised and unsupervised quality measures. Following this approach, we observe a significant decrease in text classification quality when evaluating for semantic similarity.",2022,2022,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2209.02128,10.48550/arXiv.2209.02128,https://doi.org/10.48550/arXiv.2209.02128,42,"Recent advances in the development of large language models have resulted in public access to state-of-the-art pre-trained language models (PLMs), including Generative Pre-trained Transformer 3 (GPT-3) and Bidirectional Encoder Representations from Transformers (BERT). However, evaluations of PLMs, in practice, have shown their susceptibility to adversarial attacks during the training and fine-tuning stages of development. Such attacks can result in erroneous outputs, model-generated hate speech, and the exposure of users' sensitive information. While existing research has focused on adversarial attacks during either the training or the fine-tuning of PLMs, there is a deficit of information on attacks made between these two development phases. In this work, we highlight a major security vulnerability in the public release of GPT-3 and further investigate this vulnerability in other state-of-the-art PLMs. We restrict our work to pre-trained models that have not undergone fine-tuning. Further, we underscore token distance-minimized perturbations as an effective adversarial approach, bypassing both supervised and unsupervised quality measures. Following this approach, we observe a significant decrease in text classification quality when evaluating for semantic similarity.",Document_261,Technical aspects or methods of AI or machine learning,0.09135628491640091,Other Categories
Best Practices for Text Annotation with Large Language Models,Petter Törnberg,"Large Language Models (LLMs) have ushered in a new era of text annotation, as their ease-of-use, high accuracy, and relatively low costs have meant that their use has exploded in recent months. However, the rapid growth of the field has meant that LLM-based annotation has become something of an academic Wild West: the lack of established practices and standards has led to concerns about the quality and validity of research. Researchers have warned that the ostensible simplicity of LLMs can be misleading, as they are prone to bias, misunderstandings, and unreliable results. Recognizing the transformative potential of LLMs, this paper proposes a comprehensive set of standards and best practices for their reliable, reproducible, and ethical use. These guidelines span critical areas such as model selection, prompt engineering, structured prompting, prompt stability analysis, rigorous model validation, and the consideration of ethical and legal implications. The paper emphasizes the need for a structured, directed, and formalized approach to using LLMs, aiming to ensure the integrity and robustness of text annotation practices, and advocates for a nuanced and critical engagement with LLMs in social scientific research. ",2024,2024,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2402.05129,10.48550/arXiv.2402.05129,https://doi.org/10.48550/arXiv.2402.05129,10,"Large Language Models (LLMs) have ushered in a new era of text annotation, as their ease-of-use, high accuracy, and relatively low costs have meant that their use has exploded in recent months. However, the rapid growth of the field has meant that LLM-based annotation has become something of an academic Wild West: the lack of established practices and standards has led to concerns about the quality and validity of research. Researchers have warned that the ostensible simplicity of LLMs can be misleading, as they are prone to bias, misunderstandings, and unreliable results. Recognizing the transformative potential of LLMs, this paper proposes a comprehensive set of standards and best practices for their reliable, reproducible, and ethical use. These guidelines span critical areas such as model selection, prompt engineering, structured prompting, prompt stability analysis, rigorous model validation, and the consideration of ethical and legal implications. The paper emphasizes the need for a structured, directed, and formalized approach to using LLMs, aiming to ensure the integrity and robustness of text annotation practices, and advocates for a nuanced and critical engagement with LLMs in social scientific research. ",Document_262,Building organizational support for AI through education and communication,0.05513806641101837,"Education, Awareness, and Policy Strategies"
Socio-economic landscape of digital transformation & public NLP systems: A critical review,"Satyam Mohla, Anupam Guha","The current wave of digital transformation has spurred digitisation reforms and has led to prodigious development of AI & NLP systems, with several of them entering the public domain. There is a perception that these systems have a non trivial impact on society but there is a dearth of literature in critical AI exploring what kinds of systems exist and how do they operate. This paper constructs a broad taxonomy of NLP systems which impact or are impacted by the ``public'' and provides a concrete analyses via various instrumental and normative lenses on the socio-technical nature of these systems. This paper categorises thirty examples of these systems into seven families, namely; finance, customer service, policy making, education, healthcare, law, and security, based on their public use cases. It then critically analyses these applications, first the priors and assumptions they are based on, then their mechanisms, possible methods of data collection, the models and error functions used, etc. This paper further delves into exploring the socio-economic and political contexts in which these families of systems are generally used and their potential impact on the same, and the function creep of these systems. It provides commentary on the potential long-term downstream impact of these systems on communities which use them. Aside from providing a birds eye view of what exists our in depth analysis provides insights on what is lacking in the current discourse on NLP in particular and critical AI in general, proposes additions to the current framework of analysis, provides recommendations future research direction, and highlights the need to importance of exploring the social in this socio-technical system.",2023,2023,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2304.01651,10.48550/arXiv.2304.01651,https://doi.org/10.48550/arXiv.2304.01651,1,"The current wave of digital transformation has spurred digitisation reforms and has led to prodigious development of AI & NLP systems, with several of them entering the public domain. There is a perception that these systems have a non trivial impact on society but there is a dearth of literature in critical AI exploring what kinds of systems exist and how do they operate. This paper constructs a broad taxonomy of NLP systems which impact or are impacted by the ``public'' and provides a concrete analyses via various instrumental and normative lenses on the socio-technical nature of these systems. This paper categorises thirty examples of these systems into seven families, namely; finance, customer service, policy making, education, healthcare, law, and security, based on their public use cases. It then critically analyses these applications, first the priors and assumptions they are based on, then their mechanisms, possible methods of data collection, the models and error functions used, etc. This paper further delves into exploring the socio-economic and political contexts in which these families of systems are generally used and their potential impact on the same, and the function creep of these systems. It provides commentary on the potential long-term downstream impact of these systems on communities which use them. Aside from providing a birds eye view of what exists our in depth analysis provides insights on what is lacking in the current discourse on NLP in particular and critical AI in general, proposes additions to the current framework of analysis, provides recommendations future research direction, and highlights the need to importance of exploring the social in this socio-technical system.",Document_263,Technical aspects or methods of AI or machine learning,0.226853609085083,Other Categories
Generating Natural Adversarial Examples,"Zhengli Zhao, Dheeru Dua, Sameer Singh","Due to their complex nature, it is hard to characterize the ways in which machine learning models can misbehave or be exploited when deployed. Recent work on adversarial examples, i.e. inputs with minor perturbations that result in substantially different model predictions, is helpful in evaluating the robustness of these models by exposing the adversarial scenarios where they fail. However, these malicious perturbations are often unnatural, not semantically meaningful, and not applicable to complicated domains such as language. In this paper, we propose a framework to generate natural and legible adversarial examples that lie on the data manifold, by searching in semantic space of dense and continuous data representation, utilizing the recent advances in generative adversarial networks. We present generated adversaries to demonstrate the potential of the proposed approach for black-box classifiers for a wide range of applications such as image classification, textual entailment, and machine translation. We include experiments to show that the generated adversaries are natural, legible to humans, and useful in evaluating and analyzing black-box classifiers.",2017,2017,,International Conference on Learning Representations,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.1710.11342,-,https://doi.org/10.48550/arXiv.1710.11342,585,"Due to their complex nature, it is hard to characterize the ways in which machine learning models can misbehave or be exploited when deployed. Recent work on adversarial examples, i.e. inputs with minor perturbations that result in substantially different model predictions, is helpful in evaluating the robustness of these models by exposing the adversarial scenarios where they fail. However, these malicious perturbations are often unnatural, not semantically meaningful, and not applicable to complicated domains such as language. In this paper, we propose a framework to generate natural and legible adversarial examples that lie on the data manifold, by searching in semantic space of dense and continuous data representation, utilizing the recent advances in generative adversarial networks. We present generated adversaries to demonstrate the potential of the proposed approach for black-box classifiers for a wide range of applications such as image classification, textual entailment, and machine translation. We include experiments to show that the generated adversaries are natural, legible to humans, and useful in evaluating and analyzing black-box classifiers.",Document_264,Technical aspects or methods of AI or machine learning,0.22015981376171112,Other Categories
BloombergGPT: A Large Language Model for Finance,"Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, P. Kambadur, D. Rosenberg, Gideon Mann","The use of NLP in the realm of financial technology is broad and complex, with applications ranging from sentiment analysis and named entity recognition to question answering. Large Language Models (LLMs) have been shown to be effective on a variety of tasks; however, no LLM specialized for the financial domain has been reported in literature. In this work, we present BloombergGPT, a 50 billion parameter language model that is trained on a wide range of financial data. We construct a 363 billion token dataset based on Bloomberg's extensive data sources, perhaps the largest domain-specific dataset yet, augmented with 345 billion tokens from general purpose datasets. We validate BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite of internal benchmarks that most accurately reflect our intended usage. Our mixed dataset training leads to a model that outperforms existing models on financial tasks by significant margins without sacrificing performance on general LLM benchmarks. Additionally, we explain our modeling choices, training process, and evaluation methodology. We release Training Chronicles (Appendix C) detailing our experience in training BloombergGPT.",2023,2023,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2303.17564,10.48550/arXiv.2303.17564,https://doi.org/10.48550/arXiv.2303.17564,614,"The use of NLP in the realm of financial technology is broad and complex, with applications ranging from sentiment analysis and named entity recognition to question answering. Large Language Models (LLMs) have been shown to be effective on a variety of tasks; however, no LLM specialized for the financial domain has been reported in literature. In this work, we present BloombergGPT, a 50 billion parameter language model that is trained on a wide range of financial data. We construct a 363 billion token dataset based on Bloomberg's extensive data sources, perhaps the largest domain-specific dataset yet, augmented with 345 billion tokens from general purpose datasets. We validate BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite of internal benchmarks that most accurately reflect our intended usage. Our mixed dataset training leads to a model that outperforms existing models on financial tasks by significant margins without sacrificing performance on general LLM benchmarks. Additionally, we explain our modeling choices, training process, and evaluation methodology. We release Training Chronicles (Appendix C) detailing our experience in training BloombergGPT.",Document_265,Difficulty in understanding AI decision-making is a barrier in finance,0.08116555958986282,Explainability and Transparency Barriers
NBIAS: A Natural Language Processing Framework for Bias Identification in Text,"Shaina Razaa, Muskan Garg, Deepak John Reji, S. Bashir, Chen Ding","Bias in textual data can lead to skewed interpretations and outcomes when the data is used. These biases could perpetuate stereotypes, discrimination, or other forms of unfair treatment. An algorithm trained on biased data may end up making decisions that disproportionately impact a certain group of people. Therefore, it is crucial to detect and remove these biases to ensure the fair and ethical use of data. To this end, we develop a comprehensive and robust framework NBIAS that consists of four main layers: data, corpus construction, model development and an evaluation layer. The dataset is constructed by collecting diverse data from various domains, including social media, healthcare, and job hiring portals. As such, we applied a transformer-based token classification model that is able to identify bias words/ phrases through a unique named entity BIAS. In the evaluation procedure, we incorporate a blend of quantitative and qualitative measures to gauge the effectiveness of our models. We achieve accuracy improvements ranging from 1% to 8% compared to baselines. We are also able to generate a robust understanding of the model functioning. The proposed approach is applicable to a variety of biases and contributes to the fair and ethical use of textual data.",2023,2023,,Expert systems with applications,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2308.01681,10.48550/arXiv.2308.01681,https://doi.org/10.48550/arXiv.2308.01681,33,"Bias in textual data can lead to skewed interpretations and outcomes when the data is used. These biases could perpetuate stereotypes, discrimination, or other forms of unfair treatment. An algorithm trained on biased data may end up making decisions that disproportionately impact a certain group of people. Therefore, it is crucial to detect and remove these biases to ensure the fair and ethical use of data. To this end, we develop a comprehensive and robust framework NBIAS that consists of four main layers: data, corpus construction, model development and an evaluation layer. The dataset is constructed by collecting diverse data from various domains, including social media, healthcare, and job hiring portals. As such, we applied a transformer-based token classification model that is able to identify bias words/ phrases through a unique named entity BIAS. In the evaluation procedure, we incorporate a blend of quantitative and qualitative measures to gauge the effectiveness of our models. We achieve accuracy improvements ranging from 1% to 8% compared to baselines. We are also able to generate a robust understanding of the model functioning. The proposed approach is applicable to a variety of biases and contributes to the fair and ethical use of textual data.",Document_266,Technical aspects or methods of AI or machine learning,0.06960925459861755,Other Categories
Is it possible not to cheat on the Turing Test: Exploring the potential and challenges for true natural language 'understanding' by computers,Lize Alberts,"Recent hype surrounding the increasing sophistication of language processing models has renewed optimism regarding machines achieving a human-like command of natural language. Research in the area of natural language understanding (NLU) in artificial intelligence claims to have been making great strides in this area, however, the lack of conceptual clarity/consistency in how 'understanding' is used in this and other disciplines makes it difficult to discern how close we actually are. In this interdisciplinary research thesis, I integrate insights from cognitive science/psychology, philosophy of mind, and cognitive linguistics, and evaluate it against a critical review of current approaches in NLU to explore the basic requirements--and remaining challenges--for developing artificially intelligent systems with human-like capacities for language use and comprehension. Comments: Philosophy master's thesis (2020) available on the SUNScholar research repository ( this https URL )",2022,2022,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2206.14672,10.48550/arXiv.2206.14672,https://doi.org/10.48550/arXiv.2206.14672,1,"Recent hype surrounding the increasing sophistication of language processing models has renewed optimism regarding machines achieving a human-like command of natural language. Research in the area of natural language understanding (NLU) in artificial intelligence claims to have been making great strides in this area, however, the lack of conceptual clarity/consistency in how 'understanding' is used in this and other disciplines makes it difficult to discern how close we actually are. In this interdisciplinary research thesis, I integrate insights from cognitive science/psychology, philosophy of mind, and cognitive linguistics, and evaluate it against a critical review of current approaches in NLU to explore the basic requirements--and remaining challenges--for developing artificially intelligent systems with human-like capacities for language use and comprehension. Comments: Philosophy master's thesis (2020) available on the SUNScholar research repository ( this https URL )",Document_267,Technical aspects or methods of AI or machine learning,0.06174594163894653,Other Categories
On the Security Vulnerabilities of Text-to-SQL Models,"Xutan Peng, Yipeng Zhang, Jingfeng Yang, Mark Stevenson","Although it has been demonstrated that Natural Language Processing (NLP) algorithms are vulnerable to deliberate attacks, the question of whether such weaknesses can lead to software security threats is under-explored. To bridge this gap, we conducted vulnerability tests on Text-to-SQL systems that are commonly used to create natural language interfaces to databases. We showed that the Text-to-SQL modules within six commercial applications can be manipulated to produce malicious code, potentially leading to data breaches and Denial of Service attacks. This is the first demonstration that NLP models can be exploited as attack vectors in the wild. In addition, experiments using four open-source language models verified that straightforward backdoor attacks on Text-to-SQL systems achieve a 100% success rate without affecting their performance. The aim of this work is to draw the community's attention to potential software security issues associated with NLP algorithms and encourage exploration of methods to mitigate against them.",2022,2022,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2211.15363,10.48550/arXiv.2211.15363,https://doi.org/10.48550/arXiv.2211.15363,3,"Although it has been demonstrated that Natural Language Processing (NLP) algorithms are vulnerable to deliberate attacks, the question of whether such weaknesses can lead to software security threats is under-explored. To bridge this gap, we conducted vulnerability tests on Text-to-SQL systems that are commonly used to create natural language interfaces to databases. We showed that the Text-to-SQL modules within six commercial applications can be manipulated to produce malicious code, potentially leading to data breaches and Denial of Service attacks. This is the first demonstration that NLP models can be exploited as attack vectors in the wild. In addition, experiments using four open-source language models verified that straightforward backdoor attacks on Text-to-SQL systems achieve a 100% success rate without affecting their performance. The aim of this work is to draw the community's attention to potential software security issues associated with NLP algorithms and encourage exploration of methods to mitigate against them.",Document_268,Difficulty in understanding AI decision-making is a barrier in finance,0.07097519934177399,Explainability and Transparency Barriers
Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost,"Parikshit Bansal, Amit Sharma","State-of-the-art supervised NLP models achieve high accuracy but are also susceptible to failures on inputs from low-data regimes, such as domains that are not represented in training data. As an approximation to collecting ground-truth labels for the specific domain, we study the use of large language models (LLMs) for annotating inputs and improving the generalization of NLP models. Specifically, given a budget for LLM annotations, we present an algorithm for sampling the most informative inputs to annotate and retrain the NLP model. We find that popular active learning strategies such as uncertainty-based sampling do not work well. Instead, we propose a sampling strategy based on the difference in prediction scores between the base model and the finetuned NLP model, utilizing the fact that most NLP models are finetuned from a base model. Experiments with classification (semantic similarity) and ranking (semantic search) tasks show that our sampling strategy leads to significant gains in accuracy for both the training and target domains.",2023,2023,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2306.15766,10.48550/arXiv.2306.15766,https://doi.org/10.48550/arXiv.2306.15766,35,"State-of-the-art supervised NLP models achieve high accuracy but are also susceptible to failures on inputs from low-data regimes, such as domains that are not represented in training data. As an approximation to collecting ground-truth labels for the specific domain, we study the use of large language models (LLMs) for annotating inputs and improving the generalization of NLP models. Specifically, given a budget for LLM annotations, we present an algorithm for sampling the most informative inputs to annotate and retrain the NLP model. We find that popular active learning strategies such as uncertainty-based sampling do not work well. Instead, we propose a sampling strategy based on the difference in prediction scores between the base model and the finetuned NLP model, utilizing the fact that most NLP models are finetuned from a base model. Experiments with classification (semantic similarity) and ranking (semantic search) tasks show that our sampling strategy leads to significant gains in accuracy for both the training and target domains.",Document_269,Technical aspects or methods of AI or machine learning,0.09084989130496979,Other Categories
FinBERT: Financial Sentiment Analysis with Pre-trained Language Models,Dogu Araci,"Financial sentiment analysis is a challenging task due to the specialized language and lack of labeled data in that domain. General-purpose models are not effective enough because of the specialized language used in a financial context. We hypothesize that pre-trained language models can help with this problem because they require fewer labeled examples and they can be further trained on domain-specific corpora. We introduce FinBERT, a language model based on BERT, to tackle NLP tasks in the financial domain. Our results show improvement in every measured metric on current state-of-the-art results for two financial sentiment analysis datasets. We find that even with a smaller training set and fine-tuning only a part of the model, FinBERT outperforms state-of-the-art machine learning methods. ",2019,2019,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.1908.10063,-,https://doi.org/10.48550/arXiv.1908.10063,556,"Financial sentiment analysis is a challenging task due to the specialized language and lack of labeled data in that domain. General-purpose models are not effective enough because of the specialized language used in a financial context. We hypothesize that pre-trained language models can help with this problem because they require fewer labeled examples and they can be further trained on domain-specific corpora. We introduce FinBERT, a language model based on BERT, to tackle NLP tasks in the financial domain. Our results show improvement in every measured metric on current state-of-the-art results for two financial sentiment analysis datasets. We find that even with a smaller training set and fine-tuning only a part of the model, FinBERT outperforms state-of-the-art machine learning methods. ",Document_270,Improving data quality is crucial for successful AI in finance,0.08839306235313416,Data Improvement and Availability Strategies
Are aligned neural networks adversarially aligned?,"Nicholas Carlini, Milad Nasr, Christopher A. Choquette-Choo, Matthew Jagielski, Irena Gao, Anas Awadalla, Pang Wei Koh, Daphne Ippolito, Katherine Lee, Florian Tramèr, Ludwig Schmidt","Large language models are now tuned to align with the goals of their creators, namely to be ""helpful and harmless."" These models should respond helpfully to user questions, but refuse to answer requests that could cause harm. However, adversarial users can construct inputs which circumvent attempts at alignment. In this work, we study adversarial alignment, and ask to what extent these models remain aligned when interacting with an adversarial user who constructs worst-case inputs (adversarial examples). These inputs are designed to cause the model to emit harmful content that would otherwise be prohibited. We show that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models: even when current NLP-based attacks fail, we can find adversarial inputs with brute force. As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs. However the recent trend in large-scale ML models is multimodal models that allow users to provide images that influence the text that is generated. We show these models can be easily attacked, i.e., induced to perform arbitrary un-aligned behavior through adversarial perturbation of the input image. We conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models. ",2023,2023,,Neural Information Processing Systems,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2306.15447,10.48550/arXiv.2306.15447,https://doi.org/10.48550/arXiv.2306.15447,178,"Large language models are now tuned to align with the goals of their creators, namely to be ""helpful and harmless."" These models should respond helpfully to user questions, but refuse to answer requests that could cause harm. However, adversarial users can construct inputs which circumvent attempts at alignment. In this work, we study adversarial alignment, and ask to what extent these models remain aligned when interacting with an adversarial user who constructs worst-case inputs (adversarial examples). These inputs are designed to cause the model to emit harmful content that would otherwise be prohibited. We show that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models: even when current NLP-based attacks fail, we can find adversarial inputs with brute force. As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs. However the recent trend in large-scale ML models is multimodal models that allow users to provide images that influence the text that is generated. We show these models can be easily attacked, i.e., induced to perform arbitrary un-aligned behavior through adversarial perturbation of the input image. We conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models. ",Document_271,Technical aspects or methods of AI or machine learning,0.10134345293045044,Other Categories
Can Rationalization Improve Robustness?,"Howard Chen, Jacqueline He, Karthik Narasimhan, Danqi Chen","A growing line of work has investigated the development of neural NLP models that can produce rationales--subsets of input that can explain their model predictions. In this paper, we ask whether such rationale models can also provide robustness to adversarial attacks in addition to their interpretable nature. Since these models need to first generate rationales (""rationalizer"") before making predictions (""predictor""), they have the potential to ignore noise or adversarially added text by simply masking it out of the generated rationale. To this end, we systematically generate various types of 'AddText' attacks for both token and sentence-level rationalization tasks, and perform an extensive empirical evaluation of state-of-the-art rationale models across five different tasks. Our experiments reveal that the rationale models show the promise to improve robustness, while they struggle in certain scenarios--when the rationalizer is sensitive to positional bias or lexical choices of attack text. Further, leveraging human rationale as supervision does not always translate to better performance. Our study is a first step towards exploring the interplay between interpretability and robustness in the rationalize-then-predict framework. Comments: Accepted to NAACL 2022; The code is available at this https URL",2022,2022,,North American Chapter of the Association for Computational Linguistics,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2204.11790,10.48550/arXiv.2204.11790,https://doi.org/10.48550/arXiv.2204.11790,37,"A growing line of work has investigated the development of neural NLP models that can produce rationales--subsets of input that can explain their model predictions. In this paper, we ask whether such rationale models can also provide robustness to adversarial attacks in addition to their interpretable nature. Since these models need to first generate rationales (""rationalizer"") before making predictions (""predictor""), they have the potential to ignore noise or adversarially added text by simply masking it out of the generated rationale. To this end, we systematically generate various types of 'AddText' attacks for both token and sentence-level rationalization tasks, and perform an extensive empirical evaluation of state-of-the-art rationale models across five different tasks. Our experiments reveal that the rationale models show the promise to improve robustness, while they struggle in certain scenarios--when the rationalizer is sensitive to positional bias or lexical choices of attack text. Further, leveraging human rationale as supervision does not always translate to better performance. Our study is a first step towards exploring the interplay between interpretability and robustness in the rationalize-then-predict framework. Comments: Accepted to NAACL 2022; The code is available at this https URL",Document_272,Technical aspects or methods of AI or machine learning,0.08176334947347641,Other Categories
Robustness of Explanation Methods for NLP Models,"Shriya Atmakuri, Tejas Chheda, Dinesh Kandula, Nishant Yadav, Taesung Lee, Hessel Tuinhof","Explanation methods have emerged as an important tool to highlight the features responsible for the predictions of neural networks. There is mounting evidence that many explanation methods are rather unreliable and susceptible to malicious manipulations. In this paper, we particularly aim to understand the robustness of explanation methods in the context of text modality. We provide initial insights and results towards devising a successful adversarial attack against text explanations. To our knowledge, this is the first attempt to evaluate the adversarial robustness of an explanation method. Our experiments show the explanation method can be largely disturbed for up to 86% of the tested samples with small changes in the input sentence and its semantics.",2022,2022,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2206.12284,10.48550/arXiv.2206.12284,https://doi.org/10.48550/arXiv.2206.12284,4,"Explanation methods have emerged as an important tool to highlight the features responsible for the predictions of neural networks. There is mounting evidence that many explanation methods are rather unreliable and susceptible to malicious manipulations. In this paper, we particularly aim to understand the robustness of explanation methods in the context of text modality. We provide initial insights and results towards devising a successful adversarial attack against text explanations. To our knowledge, this is the first attempt to evaluate the adversarial robustness of an explanation method. Our experiments show the explanation method can be largely disturbed for up to 86% of the tested samples with small changes in the input sentence and its semantics.",Document_273,Technical aspects or methods of AI or machine learning,0.07807965576648712,Other Categories
Towards Faithful Model Explanation in NLP: A Survey,"Qing Lyu, Marianna Apidianaki, Chris Callison-Burch","nd-to-end neural Natural Language Processing (NLP) models are notoriously difficult to understand. This has given rise to numerous efforts towards model explainability in recent years. One desideratum of model explanation is faithfulness, i.e. an explanation should accurately represent the reasoning process behind the model's prediction. In this survey, we review over 110 model explanation methods in NLP through the lens of faithfulness. We first discuss the definition and evaluation of faithfulness, as well as its significance for explainability. We then introduce recent advances in faithful explanation, grouping existing approaches into five categories: similarity-based methods, analysis of model-internal structures, backpropagation-based methods, counterfactual intervention, and self-explanatory models. For each category, we synthesize its representative studies, strengths, and weaknesses. Finally, we summarize their common virtues and remaining challenges, and reflect on future work directions towards faithful explainability in NLP.",2022,2022,,Computational Linguistics,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2209.11326,10.48550/arXiv.2209.11326,https://doi.org/10.48550/arXiv.2209.11326,83,"nd-to-end neural Natural Language Processing (NLP) models are notoriously difficult to understand. This has given rise to numerous efforts towards model explainability in recent years. One desideratum of model explanation is faithfulness, i.e. an explanation should accurately represent the reasoning process behind the model's prediction. In this survey, we review over 110 model explanation methods in NLP through the lens of faithfulness. We first discuss the definition and evaluation of faithfulness, as well as its significance for explainability. We then introduce recent advances in faithful explanation, grouping existing approaches into five categories: similarity-based methods, analysis of model-internal structures, backpropagation-based methods, counterfactual intervention, and self-explanatory models. For each category, we synthesize its representative studies, strengths, and weaknesses. Finally, we summarize their common virtues and remaining challenges, and reflect on future work directions towards faithful explainability in NLP.",Document_274,Technical aspects or methods of AI or machine learning,0.06383813917636871,Other Categories
The Law and NLP: Bridging Disciplinary Disconnects,"Robert Mahari, Dominik Stammbach, Elliott Ash, A. Pentland","Legal practice is intrinsically rooted in the fabric of language, yet legal practitioners and scholars have been slow to adopt tools from natural language processing (NLP). At the same time, the legal system is experiencing an access to justice crisis, which could be partially alleviated with NLP. In this position paper, we argue that the slow uptake of NLP in legal practice is exacerbated by a disconnect between the needs of the legal community and the focus of NLP researchers. In a review of recent trends in the legal NLP literature, we find limited overlap between the legal NLP community and legal academia. Our interpretation is that some of the most popular legal NLP tasks fail to address the needs of legal practitioners. We discuss examples of legal NLP tasks that promise to bridge disciplinary disconnects and highlight interesting areas for legal NLP research that remain underexplored. ",2023,2023,,Conference on Empirical Methods in Natural Language Processing,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2310.14346,10.48550/arXiv.2310.14346,https://doi.org/10.48550/arXiv.2310.14346,6,"Legal practice is intrinsically rooted in the fabric of language, yet legal practitioners and scholars have been slow to adopt tools from natural language processing (NLP). At the same time, the legal system is experiencing an access to justice crisis, which could be partially alleviated with NLP. In this position paper, we argue that the slow uptake of NLP in legal practice is exacerbated by a disconnect between the needs of the legal community and the focus of NLP researchers. In a review of recent trends in the legal NLP literature, we find limited overlap between the legal NLP community and legal academia. Our interpretation is that some of the most popular legal NLP tasks fail to address the needs of legal practitioners. We discuss examples of legal NLP tasks that promise to bridge disciplinary disconnects and highlight interesting areas for legal NLP research that remain underexplored. ",Document_275,Technical aspects or methods of AI or machine learning,0.10310482978820801,Other Categories
Retrieval-Augmented Chain-of-Thought in Semi-structured Domains,"Vaibhav Mavi, Abulhair Saparov, Chen Zhao","Applying existing question answering (QA) systems to specialized domains like law and finance presents challenges that necessitate domain expertise. Although large language models (LLMs) have shown impressive language comprehension and in-context learning capabilities, their inability to handle very long inputs/contexts is well known. Tasks specific to these domains need significant background knowledge, leading to contexts that can often exceed the maximum length that existing LLMs can process. This study explores leveraging the semi-structured nature of legal and financial data to efficiently retrieve relevant context, enabling the use of LLMs for domain-specialized QA. The resulting system outperforms contemporary models and also provides useful explanations for the answers, encouraging the integration of LLMs into legal and financial NLP systems for future research. Comments: to appear in NLLP 2023",2023,2023,,NLLP,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2310.14435,10.48550/arXiv.2310.14435,https://doi.org/10.48550/arXiv.2310.14435,3,"Applying existing question answering (QA) systems to specialized domains like law and finance presents challenges that necessitate domain expertise. Although large language models (LLMs) have shown impressive language comprehension and in-context learning capabilities, their inability to handle very long inputs/contexts is well known. Tasks specific to these domains need significant background knowledge, leading to contexts that can often exceed the maximum length that existing LLMs can process. This study explores leveraging the semi-structured nature of legal and financial data to efficiently retrieve relevant context, enabling the use of LLMs for domain-specialized QA. The resulting system outperforms contemporary models and also provides useful explanations for the answers, encouraging the integration of LLMs into legal and financial NLP systems for future research. Comments: to appear in NLLP 2023",Document_276,Transparency is a challenge for AI adoption in financial services,0.06800948083400726,Explainability and Transparency Barriers
Keeping Up with the Language Models: Robustness-Bias Interplay in NLI Data and Models,"Ioana Baldini, Chhavi Yadav, Payel Das, Kush R. Varshney","Bias auditing of language models (LMs) has received considerable attention as LMs are becoming widespread. As such, several benchmarks for bias auditing have been proposed. At the same time, the rapid evolution of LMs can make these benchmarks irrelevant in no time. Bias auditing is further complicated by LM brittleness: when a presumably biased outcome is observed, is it due to model bias or model brittleness? We propose enlisting the models themselves to help construct bias auditing datasets that remain challenging, and introduce bias measures that distinguish between different types of model errors. First, we extend an existing bias benchmark for NLI (BBNLI) using a combination of LM-generated lexical variations, adversarial filtering, and human validation. We demonstrate that the newly created dataset BBNLI-next is more challenging than BBNLI: on average, BBNLI-next reduces the accuracy of state-of-the-art NLI models from 95.3%, as observed by BBNLI, to a strikingly low 57.5%. Second, we employ BBNLI-next to showcase the interplay between robustness and bias: we point out shortcomings in current bias scores and propose bias measures that take into account both bias and model brittleness. Third, despite the fact that BBNLI-next was designed with non-generative models in mind, we show that the new dataset is also able to uncover bias in state-of-the-art open-source generative LMs. Note: All datasets included in this work are in English and they address US-centered social biases. In the spirit of efficient NLP research, no model training or fine-tuning was performed to conduct this research. Warning: This paper contains offensive text examples.",2023,2023,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2305.12620,10.48550/arXiv.2305.12620,https://doi.org/10.48550/arXiv.2305.12620,3,"Bias auditing of language models (LMs) has received considerable attention as LMs are becoming widespread. As such, several benchmarks for bias auditing have been proposed. At the same time, the rapid evolution of LMs can make these benchmarks irrelevant in no time. Bias auditing is further complicated by LM brittleness: when a presumably biased outcome is observed, is it due to model bias or model brittleness? We propose enlisting the models themselves to help construct bias auditing datasets that remain challenging, and introduce bias measures that distinguish between different types of model errors. First, we extend an existing bias benchmark for NLI (BBNLI) using a combination of LM-generated lexical variations, adversarial filtering, and human validation. We demonstrate that the newly created dataset BBNLI-next is more challenging than BBNLI: on average, BBNLI-next reduces the accuracy of state-of-the-art NLI models from 95.3%, as observed by BBNLI, to a strikingly low 57.5%. Second, we employ BBNLI-next to showcase the interplay between robustness and bias: we point out shortcomings in current bias scores and propose bias measures that take into account both bias and model brittleness. Third, despite the fact that BBNLI-next was designed with non-generative models in mind, we show that the new dataset is also able to uncover bias in state-of-the-art open-source generative LMs. Note: All datasets included in this work are in English and they address US-centered social biases. In the spirit of efficient NLP research, no model training or fine-tuning was performed to conduct this research. Warning: This paper contains offensive text examples.",Document_277,Technical aspects or methods of AI or machine learning,0.051832687109708786,Other Categories
Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey,"W. Zhang, Quan.Z Sheng, A. Alhazmi, Chenliang Li","With the development of high computational devices, deep neural networks (DNNs), in recent years, have gained significant popularity in many Artificial Intelligence (AI) applications. However, previous efforts have shown that DNNs were vulnerable to strategically modified samples, named adversarial examples. These samples are generated with some imperceptible perturbations but can fool the DNNs to give false predictions. Inspired by the popularity of generating adversarial examples for image DNNs, research efforts on attacking DNNs for textual applications emerges in recent years. However, existing perturbation methods for images cannotbe directly applied to texts as text data is discrete. In this article, we review research works that address this difference and generatetextual adversarial examples on DNNs. We collect, select, summarize, discuss and analyze these works in a comprehensive way andcover all the related information to make the article self-contained. Finally, drawing on the reviewed literature, we provide further discussions and suggestions on this topic.",2019,2019,,-,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.1901.06796,-,https://doi.org/10.48550/arXiv.1901.06796,447,"With the development of high computational devices, deep neural networks (DNNs), in recent years, have gained significant popularity in many Artificial Intelligence (AI) applications. However, previous efforts have shown that DNNs were vulnerable to strategically modified samples, named adversarial examples. These samples are generated with some imperceptible perturbations but can fool the DNNs to give false predictions. Inspired by the popularity of generating adversarial examples for image DNNs, research efforts on attacking DNNs for textual applications emerges in recent years. However, existing perturbation methods for images cannotbe directly applied to texts as text data is discrete. In this article, we review research works that address this difference and generatetextual adversarial examples on DNNs. We collect, select, summarize, discuss and analyze these works in a comprehensive way andcover all the related information to make the article self-contained. Finally, drawing on the reviewed literature, we provide further discussions and suggestions on this topic.",Document_278,Technical aspects or methods of AI or machine learning,0.17751158773899078,Other Categories
Coercing LLMs to do and reveal (almost) anything,"Jonas Geiping, Alex Stein, Manli Shu, Khalid Saifullah, Yuxin Wen, Tom Goldstein","It has recently been shown that adversarial attacks on large language models (LLMs) can ""jailbreak"" the model into making harmful statements. In this work, we argue that the spectrum of adversarial attacks on LLMs is much larger than merely jailbreaking. We provide a broad overview of possible attack surfaces and attack goals. Based on a series of concrete examples, we discuss, categorize and systematize attacks that coerce varied unintended behaviors, such as misdirection, model control, denial-of-service, or data extraction. We analyze these attacks in controlled experiments, and find that many of them stem from the practice of pre-training LLMs with coding capabilities, as well as the continued existence of strange ""glitch"" tokens in common LLM vocabularies that should be removed for security reasons. ",2024,2024,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2402.14020,10.48550/arXiv.2402.14020,https://doi.org/10.48550/arXiv.2402.14020,34,"It has recently been shown that adversarial attacks on large language models (LLMs) can ""jailbreak"" the model into making harmful statements. In this work, we argue that the spectrum of adversarial attacks on LLMs is much larger than merely jailbreaking. We provide a broad overview of possible attack surfaces and attack goals. Based on a series of concrete examples, we discuss, categorize and systematize attacks that coerce varied unintended behaviors, such as misdirection, model control, denial-of-service, or data extraction. We analyze these attacks in controlled experiments, and find that many of them stem from the practice of pre-training LLMs with coding capabilities, as well as the continued existence of strange ""glitch"" tokens in common LLM vocabularies that should be removed for security reasons. ",Document_279,Technical aspects or methods of AI or machine learning,0.05466590076684952,Other Categories
Fairness Certification for Natural Language Processing and Large Language Models,"Vincent Freiberger, Erik Buchmann","Natural Language Processing (NLP) plays an important role in our daily lives, particularly due to the enormous progress of Large Language Models (LLM). However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education. Since NLP is based on human language, potentially harmful biases can diffuse into NLP systems and produce unfair results, discriminate against minorities or generate legal issues. Hence, it is important to develop a fairness certification for NLP approaches. We follow a qualitative research approach towards a fairness certification for NLP. In particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area. We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories. Our criteria offer a foundation for operationalizing and testing processes to certify fairness, both from the perspective of the auditor and the audited organization.",2024,2024,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2401.01262,10.48550/arXiv.2401.01262,https://doi.org/10.48550/arXiv.2401.01262,1,"Natural Language Processing (NLP) plays an important role in our daily lives, particularly due to the enormous progress of Large Language Models (LLM). However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education. Since NLP is based on human language, potentially harmful biases can diffuse into NLP systems and produce unfair results, discriminate against minorities or generate legal issues. Hence, it is important to develop a fairness certification for NLP approaches. We follow a qualitative research approach towards a fairness certification for NLP. In particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area. We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories. Our criteria offer a foundation for operationalizing and testing processes to certify fairness, both from the perspective of the auditor and the audited organization.",Document_280,Building organizational support for AI through education and communication,0.0887380987405777,"Education, Awareness, and Policy Strategies"
Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks,"Erfan Shayegani, Md Abdullah Al Mamun, Yu Fu, Pedram Zaree, Yue Dong, Nael B. Abu-Ghazaleh","Large Language Models (LLMs) are swiftly advancing in architecture and capability, and as they integrate more deeply into complex systems, the urgency to scrutinize their security properties grows. This paper surveys research in the emerging interdisciplinary field of adversarial attacks on LLMs, a subfield of trustworthy ML, combining the perspectives of Natural Language Processing and Security. Prior work has shown that even safety-aligned LLMs (via instruction tuning and reinforcement learning through human feedback) can be susceptible to adversarial attacks, which exploit weaknesses and mislead AI systems, as evidenced by the prevalence of `jailbreak' attacks on models like ChatGPT and Bard. In this survey, we first provide an overview of large language models, describe their safety alignment, and categorize existing research based on various learning structures: textual-only attacks, multi-modal attacks, and additional attack methods specifically targeting complex systems, such as federated learning or multi-agent systems. We also offer comprehensive remarks on works that focus on the fundamental sources of vulnerabilities and potential defenses. To make this field more accessible to newcomers, we present a systematic review of existing works, a structured typology of adversarial attack concepts, and additional resources, including slides for presentations on related topics at the 62nd Annual Meeting of the Association for Computational Linguistics (ACL'24).",2023,2023,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2310.10844,10.48550/arXiv.2310.10844,https://doi.org/10.48550/arXiv.2310.10844,104,"Large Language Models (LLMs) are swiftly advancing in architecture and capability, and as they integrate more deeply into complex systems, the urgency to scrutinize their security properties grows. This paper surveys research in the emerging interdisciplinary field of adversarial attacks on LLMs, a subfield of trustworthy ML, combining the perspectives of Natural Language Processing and Security. Prior work has shown that even safety-aligned LLMs (via instruction tuning and reinforcement learning through human feedback) can be susceptible to adversarial attacks, which exploit weaknesses and mislead AI systems, as evidenced by the prevalence of `jailbreak' attacks on models like ChatGPT and Bard. In this survey, we first provide an overview of large language models, describe their safety alignment, and categorize existing research based on various learning structures: textual-only attacks, multi-modal attacks, and additional attack methods specifically targeting complex systems, such as federated learning or multi-agent systems. We also offer comprehensive remarks on works that focus on the fundamental sources of vulnerabilities and potential defenses. To make this field more accessible to newcomers, we present a systematic review of existing works, a structured typology of adversarial attack concepts, and additional resources, including slides for presentations on related topics at the 62nd Annual Meeting of the Association for Computational Linguistics (ACL'24).",Document_281,Technical aspects or methods of AI or machine learning,0.19093337655067444,Other Categories
Legal NLP Meets MiCAR: Advancing the Analysis of Crypto White Papers,C. Camassa,"In the rapidly evolving field of crypto assets, white papers are essential documents for investor guidance, and are now subject to unprecedented content requirements under the European Union's Markets in Crypto-Assets Regulation (MiCAR). Natural Language Processing (NLP) can serve as a powerful tool for both analyzing these documents and assisting in regulatory compliance. This paper delivers two contributions to the topic. First, we survey existing applications of textual analysis to unregulated crypto asset white papers, uncovering a research gap that could be bridged with interdisciplinary collaboration. We then conduct an analysis of the changes introduced by MiCAR, highlighting the opportunities and challenges of integrating NLP within the new regulatory framework. The findings set the stage for further research, with the potential to benefit regulators, crypto asset issuers, and investors.",2023,2023,,NLLP,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2310.10333,10.48550/arXiv.2310.10333,https://doi.org/10.48550/arXiv.2310.10333,1,"In the rapidly evolving field of crypto assets, white papers are essential documents for investor guidance, and are now subject to unprecedented content requirements under the European Union's Markets in Crypto-Assets Regulation (MiCAR). Natural Language Processing (NLP) can serve as a powerful tool for both analyzing these documents and assisting in regulatory compliance. This paper delivers two contributions to the topic. First, we survey existing applications of textual analysis to unregulated crypto asset white papers, uncovering a research gap that could be bridged with interdisciplinary collaboration. We then conduct an analysis of the changes introduced by MiCAR, highlighting the opportunities and challenges of integrating NLP within the new regulatory framework. The findings set the stage for further research, with the potential to benefit regulators, crypto asset issuers, and investors.",Document_282,Demonstrating the value of AI for compliance and risk management,0.06227174773812294,Business Case and Value Demonstration Strategies
From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models,"Shangbin Feng, Chan Young Park, Yuhan Liu, Yulia Tsvetkov","Language models (LMs) are pretrained on diverse data sources, including news, discussion forums, books, and online encyclopedias. A significant portion of this data includes opinions and perspectives which, on one hand, celebrate democracy and diversity of ideas, and on the other hand are inherently socially biased. Our work develops new methods to (1) measure political biases in LMs trained on such corpora, along social and economic axes, and (2) measure the fairness of downstream NLP models trained on top of politically biased LMs. We focus on hate speech and misinformation detection, aiming to empirically quantify the effects of political (social, economic) biases in pretraining data on the fairness of high-stakes social-oriented tasks. Our findings reveal that pretrained LMs do have political leanings that reinforce the polarization present in pretraining corpora, propagating social biases into hate speech predictions and misinformation detectors. We discuss the implications of our findings for NLP research and propose future directions to mitigate unfairness.",2023,2023,,Annual Meeting of the Association for Computational Linguistics,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2305.08283,10.48550/arXiv.2305.08283,https://doi.org/10.48550/arXiv.2305.08283,185,"Language models (LMs) are pretrained on diverse data sources, including news, discussion forums, books, and online encyclopedias. A significant portion of this data includes opinions and perspectives which, on one hand, celebrate democracy and diversity of ideas, and on the other hand are inherently socially biased. Our work develops new methods to (1) measure political biases in LMs trained on such corpora, along social and economic axes, and (2) measure the fairness of downstream NLP models trained on top of politically biased LMs. We focus on hate speech and misinformation detection, aiming to empirically quantify the effects of political (social, economic) biases in pretraining data on the fairness of high-stakes social-oriented tasks. Our findings reveal that pretrained LMs do have political leanings that reinforce the polarization present in pretraining corpora, propagating social biases into hate speech predictions and misinformation detectors. We discuss the implications of our findings for NLP research and propose future directions to mitigate unfairness.",Document_283,Technical aspects or methods of AI or machine learning,0.12006250768899918,Other Categories
Natural Language Processing for Financial Regulation,"I. Achitouv, Dragos Gorduza, Antoine Jacquier","This article provides an understanding of Natural Language Processing techniques in the framework of financial regulation, more specifically in order to perform semantic matching search between rules and policy when no dataset is available for supervised learning. We outline how to outperform simple pre-trained sentences-transformer models using freely available resources and explain the mathematical concepts behind the key building blocks of Natural Language Processing. ",2023,2023,,Social Science Research Network,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2311.08533,10.48550/arXiv.2311.08533,https://doi.org/10.48550/arXiv.2311.08533,1,"This article provides an understanding of Natural Language Processing techniques in the framework of financial regulation, more specifically in order to perform semantic matching search between rules and policy when no dataset is available for supervised learning. We outline how to outperform simple pre-trained sentences-transformer models using freely available resources and explain the mathematical concepts behind the key building blocks of Natural Language Processing. ",Document_284,General discussion of financial or regulatory topics (non-AI focus),0.1292492151260376,Other Categories
FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing,"Ilias Chalkidis, Tommaso Pasini, Shenmin Zhang, Letizia Tomada, Sebastian Felix Schwemer, Anders Søgaard","We present a benchmark suite of four datasets for evaluating the fairness of pre-trained language models and the techniques used to fine-tune them for downstream tasks. Our benchmarks cover four jurisdictions (European Council, USA, Switzerland, and China), five languages (English, German, French, Italian and Chinese) and fairness across five attributes (gender, age, region, language, and legal area). In our experiments, we evaluate pre-trained language models using several group-robust fine-tuning techniques and show that performance group disparities are vibrant in many cases, while none of these techniques guarantee fairness, nor consistently mitigate group disparities. Furthermore, we provide a quantitative and qualitative analysis of our results, highlighting open challenges in the development of robustness methods in legal NLP. ",2022,2022,,Annual Meeting of the Association for Computational Linguistics,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2203.07228,10.48550/arXiv.2203.07228,https://doi.org/10.48550/arXiv.2203.07228,49,"We present a benchmark suite of four datasets for evaluating the fairness of pre-trained language models and the techniques used to fine-tune them for downstream tasks. Our benchmarks cover four jurisdictions (European Council, USA, Switzerland, and China), five languages (English, German, French, Italian and Chinese) and fairness across five attributes (gender, age, region, language, and legal area). In our experiments, we evaluate pre-trained language models using several group-robust fine-tuning techniques and show that performance group disparities are vibrant in many cases, while none of these techniques guarantee fairness, nor consistently mitigate group disparities. Furthermore, we provide a quantitative and qualitative analysis of our results, highlighting open challenges in the development of robustness methods in legal NLP. ",Document_285,Building organizational support for AI through education and communication,0.0683407410979271,"Education, Awareness, and Policy Strategies"
FETILDA: An Effective Framework For Fin-tuned Embeddings For Long Financial Text Documents,"BolunNamirXia, Vipula Rawte, Mohammed J. Zaki, Aparna Gupta","Unstructured data, especially text, continues to grow rapidly in various domains. In particular, in the financial sphere, there is a wealth of accumulated unstructured financial data, such as the textual disclosure documents that companies submit on a regular basis to regulatory agencies, such as the Securities and Exchange Commission (SEC). These documents are typically very long and tend to contain valuable soft information about a company's performance. It is therefore of great interest to learn predictive models from these long textual documents, especially for forecasting numerical key performance indicators (KPIs). Whereas there has been a great progress in pre-trained language models (LMs) that learn from tremendously large corpora of textual data, they still struggle in terms of effective representations for long documents. Our work fills this critical need, namely how to develop better models to extract useful information from long textual documents and learn effective features that can leverage the soft financial and risk information for text regression (prediction) tasks. In this paper, we propose and implement a deep learning framework that splits long documents into chunks and utilizes pre-trained LMs to process and aggregate the chunks into vector representations, followed by self-attention to extract valuable document-level features. We evaluate our model on a collection of 10-K public disclosure reports from US banks, and another dataset of reports submitted by US companies. Overall, our framework outperforms strong baseline methods for textual modeling as well as a baseline regression model using only numerical data. Our work provides better insights into how utilizing pre-trained domain-specific and fine-tuned long-input LMs in representing long documents can improve the quality of representation of textual data, and therefore, help in improving predictive analyses.",2022,2022,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2206.06952,10.48550/arXiv.2206.06952,https://doi.org/10.48550/arXiv.2206.06952,1,"Unstructured data, especially text, continues to grow rapidly in various domains. In particular, in the financial sphere, there is a wealth of accumulated unstructured financial data, such as the textual disclosure documents that companies submit on a regular basis to regulatory agencies, such as the Securities and Exchange Commission (SEC). These documents are typically very long and tend to contain valuable soft information about a company's performance. It is therefore of great interest to learn predictive models from these long textual documents, especially for forecasting numerical key performance indicators (KPIs). Whereas there has been a great progress in pre-trained language models (LMs) that learn from tremendously large corpora of textual data, they still struggle in terms of effective representations for long documents. Our work fills this critical need, namely how to develop better models to extract useful information from long textual documents and learn effective features that can leverage the soft financial and risk information for text regression (prediction) tasks. In this paper, we propose and implement a deep learning framework that splits long documents into chunks and utilizes pre-trained LMs to process and aggregate the chunks into vector representations, followed by self-attention to extract valuable document-level features. We evaluate our model on a collection of 10-K public disclosure reports from US banks, and another dataset of reports submitted by US companies. Overall, our framework outperforms strong baseline methods for textual modeling as well as a baseline regression model using only numerical data. Our work provides better insights into how utilizing pre-trained domain-specific and fine-tuned long-input LMs in representing long documents can improve the quality of representation of textual data, and therefore, help in improving predictive analyses.",Document_286,Improving data quality is crucial for successful AI in finance,0.0760391503572464,Data Improvement and Availability Strategies
Backdoor Attacks and Countermeasures in Natural Language Processing Models: A Comprehensive Security Review,"Pengzhou Cheng, Zongru Wu, Wei Du, Haodong Zhao, Gongshen Liu","Language Models (LMs) are becoming increasingly popular in real-world applications. Outsourcing model training and data hosting to third-party platforms has become a standard method for reducing costs. In such a situation, the attacker can manipulate the training process or data to inject a backdoor into models. Backdoor attacks are a serious threat where malicious behavior is activated when triggers are present, otherwise, the model operates normally. However, there is still no systematic and comprehensive review of LMs from the attacker's capabilities and purposes on different backdoor attack surfaces. Moreover, there is a shortage of analysis and comparison of the diverse emerging backdoor countermeasures. Therefore, this work aims to provide the NLP community with a timely review of backdoor attacks and countermeasures. According to the attackers' capability and affected stage of the LMs, the attack surfaces are formalized into four categorizations: attacking the pre-trained model with fine-tuning (APMF) or parameter-efficient fine-tuning (APMP), attacking the final model with training (AFMT), and attacking Large Language Models (ALLM). Thus, attacks under each categorization are combed. The countermeasures are categorized into two general classes: sample inspection and model inspection. Thus, we review countermeasures and analyze their advantages and disadvantages. Also, we summarize the benchmark datasets and provide comparable evaluations for representative attacks and defenses. Drawing the insights from the review, we point out the crucial areas for future research on the backdoor, especially soliciting more efficient and practical countermeasures. ",2023,2023,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2309.06055,10.48550/arXiv.2309.06055,https://doi.org/10.48550/arXiv.2309.06055,13,"Language Models (LMs) are becoming increasingly popular in real-world applications. Outsourcing model training and data hosting to third-party platforms has become a standard method for reducing costs. In such a situation, the attacker can manipulate the training process or data to inject a backdoor into models. Backdoor attacks are a serious threat where malicious behavior is activated when triggers are present, otherwise, the model operates normally. However, there is still no systematic and comprehensive review of LMs from the attacker's capabilities and purposes on different backdoor attack surfaces. Moreover, there is a shortage of analysis and comparison of the diverse emerging backdoor countermeasures. Therefore, this work aims to provide the NLP community with a timely review of backdoor attacks and countermeasures. According to the attackers' capability and affected stage of the LMs, the attack surfaces are formalized into four categorizations: attacking the pre-trained model with fine-tuning (APMF) or parameter-efficient fine-tuning (APMP), attacking the final model with training (AFMT), and attacking Large Language Models (ALLM). Thus, attacks under each categorization are combed. The countermeasures are categorized into two general classes: sample inspection and model inspection. Thus, we review countermeasures and analyze their advantages and disadvantages. Also, we summarize the benchmark datasets and provide comparable evaluations for representative attacks and defenses. Drawing the insights from the review, we point out the crucial areas for future research on the backdoor, especially soliciting more efficient and practical countermeasures. ",Document_287,Technical aspects or methods of AI or machine learning,0.05188245698809624,Other Categories
Baseline Defenses for Adversarial Attacks Against Aligned Language Models,"Neel Jain, Avi Schwarzschild, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer, Ping-yeh Chiang, Micah Goldblum, Aniruddha Saha, Jonas Geiping, Tom Goldstein","As Large Language Models quickly become ubiquitous, it becomes critical to understand their security vulnerabilities. Recent work shows that text optimizers can produce jailbreaking prompts that bypass moderation and alignment. Drawing from the rich body of work on adversarial machine learning, we approach these attacks with three questions: What threat models are practically useful in this domain? How do baseline defense techniques perform in this new domain? How does LLM security differ from computer vision? We evaluate several baseline defense strategies against leading adversarial attacks on LLMs, discussing the various settings in which each is feasible and effective. Particularly, we look at three types of defenses: detection (perplexity based), input preprocessing (paraphrase and retokenization), and adversarial training. We discuss white-box and gray-box settings and discuss the robustness-performance trade-off for each of the defenses considered. We find that the weakness of existing discrete optimizers for text, combined with the relatively high costs of optimization, makes standard adaptive attacks more challenging for LLMs. Future research will be needed to uncover whether more powerful optimizers can be developed, or whether the strength of filtering and preprocessing defenses is greater in the LLMs domain than it has been in computer vision. ",2023,2023,,arXiv.org,Selector (div#abs / Date Not Found (URL Source: DOI Link),https://doi.org/10.48550/arXiv.2309.00614,10.48550/arXiv.2309.00614,https://doi.org/10.48550/arXiv.2309.00614,251,"As Large Language Models quickly become ubiquitous, it becomes critical to understand their security vulnerabilities. Recent work shows that text optimizers can produce jailbreaking prompts that bypass moderation and alignment. Drawing from the rich body of work on adversarial machine learning, we approach these attacks with three questions: What threat models are practically useful in this domain? How do baseline defense techniques perform in this new domain? How does LLM security differ from computer vision? We evaluate several baseline defense strategies against leading adversarial attacks on LLMs, discussing the various settings in which each is feasible and effective. Particularly, we look at three types of defenses: detection (perplexity based), input preprocessing (paraphrase and retokenization), and adversarial training. We discuss white-box and gray-box settings and discuss the robustness-performance trade-off for each of the defenses considered. We find that the weakness of existing discrete optimizers for text, combined with the relatively high costs of optimization, makes standard adaptive attacks more challenging for LLMs. Future research will be needed to uncover whether more powerful optimizers can be developed, or whether the strength of filtering and preprocessing defenses is greater in the LLMs domain than it has been in computer vision. ",Document_288,Technical aspects or methods of AI or machine learning,0.133016437292099,Other Categories
Public Interest in the Regulation of Competition Evidence from Wholesale Internet Access Consultations in Canada,"Reza Rajabiun, C. Middleton","How should a new regulatory framework for the future of wholesale fiber access services in Canada be determined? To best balance public and private interests, the authors conclude that Natural Language Processing (NLP) technologies should be employed in the regulatory policymaking process. Using NLP, they analyze 40 formal interventions in the CRTC's 2013-551 review of its wholesale broadband policy. They classify major interest groups, map key concepts, and quantify asymmetries in stakeholders' influence. They conclude that by reducing the costs of regulatory participation, deploying NLP technologies can help offset the advantages large incumbent organizations already have in shaping law and policy.",2015,2015,,-,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.5325/JINFOPOLI.5.2015.0032,10.5325/JINFOPOLI.5.2015.0032,https://doi.org/10.5325/JINFOPOLI.5.2015.0032,9,"How should a new regulatory framework for the future of wholesale fiber access services in Canada be determined? To best balance public and private interests, the authors conclude that Natural Language Processing (NLP) technologies should be employed in the regulatory policymaking process. Using NLP, they analyze 40 formal interventions in the CRTC's 2013-551 review of its wholesale broadband policy. They classify major interest groups, map key concepts, and quantify asymmetries in stakeholders' influence. They conclude that by reducing the costs of regulatory participation, deploying NLP technologies can help offset the advantages large incumbent organizations already have in shaping law and policy.",Document_289,Technical aspects or methods of AI or machine learning,0.07015334814786911,Other Categories
User-adaptable Natural Language Generation for Regression Testing within the Finance Domain,"Daniel Braun, Anupama Sajwan, F. Matthes","Reporting duties and regression testing within the financial industry produce huge amounts of data which has to be sighted and analyzed by experts. This time-consuming and expensive process does not fit to modern, agile software developing practices with fast update cycles. In this paper, we present a user-adaptable natural language generation system that supports financial experts from the insurance industry in analysing the results from regression tests for Solvency II risk calculations and evaluate it with a group of experts.",2020,2025,4.0,International Conference on Enterprise Information Systems,Abstract Not Found / Date (Meta (citation_publication_date)) / LLM Skipped (Context Error) (Possible Paywall/Login Page Detected) (URL Source: DOI Link),https://doi.org/10.5220/0009563306130618,10.5220/0009563306130618,https://doi.org/10.5220/0009563306130618,1,"Reporting duties and regression testing within the financial industry produce huge amounts of data which has to be sighted and analyzed by experts. This time-consuming and expensive process does not fit to modern, agile software developing practices with fast update cycles. In this paper, we present a user-adaptable natural language generation system that supports financial experts from the insurance industry in analysing the results from regression tests for Solvency II risk calculations and evaluate it with a group of experts.",Document_290,High implementation costs are a barrier to AI in financial services,0.08340805768966675,Integration and Cost Barriers
uAIS: An Experience of Increasing Performance of NLP Information Extraction Tasks from Legal Documents in an Electronic Document Management System,"M. Ruiz, Cristian Román, Angel Luis Garrido, E. Mena","Nowadays, the huge number of documents which are managed through document management systems maketheir manual processing practically impossible. That is why the use of natural language processing subsys-tems that help to perform certain tasks begins to be essential for many commercial systems. Although its useis gradually extending to all levels, this type of subsystems presents the problem of its high requirements ofresources from CPU and memory that can harm the entire system to which it intends to provide assistance. Inthis work, we propose and study an architecture based on microservices and message brokers which improvesthe performance of these NLP subsystems. We have implemented our approach on a real document manage-ment system, which performs intensive processes of language analysis on large legal documents. Experimentalresults show promising results, greatly increasing the productivity of systems based on other approaches.",2020,2025,4.0,International Conference on Enterprise Information Systems,Abstract Not Found / Date (Meta (citation_publication_date)) / LLM Skipped (Context Error) (Possible Paywall/Login Page Detected) (URL Source: DOI Link),https://doi.org/10.5220/0009421201890196,10.5220/0009421201890196,https://doi.org/10.5220/0009421201890196,5,"Nowadays, the huge number of documents which are managed through document management systems maketheir manual processing practically impossible. That is why the use of natural language processing subsys-tems that help to perform certain tasks begins to be essential for many commercial systems. Although its useis gradually extending to all levels, this type of subsystems presents the problem of its high requirements ofresources from CPU and memory that can harm the entire system to which it intends to provide assistance. Inthis work, we propose and study an architecture based on microservices and message brokers which improvesthe performance of these NLP subsystems. We have implemented our approach on a real document manage-ment system, which performs intensive processes of language analysis on large legal documents. Experimentalresults show promising results, greatly increasing the productivity of systems based on other approaches.",Document_291,General discussion of AI in finance (neutral focus),0.07006330043077469,Other Categories
Power Plants Failure Reports Analysis for Predictive Maintenance,"V. Carchiolo, A. Longheu, V. D. Martino, N. Consoli","The shifting from reactive to predictive maintenance heavily improves the assets management, especially for complex systems with high business value. This occurs in particular in power plants, whose functioning is a mission-critical task. In this work, an NLP-based analysis of failure reports in power plants is presented, showing how they can be effectively used to implement a predictive maintenance aiming to reduce unplanned downtime and repair time, thus increasing operational efficiency while reducing costs.",2019,2025,4.0,International Conference on Web Information Systems and Technologies,Abstract Not Found / Date (Meta (citation_publication_date)) / LLM Skipped (Context Error) (Possible Paywall/Login Page Detected) (URL Source: DOI Link),https://doi.org/10.5220/0008388204040410,10.5220/0008388204040410,https://doi.org/10.5220/0008388204040410,9,"The shifting from reactive to predictive maintenance heavily improves the assets management, especially for complex systems with high business value. This occurs in particular in power plants, whose functioning is a mission-critical task. In this work, an NLP-based analysis of failure reports in power plants is presented, showing how they can be effectively used to implement a predictive maintenance aiming to reduce unplanned downtime and repair time, thus increasing operational efficiency while reducing costs.",Document_292,Technical aspects or methods of AI or machine learning,0.235968217253685,Other Categories
From Natural-language Regulations to Enterprise Data using Knowledge Representation and Model Transformations,"Deepali Kholkar, Sagar Sunkle, V. Kulkarni","Enterprises today face an unprecedented regulatory regime and are increasingly looking to technology to ease their regulatory compliance concerns. Formal approaches in research focus on checking compliance of business processes against rules, and assume usage of matching terminology on both sides. We focus on run-time compliance of enterprise data, and the specific problem of identifying enterprise data relevant to a regulation, in an automated manner. We present a knowledge representation approach and semi-automated solution using models and model transformations to extract the same from distributed enterprise databases. We use a Semantics of Business Vocabulary and Rules (SBVR) model of regulation rules as the basis to arrive at the necessary and sufficient model of enterprise data. The approach is illustrated using a real-life case study of the MiFID-II financial regulation.",2016,2025,4.0,ICSOFT-PT,Abstract Not Found / Date (Meta (citation_publication_date)) / LLM Skipped (Context Error) (Possible Paywall/Login Page Detected) (URL Source: DOI Link),https://doi.org/10.5220/0006002600600071,10.5220/0006002600600071,https://doi.org/10.5220/0006002600600071,5,"Enterprises today face an unprecedented regulatory regime and are increasingly looking to technology to ease their regulatory compliance concerns. Formal approaches in research focus on checking compliance of business processes against rules, and assume usage of matching terminology on both sides. We focus on run-time compliance of enterprise data, and the specific problem of identifying enterprise data relevant to a regulation, in an automated manner. We present a knowledge representation approach and semi-automated solution using models and model transformations to extract the same from distributed enterprise databases. We use a Semantics of Business Vocabulary and Rules (SBVR) model of regulation rules as the basis to arrive at the necessary and sufficient model of enterprise data. The approach is illustrated using a real-life case study of the MiFID-II financial regulation.",Document_293,General discussion of financial or regulatory topics (non-AI focus),0.1298736184835434,Other Categories
BigTech in Financial Services,"Christopher J. Wilson, Nobuyasu Sugimoto, Parma Bains","The prevalent strong preference for public sector employment among young Omanis, coupled with demographic pressures and medium-term fiscal sustainability objectives amid economic diversification away from hydrocarbons, underscores the urgency to pivot towards a more dynamic private sector that attracts Omanis towards private sector jobs. This note delves into recent developments and structural idiosyncrasies in Oman's labor market, highlighting distinct segmentation and limited mobility, which disincentivized upskilling and impeded sectoral labor reallocation. The analysis reveals that comprehensive reforms are needed to narrow the public-private wage gap, boost private sector employment for nationals, and elevate overall productivity. These include aligning wages with productivity, improving vocational training, fostering female labor market participation, and enhancing labor market mobility for expatriate workers. Implementing these measures is pivotal for Oman to realize its Vision 2040 objectives, transitioning towards a knowledge-based economy, and achieving sustainable nonhydrocarbon growth.",2022,2022,,FinTech Notes,Abstract & Date Not Found (Rules) / LLM Skipped (Filtered HTML too short) (URL Source: DOI Link),https://doi.org/10.5089/9781557756756.063,10.5089/9781557756756.063,https://doi.org/10.5089/9781557756756.063,6,"The prevalent strong preference for public sector employment among young Omanis, coupled with demographic pressures and medium-term fiscal sustainability objectives amid economic diversification away from hydrocarbons, underscores the urgency to pivot towards a more dynamic private sector that attracts Omanis towards private sector jobs. This note delves into recent developments and structural idiosyncrasies in Oman's labor market, highlighting distinct segmentation and limited mobility, which disincentivized upskilling and impeded sectoral labor reallocation. The analysis reveals that comprehensive reforms are needed to narrow the public-private wage gap, boost private sector employment for nationals, and elevate overall productivity. These include aligning wages with productivity, improving vocational training, fostering female labor market participation, and enhancing labor market mobility for expatriate workers. Implementing these measures is pivotal for Oman to realize its Vision 2040 objectives, transitioning towards a knowledge-based economy, and achieving sustainable nonhydrocarbon growth.",Document_294,General discussion of financial or regulatory topics (non-AI focus),0.04875955730676651,Other Categories
Text Mining Business Policy Documents: Applied Data Science in Finance,"M. Spruit, D. Ferati","In a time when the employment of natural language processing techniques in domains such as biomedicine, national security, finance, and law is flourishing, this study takes a deep look at its application in policy documents. Besides providing an overview of the current state of the literature that treats these concepts, the authors implement a set of natural language processing techniques on internal bank policies. The implementation of these techniques, together with the results that derive from the experiments and expert evaluation, introduce a meta-algorithmic modelling framework for processing internal business policies. This framework relies on three natural language processing techniques, namely information extraction, automatic summarization, and automatic keyword extraction. For the reference extraction and keyword extraction tasks, the authors calculated precision, recall, and F-scores. For the former, the researchers obtained 0.99, 0.84, and 0.89; for the latter, this research obtained 0.79, 0.87, and 0.83, respectively. Finally, the summary extraction approach was positively evaluated using a qualitative assessment.",2020,2020,,International Journal of Business Intelligence Research,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.4018/ijbir.20200701.oa1,10.4018/ijbir.20200701.oa1,https://doi.org/10.4018/ijbir.20200701.oa1,6,"In a time when the employment of natural language processing techniques in domains such as biomedicine, national security, finance, and law is flourishing, this study takes a deep look at its application in policy documents. Besides providing an overview of the current state of the literature that treats these concepts, the authors implement a set of natural language processing techniques on internal bank policies. The implementation of these techniques, together with the results that derive from the experiments and expert evaluation, introduce a meta-algorithmic modelling framework for processing internal business policies. This framework relies on three natural language processing techniques, namely information extraction, automatic summarization, and automatic keyword extraction. For the reference extraction and keyword extraction tasks, the authors calculated precision, recall, and F-scores. For the former, the researchers obtained 0.99, 0.84, and 0.89; for the latter, this research obtained 0.79, 0.87, and 0.83, respectively. Finally, the summary extraction approach was positively evaluated using a qualitative assessment.",Document_295,Security risks associated with AI are a concern in financial regulation,0.059461575001478195,Organizational and Human Barriers
From ELIZA to ChatGPT: The Evolution of Natural Language Processing and Financial Applications,"A. Lo, Manish Singh","Natural language processing (NLP) has revolutionized the financial industry, providing advanced techniques for the processing, analyzing, and understanding of unstructured financial text. We provide a comprehensive overview of the historical development of NLP, starting from early rules-based approaches to recent advances in deep-learning-based NLP models. We also discuss applications of NLP in finance along with its challenges, including data scarcity and adversarial examples, and speculate about the future of NLP in the financial industry. To illustrate the capability of current NLP models, we employ a state-of-the-art chatbot as a co-author of this article. KEY FINDINGS (1) The use of NLP in finance has evolved significantly over the past few decades with the growth of data, storage, and computational power. NLP is now used for wide range of sophisticated tasks including asset management, risk management, and impact investing. (2) The development of deep-learning-based large-language models like GPT-3/ChatGPT have significantly advanced the applications of NLP in finance. These models have the ability to understand and generate human-like language, making them useful for various tasks, including assisting in the writing of this article. (3) Solving problems related to data bias, high computational needs, and inaccurate responses generated by the models will make NLP models even more accessible and indispensable.",2023,2023,,Journal of Portfolio Management,Failed (JS Challenge/Bot Protection?) (URL Source: DOI Link),https://doi.org/10.3905/jpm.2023.1.512,10.3905/jpm.2023.1.512,https://doi.org/10.3905/jpm.2023.1.512,9,"Natural language processing (NLP) has revolutionized the financial industry, providing advanced techniques for the processing, analyzing, and understanding of unstructured financial text. We provide a comprehensive overview of the historical development of NLP, starting from early rules-based approaches to recent advances in deep-learning-based NLP models. We also discuss applications of NLP in finance along with its challenges, including data scarcity and adversarial examples, and speculate about the future of NLP in the financial industry. To illustrate the capability of current NLP models, we employ a state-of-the-art chatbot as a co-author of this article. KEY FINDINGS (1) The use of NLP in finance has evolved significantly over the past few decades with the growth of data, storage, and computational power. NLP is now used for wide range of sophisticated tasks including asset management, risk management, and impact investing. (2) The development of deep-learning-based large-language models like GPT-3/ChatGPT have significantly advanced the applications of NLP in finance. These models have the ability to understand and generate human-like language, making them useful for various tasks, including assisting in the writing of this article. (3) Solving problems related to data bias, high computational needs, and inaccurate responses generated by the models will make NLP models even more accessible and indispensable.",Document_296,Technical aspects or methods of AI or machine learning,0.09927674382925034,Other Categories
Challenges and Open Problems of Legal Document Anonymization,"G. Csányi, D. Nagy, Renátó Vági, János Pál Vadász, T. Orosz","Data sharing is a central aspect of judicial systems. The openly accessible documents can make the judiciary system more transparent. On the other hand, the published legal documents can contain much sensitive information about the involved persons or companies. For this reason, the anonymization of these documents is obligatory to prevent privacy breaches. General Data Protection Regulation (GDPR) and other modern privacy-protecting regulations have strict definitions of private data containing direct and indirect identifiers. In legal documents, there is a wide range of attributes regarding the involved parties. Moreover, legal documents can contain additional information about the relations between the involved parties and rare events. Hence, the personal data can be represented by a sparse matrix of these attributes. The application of Named Entity Recognition methods is essential for a fair anonymization process but is not enough. Machine learning-based methods should be used together with anonymization models, such as differential privacy, to reduce re-identification risk. On the other hand, the information content (utility) of the text should be preserved. This paper aims to summarize and highlight the open and symmetrical problems from the fields of structured and unstructured text anonymization. The possible methods for anonymizing legal documents discussed and illustrated by case studies from the Hungarian legal practice.

",2021,2021,,Symmetry,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/sym13081490,10.3390/sym13081490,https://doi.org/10.3390/sym13081490,34,"Data sharing is a central aspect of judicial systems. The openly accessible documents can make the judiciary system more transparent. On the other hand, the published legal documents can contain much sensitive information about the involved persons or companies. For this reason, the anonymization of these documents is obligatory to prevent privacy breaches. General Data Protection Regulation (GDPR) and other modern privacy-protecting regulations have strict definitions of private data containing direct and indirect identifiers. In legal documents, there is a wide range of attributes regarding the involved parties. Moreover, legal documents can contain additional information about the relations between the involved parties and rare events. Hence, the personal data can be represented by a sparse matrix of these attributes. The application of Named Entity Recognition methods is essential for a fair anonymization process but is not enough. Machine learning-based methods should be used together with anonymization models, such as differential privacy, to reduce re-identification risk. On the other hand, the information content (utility) of the text should be preserved. This paper aims to summarize and highlight the open and symmetrical problems from the fields of structured and unstructured text anonymization. The possible methods for anonymizing legal documents discussed and illustrated by case studies from the Hungarian legal practice.

",Document_297,Technical aspects or methods of AI or machine learning,0.0954587385058403,Other Categories
Word Vector Models Approach to Text Regression of Financial Risk Prediction,"Hsiang-Yuan Yeh, Yu-Ching Yeh, Da-Bai Shen","Linking textual information in finance reports to the stock return volatility provides a perspective on exploring useful insights for risk management. We introduce different kinds of word vector representations in the modeling of textual information: bag-of-words, pre-trained word embeddings, and domain-specific word embeddings. We apply linear and non-linear methods to establish a text regression model for volatility prediction. A large number of collected annually-published financial reports in the period from 1996 to 2013 is used in the experiments. We demonstrate that the domain-specific word vector learned from data not only captures lexical semantics, but also has better performance than the pre-trained word embeddings and traditional bag-of-words model. Our approach significantly outperforms with smaller prediction error in the regression task and obtains a 4%–10% improvement in the ranking task compared to state-of-the-art methods. These improvements suggest that the textual information may provide measurable effects on long-term volatility forecasting. In addition, we also find that the variations and regulatory changes in reports make older reports less relevant for volatility prediction. Our approach opens a new method of research into information economics and can be applied to a wide range of financial-related applications.",2020,2020,,Symmetry,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/sym12010089,10.3390/sym12010089,https://doi.org/10.3390/sym12010089,14,"Linking textual information in finance reports to the stock return volatility provides a perspective on exploring useful insights for risk management. We introduce different kinds of word vector representations in the modeling of textual information: bag-of-words, pre-trained word embeddings, and domain-specific word embeddings. We apply linear and non-linear methods to establish a text regression model for volatility prediction. A large number of collected annually-published financial reports in the period from 1996 to 2013 is used in the experiments. We demonstrate that the domain-specific word vector learned from data not only captures lexical semantics, but also has better performance than the pre-trained word embeddings and traditional bag-of-words model. Our approach significantly outperforms with smaller prediction error in the regression task and obtains a 4%–10% improvement in the ranking task compared to state-of-the-art methods. These improvements suggest that the textual information may provide measurable effects on long-term volatility forecasting. In addition, we also find that the variations and regulatory changes in reports make older reports less relevant for volatility prediction. Our approach opens a new method of research into information economics and can be applied to a wide range of financial-related applications.",Document_298,General discussion of financial or regulatory topics (non-AI focus),0.07770256698131561,Other Categories
Examining Compliance with Personal Data Protection Regulations in Interorganizational Data Analysis,"Szu-Chuang Li, Yi-Wen Chen, Yennun Huang","The development of big data analysis technologies has changed how organizations work. Tech giants, such as Google and Facebook, are well positioned because they possess not only big data sets but also the in-house capability to analyze them. For small and medium-sized enterprises (SMEs), which have limited resources, capacity, and a relatively small collection of data, the ability to conduct data analysis collaboratively is key. Personal data protection regulations have become stricter due to incidents of private data being leaked, making it more difficult for SMEs to perform interorganizational data analysis. This problem can be resolved by anonymizing the data such that reidentifying an individual is no longer a concern or by deploying technical procedures that enable interorganizational data analysis without the exchange of actual data, such as data deidentification, data synthesis, and federated learning. Herein, we compared the technical options and their compliance with personal data protection regulations from several countries and regions. Using the EU’s GDPR (General Data Protection Regulation) as the main point of reference, technical studies, legislative studies, related regulations, and government-sponsored reports from various countries and regions were also reviewed. Alignment of the technical description with the government regulations and guidelines revealed that the solutions are compliant with the personal data protection regulations. Current regulations require “reasonable” privacy preservation efforts from data controllers; potential attackers are not assumed to be experts with knowledge of the target data set. This means that relevant requirements can be fulfilled without considerably sacrificing data utility. However, the potential existence of an extremely knowledgeable adversary when the stakes of data leakage are high still needs to be considered carefully.",2021,2021,,Sustainability,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/su132011459,10.3390/su132011459,https://doi.org/10.3390/su132011459,4,"The development of big data analysis technologies has changed how organizations work. Tech giants, such as Google and Facebook, are well positioned because they possess not only big data sets but also the in-house capability to analyze them. For small and medium-sized enterprises (SMEs), which have limited resources, capacity, and a relatively small collection of data, the ability to conduct data analysis collaboratively is key. Personal data protection regulations have become stricter due to incidents of private data being leaked, making it more difficult for SMEs to perform interorganizational data analysis. This problem can be resolved by anonymizing the data such that reidentifying an individual is no longer a concern or by deploying technical procedures that enable interorganizational data analysis without the exchange of actual data, such as data deidentification, data synthesis, and federated learning. Herein, we compared the technical options and their compliance with personal data protection regulations from several countries and regions. Using the EU’s GDPR (General Data Protection Regulation) as the main point of reference, technical studies, legislative studies, related regulations, and government-sponsored reports from various countries and regions were also reviewed. Alignment of the technical description with the government regulations and guidelines revealed that the solutions are compliant with the personal data protection regulations. Current regulations require “reasonable” privacy preservation efforts from data controllers; potential attackers are not assumed to be experts with knowledge of the target data set. This means that relevant requirements can be fulfilled without considerably sacrificing data utility. However, the potential existence of an extremely knowledgeable adversary when the stakes of data leakage are high still needs to be considered carefully.",Document_299,Technical aspects or methods of AI or machine learning,0.089202381670475,Other Categories
Extracting Proceedings Data from Court Cases with Machine Learning,Bruno Mathis,"France is rolling out an open data program for all court cases, but with few metadata attached. Reusers will have to use named-entity recognition (NER) within the text body of the case to extract any value from it. Any court case may include up to 26 variables, or labels, that are related to the proceeding, regardless of the case substance. These labels are from different syntactic types: some of them are rare; others are ubiquitous. This experiment compares different algorithms, namely CRF, SpaCy, Flair and DeLFT, to extract proceedings data and uses the learning model assessment capabilities of Kairntech, an NLP platform. It shows that an NER model can apply to this large and diverse set of labels and extract data of high quality. We achieved an 87.5% F1 measure with Flair trained on more than 27,000 manual annotations. Quality may yet be improved by combining NER models by data type.",2022,2022,,Stats,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/stats5040079,10.3390/stats5040079,https://doi.org/10.3390/stats5040079,5,"France is rolling out an open data program for all court cases, but with few metadata attached. Reusers will have to use named-entity recognition (NER) within the text body of the case to extract any value from it. Any court case may include up to 26 variables, or labels, that are related to the proceeding, regardless of the case substance. These labels are from different syntactic types: some of them are rare; others are ubiquitous. This experiment compares different algorithms, namely CRF, SpaCy, Flair and DeLFT, to extract proceedings data and uses the learning model assessment capabilities of Kairntech, an NLP platform. It shows that an NER model can apply to this large and diverse set of labels and extract data of high quality. We achieved an 87.5% F1 measure with Flair trained on more than 27,000 manual annotations. Quality may yet be improved by combining NER models by data type.",Document_300,Technical aspects or methods of AI or machine learning,0.09560878574848175,Other Categories
A Scoping Literature Review of Natural Language Processing Application to Safety Occurrence Reports,"John W. Ricketts, David Barry, Weisi Guo, Jonathan Pelham","Safety occurrence reports can contain valuable information on how incidents occur, revealing knowledge that can assist safety practitioners. This paper presents and discusses a literature review exploring how Natural Language Processing (NLP) has been applied to occurrence reports within safety-critical industries, informing further research on the topic and highlighting common challenges. Some of the uses of NLP include the ability for occurrence reports to be automatically classified against categories, and entities such as causes and consequences to be extracted from the text as well as the semantic searching of occurrence databases. The review revealed that machine learning models form the dominant method when applying NLP, although rule-based algorithms still provide a viable option for some entity extraction tasks. Recent advances in deep learning models such as Bidirectional Transformers for Language Understanding are now achieving a high accuracy while eliminating the need to substantially pre-process text. The construction of safety-themed datasets would be of benefit for the application of NLP to occurrence reporting, as this would allow the fine-tuning of current language models to safety tasks. An interesting approach is the use of topic modelling, which represents a shift away from the prescriptive classification taxonomies, splitting data into “topics”. Where many papers focus on the computational accuracy of models, they would also benefit from real-world trials to further inform usefulness. It is anticipated that NLP will soon become a mainstream tool used by safety practitioners to efficiently process and gain knowledge from safety-related text.",2023,2023,,Safety,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/safety9020022,10.3390/safety9020022,https://doi.org/10.3390/safety9020022,634,"Safety occurrence reports can contain valuable information on how incidents occur, revealing knowledge that can assist safety practitioners. This paper presents and discusses a literature review exploring how Natural Language Processing (NLP) has been applied to occurrence reports within safety-critical industries, informing further research on the topic and highlighting common challenges. Some of the uses of NLP include the ability for occurrence reports to be automatically classified against categories, and entities such as causes and consequences to be extracted from the text as well as the semantic searching of occurrence databases. The review revealed that machine learning models form the dominant method when applying NLP, although rule-based algorithms still provide a viable option for some entity extraction tasks. Recent advances in deep learning models such as Bidirectional Transformers for Language Understanding are now achieving a high accuracy while eliminating the need to substantially pre-process text. The construction of safety-themed datasets would be of benefit for the application of NLP to occurrence reporting, as this would allow the fine-tuning of current language models to safety tasks. An interesting approach is the use of topic modelling, which represents a shift away from the prescriptive classification taxonomies, splitting data into “topics”. Where many papers focus on the computational accuracy of models, they would also benefit from real-world trials to further inform usefulness. It is anticipated that NLP will soon become a mainstream tool used by safety practitioners to efficiently process and gain knowledge from safety-related text.",Document_301,Technical aspects or methods of AI or machine learning,0.14542371034622192,Other Categories
Enhancing Domain-Specific Supervised Natural Language Intent Classification with a Top-Down Selective Ensemble Model,"Gard B. Jenset, Barbara McGillivray","Natural Language Understanding (NLU) systems are essential components in many industry conversational artificial intelligence applications. There are strong incentives to develop a good NLU capability in such systems, both to improve the user experience and in the case of regulated industries for compliance reasons. We report on a series of experiments comparing the effects of optimizing word embeddings versus implementing a multi-classifier ensemble approach and conclude that in our case, only the latter approach leads to significant improvements. The study provides a high-level primer for developing NLU systems in regulated domains, as well as providing a specific baseline accuracy for evaluating NLU systems for financial guidance.",2019,2019,,Machine Learning and Knowledge Extraction,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/MAKE1020037,10.3390/MAKE1020037,https://doi.org/10.3390/MAKE1020037,3,"Natural Language Understanding (NLU) systems are essential components in many industry conversational artificial intelligence applications. There are strong incentives to develop a good NLU capability in such systems, both to improve the user experience and in the case of regulated industries for compliance reasons. We report on a series of experiments comparing the effects of optimizing word embeddings versus implementing a multi-classifier ensemble approach and conclude that in our case, only the latter approach leads to significant improvements. The study provides a high-level primer for developing NLU systems in regulated domains, as well as providing a specific baseline accuracy for evaluating NLU systems for financial guidance.",Document_302,Aligning AI implementation with financial regulatory requirements,0.08151952177286148,Regulatory Engagement and Proactive Compliance Strategies
Time to Assess Bias in Machine Learning Models for Credit Decisions,Liming Brotcke,"Focus on fair lending has become more intensified recently as bank and non-bank lenders apply artificial-intelligence (AI)-based credit determination approaches. The data analytics technique behind AI and machine learning (ML) has proven to be powerful in many application areas. However, ML can be less transparent and explainable than traditional regression models, which may raise unique questions about its compliance with fair lending laws. ML may also reduce potential for discrimination, by reducing discretionary and judgmental decisions. As financial institutions continue to explore ML applications in loan underwriting and pricing, the fair lending assessments typically led by compliance and legal functions will likely continue to evolve. In this paper, the author discusses unique considerations around ML in the existing fair lending risk assessment practice for underwriting and pricing models and proposes consideration of additional evaluations to be added in the present practice.",2022,2022,,Journal of Risk and Financial Management,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/jrfm15040165,10.3390/jrfm15040165,https://doi.org/10.3390/jrfm15040165,18,"Focus on fair lending has become more intensified recently as bank and non-bank lenders apply artificial-intelligence (AI)-based credit determination approaches. The data analytics technique behind AI and machine learning (ML) has proven to be powerful in many application areas. However, ML can be less transparent and explainable than traditional regression models, which may raise unique questions about its compliance with fair lending laws. ML may also reduce potential for discrimination, by reducing discretionary and judgmental decisions. As financial institutions continue to explore ML applications in loan underwriting and pricing, the fair lending assessments typically led by compliance and legal functions will likely continue to evolve. In this paper, the author discusses unique considerations around ML in the existing fair lending risk assessment practice for underwriting and pricing models and proposes consideration of additional evaluations to be added in the present practice.",Document_303,Transparency is a challenge for AI adoption in financial services,0.15767981112003326,Explainability and Transparency Barriers
Industry 4.0 Technological Advancement in the Food and Beverage Manufacturing Industry in South Africa - Bibliometric Analysis via Natural Language Processing,"A. Telukdarie, M. Munsamy, T. Katsumbe, Xolani Maphisa, Simon P. Philbin","The food and beverage (FOODBEV) manufacturing industry is a significant contributor to global economic development, but it is also subject to major global competition. Manufacturing technology evolution is rapid and, with the Fourth Industrial Revolution (4IR), ever accelerating. Thus, the ability of companies to review and identify appropriate, beneficial technologies and forecast the skills required is a challenge. 4IR technologies, as a collection of tools to assist technological advancement in the manufacturing sector, are essential. The vast and diverse global technology knowledge base, together with the complexities associated with screening in technologies and the lack of appropriate enablement skills, makes technology selection and implementation a challenge. This challenge is premised on the knowledge that there are vast amounts of information available on various research databases and web search engines; however, the extraction of specific and relevant information is time-intensive. Whilst existing techniques such as conventional bibliometric analysis are available, there is a need for dynamic approaches that optimise the ability to acquire the relevant information or knowledge within a short period with minimum effort. This research study adopts smart knowledge management together with artificial intelligence (AI) for knowledge extraction, classification, and adoption. This research defines 18 FOODBEV manufacturing processes and adopts a two-tier Natural Language Processing (NLP) protocol to identify technological substitution for process optimisation and the associated skills required in the FOODBEV manufacturing sector in South Africa.",2023,2023,,Inf.,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/info14080454,10.3390/info14080454,https://doi.org/10.3390/info14080454,6,"The food and beverage (FOODBEV) manufacturing industry is a significant contributor to global economic development, but it is also subject to major global competition. Manufacturing technology evolution is rapid and, with the Fourth Industrial Revolution (4IR), ever accelerating. Thus, the ability of companies to review and identify appropriate, beneficial technologies and forecast the skills required is a challenge. 4IR technologies, as a collection of tools to assist technological advancement in the manufacturing sector, are essential. The vast and diverse global technology knowledge base, together with the complexities associated with screening in technologies and the lack of appropriate enablement skills, makes technology selection and implementation a challenge. This challenge is premised on the knowledge that there are vast amounts of information available on various research databases and web search engines; however, the extraction of specific and relevant information is time-intensive. Whilst existing techniques such as conventional bibliometric analysis are available, there is a need for dynamic approaches that optimise the ability to acquire the relevant information or knowledge within a short period with minimum effort. This research study adopts smart knowledge management together with artificial intelligence (AI) for knowledge extraction, classification, and adoption. This research defines 18 FOODBEV manufacturing processes and adopts a two-tier Natural Language Processing (NLP) protocol to identify technological substitution for process optimisation and the associated skills required in the FOODBEV manufacturing sector in South Africa.",Document_304,Technical aspects or methods of AI or machine learning,0.25746065378189087,Other Categories
Natural Language Processing and Cognitive Networks Identify UK Insurers' Trends in Investor Day Transcripts,"Stefan Claus, Massimo Stella","The ability to spot key ideas, trends, and relationships between them in documents is key to financial services, such as banks and insurers. Identifying patterns across vast amounts of domain-specific reports is crucial for devising efficient and targeted supervisory plans, subsequently allocating limited resources where most needed. Today, insurance supervisory planning primarily relies on quantitative metrics based on numerical data (e.g., solvency financial returns). The purpose of this work is to assess whether Natural Language Processing (NLP) and cognitive networks can highlight events and relationships of relevance for regulators that supervise the insurance market, replacing human coding of information with automatic text analysis. To this aim, this work introduces a dataset of 
𝑁
𝐼𝐷𝑇
=829
N
I
D
T
=
829
 investor transcripts from Bloomberg and explores/tunes 3 NLP techniques: (1) keyword extraction enhanced by cognitive network analysis; (2) valence/sentiment analysis; and (3) topic modelling. Results highlight that keyword analysis, enriched by term frequency-inverse document frequency scores and semantic framing through cognitive networks, could detect events of relevance for the insurance system like cyber-attacks or the COVID-19 pandemic. Cognitive networks were found to highlight events that related to specific financial transitions: The semantic frame of “climate” grew in size by +538% between 2018 and 2020 and outlined an increased awareness that agents and insurers expressed towards climate change. A lexicon-based sentiment analysis achieved a Pearson’s correlation of 
𝜌=0.16
ρ
=
0.16
 (
𝑝<0.001,𝑁=829
p
<
0.001
,
N
=
829
) between sentiment levels and daily share prices. Although relatively weak, this finding indicates that insurance jargon is insightful to support risk supervision. Topic modelling is considered less amenable to support supervision, because of a lack of results’ stability and an intrinsic difficulty to interpret risk patterns. We discuss how these automatic methods could complement existing supervisory tools in supporting effective oversight of the insurance market.",2022,2022,,Future Internet,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/fi14100291,10.3390/fi14100291,https://doi.org/10.3390/fi14100291,5,"The ability to spot key ideas, trends, and relationships between them in documents is key to financial services, such as banks and insurers. Identifying patterns across vast amounts of domain-specific reports is crucial for devising efficient and targeted supervisory plans, subsequently allocating limited resources where most needed. Today, insurance supervisory planning primarily relies on quantitative metrics based on numerical data (e.g., solvency financial returns). The purpose of this work is to assess whether Natural Language Processing (NLP) and cognitive networks can highlight events and relationships of relevance for regulators that supervise the insurance market, replacing human coding of information with automatic text analysis. To this aim, this work introduces a dataset of 
𝑁
𝐼𝐷𝑇
=829
N
I
D
T
=
829
 investor transcripts from Bloomberg and explores/tunes 3 NLP techniques: (1) keyword extraction enhanced by cognitive network analysis; (2) valence/sentiment analysis; and (3) topic modelling. Results highlight that keyword analysis, enriched by term frequency-inverse document frequency scores and semantic framing through cognitive networks, could detect events of relevance for the insurance system like cyber-attacks or the COVID-19 pandemic. Cognitive networks were found to highlight events that related to specific financial transitions: The semantic frame of “climate” grew in size by +538% between 2018 and 2020 and outlined an increased awareness that agents and insurers expressed towards climate change. A lexicon-based sentiment analysis achieved a Pearson’s correlation of 
𝜌=0.16
ρ
=
0.16
 (
𝑝<0.001,𝑁=829
p
<
0.001
,
N
=
829
) between sentiment levels and daily share prices. Although relatively weak, this finding indicates that insurance jargon is insightful to support risk supervision. Topic modelling is considered less amenable to support supervision, because of a lack of results’ stability and an intrinsic difficulty to interpret risk patterns. We discuss how these automatic methods could complement existing supervisory tools in supporting effective oversight of the insurance market.",Document_305,Technical aspects or methods of AI or machine learning,0.09410650283098221,Other Categories
Automatic Detection of Sensitive Data Using Transformer- Based Classifiers,"Michael Petrolini, S. Cagnoni, M. Mordonini","The General Data Protection Regulation (GDPR) has allowed EU citizens and residents to have more control over their personal data, simplifying the regulatory environment affecting international business and unifying and homogenising privacy legislation within the EU. This regulation affects all companies that process data of European residents regardless of the place in which they are processed and their registered office, providing for a strict discipline of data protection. These companies must comply with the GDPR and be aware of the content of the data they manage; this is especially important if they are holding sensitive data, that is, any information regarding racial or ethnic origin, political opinions, religious or philosophical beliefs, trade union membership, data relating to the sexual life or sexual orientation of the person, as well as data on physical and mental health. These classes of data are hardly structured, and most frequently they appear within a document such as an email message, a review or a post. It is extremely difficult to know if a company is in possession of sensitive data at the risk of not protecting them properly. The goal of the study described in this paper is to use Machine Learning, in particular the Transformer deep-learning model, to develop classifiers capable of detecting documents that are likely to include sensitive data. Additionally, we want the classifiers to recognize the particular type of sensitive topic with which they deal, in order for a company to have a better knowledge of the data they own. We expect to make the model described in this paper available as a web service, customized to private data of possible customers, or even in a free-to-use version based on the freely available data set we have built to train the classifiers.",2022,2022,,Future Internet,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/fi14080228,10.3390/fi14080228,https://doi.org/10.3390/fi14080228,7,"The General Data Protection Regulation (GDPR) has allowed EU citizens and residents to have more control over their personal data, simplifying the regulatory environment affecting international business and unifying and homogenising privacy legislation within the EU. This regulation affects all companies that process data of European residents regardless of the place in which they are processed and their registered office, providing for a strict discipline of data protection. These companies must comply with the GDPR and be aware of the content of the data they manage; this is especially important if they are holding sensitive data, that is, any information regarding racial or ethnic origin, political opinions, religious or philosophical beliefs, trade union membership, data relating to the sexual life or sexual orientation of the person, as well as data on physical and mental health. These classes of data are hardly structured, and most frequently they appear within a document such as an email message, a review or a post. It is extremely difficult to know if a company is in possession of sensitive data at the risk of not protecting them properly. The goal of the study described in this paper is to use Machine Learning, in particular the Transformer deep-learning model, to develop classifiers capable of detecting documents that are likely to include sensitive data. Additionally, we want the classifiers to recognize the particular type of sensitive topic with which they deal, in order for a company to have a better knowledge of the data they own. We expect to make the model described in this paper available as a web service, customized to private data of possible customers, or even in a free-to-use version based on the freely available data set we have built to train the classifiers.",Document_306,Demonstrating the value of AI for compliance and risk management,0.18495716154575348,Business Case and Value Demonstration Strategies
Natural Language Generation and Understanding of Big Code for AI-Assisted Programming: A Review,"M. Wong, Shangxin Guo, C. Hang, Siu-Wai Ho, C. Tan","This paper provides a comprehensive review of the literature concerning the utilization of Natural Language Processing (NLP) techniques, with a particular focus on transformer-based large language models (LLMs) trained using Big Code, within the domain of AI-assisted programming tasks. LLMs, augmented with software naturalness, have played a crucial role in facilitating AI-assisted programming applications, including code generation, code completion, code translation, code refinement, code summarization, defect detection, and clone detection. Notable examples of such applications include the GitHub Copilot powered by OpenAI’s Codex and DeepMind AlphaCode. This paper presents an overview of the major LLMs and their applications in downstream tasks related to AI-assisted programming. Furthermore, it explores the challenges and opportunities associated with incorporating NLP techniques with software naturalness in these applications, with a discussion on extending AI-assisted programming capabilities to Apple’s Xcode for mobile software development. This paper also presents the challenges of and opportunities for incorporating NLP techniques with software naturalness, empowering developers with advanced coding assistance and streamlining the software development process.",2023,2023,,Entropy,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/e25060888,10.3390/e25060888,https://doi.org/10.3390/e25060888,60,"This paper provides a comprehensive review of the literature concerning the utilization of Natural Language Processing (NLP) techniques, with a particular focus on transformer-based large language models (LLMs) trained using Big Code, within the domain of AI-assisted programming tasks. LLMs, augmented with software naturalness, have played a crucial role in facilitating AI-assisted programming applications, including code generation, code completion, code translation, code refinement, code summarization, defect detection, and clone detection. Notable examples of such applications include the GitHub Copilot powered by OpenAI’s Codex and DeepMind AlphaCode. This paper presents an overview of the major LLMs and their applications in downstream tasks related to AI-assisted programming. Furthermore, it explores the challenges and opportunities associated with incorporating NLP techniques with software naturalness in these applications, with a discussion on extending AI-assisted programming capabilities to Apple’s Xcode for mobile software development. This paper also presents the challenges of and opportunities for incorporating NLP techniques with software naturalness, empowering developers with advanced coding assistance and streamlining the software development process.",Document_307,Technical aspects or methods of AI or machine learning,0.2562054693698883,Other Categories
Automated Building Information Modeling Compliance Check through a Large Language Model Combined with Deep Learning and Ontology,"Nanjiang Chen, Xuhui Lin, Hai Jiang, Yi An","Ensuring compliance with complex industry standards and regulations during the design and implementation phases of construction projects is a significant challenge in the building information modeling (BIM) domain. Traditional manual compliance checking methods are inefficient and error-prone, failing to meet modern engineering demands. Natural language processing (NLP) and deep learning methods have improved efficiency and accuracy in rule interpretation and compliance checking. However, these methods still require extensive manual feature engineering, large, annotated datasets, and significant computational resources. Large language models (LLMs) provide robust language understanding with minimal labeled data due to their pre-training and few-shot learning capabilities. However, their application in the AEC field is still limited by the need for fine-tuning for specific tasks, handling complex texts with nested clauses and conditional statements. This study introduces an innovative automated compliance checking framework that integrates LLM, deep learning models, and ontology knowledge models. The use of LLM is motivated by its few-shot learning capability, which significantly reduces the need for large, annotated datasets required by previous methods. Deep learning is employed to preliminarily classify regulatory texts, which further enhances the accuracy of structured information extraction by the LLM compared to directly feeding raw data into the LLM. This novel combination of deep learning and LLM significantly enhances the efficiency and accuracy of compliance checks by automating the processing of regulatory texts and reducing manual intervention. This approach is crucial for architects, engineers, project managers, and regulators, providing a scalable and adaptable solution for automated compliance in the construction industry with broad application prospects.",2024,2024,,Buildings,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/buildings14071983,10.3390/buildings14071983,https://doi.org/10.3390/buildings14071983,3,"Ensuring compliance with complex industry standards and regulations during the design and implementation phases of construction projects is a significant challenge in the building information modeling (BIM) domain. Traditional manual compliance checking methods are inefficient and error-prone, failing to meet modern engineering demands. Natural language processing (NLP) and deep learning methods have improved efficiency and accuracy in rule interpretation and compliance checking. However, these methods still require extensive manual feature engineering, large, annotated datasets, and significant computational resources. Large language models (LLMs) provide robust language understanding with minimal labeled data due to their pre-training and few-shot learning capabilities. However, their application in the AEC field is still limited by the need for fine-tuning for specific tasks, handling complex texts with nested clauses and conditional statements. This study introduces an innovative automated compliance checking framework that integrates LLM, deep learning models, and ontology knowledge models. The use of LLM is motivated by its few-shot learning capability, which significantly reduces the need for large, annotated datasets required by previous methods. Deep learning is employed to preliminarily classify regulatory texts, which further enhances the accuracy of structured information extraction by the LLM compared to directly feeding raw data into the LLM. This novel combination of deep learning and LLM significantly enhances the efficiency and accuracy of compliance checks by automating the processing of regulatory texts and reducing manual intervention. This approach is crucial for architects, engineers, project managers, and regulators, providing a scalable and adaptable solution for automated compliance in the construction industry with broad application prospects.",Document_308,Demonstrating the value of AI for compliance and risk management,0.1576707810163498,Business Case and Value Demonstration Strategies
Exploring Natural Language Processing in Construction and Integration with Building Information Modeling: A Scientometric Analysis,"Mirko Locatelli, E. Seghezzi, Laura Pellegrini, L. Tagliabue, G. D. Di Giuda","The European Union (EU) aims to increase the efficiency and productivity of the construction industry. The EU suggests pairing Building Information Modeling with other digitalization technologies to seize the full potential of the digital transition. Meanwhile, industrial applications of Natural Language Processing (NLP) have emerged. The growth of NLP is affecting the construction industry. However, the potential of NLP and the combination of an NLP and BIM approach is still unexplored. The study tries to address this lack by applying a scientometric analysis to explore the state of the art of NLP in the AECO sector, and the combined applications of NLP and BIM. Science mapping is used to analyze 254 bibliographic records from Scopus Database analyzing the structure and dynamics of the domain by drawing a picture of the body of knowledge. NLP in AECO, and its pairing with BIM domain and applications, are investigated by representing: Conceptual, Intellectual, and Social structure. The highest number of NLP applications in AECO are in the fields of Project, Safety, and Risk Management. Attempts at combining NLP and BIM mainly concern the Automated Compliance Checking and semantic BIM enrichment goals. Artificial intelligence, learning algorithms, and ontologies emerge as the most widespread and promising technological drivers.",2021,2021,,Buildings,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/buildings11120583,10.3390/buildings11120583,https://doi.org/10.3390/buildings11120583,31,"The European Union (EU) aims to increase the efficiency and productivity of the construction industry. The EU suggests pairing Building Information Modeling with other digitalization technologies to seize the full potential of the digital transition. Meanwhile, industrial applications of Natural Language Processing (NLP) have emerged. The growth of NLP is affecting the construction industry. However, the potential of NLP and the combination of an NLP and BIM approach is still unexplored. The study tries to address this lack by applying a scientometric analysis to explore the state of the art of NLP in the AECO sector, and the combined applications of NLP and BIM. Science mapping is used to analyze 254 bibliographic records from Scopus Database analyzing the structure and dynamics of the domain by drawing a picture of the body of knowledge. NLP in AECO, and its pairing with BIM domain and applications, are investigated by representing: Conceptual, Intellectual, and Social structure. The highest number of NLP applications in AECO are in the fields of Project, Safety, and Risk Management. Attempts at combining NLP and BIM mainly concern the Automated Compliance Checking and semantic BIM enrichment goals. Artificial intelligence, learning algorithms, and ontologies emerge as the most widespread and promising technological drivers.",Document_309,Technical aspects or methods of AI or machine learning,0.13790249824523926,Other Categories
Natural Language Processing Model for Managing Maintenance Requests in Buildings,"Yassine Bouabdallaoui, Z. Lafhaj, Pascal Yim, Laure Ducoulombier, Belkacem Bennadji","In recent years, facility management (FM) has adopted many computer technology solutions for building maintenance, such as building information modelling (BIM) and computerized maintenance management systems (CMMS). However, maintenance requests management in buildings remains a manual and a time-consuming process that depends on human management. In this paper, a machine-learning algorithm based on natural language processing (NLP) is proposed to classify maintenance requests. This algorithm aims to assist the FM teams in managing day-to-day maintenance activities. A healthcare facility is addressed as a case study in this work. Ten-year maintenance records from the facility contributed to the design and development of the algorithm. Multiple NLP methods were used in this study, and the results reveal that the NLP model can classify work requests with an average accuracy of 78%. Furthermore, NLP methods have proven to be effective for managing unstructured text data.",2020,2020,,Buildings,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/buildings10090160,10.3390/buildings10090160,https://doi.org/10.3390/buildings10090160,23,"In recent years, facility management (FM) has adopted many computer technology solutions for building maintenance, such as building information modelling (BIM) and computerized maintenance management systems (CMMS). However, maintenance requests management in buildings remains a manual and a time-consuming process that depends on human management. In this paper, a machine-learning algorithm based on natural language processing (NLP) is proposed to classify maintenance requests. This algorithm aims to assist the FM teams in managing day-to-day maintenance activities. A healthcare facility is addressed as a case study in this work. Ten-year maintenance records from the facility contributed to the design and development of the algorithm. Multiple NLP methods were used in this study, and the results reveal that the NLP model can classify work requests with an average accuracy of 78%. Furthermore, NLP methods have proven to be effective for managing unstructured text data.",Document_310,Technical aspects or methods of AI or machine learning,0.19338150322437286,Other Categories
FinSoSent: Advancing Financial Market Sentiment Analysis through Pretrained Large Language Models,"Josiel Delgadillo, J. Kinyua, C. Mutigwe","Predicting the directions of financial markets has been performed using a variety of approaches, and the large volume of unstructured data generated by traders and other stakeholders on social media microblog platforms provides unique opportunities for analyzing financial markets using additional perspectives. Pretrained large language models (LLMs) have demonstrated very good performance on a variety of sentiment analysis tasks in different domains. However, it is known that sentiment analysis is a very domain-dependent NLP task that requires knowledge of the domain ontology, and this is particularly the case with the financial domain, which uses its own unique vocabulary. Recent developments in NLP and deep learning including LLMs have made it possible to generate actionable financial sentiments using multiple sources including financial news, company fundamentals, technical indicators, as well social media microblogs posted on platforms such as StockTwits and X (formerly Twitter). We developed a financial social media sentiment analyzer (FinSoSent), which is a domain-specific large language model for the financial domain that was pretrained on financial news articles and fine-tuned and tested using several financial social media corpora. We conducted a large number of experiments using different learning rates, epochs, and batch sizes to yield the best performing model. Our model outperforms current state-of-the-art FSA models based on over 860 experiments, demonstrating the efficacy and effectiveness of FinSoSent. We also conducted experiments using ensemble models comprising FinSoSent and the other current state-of-the-art FSA models used in this research, and a slight performance improvement was obtained based on majority voting. Based on the results obtained across all models in these experiments, the significance of this study is that it highlights the fact that, despite the recent advances of LLMs, sentiment analysis even in domain-specific contexts remains a difficult research problem.",2024,2024,,Big Data and Cognitive Computing,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/bdcc8080087,10.3390/bdcc8080087,https://doi.org/10.3390/bdcc8080087,4,"Predicting the directions of financial markets has been performed using a variety of approaches, and the large volume of unstructured data generated by traders and other stakeholders on social media microblog platforms provides unique opportunities for analyzing financial markets using additional perspectives. Pretrained large language models (LLMs) have demonstrated very good performance on a variety of sentiment analysis tasks in different domains. However, it is known that sentiment analysis is a very domain-dependent NLP task that requires knowledge of the domain ontology, and this is particularly the case with the financial domain, which uses its own unique vocabulary. Recent developments in NLP and deep learning including LLMs have made it possible to generate actionable financial sentiments using multiple sources including financial news, company fundamentals, technical indicators, as well social media microblogs posted on platforms such as StockTwits and X (formerly Twitter). We developed a financial social media sentiment analyzer (FinSoSent), which is a domain-specific large language model for the financial domain that was pretrained on financial news articles and fine-tuned and tested using several financial social media corpora. We conducted a large number of experiments using different learning rates, epochs, and batch sizes to yield the best performing model. Our model outperforms current state-of-the-art FSA models based on over 860 experiments, demonstrating the efficacy and effectiveness of FinSoSent. We also conducted experiments using ensemble models comprising FinSoSent and the other current state-of-the-art FSA models used in this research, and a slight performance improvement was obtained based on majority voting. Based on the results obtained across all models in these experiments, the significance of this study is that it highlights the fact that, despite the recent advances of LLMs, sentiment analysis even in domain-specific contexts remains a difficult research problem.",Document_311,Technical aspects or methods of AI or machine learning,0.0724736675620079,Other Categories
Evaluating Retrieval-Augmented Generation Models for Financial Report Question and Answering,"Ivan Iaroshev, Ramalingam Pillai, Leandro Vaglietti, T. Hanne","This study explores the application of retrieval-augmented generation (RAG) to improve the accuracy and reliability of large language models (LLMs) in the context of financial report analysis. The focus is on enabling private investors to make informed decisions by enhancing the question-and-answering capabilities regarding the half-yearly or quarterly financial reports of banks. The study adopts a Design Science Research (DSR) methodology to develop and evaluate an RAG system tailored for this use case. The study conducts a series of experiments to explore models in which different RAG components are used. The aim is to enhance context relevance, answer faithfulness, and answer relevance. The results indicate that model one (OpenAI ADA and OpenAI GPT-4) achieved the highest performance, showing robust accuracy and relevance in response. Model three (MiniLM Embedder and OpenAI GPT-4) scored significantly lower, indicating the importance of high-quality components. The evaluation also revealed that well-structured reports result in better RAG performance than less coherent reports. Qualitative questions received higher scores than the quantitative ones, demonstrating the RAG’s proficiency in handling descriptive data. In conclusion, a tailored RAG can aid investors in providing accurate and contextually relevant information from financial reports, thereby enhancing decision making.",2024,2024,,Applied Sciences,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/app14209318,10.3390/app14209318,https://doi.org/10.3390/app14209318,1,"This study explores the application of retrieval-augmented generation (RAG) to improve the accuracy and reliability of large language models (LLMs) in the context of financial report analysis. The focus is on enabling private investors to make informed decisions by enhancing the question-and-answering capabilities regarding the half-yearly or quarterly financial reports of banks. The study adopts a Design Science Research (DSR) methodology to develop and evaluate an RAG system tailored for this use case. The study conducts a series of experiments to explore models in which different RAG components are used. The aim is to enhance context relevance, answer faithfulness, and answer relevance. The results indicate that model one (OpenAI ADA and OpenAI GPT-4) achieved the highest performance, showing robust accuracy and relevance in response. Model three (MiniLM Embedder and OpenAI GPT-4) scored significantly lower, indicating the importance of high-quality components. The evaluation also revealed that well-structured reports result in better RAG performance than less coherent reports. Qualitative questions received higher scores than the quantitative ones, demonstrating the RAG’s proficiency in handling descriptive data. In conclusion, a tailored RAG can aid investors in providing accurate and contextually relevant information from financial reports, thereby enhancing decision making.",Document_312,Highlighting the benefits of AI for customer insights in finance,0.06922228634357452,Business Case and Value Demonstration Strategies
Natural Language Processing Adoption in Governments and Future Research Directions: A Systematic Review,"Yunqing Jiang, P. Pang, Dennis Wong, Ho Yin Kan","Natural language processing (NLP), which is known as an emerging technology creating considerable value in multiple areas, has recently shown its great potential in government operations and public administration applications. However, while the number of publications on NLP is increasing steadily, there is no comprehensive review for a holistic understanding of how NLP is being adopted by governments. In this regard, we present a systematic literature review on NLP applications in governments by following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) protocol. The review shows that the current literature comprises three levels of contribution: automation, extension, and transformation. The most-used NLP techniques reported in government-related research are sentiment analysis, machine learning, deep learning, classification, data extraction, data mining, topic modelling, opinion mining, chatbots, and question answering. Data classification, management, and decision-making are the most frequently reported reasons for using NLP. The salient research topics being discussed in the literature can be grouped into four categories: (1) governance and policy, (2) citizens and public opinion, (3) medical and healthcare, and (4) economy and environment. Future research directions should focus on (1) the potential of chatbots, (2) NLP applications in the post-pandemic era, and (3) empirical research for government work.",2023,2023,,Applied Sciences,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/app132212346,10.3390/app132212346,https://doi.org/10.3390/app132212346,4,"Natural language processing (NLP), which is known as an emerging technology creating considerable value in multiple areas, has recently shown its great potential in government operations and public administration applications. However, while the number of publications on NLP is increasing steadily, there is no comprehensive review for a holistic understanding of how NLP is being adopted by governments. In this regard, we present a systematic literature review on NLP applications in governments by following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) protocol. The review shows that the current literature comprises three levels of contribution: automation, extension, and transformation. The most-used NLP techniques reported in government-related research are sentiment analysis, machine learning, deep learning, classification, data extraction, data mining, topic modelling, opinion mining, chatbots, and question answering. Data classification, management, and decision-making are the most frequently reported reasons for using NLP. The salient research topics being discussed in the literature can be grouped into four categories: (1) governance and policy, (2) citizens and public opinion, (3) medical and healthcare, and (4) economy and environment. Future research directions should focus on (1) the potential of chatbots, (2) NLP applications in the post-pandemic era, and (3) empirical research for government work.",Document_313,Technical aspects or methods of AI or machine learning,0.14450699090957642,Other Categories
Natural Language Processing and Artificial Intelligence for Enterprise Management in the Era of Industry 4.0,"Pascal Muam Mah, I. Skalna, John Muzam","Introduction: The advances in the digital era have necessitated the adoption of communication as the main channel for modern business. In the past, business negotiations, profiling, seminars, shopping, and agreements were in-person but today everything is almost digitalized. Objectives: The study aims to examine how the Internet of things (IoTs) connects text-object as part of NLP and AI responding to human needs. Also, how precipitated changes in the business environment and modern applications such as NLP and AI embedded with IoTs services have changed business settings. Problem statement: As communication takes lead in the business environment, companies have developed sophisticated applications of NLP that take human desires and fulfill them instantly with the help of text, phone calls, smart records, and chatbots. The ease of communication and interaction has shown a greater influence on customer choice, desires, and needs. Modern service providers now use email, text, phone calls, smart records, and virtual assistants as first contact points for almost all of their dealings, customer inquiries, and most preferred trading channels. Method: The study uses text content as part of NLP and AI to demonstrate how companies capture customers’ insight and how they use IoTs to influence customers’ reactions, responses, and engagement with enterprise management in Industry 4.0. The “Behavior-oriented drive and influential function of IoTs on Customers in Industry 4.0” concept was used in this study to determine the influence of Industry 4.0 on customers. Results: The result indicates the least score of 12 out of 15 grades for all the measurements on a behavior-oriented drive and influential function of IoTs on customers. Conclusion: The study concluded that NLP and AI are the preferred system for enterprise management in the era of Industry 4.0 to understand customers’ demands and achieve customer satisfaction. Therefore, NLP and AI techniques are a necessity to attain business goals.",2022,2022,,Applied Sciences,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/app12189207,10.3390/app12189207,https://doi.org/10.3390/app12189207,30,"Introduction: The advances in the digital era have necessitated the adoption of communication as the main channel for modern business. In the past, business negotiations, profiling, seminars, shopping, and agreements were in-person but today everything is almost digitalized. Objectives: The study aims to examine how the Internet of things (IoTs) connects text-object as part of NLP and AI responding to human needs. Also, how precipitated changes in the business environment and modern applications such as NLP and AI embedded with IoTs services have changed business settings. Problem statement: As communication takes lead in the business environment, companies have developed sophisticated applications of NLP that take human desires and fulfill them instantly with the help of text, phone calls, smart records, and chatbots. The ease of communication and interaction has shown a greater influence on customer choice, desires, and needs. Modern service providers now use email, text, phone calls, smart records, and virtual assistants as first contact points for almost all of their dealings, customer inquiries, and most preferred trading channels. Method: The study uses text content as part of NLP and AI to demonstrate how companies capture customers’ insight and how they use IoTs to influence customers’ reactions, responses, and engagement with enterprise management in Industry 4.0. The “Behavior-oriented drive and influential function of IoTs on Customers in Industry 4.0” concept was used in this study to determine the influence of Industry 4.0 on customers. Results: The result indicates the least score of 12 out of 15 grades for all the measurements on a behavior-oriented drive and influential function of IoTs on customers. Conclusion: The study concluded that NLP and AI are the preferred system for enterprise management in the era of Industry 4.0 to understand customers’ demands and achieve customer satisfaction. Therefore, NLP and AI techniques are a necessity to attain business goals.",Document_314,Technical aspects or methods of AI or machine learning,0.1174488365650177,Other Categories
From Word Embeddings to Pre-Trained Language Models: A State-of-the-Art Walkthrough,Mourad Mars,"With the recent advances in deep learning, different approaches to improving pre-trained language models (PLMs) have been proposed. PLMs have advanced state-of-the-art (SOTA) performance on various natural language processing (NLP) tasks such as machine translation, text classification, question answering, text summarization, information retrieval, recommendation systems, named entity recognition, etc. In this paper, we provide a comprehensive review of prior embedding models as well as current breakthroughs in the field of PLMs. Then, we analyse and contrast the various models and provide an analysis of the way they have been built (number of parameters, compression techniques, etc.). Finally, we discuss the major issues and future directions for each of the main points.",2022,2022,,Applied Sciences,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/app12178805,10.3390/app12178805,https://doi.org/10.3390/app12178805,53,"With the recent advances in deep learning, different approaches to improving pre-trained language models (PLMs) have been proposed. PLMs have advanced state-of-the-art (SOTA) performance on various natural language processing (NLP) tasks such as machine translation, text classification, question answering, text summarization, information retrieval, recommendation systems, named entity recognition, etc. In this paper, we provide a comprehensive review of prior embedding models as well as current breakthroughs in the field of PLMs. Then, we analyse and contrast the various models and provide an analysis of the way they have been built (number of parameters, compression techniques, etc.). Finally, we discuss the major issues and future directions for each of the main points.",Document_315,Technical aspects or methods of AI or machine learning,0.11009331047534943,Other Categories
On the Black-Box Challenge for Fraud Detection Using Machine Learning (II): Nonlinear Analysis through Interpretable Autoencoders,"Jacobo Chaquet-Ulldemolins, F. Gimeno-Blanes, Santiago Moral-Rubio, Sergio Muñoz-Romero, J. Rojo-álvarez","Artificial intelligence (AI) has recently intensified in the global economy due to the great competence that it has demonstrated for analysis and modeling in many disciplines. This situation is accelerating the shift towards a more automated society, where these new techniques can be consolidated as a valid tool to face the difficult challenge of credit fraud detection (CFD). However, tight regulations do not make it easy for financial entities to comply with them while using modern techniques. From a methodological perspective, autoencoders have demonstrated their effectiveness in discovering nonlinear features across several problem domains. However, autoencoders are opaque and often seen as black boxes. In this work, we propose an interpretable and agnostic methodology for CFD. This type of approach allows a double advantage: on the one hand, it can be applied together with any machine learning (ML) technique, and on the other hand, it offers the necessary traceability between inputs and outputs, hence escaping from the black-box model. We first applied the state-of-the-art feature selection technique defined in the companion paper. Second, we proposed a novel technique, based on autoencoders, capable of evaluating the relationship among input and output of a sophisticated ML model for each and every one of the samples that are submitted to the analysis, through a single transaction-level explanation (STE) approach. This technique allows each instance to be analyzed individually by applying small fluctuations of the input space and evaluating how it is triggered in the output, thereby shedding light on the underlying dynamics of the model. Based on this, an individualized transaction ranking (ITR) can be formulated, leveraging on the contributions of each feature through STE. These rankings represent a close estimate of the most important features playing a role in the decision process. The results obtained in this work were consistent with previous published papers, and showed that certain features, such as living beyond means, lack or absence of transaction trail, and car loans, have strong influence on the model outcome. Additionally, this proposal using the latent space outperformed, in terms of accuracy, our previous results, which already improved prior published papers, by 5.5% and 1.5% for the datasets under study, from a baseline of 76% and 93%. The contribution of this paper is twofold, as far as a new outperforming CFD classification model is presented, and at the same time, we developed a novel methodology, applicable across classification techniques, that allows to breach black-box models, erasingthe dependencies and, eventually, undesirable biases. We conclude that it is possible to develop an effective, individualized, unbiased, and traceable ML technique, not only to comply with regulations, but also to be able to cope with transaction-level inquiries from clients and authorities.",2022,2022,,Applied Sciences,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/app12083856,10.3390/app12083856,https://doi.org/10.3390/app12083856,18,"Artificial intelligence (AI) has recently intensified in the global economy due to the great competence that it has demonstrated for analysis and modeling in many disciplines. This situation is accelerating the shift towards a more automated society, where these new techniques can be consolidated as a valid tool to face the difficult challenge of credit fraud detection (CFD). However, tight regulations do not make it easy for financial entities to comply with them while using modern techniques. From a methodological perspective, autoencoders have demonstrated their effectiveness in discovering nonlinear features across several problem domains. However, autoencoders are opaque and often seen as black boxes. In this work, we propose an interpretable and agnostic methodology for CFD. This type of approach allows a double advantage: on the one hand, it can be applied together with any machine learning (ML) technique, and on the other hand, it offers the necessary traceability between inputs and outputs, hence escaping from the black-box model. We first applied the state-of-the-art feature selection technique defined in the companion paper. Second, we proposed a novel technique, based on autoencoders, capable of evaluating the relationship among input and output of a sophisticated ML model for each and every one of the samples that are submitted to the analysis, through a single transaction-level explanation (STE) approach. This technique allows each instance to be analyzed individually by applying small fluctuations of the input space and evaluating how it is triggered in the output, thereby shedding light on the underlying dynamics of the model. Based on this, an individualized transaction ranking (ITR) can be formulated, leveraging on the contributions of each feature through STE. These rankings represent a close estimate of the most important features playing a role in the decision process. The results obtained in this work were consistent with previous published papers, and showed that certain features, such as living beyond means, lack or absence of transaction trail, and car loans, have strong influence on the model outcome. Additionally, this proposal using the latent space outperformed, in terms of accuracy, our previous results, which already improved prior published papers, by 5.5% and 1.5% for the datasets under study, from a baseline of 76% and 93%. The contribution of this paper is twofold, as far as a new outperforming CFD classification model is presented, and at the same time, we developed a novel methodology, applicable across classification techniques, that allows to breach black-box models, erasingthe dependencies and, eventually, undesirable biases. We conclude that it is possible to develop an effective, individualized, unbiased, and traceable ML technique, not only to comply with regulations, but also to be able to cope with transaction-level inquiries from clients and authorities.",Document_316,AI-specific regulations pose challenges for financial institutions,0.11199405044317245,Regulatory and Ethical Barriers
Improving the Consistency of the Failure Mode Effect Analysis (FMEA) Documents in Semiconductor Manufacturing,"Houssam Razouk, Roman Kern","Digitalization of causal domain knowledge is crucial. Especially since the inclusion of causal domain knowledge in the data analysis processes helps to avoid biased results. To extract such knowledge, the Failure Mode Effect Analysis (FMEA) documents represent a valuable data source. Originally, FMEA documents were designed to be exclusively produced and interpreted by human domain experts. As a consequence, these documents often suffer from data consistency issues. This paper argues that due to the transitive perception of the causal relations, discordant and merged information cases are likely to occur. Thus, we propose to improve the consistency of FMEA documents as a step towards more efficient use of causal domain knowledge. In contrast to other work, this paper focuses on the consistency of causal relations expressed in the FMEA documents. To this end, based on an explicit scheme of types of inconsistencies derived from the causal perspective, novel methods to enhance the data quality in FMEA documents are presented. Data quality improvement will significantly improve downstream tasks, such as root cause analysis and automatic process control.",2022,2022,,Applied Sciences,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/app12041840,10.3390/app12041840,https://doi.org/10.3390/app12041840,12,"Digitalization of causal domain knowledge is crucial. Especially since the inclusion of causal domain knowledge in the data analysis processes helps to avoid biased results. To extract such knowledge, the Failure Mode Effect Analysis (FMEA) documents represent a valuable data source. Originally, FMEA documents were designed to be exclusively produced and interpreted by human domain experts. As a consequence, these documents often suffer from data consistency issues. This paper argues that due to the transitive perception of the causal relations, discordant and merged information cases are likely to occur. Thus, we propose to improve the consistency of FMEA documents as a step towards more efficient use of causal domain knowledge. In contrast to other work, this paper focuses on the consistency of causal relations expressed in the FMEA documents. To this end, based on an explicit scheme of types of inconsistencies derived from the causal perspective, novel methods to enhance the data quality in FMEA documents are presented. Data quality improvement will significantly improve downstream tasks, such as root cause analysis and automatic process control.",Document_317,Technical aspects or methods of AI or machine learning,0.06375078111886978,Other Categories
Toward Business Integrity Modeling and Analysis Framework for Risk Measurement and Analysis,"V. Chang, Raul Valverde, M. Ramachandran, Chung-Sheng Li","Financialization has contributed to economic growth but has caused scandals, misselling, rogue trading, tax evasion, and market speculation. To a certain extent, it has also created problems in social and economic instability. It is an important aspect of Enterprise Security, Privacy, and Risk (ESPR), particularly in risk research and analysis. In order to minimize the damaging impacts caused by the lack of regulatory compliance, governance, ethical responsibilities, and trust, we propose a Business Integrity Modeling and Analysis (BIMA) framework to unify business integrity with performance using big data predictive analytics and business intelligence. Comprehensive services include modeling risk and asset prices, and consequently, aligning them with business strategies, making our services, according to market trend analysis, both transparent and fair. The BIMA framework uses Monte Carlo simulation, the Black–Scholes–Merton model, and the Heston model for performing financial, operational, and liquidity risk analysis and present outputs in the form of analytics and visualization. Our results and analysis demonstrate supplier bankruptcy modeling, risk pricing, high-frequency pricing simulations, London Interbank Offered Rate (LIBOR) rate simulation, and speculation detection results to provide a variety of critical risk analysis. Our approaches to tackle problems caused by financial services and the operational risk clearly demonstrate that the BIMA framework, as the outputs of our data analytics research, can effectively combine integrity and risk analysis together with overall business performance and can contribute to operational risk research.",2020,2020,,Applied Sciences,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3390/app10093145,10.3390/app10093145,https://doi.org/10.3390/app10093145,17,"Financialization has contributed to economic growth but has caused scandals, misselling, rogue trading, tax evasion, and market speculation. To a certain extent, it has also created problems in social and economic instability. It is an important aspect of Enterprise Security, Privacy, and Risk (ESPR), particularly in risk research and analysis. In order to minimize the damaging impacts caused by the lack of regulatory compliance, governance, ethical responsibilities, and trust, we propose a Business Integrity Modeling and Analysis (BIMA) framework to unify business integrity with performance using big data predictive analytics and business intelligence. Comprehensive services include modeling risk and asset prices, and consequently, aligning them with business strategies, making our services, according to market trend analysis, both transparent and fair. The BIMA framework uses Monte Carlo simulation, the Black–Scholes–Merton model, and the Heston model for performing financial, operational, and liquidity risk analysis and present outputs in the form of analytics and visualization. Our results and analysis demonstrate supplier bankruptcy modeling, risk pricing, high-frequency pricing simulations, London Interbank Offered Rate (LIBOR) rate simulation, and speculation detection results to provide a variety of critical risk analysis. Our approaches to tackle problems caused by financial services and the operational risk clearly demonstrate that the BIMA framework, as the outputs of our data analytics research, can effectively combine integrity and risk analysis together with overall business performance and can contribute to operational risk research.",Document_318,General discussion of financial or regulatory topics (non-AI focus),0.08753622323274612,Other Categories
On Fintech and Financial Inclusion,Thomas Philippon,The cost of financial intermediation has declined in recent years thanks to technology and increased competition in some parts of the finance industry. I document this fact and I analyze two features of new financial technologies that have stirred controversy: returns to scale and the use of big data and machine learning. I argue that the nature of fixed versus variable costs in robo-advising is likely to democratize access to financial services. Big data is likely to reduce the impact of negative prejudice in the credit market but it could reduce the effectiveness of existing policies aimed at protecting minorities.,2019,2019,,-,Skipped (Content is PDF) (URL Source: DOI Link),https://doi.org/10.3386/w26330,10.3386/w26330,https://doi.org/10.3386/w26330,53,The cost of financial intermediation has declined in recent years thanks to technology and increased competition in some parts of the finance industry. I document this fact and I analyze two features of new financial technologies that have stirred controversy: returns to scale and the use of big data and machine learning. I argue that the nature of fixed versus variable costs in robo-advising is likely to democratize access to financial services. Big data is likely to reduce the impact of negative prejudice in the credit market but it could reduce the effectiveness of existing policies aimed at protecting minorities.,Document_319,Technical aspects or methods of AI or machine learning,0.39194434881210327,Other Categories
Is Neuro-Symbolic AI Meeting its Promise in Natural Language Processing? A Structured Review,"Kyle Hamilton, Aparna Nayak, Bojan Bozic, Luca Longo","Advocates for Neuro-Symbolic Artificial Intelligence (NeSy) assert that combining deep learning with symbolic reasoning will lead to stronger AI than either paradigm on its own. As successful as deep learning has been, it is generally accepted that even our best deep learning systems are not very good at abstract reasoning. And since reasoning is inextricably linked to language, it makes intuitive sense that Natural Language Processing (NLP), would be a particularly well-suited candidate for NeSy. We conduct a structured review of studies implementing NeSy for NLP, with the aim of answering the question of whether NeSy is indeed meeting its promises: reasoning, out-of-distribution generalization, interpretability, learning and reasoning from small data, and transferability to new domains. We examine the impact of knowledge representation, such as rules and semantic networks, language structure and relational structure, and whether implicit or explicit reasoning contributes to higher promise scores. We find that systems where logic is compiled into the neural network lead to the most NeSy goals being satisfied, while other factors such as knowledge representation, or type of neural architecture do not exhibit a clear correlation with goals being met. We find many discrepancies in how reasoning is defined, specifically in relation to human level reasoning, which impact decisions about model architectures and drive conclusions which are not always consistent across studies. Hence we advocate for a more methodical approach to the application of theories of human reasoning as well as the development of appropriate benchmarks, which we hope can lead to a better understanding of progress in the field. We make our data and code available on github for further analysis.",2022,2022,,Semantic Web,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3233/SW-223228,10.3233/SW-223228,https://doi.org/10.3233/SW-223228,46,"Advocates for Neuro-Symbolic Artificial Intelligence (NeSy) assert that combining deep learning with symbolic reasoning will lead to stronger AI than either paradigm on its own. As successful as deep learning has been, it is generally accepted that even our best deep learning systems are not very good at abstract reasoning. And since reasoning is inextricably linked to language, it makes intuitive sense that Natural Language Processing (NLP), would be a particularly well-suited candidate for NeSy. We conduct a structured review of studies implementing NeSy for NLP, with the aim of answering the question of whether NeSy is indeed meeting its promises: reasoning, out-of-distribution generalization, interpretability, learning and reasoning from small data, and transferability to new domains. We examine the impact of knowledge representation, such as rules and semantic networks, language structure and relational structure, and whether implicit or explicit reasoning contributes to higher promise scores. We find that systems where logic is compiled into the neural network lead to the most NeSy goals being satisfied, while other factors such as knowledge representation, or type of neural architecture do not exhibit a clear correlation with goals being met. We find many discrepancies in how reasoning is defined, specifically in relation to human level reasoning, which impact decisions about model architectures and drive conclusions which are not always consistent across studies. Hence we advocate for a more methodical approach to the application of theories of human reasoning as well as the development of appropriate benchmarks, which we hope can lead to a better understanding of progress in the field. We make our data and code available on github for further analysis.",Document_320,Technical aspects or methods of AI or machine learning,0.2196352481842041,Other Categories
Leveraging Knowledge Graphs for Big Data Integration: the XI Pipeline,P. Cudré-Mauroux,"This article gives an overview of recent efforts focusing on integrating heterogeneous data using Knowledge Graphs. I introduce a pipeline consisting of five steps to integrate semi-structured or unstructured content. I discuss some of the key applications of this pipeline through three use-cases, and present the lessons learnt along the way while designing and building data integration systems.",2020,2020,,Semantic Web,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3233/sw-190371,10.3233/sw-190371,https://doi.org/10.3233/sw-190371,20,"This article gives an overview of recent efforts focusing on integrating heterogeneous data using Knowledge Graphs. I introduce a pipeline consisting of five steps to integrate semi-structured or unstructured content. I discuss some of the key applications of this pipeline through three use-cases, and present the lessons learnt along the way while designing and building data integration systems.",Document_321,Other AI topic (not related to finance/regulation),0.10427676141262054,Other Categories
Artificial intelligence in scholarly communications: An elsevier case study,Ann Gabriel,"This paper is an adaptation of presentation given by the author at the NFAIS Conference on Artificial Intelligence that was held in Alexandria, VA from May 15–16, 2019. It provides an overview on the need for increased Artificial Intelligence (AI) usage in scholarly communications for both information providers and the research community. It also includes an introduction to how Elsevier transitioned from print to electronic to information solutions (P – E – S) and how some of its tools employ AI. In addition, it covers two case studies showcasing how Elsevier incorporated Machine Learning (ML) and Natural Language Processing (NLP) to create two technological and data-based solutions for researchers, as well as a summary of the solutions’ positive outcomes.",2020,2020,,Information Services and Use,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3233/isu-190063,10.3233/isu-190063,https://doi.org/10.3233/isu-190063,4,"This paper is an adaptation of presentation given by the author at the NFAIS Conference on Artificial Intelligence that was held in Alexandria, VA from May 15–16, 2019. It provides an overview on the need for increased Artificial Intelligence (AI) usage in scholarly communications for both information providers and the research community. It also includes an introduction to how Elsevier transitioned from print to electronic to information solutions (P – E – S) and how some of its tools employ AI. In addition, it covers two case studies showcasing how Elsevier incorporated Machine Learning (ML) and Natural Language Processing (NLP) to create two technological and data-based solutions for researchers, as well as a summary of the solutions’ positive outcomes.",Document_322,Technical aspects or methods of AI or machine learning,0.4188522696495056,Other Categories
An Analysis of Active Learning Strategies for Sequence Labeling Tasks,"Burr Settles, M. Craven","Active learning is well-suited to many problems in natural language processing, where unlabeled data may be abundant but annotation is slow and expensive. This paper aims to shed light on the best active learning approaches for sequence labeling tasks such as information extraction and document segmentation. We survey previously used query selection strategies for sequence models, and propose several novel algorithms to address their shortcomings. We also conduct a large-scale empirical comparison using multiple corpora, which demonstrates that our proposed methods advance the state of the art.",2008,2008,,Conference on Empirical Methods in Natural Language Processing,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.3115/1613715.1613855,10.3115/1613715.1613855,https://doi.org/10.3115/1613715.1613855,1080,"Active learning is well-suited to many problems in natural language processing, where unlabeled data may be abundant but annotation is slow and expensive. This paper aims to shed light on the best active learning approaches for sequence labeling tasks such as information extraction and document segmentation. We survey previously used query selection strategies for sequence models, and propose several novel algorithms to address their shortcomings. We also conduct a large-scale empirical comparison using multiple corpora, which demonstrates that our proposed methods advance the state of the art.",Document_323,Technical aspects or methods of AI or machine learning,0.12993675470352173,Other Categories
Text Preprocessing and its Implications in a Digital Humanities Project,"M. Kunilovskaya, Alistair Plum","This paper focuses on data cleaning as part of a preprocessing procedure applied to text data retrieved from the web. Although the importance of this early stage in a project using NLP methods is often highlighted by researchers, the details, general principles and techniques are usually left out due to consideration of space. At best, they are dismissed with a comment “The usual data cleaning and preprocessing procedures were applied”. More coverage is usually given to automatic text annotation such as lemmatisation, part-of-speech tagging and parsing, which is often included in preprocessing. In the literature, the term ‘preprocessing’ is used to refer to a wide range of procedures, from filtering and cleaning to data transformation such as stemming and numeric representation, which might create confusion. We argue that text preprocessing might skew original data distribution with regard to the metadata, such as types, locations and times of registered datapoints. In this paper we describe a systematic approach to cleaning text data mined by a data-providing company for a Digital Humanities (DH) project focused on cultural analytics. We reveal the types and amount of noise in the data coming from various web sources and estimate the changes in the size of the data associated with preprocessing. We also compare the results of a text classification experiment run on the raw and preprocessed data. We hope that our experience and approaches will help the DH community to diagnose the quality of textual data collected from the web and prepare it for further natural language processing.",2021,2021,,Recent Advances in Natural Language Processing,Skipped (Content is PDF) (URL Source: DOI Link),https://doi.org/10.26615/issn.2603-2821.2021_013,10.26615/issn.2603-2821.2021_013,https://doi.org/10.26615/issn.2603-2821.2021_013,3,"This paper focuses on data cleaning as part of a preprocessing procedure applied to text data retrieved from the web. Although the importance of this early stage in a project using NLP methods is often highlighted by researchers, the details, general principles and techniques are usually left out due to consideration of space. At best, they are dismissed with a comment “The usual data cleaning and preprocessing procedures were applied”. More coverage is usually given to automatic text annotation such as lemmatisation, part-of-speech tagging and parsing, which is often included in preprocessing. In the literature, the term ‘preprocessing’ is used to refer to a wide range of procedures, from filtering and cleaning to data transformation such as stemming and numeric representation, which might create confusion. We argue that text preprocessing might skew original data distribution with regard to the metadata, such as types, locations and times of registered datapoints. In this paper we describe a systematic approach to cleaning text data mined by a data-providing company for a Digital Humanities (DH) project focused on cultural analytics. We reveal the types and amount of noise in the data coming from various web sources and estimate the changes in the size of the data associated with preprocessing. We also compare the results of a text classification experiment run on the raw and preprocessed data. We hope that our experience and approaches will help the DH community to diagnose the quality of textual data collected from the web and prepare it for further natural language processing.",Document_324,Technical aspects or methods of AI or machine learning,0.08583839982748032,Other Categories
Governance of Legislative Requirements for the Development of Natural Language Processing Tools,"I. Opmane, J. Balodis, R. Balodis","Abstract. Information technology policy makers prioritize Artificial Intelligence as a new and important area of innovation. The focus on AI development is highlighted by Microsoft, as well as the US and European governments, who believe that the development of AI should remove the existing legislative barriers. New legislation and AI regulations are needed as there are not enough for a new researcher's code of ethics. The discussion is about basic issues: BIG Data and EU Data Regulation, GDPR, the new Copyright Law, as well as the international harmonization of AI regulation. The Institute of Mathematics and Computer Science of the University of Latvia is also conducting internationally recognized research in the field of language technologies. This study describes the regulatory compliance and risk management for Law Enforcement in our case. Regulatory compliance is the process of putting in place the measures necessary to comply with the regulations, laws, and guidelines that govern the operations of a business on a day-to-day basis. Information technologies policy makers prioritize Artificial Intelligence as a new and important area of innovation.",2019,2019,,Managing Geostrategic Issues,Skipped (Content is PDF) (URL Source: DOI Link),https://doi.org/10.26493/978-961-6832-68-7.2,10.26493/978-961-6832-68-7.2,https://doi.org/10.26493/978-961-6832-68-7.2,1,"Abstract. Information technology policy makers prioritize Artificial Intelligence as a new and important area of innovation. The focus on AI development is highlighted by Microsoft, as well as the US and European governments, who believe that the development of AI should remove the existing legislative barriers. New legislation and AI regulations are needed as there are not enough for a new researcher's code of ethics. The discussion is about basic issues: BIG Data and EU Data Regulation, GDPR, the new Copyright Law, as well as the international harmonization of AI regulation. The Institute of Mathematics and Computer Science of the University of Latvia is also conducting internationally recognized research in the field of language technologies. This study describes the regulatory compliance and risk management for Law Enforcement in our case. Regulatory compliance is the process of putting in place the measures necessary to comply with the regulations, laws, and guidelines that govern the operations of a business on a day-to-day basis. Information technologies policy makers prioritize Artificial Intelligence as a new and important area of innovation.",Document_325,Demonstrating the value of AI for compliance and risk management,0.2404325306415558,Business Case and Value Demonstration Strategies
Metamorphic Testing and Certified Mitigation of Fairness Violations in NLP Models,"Pingchuan Ma, Shuai Wang, Jin Liu","Natural language processing (NLP) models have been increasingly used in sensitive application domains including credit scoring, insurance, and loan assessment. Hence, it is critical to know that the decisions made by NLP models are free of unfair bias toward certain subpopulation groups. In this paper, we propose a novel framework employing metamorphic testing, a well-established software testing scheme, to test NLP models and find discriminatory inputs that provoke fairness violations. Furthermore, inspired by recent breakthroughs in the certified robustness of machine learning, we formulate NLP model fairness in a practical setting as (ε, k)-fairness and accordingly smooth the model predictions to mitigate fairness violations. We demonstrate our technique using popular (commercial) NLP models, and successfully flag thousands of discriminatory inputs that can cause fairness violations. We further enhance the evaluated models by adding certified fairness guarantee at a modest cost.",2020,2020,7.0,International Joint Conference on Artificial Intelligence,"Abstract Not Found / Date (Meta (citation_publication_date)) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.34) (URL Source: DOI Link)",https://doi.org/10.24963/ijcai.2020/64,10.24963/ijcai.2020/64,https://doi.org/10.24963/ijcai.2020/64,68,"Natural language processing (NLP) models have been increasingly used in sensitive application domains including credit scoring, insurance, and loan assessment. Hence, it is critical to know that the decisions made by NLP models are free of unfair bias toward certain subpopulation groups. In this paper, we propose a novel framework employing metamorphic testing, a well-established software testing scheme, to test NLP models and find discriminatory inputs that provoke fairness violations. Furthermore, inspired by recent breakthroughs in the certified robustness of machine learning, we formulate NLP model fairness in a practical setting as (ε, k)-fairness and accordingly smooth the model predictions to mitigate fairness violations. We demonstrate our technique using popular (commercial) NLP models, and successfully flag thousands of discriminatory inputs that can cause fairness violations. We further enhance the evaluated models by adding certified fairness guarantee at a modest cost.",Document_326,Technical aspects or methods of AI or machine learning,0.06810462474822998,Other Categories
Interpretable Adversarial Perturbation in Input Embedding Space for Text,"Motoki Sato, Jun Suzuki, Hiroyuki Shindo, Yuji Matsumoto","Following great success in the image processing field, the idea of adversarial training has been applied to tasks in the natural language processing (NLP) field. One promising approach directly applies adversarial training developed in the image processing field to the input word embedding space instead of the discrete input space of texts. However, this approach abandons such interpretability as generating adversarial texts to significantly improve the performance of NLP tasks. This paper restores interpretability to such methods by restricting the directions of perturbations toward the existing words in the input embedding space. As a result, we can straightforwardly reconstruct each input with perturbations to an actual text by considering the perturbations to be the replacement of words in the sentence while maintaining or even improving the task performance.",2018,2018,4.0,International Joint Conference on Artificial Intelligence,"Abstract Not Found / Date (Meta (citation_publication_date)) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.13) (URL Source: DOI Link)",https://doi.org/10.24963/ijcai.2018/601,10.24963/ijcai.2018/601,https://doi.org/10.24963/ijcai.2018/601,182,"Following great success in the image processing field, the idea of adversarial training has been applied to tasks in the natural language processing (NLP) field. One promising approach directly applies adversarial training developed in the image processing field to the input word embedding space instead of the discrete input space of texts. However, this approach abandons such interpretability as generating adversarial texts to significantly improve the performance of NLP tasks. This paper restores interpretability to such methods by restricting the directions of perturbations toward the existing words in the input embedding space. As a result, we can straightforwardly reconstruct each input with perturbations to an actual text by considering the perturbations to be the replacement of words in the sentence while maintaining or even improving the task performance.",Document_327,Technical aspects or methods of AI or machine learning,0.10577023774385452,Other Categories
The Data Standardization Challenge,"R. Berner, Kathryn Judge","Data standardization offers significant benefits for industry and regulators alike, suggesting that it should be easy. In practice, however, the process has been difficult and slow moving. Moving from an abstract incentive-based analysis to one focused on institutional detail reveals myriad frictions favoring the status quo despite foregone gains. This paper explores the benefits of and challenges confronting standardization, why it should be a top regulatory priority, and how to overcome some of the obstacles to implementation.
The paper also uses data standardization as a lens into the challenges that impede optimal financial regulation. Alongside capture and other common explanations for regulatory failures, this paper suggests that coordination problems, delayed benefits, and other banal, but perhaps no less intractable, challenges are often the real impediments to better financial regulation.",2019,2019,,Systemic Risk in the Financial Sector,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.2307/j.ctvqmp0vn.12,10.2307/j.ctvqmp0vn.12,https://doi.org/10.2307/j.ctvqmp0vn.12,17,"Data standardization offers significant benefits for industry and regulators alike, suggesting that it should be easy. In practice, however, the process has been difficult and slow moving. Moving from an abstract incentive-based analysis to one focused on institutional detail reveals myriad frictions favoring the status quo despite foregone gains. This paper explores the benefits of and challenges confronting standardization, why it should be a top regulatory priority, and how to overcome some of the obstacles to implementation.
The paper also uses data standardization as a lens into the challenges that impede optimal financial regulation. Alongside capture and other common explanations for regulatory failures, this paper suggests that coordination problems, delayed benefits, and other banal, but perhaps no less intractable, challenges are often the real impediments to better financial regulation.",Document_328,General discussion of financial or regulatory topics (non-AI focus),0.18372300267219543,Other Categories
Text Analytics and Natural Language Processing for Business Insights: A Comprehensive Review,Yusupha Sinjanka,"In today's fast-paced business era, data reigns supreme. From emails and social media to reviews and articles, we've amassed a treasure trove of textual information that unveils customer sentiments, market trends, and brand perceptions. However, the real challenge lies in extracting valuable insights from this textual abundance. With that, we present an intensive and thorough review of the existing methods of over the past six years, from 2018 to 2023. We found two game-changers: text analytics, the detective of text patterns, and Natural Language Processing (NLP), the language expert for computers. Together, they bring order to the chaotic world of words. Our review explores the quick development of NLP and offers suggestions for problems. Businesses can make educated decisions, outperform rivals, and make data their greatest asset with the help of these cutting-edge solutions. In order to ensure they find gold in the sea of text data, our study serves as the compass that directs them on this revolutionary journey.",2023,2023,,International Journal for Research in Applied Science and Engineering Technology,Skipped (Content is PDF) (URL Source: DOI Link),https://doi.org/10.22214/ijraset.2023.55893,10.22214/ijraset.2023.55893,https://doi.org/10.22214/ijraset.2023.55893,2,"In today's fast-paced business era, data reigns supreme. From emails and social media to reviews and articles, we've amassed a treasure trove of textual information that unveils customer sentiments, market trends, and brand perceptions. However, the real challenge lies in extracting valuable insights from this textual abundance. With that, we present an intensive and thorough review of the existing methods of over the past six years, from 2018 to 2023. We found two game-changers: text analytics, the detective of text patterns, and Natural Language Processing (NLP), the language expert for computers. Together, they bring order to the chaotic world of words. Our review explores the quick development of NLP and offers suggestions for problems. Businesses can make educated decisions, outperform rivals, and make data their greatest asset with the help of these cutting-edge solutions. In order to ensure they find gold in the sea of text data, our study serves as the compass that directs them on this revolutionary journey.",Document_329,Technical aspects or methods of AI or machine learning,0.08809656649827957,Other Categories
"Textual Factors: A Scalable, Interpretable, and Data-Driven Approach to Analyzing Unstructured Information","L. Cong, Tengyuan Liang, Xiao Zhang","We introduce a general approach for analyzing large-scale text-based data, combining the strengths of neural network language processing and generative statistical modeling to create a factor structure of unstructured data for downstream regressions typically used in social sciences. We generate textual factors by (i) representing texts using vector word embedding, (ii) clustering the vectors using Locality-Sensitive Hashing to generate supports of topics, and (iii) identifying relatively interpretable spanning clusters (i.e., textual factors) through topic modeling. Our data-driven approach captures complex linguistic structures while ensuring computational scalability and economic interpretability, plausibly attaining certain advantages over and complementing other unstructured data analytics used by researchers, including emergent large language models. We conduct initial validation tests of the framework and discuss three types of its applications: (i) enhancing prediction and inference with texts, (ii) interpreting (non-text-based) models, and (iii) constructing new text-based metrics and explanatory variables. We illustrate each of these applications using examples in finance and economics such as macroeconomic forecasting from news articles, interpreting multifactor asset pricing models from corporate filings, and measuring theme-based technology breakthroughs from patents. Finally, we provide a flexible statistical package of textual factors for online distribution to facilitate future research and applications.",2024,2024,,Social Science Research Network,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.5024264,10.2139/ssrn.5024264,https://doi.org/10.2139/ssrn.5024264,27,"We introduce a general approach for analyzing large-scale text-based data, combining the strengths of neural network language processing and generative statistical modeling to create a factor structure of unstructured data for downstream regressions typically used in social sciences. We generate textual factors by (i) representing texts using vector word embedding, (ii) clustering the vectors using Locality-Sensitive Hashing to generate supports of topics, and (iii) identifying relatively interpretable spanning clusters (i.e., textual factors) through topic modeling. Our data-driven approach captures complex linguistic structures while ensuring computational scalability and economic interpretability, plausibly attaining certain advantages over and complementing other unstructured data analytics used by researchers, including emergent large language models. We conduct initial validation tests of the framework and discuss three types of its applications: (i) enhancing prediction and inference with texts, (ii) interpreting (non-text-based) models, and (iii) constructing new text-based metrics and explanatory variables. We illustrate each of these applications using examples in finance and economics such as macroeconomic forecasting from news articles, interpreting multifactor asset pricing models from corporate filings, and measuring theme-based technology breakthroughs from patents. Finally, we provide a flexible statistical package of textual factors for online distribution to facilitate future research and applications.",Document_330,Technical aspects or methods of AI or machine learning,0.08121252059936523,Other Categories
AI Regulations in the Context of Natural Language Processing Research,"Srishti Kumar, Helena U Vrabec, Zhongli Xie, Somaieh Nikpoor, Dandan Zhao, Luisa Shinzato, R. Eisenberg","Recent advances in development and applications of AI technologies including Natural Language Processing (NLP) models, such as the newly developed model known as GPT3 that can generate human-line text/speech on demand, has created a great deal of hype and excitement. With increasing use of NLP models, extensive and proper guardrails need to be in place to ensure safety and trustworthiness of these systems.

Numerous policy and regulation initiatives, such as EU AI Act, UNESCO recommendation on AI, US AI Bill of right, OECD AI principle, China’s AI regulatory initiatives, and the US-EU AI agreement, are shaping the global AI regulation landscape. The proposed EU AI Act, which is the world's first comprehensive attempt to regulate AI, is expected to set global standards for emulation by other jurisdictions. NLP models do not escape the existing regulations, notably the rules on data protection such as the EU General Data Protection Regulation (GDPR).

In this paper, we briefly introduce some AI regulation initiatives in Chapter 1, we then introduce how the GDPR applies to AI usage in Chapter 2, and we discuss specifically the proposed EU AI Act and its risk-based approach to AI in Chapter 3, and NLP as applied to the risk-based approach of EU AI Act in Chapter 4. In all these chapters, we focus on how these proposals or laws relate to NLP research.",2023,2023,,Social Science Research Network,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.4526253,10.2139/ssrn.4526253,https://doi.org/10.2139/ssrn.4526253,1,"Recent advances in development and applications of AI technologies including Natural Language Processing (NLP) models, such as the newly developed model known as GPT3 that can generate human-line text/speech on demand, has created a great deal of hype and excitement. With increasing use of NLP models, extensive and proper guardrails need to be in place to ensure safety and trustworthiness of these systems.

Numerous policy and regulation initiatives, such as EU AI Act, UNESCO recommendation on AI, US AI Bill of right, OECD AI principle, China’s AI regulatory initiatives, and the US-EU AI agreement, are shaping the global AI regulation landscape. The proposed EU AI Act, which is the world's first comprehensive attempt to regulate AI, is expected to set global standards for emulation by other jurisdictions. NLP models do not escape the existing regulations, notably the rules on data protection such as the EU General Data Protection Regulation (GDPR).

In this paper, we briefly introduce some AI regulation initiatives in Chapter 1, we then introduce how the GDPR applies to AI usage in Chapter 2, and we discuss specifically the proposed EU AI Act and its risk-based approach to AI in Chapter 3, and NLP as applied to the risk-based approach of EU AI Act in Chapter 4. In all these chapters, we focus on how these proposals or laws relate to NLP research.",Document_331,Demonstrating the value of AI for compliance and risk management,0.12195289880037308,Business Case and Value Demonstration Strategies
Natural Language Processing in the Legal Domain,"D. Katz, D. Hartung, Lauritz Gerlach, Abhik Jana, M. Bommarito","In this paper, we summarize the current state of the field of NLP & Law with a specific focus on recent technical and substantive developments. To support our analysis, we construct and analyze a nearly complete corpus of more than six hundred NLP & Law related papers published over the past decade. Our analysis highlights several major trends. Namely, we document an increasing number of papers written, tasks undertaken, and languages covered over the course of the past decade. We observe an increase in the sophistication of the methods which researchers deployed in this applied context. Slowly but surely, Legal NLP is beginning to match not only the methodological sophistication of general NLP but also the professional standards of data availability and code reproducibility observed within the broader scientific community. We believe all of these trends bode well for the future of the field, but many questions in both the academic and commercial sphere still remain open.",2023,2023,,Social Science Research Network,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.4336224,10.2139/ssrn.4336224,https://doi.org/10.2139/ssrn.4336224,39,"In this paper, we summarize the current state of the field of NLP & Law with a specific focus on recent technical and substantive developments. To support our analysis, we construct and analyze a nearly complete corpus of more than six hundred NLP & Law related papers published over the past decade. Our analysis highlights several major trends. Namely, we document an increasing number of papers written, tasks undertaken, and languages covered over the course of the past decade. We observe an increase in the sophistication of the methods which researchers deployed in this applied context. Slowly but surely, Legal NLP is beginning to match not only the methodological sophistication of general NLP but also the professional standards of data availability and code reproducibility observed within the broader scientific community. We believe all of these trends bode well for the future of the field, but many questions in both the academic and commercial sphere still remain open.",Document_332,Technical aspects or methods of AI or machine learning,0.05707109719514847,Other Categories
ChatGPT: Unlocking the Future of NLP in Finance,"Adam Zaremba, Ender Demir","This paper reviews the current state of ChatGPT technology in finance and its potential to improve existing NLP-based financial applications. We discuss the ethical and regulatory considerations, as well as potential future research directions in the field. The literature suggests that ChatGPT has the potential to improve NLP-based financial applications, but also raises ethical and regulatory concerns that need to be addressed. The paper highlights the need for research in robustness, interpretability, and ethical considerations to ensure responsible use of ChatGPT technology in finance.",2023,2023,,Social Science Research Network,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.4323643,10.2139/ssrn.4323643,https://doi.org/10.2139/ssrn.4323643,59,"This paper reviews the current state of ChatGPT technology in finance and its potential to improve existing NLP-based financial applications. We discuss the ethical and regulatory considerations, as well as potential future research directions in the field. The literature suggests that ChatGPT has the potential to improve NLP-based financial applications, but also raises ethical and regulatory concerns that need to be addressed. The paper highlights the need for research in robustness, interpretability, and ethical considerations to ensure responsible use of ChatGPT technology in finance.",Document_333,General discussion of financial or regulatory topics (non-AI focus),0.11918777972459793,Other Categories
A Primer on Natural Language Processing for Finance,Joerg Osterrieder,"Natural language processing (NLP) is a technical and quantitative field that involves the use of computer algorithms and techniques to analyze, understand, and generate human language. NLP has many applications and benefits in finance, such as the ability to analyze sentiment and extract information from financial text data, to automate the generation of trading signals and risk alerts, and to inform decision-making and risk management in the finance industry. In this primer, we provide a detailed overview of NLP for finance, covering the definition, importance, challenges and approaches, applications, and case studies and examples of NLP in finance. We also discuss the future directions and open challenges in NLP for finance, which will shape the development and advancement of NLP techniques and approaches in the finance industry. This primer is intended for technical and quantitative readers with an interest in NLP and finance, and is designed to provide a comprehensive and detailed understanding of NLP for finance",2023,2023,,Social Science Research Network,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.4317320,10.2139/ssrn.4317320,https://doi.org/10.2139/ssrn.4317320,7,"Natural language processing (NLP) is a technical and quantitative field that involves the use of computer algorithms and techniques to analyze, understand, and generate human language. NLP has many applications and benefits in finance, such as the ability to analyze sentiment and extract information from financial text data, to automate the generation of trading signals and risk alerts, and to inform decision-making and risk management in the finance industry. In this primer, we provide a detailed overview of NLP for finance, covering the definition, importance, challenges and approaches, applications, and case studies and examples of NLP in finance. We also discuss the future directions and open challenges in NLP for finance, which will shape the development and advancement of NLP techniques and approaches in the finance industry. This primer is intended for technical and quantitative readers with an interest in NLP and finance, and is designed to provide a comprehensive and detailed understanding of NLP for finance",Document_334,General discussion of financial or regulatory topics (non-AI focus),0.06191657856106758,Other Categories
Deep Learning in Finance: From Implementation to Regulation,"Louis Bertucci, M. Brière, Olivier Fliche, Joseph Mikael, L. Szpruch","Despite important theoretical questions that remain to be solved, Artificial Intelligence and Deep Learning are being increasingly used in the Finance and Insurance sector. Beyond straightforward data analytics, decision models are being implemented with Deep Learning. These algorithms cannot be used blindly. The understanding of the underlying problem is key. Humans, engineers or mathematicians, are essential. One trendy application is the use of Deep Learning (specifically GANs) to generate datasets. In finance, data are often scarce and having the possibility to generate new data (similar to an original dataset) can be decisive. In many applications, explainability of Artificial Intelligence is critical to protect consumers. Explainability is not a one-size-fits-all concept, and several degrees of explainability may have to be reached. Explainability to non-specialists is an additional challenge. Biais in the learning data is critical to assess because biases will be reproduced by the algorithm, and lead to unexplained discriminations. The role of regulatory agencies will be crucial to protect consumers while allowing innovation. There is currently no unified regulatory framework. The European Commission's Artificial Intelligence Act (draft proposal in April 2021) lists prohibited artificial intelligence practices and defines high-risk application areas for which they identify requirements ( risk management system, data governance, technical documentation and record keeping, transparency, human oversight, accuracy, robustness and cybersecurity).",2022,2022,,Social Science Research Network,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.4080171,10.2139/ssrn.4080171,https://doi.org/10.2139/ssrn.4080171,6,"Despite important theoretical questions that remain to be solved, Artificial Intelligence and Deep Learning are being increasingly used in the Finance and Insurance sector. Beyond straightforward data analytics, decision models are being implemented with Deep Learning. These algorithms cannot be used blindly. The understanding of the underlying problem is key. Humans, engineers or mathematicians, are essential. One trendy application is the use of Deep Learning (specifically GANs) to generate datasets. In finance, data are often scarce and having the possibility to generate new data (similar to an original dataset) can be decisive. In many applications, explainability of Artificial Intelligence is critical to protect consumers. Explainability is not a one-size-fits-all concept, and several degrees of explainability may have to be reached. Explainability to non-specialists is an additional challenge. Biais in the learning data is critical to assess because biases will be reproduced by the algorithm, and lead to unexplained discriminations. The role of regulatory agencies will be crucial to protect consumers while allowing innovation. There is currently no unified regulatory framework. The European Commission's Artificial Intelligence Act (draft proposal in April 2021) lists prohibited artificial intelligence practices and defines high-risk application areas for which they identify requirements ( risk management system, data governance, technical documentation and record keeping, transparency, human oversight, accuracy, robustness and cybersecurity).",Document_335,Difficulty in understanding AI decision-making is a barrier in finance,0.09959475696086884,Explainability and Transparency Barriers
Technology and the ‘New Governance’ Techniques of Financial Regulation,"David McNulty, A. Miglionico, A. Milne","Modern data and information technologies are having a profound impact on financial services and opening new frontiers in regulation. This article explores the deployment of technology to embed regulatory objectives within the management and decision-making processes of financial firms. Technological innovations can enhance oversight of prudential and conducts risks, and substantially lower compliance costs. They can also address the information imbalances that limit the effectiveness of older approaches, in which the firm is a ‘black box’ that can only be externally supervised. The central challenge is establishing an appropriate governance of technology in regulated firms to ensure that these serve regulatory as well as business outcomes. Such an approach should be embedded as a development of the ‘new governance’ techniques of financial regulation. This perspective is developed by reviewing current debate on the use of technology and its application to a range of challenges in financial regulation and supervision.",2022,2022,,Social Science Research Network,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.4054300,10.2139/ssrn.4054300,https://doi.org/10.2139/ssrn.4054300,3,"Modern data and information technologies are having a profound impact on financial services and opening new frontiers in regulation. This article explores the deployment of technology to embed regulatory objectives within the management and decision-making processes of financial firms. Technological innovations can enhance oversight of prudential and conducts risks, and substantially lower compliance costs. They can also address the information imbalances that limit the effectiveness of older approaches, in which the firm is a ‘black box’ that can only be externally supervised. The central challenge is establishing an appropriate governance of technology in regulated firms to ensure that these serve regulatory as well as business outcomes. Such an approach should be embedded as a development of the ‘new governance’ techniques of financial regulation. This perspective is developed by reviewing current debate on the use of technology and its application to a range of challenges in financial regulation and supervision.",Document_336,General discussion of financial or regulatory topics (non-AI focus),0.10668227821588516,Other Categories
"FinTech Regulation in the United States: Past, Present, and Future",Jillian Grennan,"Research on regulating emerging financial technologies (``FinTech"") has been siloed to individual branches. Instead, I present a high-level view of various FinTech branches and analyze the economic incentives of each. By focusing on the dynamics and parallels between the branches, I offer new insights for optimal regulation that balances the costs and benefits as use cases expand. DeFi, which combines advances from the AI and blockchain branches, reduces the cost of coordinating complex financial services. Yet the efficiency gains intertwine with potential legal risks associated with liability, financial crime, dispute resolution, jurisdiction, and taxes. To ensure financial stability, effective regulatory solutions include adapted definitions and safe harbors, regulatory sandboxes, self-regulatory organizations, and/or policing misleading characterizations (e.g., regarding the extent of decentralization or agreed to data uses).",2022,2022,,Social Science Research Network,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.4045057,10.2139/ssrn.4045057,https://doi.org/10.2139/ssrn.4045057,5,"Research on regulating emerging financial technologies (``FinTech"") has been siloed to individual branches. Instead, I present a high-level view of various FinTech branches and analyze the economic incentives of each. By focusing on the dynamics and parallels between the branches, I offer new insights for optimal regulation that balances the costs and benefits as use cases expand. DeFi, which combines advances from the AI and blockchain branches, reduces the cost of coordinating complex financial services. Yet the efficiency gains intertwine with potential legal risks associated with liability, financial crime, dispute resolution, jurisdiction, and taxes. To ensure financial stability, effective regulatory solutions include adapted definitions and safe harbors, regulatory sandboxes, self-regulatory organizations, and/or policing misleading characterizations (e.g., regarding the extent of decentralization or agreed to data uses).",Document_337,Security risks associated with AI are a concern in financial regulation,0.12500885128974915,Organizational and Human Barriers
Dynamism in Financial Market Regulation: Harnessing Regulatory and Supervisory Technologies,"Pedro M. Batista, W. Ringe","The dynamic development of market practices and services frequently limits regulatory effectiveness. New technologies, however, might assist regulators in better tracking market changes. While Regulatory Technology (""RegTech"") has been vastly reducing compliance costs, Supervisory Technology (""SupTech"") has the potential to enhance data accuracy even further. Proper integration between these two will assist regulators in obtaining a continuously updated picture of their regulatees and allow higher regulatory adaptability, without incurring extensive additional costs. Still, harnessing technology for regulatory purposes might lead to an increased dependence on technology providers which risks regulatory capture. We argue in this essay that additional requirements, such as technological neutrality and interoperability, are needed to mitigate such risks. We illustrate our case through blockchain proposals for RegTech and SupTech and their interoperability challenge.",2020,2020,,Social Science Research Network,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.3711618,10.2139/ssrn.3711618,https://doi.org/10.2139/ssrn.3711618,3,"The dynamic development of market practices and services frequently limits regulatory effectiveness. New technologies, however, might assist regulators in better tracking market changes. While Regulatory Technology (""RegTech"") has been vastly reducing compliance costs, Supervisory Technology (""SupTech"") has the potential to enhance data accuracy even further. Proper integration between these two will assist regulators in obtaining a continuously updated picture of their regulatees and allow higher regulatory adaptability, without incurring extensive additional costs. Still, harnessing technology for regulatory purposes might lead to an increased dependence on technology providers which risks regulatory capture. We argue in this essay that additional requirements, such as technological neutrality and interoperability, are needed to mitigate such risks. We illustrate our case through blockchain proposals for RegTech and SupTech and their interoperability challenge.",Document_338,General discussion of financial or regulatory topics (non-AI focus),0.08810313791036606,Other Categories
Fintech and International Financial Regulation,Yesha Yadav,"This Article shows that fintech exacerbates the difficulties of standard setting in international financial regulation. Earlier work introduced the “Innovation Trilemma” (the Trilemma). When seeking to balance the goals of achieving market integrity and innovation through clear and simple rulemaking, regulators can—at best—achieve only two out of these three objectives. Fintech’s unique characteristics—a reliance on automation and artificial intelligence, novel types of big data, as well as the use of disintermediating financial supply chains comprising a mix of traditional firms as well as technology specialists and newcomers—complicates the application of the Trilemma. Rulemaking struggles to achieve needed clarity where innovative algorithms introduce informational uncertainties and complex risks for market integrity. Further, regulation’s ability to impose compliance costs on firms in response to these risks is limited when a preference for innovation favors smaller upstarts and nontraditional players.
International financial regulation presents even steeper challenges when viewed through the lens of the Trilemma. First, rules clarity is harder to achieve owing to divergences in national legal systems, administrative processes, and market structures. Secondly, fintech increases negotiation costs in international standard setting owing to the emergence of a much more expansive cast of economies—like China and India—that dominate as fintech hubs alongside the traditional power players such as the United States or European Union (EU). With distinctive policy preferences, emerging economies constitute powerful voices that mean that negotiation must account for a wider range of distributive preferences. Finally, standard setting must bridge the particularities of domestic market structures that are experiencing varying degrees of disintermediation and transformations in financial supply chains. Rules that impose high compliance costs may be acceptable to economies dominated by traditional intermediaries but may lack buy-in from those where nonbank firms hold sway. In concluding, this Article briefly surveys strategies for fostering greater global cooperation in standard setting for fintech.",2020,2020,,Social Science Research Network,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.3684821,10.2139/ssrn.3684821,https://doi.org/10.2139/ssrn.3684821,8,"This Article shows that fintech exacerbates the difficulties of standard setting in international financial regulation. Earlier work introduced the “Innovation Trilemma” (the Trilemma). When seeking to balance the goals of achieving market integrity and innovation through clear and simple rulemaking, regulators can—at best—achieve only two out of these three objectives. Fintech’s unique characteristics—a reliance on automation and artificial intelligence, novel types of big data, as well as the use of disintermediating financial supply chains comprising a mix of traditional firms as well as technology specialists and newcomers—complicates the application of the Trilemma. Rulemaking struggles to achieve needed clarity where innovative algorithms introduce informational uncertainties and complex risks for market integrity. Further, regulation’s ability to impose compliance costs on firms in response to these risks is limited when a preference for innovation favors smaller upstarts and nontraditional players.
International financial regulation presents even steeper challenges when viewed through the lens of the Trilemma. First, rules clarity is harder to achieve owing to divergences in national legal systems, administrative processes, and market structures. Secondly, fintech increases negotiation costs in international standard setting owing to the emergence of a much more expansive cast of economies—like China and India—that dominate as fintech hubs alongside the traditional power players such as the United States or European Union (EU). With distinctive policy preferences, emerging economies constitute powerful voices that mean that negotiation must account for a wider range of distributive preferences. Finally, standard setting must bridge the particularities of domestic market structures that are experiencing varying degrees of disintermediation and transformations in financial supply chains. Rules that impose high compliance costs may be acceptable to economies dominated by traditional intermediaries but may lack buy-in from those where nonbank firms hold sway. In concluding, this Article briefly surveys strategies for fostering greater global cooperation in standard setting for fintech.",Document_339,Security risks associated with AI are a concern in financial regulation,0.17603151500225067,Organizational and Human Barriers
"The Art of Natural Language Processing: Classical, Modern and Contemporary Approaches to Text Document Classification","Andrea Ferrario, Mara Naegelin","In this tutorial we introduce three approaches to preprocess text data with Natural Language Processing (NLP) and perform text document classification using machine learning. The first approach is based on 'bag-of-' models, the second one on word embeddings, while the third one introduces the two most popular Recurrent Neural Networks (RNNs), i.e. the Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) architectures. We apply all approaches on a case study where we classify movie reviews using Python and Tensorflow 2.0. The results of the case study show that extreme gradient boosting algorithms outperform adaptive boosting and random forests on bag-of-words and word embedding models, as well as LSTM and GRU RNNs, but at a steep computational cost. Finally, we provide the reader with comments on NLP applications for the insurance industry.",2020,2020,,Social Science Research Network,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.3547887,10.2139/ssrn.3547887,https://doi.org/10.2139/ssrn.3547887,12,"In this tutorial we introduce three approaches to preprocess text data with Natural Language Processing (NLP) and perform text document classification using machine learning. The first approach is based on 'bag-of-' models, the second one on word embeddings, while the third one introduces the two most popular Recurrent Neural Networks (RNNs), i.e. the Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) architectures. We apply all approaches on a case study where we classify movie reviews using Python and Tensorflow 2.0. The results of the case study show that extreme gradient boosting algorithms outperform adaptive boosting and random forests on bag-of-words and word embedding models, as well as LSTM and GRU RNNs, but at a steep computational cost. Finally, we provide the reader with comments on NLP applications for the insurance industry.",Document_340,Difficulty in understanding AI decision-making is a barrier in finance,0.10492422431707382,Explainability and Transparency Barriers
Natural Language Processing and Machine Learning for Law and Policy Texts,John J. Nay,"Almost all law is expressed in natural language; ther.efore, natural language processing (NLP) is a key component of understanding and predicting law at scale. NLP converts unstructured text into a formal representation that computers can understand and analyze. The intersection of NLP and law is poised for innovation because there are (i.) a growing number of repositories of digitized machine-readable legal text data, (ii.) advances in NLP methods driven by algorithmic and hardware improvements, and (iii.) the potential to improve the effectiveness of legal services due to inefficiencies in its current practice.

NLP is a large field and like many research areas related to computer science, it is rapidly evolving. Within NLP, this paper focuses primarily on statistical machine learning techniques because they demonstrate significant promise for advancing text informatics systems and will likely be relevant in the foreseeable future.

First, we provide a brief overview of the different types of legal texts and the different types of machine learning methods to process those texts. We introduce the core idea of representing words and documents as numbers. Then we describe NLP tools for leveraging legal text data to accomplish tasks. Along the way, we define important NLP terms in italics and offer examples to illustrate the utility of these tools. We describe methods for automatically summarizing content (sentiment analyses, text summaries, topic models, extracting attributes and relations, document relevance scoring), predicting outcomes, and answering questions",2018,2018,,-,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.3438276,10.2139/ssrn.3438276,https://doi.org/10.2139/ssrn.3438276,10,"Almost all law is expressed in natural language; ther.efore, natural language processing (NLP) is a key component of understanding and predicting law at scale. NLP converts unstructured text into a formal representation that computers can understand and analyze. The intersection of NLP and law is poised for innovation because there are (i.) a growing number of repositories of digitized machine-readable legal text data, (ii.) advances in NLP methods driven by algorithmic and hardware improvements, and (iii.) the potential to improve the effectiveness of legal services due to inefficiencies in its current practice.

NLP is a large field and like many research areas related to computer science, it is rapidly evolving. Within NLP, this paper focuses primarily on statistical machine learning techniques because they demonstrate significant promise for advancing text informatics systems and will likely be relevant in the foreseeable future.

First, we provide a brief overview of the different types of legal texts and the different types of machine learning methods to process those texts. We introduce the core idea of representing words and documents as numbers. Then we describe NLP tools for leveraging legal text data to accomplish tasks. Along the way, we define important NLP terms in italics and offer examples to illustrate the utility of these tools. We describe methods for automatically summarizing content (sentiment analyses, text summaries, topic models, extracting attributes and relations, document relevance scoring), predicting outcomes, and answering questions",Document_341,Technical aspects or methods of AI or machine learning,0.1639590561389923,Other Categories
LexNLP: Natural Language Processing and Information Extraction For Legal and Regulatory Texts,"M. Bommarito, D. Katz, E. M. Detterman","LexNLP is an open source Python package focused on natural language processing and machine learning for legal and regulatory text. The package includes functionality to (i) segment documents, (ii) identify key text such as titles and section headings, (iii) extract over eighteen types of structured information like distances and dates, (iv) extract named entities such as companies and geopolitical entities, (v) transform text into features for model training, and (vi) build unsupervised and supervised models such as word embedding or tagging models. LexNLP includes pre-trained models based on thousands of unit tests drawn from real documents available from the SEC EDGAR database as well as various judicial and regulatory proceedings. LexNLP is designed for use in both academic research and industrial applications, and is distributed at this https URL.",2018,2018,,Research Handbook on Big Data Law,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.3192101,10.2139/ssrn.3192101,https://doi.org/10.2139/ssrn.3192101,66,"LexNLP is an open source Python package focused on natural language processing and machine learning for legal and regulatory text. The package includes functionality to (i) segment documents, (ii) identify key text such as titles and section headings, (iii) extract over eighteen types of structured information like distances and dates, (iv) extract named entities such as companies and geopolitical entities, (v) transform text into features for model training, and (vi) build unsupervised and supervised models such as word embedding or tagging models. LexNLP includes pre-trained models based on thousands of unit tests drawn from real documents available from the SEC EDGAR database as well as various judicial and regulatory proceedings. LexNLP is designed for use in both academic research and industrial applications, and is distributed at this https URL.",Document_342,Technical aspects or methods of AI or machine learning,0.09201405197381973,Other Categories
The Intuitive Appeal of Explainable Machines,"Andrew D. Selbst, Solon Barocas","Algorithmic decision-making has become synonymous with inexplicable decision-making, but what makes algorithms so difficult to explain? This Article examines what sets machine learning apart from other ways of developing rules for decision-making and the problem these properties pose for explanation. We show that machine learning models can be both inscrutable and nonintuitive and that these are related, but distinct, properties.

Calls for explanation have treated these problems as one and the same, but disentangling the two reveals that they demand very different responses. Dealing with inscrutability requires providing a sensible description of the rules; addressing nonintuitiveness requires providing a satisfying explanation for why the rules are what they are. Existing laws like the Fair Credit Reporting Act (FCRA), the Equal Credit Opportunity Act (ECOA), and the General Data Protection Regulation (GDPR), as well as techniques within machine learning, are focused almost entirely on the problem of inscrutability. While such techniques could allow a machine learning system to comply with existing law, doing so may not help if the goal is to assess whether the basis for decision-making is normatively defensible.

In most cases, intuition serves as the unacknowledged bridge between a descriptive account and a normative evaluation. But because machine learning is often valued for its ability to uncover statistical relationships that defy intuition, relying on intuition is not a satisfying approach. This Article thus argues for other mechanisms for normative evaluation. To know why the rules are what they are, one must seek explanations of the process behind a model’s development, not just explanations of the model itself.",2018,2018,,-,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/SSRN.3126971,10.2139/SSRN.3126971,https://doi.org/10.2139/SSRN.3126971,280,"Algorithmic decision-making has become synonymous with inexplicable decision-making, but what makes algorithms so difficult to explain? This Article examines what sets machine learning apart from other ways of developing rules for decision-making and the problem these properties pose for explanation. We show that machine learning models can be both inscrutable and nonintuitive and that these are related, but distinct, properties.

Calls for explanation have treated these problems as one and the same, but disentangling the two reveals that they demand very different responses. Dealing with inscrutability requires providing a sensible description of the rules; addressing nonintuitiveness requires providing a satisfying explanation for why the rules are what they are. Existing laws like the Fair Credit Reporting Act (FCRA), the Equal Credit Opportunity Act (ECOA), and the General Data Protection Regulation (GDPR), as well as techniques within machine learning, are focused almost entirely on the problem of inscrutability. While such techniques could allow a machine learning system to comply with existing law, doing so may not help if the goal is to assess whether the basis for decision-making is normatively defensible.

In most cases, intuition serves as the unacknowledged bridge between a descriptive account and a normative evaluation. But because machine learning is often valued for its ability to uncover statistical relationships that defy intuition, relying on intuition is not a satisfying approach. This Article thus argues for other mechanisms for normative evaluation. To know why the rules are what they are, one must seek explanations of the process behind a model’s development, not just explanations of the model itself.",Document_343,Technical aspects or methods of AI or machine learning,0.19565831124782562,Other Categories
The API Economy and Digital Transformation in Financial Services: The Case of Open Banking,"Markos Zachariadis, Pinar Ozcan","In this paper we seek to do two things. Firstly, by exploring the fundamental properties and various applications of open application programming interfaces (APIs) mentioned in extant literature, we articulate what are the relevant theories that give rise to the new organisational structures and platform business models we observe in the digital age. Understanding such phenomena will help us anticipate, and in some ways predict, the implications of public APIs’ adoption in the financial services sector. The second part of our paper exposes some of our findings around the key challenges and opportunities that open APIs pose for the banking sector in the UK and the EU following the introduction of the Open Banking Working Group (OBWG) and Second Payments Services Directive (PSD2) regulatory frameworks. Our insights were produced from extensive field research and interviews with key industry experts between July 2016 and February 2017. Our use of theory helps us translate these findings and provide recommendations for financial institutions, FinTech startups, technology companies, and regulators. We hope to help them prepare for some of the key changes and issues that the financial sector may be facing in the next few years as the use of open APIs becomes more ‘mainstream’.",2017,2017,,-,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.2975199,10.2139/ssrn.2975199,https://doi.org/10.2139/ssrn.2975199,133,"In this paper we seek to do two things. Firstly, by exploring the fundamental properties and various applications of open application programming interfaces (APIs) mentioned in extant literature, we articulate what are the relevant theories that give rise to the new organisational structures and platform business models we observe in the digital age. Understanding such phenomena will help us anticipate, and in some ways predict, the implications of public APIs’ adoption in the financial services sector. The second part of our paper exposes some of our findings around the key challenges and opportunities that open APIs pose for the banking sector in the UK and the EU following the introduction of the Open Banking Working Group (OBWG) and Second Payments Services Directive (PSD2) regulatory frameworks. Our insights were produced from extensive field research and interviews with key industry experts between July 2016 and February 2017. Our use of theory helps us translate these findings and provide recommendations for financial institutions, FinTech startups, technology companies, and regulators. We hope to help them prepare for some of the key changes and issues that the financial sector may be facing in the next few years as the use of open APIs becomes more ‘mainstream’.",Document_344,General discussion of financial or regulatory topics (non-AI focus),0.08832693845033646,Other Categories
Meeting Upcoming GDPR Requirements While Maximizing the Full Value of Data Analytics,"Mike Hintze, Gary LaFever","The new obligations imposed by the General Data Protection Regulation (GDPR) do not prohibit the use of personal data for analytics or other beneficial secondary uses. But they do require the adoption of new technical and organizational measures to protect that data. The GDPR explicitly points to pseudonymizing as one such measure that can help meet the requirements of several of its provisions. The GDPR further recognizes differing levels of de-identi cation in a way that provides incentives for organizations to adopt the optimal type and level of de-identification that can help them use personal data for bene cial purposes while meeting their compliance obligations and protecting the privacy of individuals. By enabling the use of “Controlled Linkable Data” (as described in this White Paper) that retains the utility of personal data while helping to meet organizations’ compliance obligations and to significantly reduce their risk of liability, Anonos® BigPrivacy® technology can help organizations navigate and meet these new GDPR requirements. Thus, Anonos BigPrivacy technology can ease regulatory burdens and be a key component of an overall GDPR compliance program. The body of this paper describes in detail the regulatory background, technological innovations, and practical applications of Controlled Linkable Data, leading to the maximization of data value and individual privacy in a GDPR-compliant manner. First, in Section III, we introduce the concept of Controlled Linkable Data in the context of the GDPR. Next, in Section IV, we describe the GDPR’s new requirements, focusing on the distinction between privacy by design and data protection by default, and noting that the former is merely a subset of the latter, making it insuf cient to satisfy the GDPR’s stringency. We also introduce the essential concept of Controlled Linkable Data. In Section V, we explain how Controlled Linkable Data enables a more powerful form of de-identification, one encouraged by the GDPR, but which has previously not been achievable by technical methods. This leads to the conclusion that “data protection over the full lifecycle of data by leveraging technical and organizational measures, including pseudonymisation, [ensures] that, by default, personal data are not made accessible without the individual’s intervention to an inde nite number of natural persons.” Next, Section VI analyzes numerous relevant sections of the GDPR (speci cally, Articles 5, 6, 11(2), 12(2), 15-22, 32-36, 40, 42, 82 and 88), showing how Controlled Linkable Data helps satisfy the specific GDPR requirements. Last, in light of this understanding of the requirements, limitations, exclusions and overall principles of the GDPR, Section VII explains the technical basis of Anonos BigPrivacy technology, how it implements Controlled Linkable Data, and how this solution addresses GDPR compliance concerns for all parties: data controllers, regulators and data subjects. Global firms that gather, use or store GDPR personal data should consider the possibility that Controlled Linkable Data as described in this White Paper enables secondary uses of data while ensuring compliance with GDPR requirements.",2017,2017,,-,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/SSRN.2927540,10.2139/SSRN.2927540,https://doi.org/10.2139/SSRN.2927540,10,"The new obligations imposed by the General Data Protection Regulation (GDPR) do not prohibit the use of personal data for analytics or other beneficial secondary uses. But they do require the adoption of new technical and organizational measures to protect that data. The GDPR explicitly points to pseudonymizing as one such measure that can help meet the requirements of several of its provisions. The GDPR further recognizes differing levels of de-identi cation in a way that provides incentives for organizations to adopt the optimal type and level of de-identification that can help them use personal data for bene cial purposes while meeting their compliance obligations and protecting the privacy of individuals. By enabling the use of “Controlled Linkable Data” (as described in this White Paper) that retains the utility of personal data while helping to meet organizations’ compliance obligations and to significantly reduce their risk of liability, Anonos® BigPrivacy® technology can help organizations navigate and meet these new GDPR requirements. Thus, Anonos BigPrivacy technology can ease regulatory burdens and be a key component of an overall GDPR compliance program. The body of this paper describes in detail the regulatory background, technological innovations, and practical applications of Controlled Linkable Data, leading to the maximization of data value and individual privacy in a GDPR-compliant manner. First, in Section III, we introduce the concept of Controlled Linkable Data in the context of the GDPR. Next, in Section IV, we describe the GDPR’s new requirements, focusing on the distinction between privacy by design and data protection by default, and noting that the former is merely a subset of the latter, making it insuf cient to satisfy the GDPR’s stringency. We also introduce the essential concept of Controlled Linkable Data. In Section V, we explain how Controlled Linkable Data enables a more powerful form of de-identification, one encouraged by the GDPR, but which has previously not been achievable by technical methods. This leads to the conclusion that “data protection over the full lifecycle of data by leveraging technical and organizational measures, including pseudonymisation, [ensures] that, by default, personal data are not made accessible without the individual’s intervention to an inde nite number of natural persons.” Next, Section VI analyzes numerous relevant sections of the GDPR (speci cally, Articles 5, 6, 11(2), 12(2), 15-22, 32-36, 40, 42, 82 and 88), showing how Controlled Linkable Data helps satisfy the specific GDPR requirements. Last, in light of this understanding of the requirements, limitations, exclusions and overall principles of the GDPR, Section VII explains the technical basis of Anonos BigPrivacy technology, how it implements Controlled Linkable Data, and how this solution addresses GDPR compliance concerns for all parties: data controllers, regulators and data subjects. Global firms that gather, use or store GDPR personal data should consider the possibility that Controlled Linkable Data as described in this White Paper enables secondary uses of data while ensuring compliance with GDPR requirements.",Document_345,Collaborating with regulators to create AI compliance frameworks,0.05683604255318642,Regulatory Engagement and Proactive Compliance Strategies
Zero-Revelation RegTech: Detecting Risk through Linguistic Analysis of Corporate Emails and News,"Sanjiv Ranjan Das, Seoyoung Kim, Bhushan Kothari","We demonstrate how an applied linguistics platform may be used to parse corporate email content and news to assess factors predicting escalating risk or the gradual shifting of other critical characteristics within the ﬁrm before they are eventually manifested in observable data and ﬁnancial outcomes. We ﬁnd that email content and news articles meaningfully predict increased risk and potential malaise. We also ﬁnd that other structural characteristics, such as average email length, are strong predictors of risk and subsequent performance. We present implementations of three spatial analyses of internal corporate communication, i.e., email networks, vocabulary trends, and topic analysis. Overall, we propose a RegTech solution by which to systematically and eﬀectively detect escalating risk or potential malaise without the need to manually read individual employee emails",2017,2017,,The Journal of Financial Data Science,Too Many Requests (429) (URL Source: DOI Link),https://doi.org/10.2139/ssrn.2909380,10.2139/ssrn.2909380,https://doi.org/10.2139/ssrn.2909380,7,"We demonstrate how an applied linguistics platform may be used to parse corporate email content and news to assess factors predicting escalating risk or the gradual shifting of other critical characteristics within the ﬁrm before they are eventually manifested in observable data and ﬁnancial outcomes. We ﬁnd that email content and news articles meaningfully predict increased risk and potential malaise. We also ﬁnd that other structural characteristics, such as average email length, are strong predictors of risk and subsequent performance. We present implementations of three spatial analyses of internal corporate communication, i.e., email networks, vocabulary trends, and topic analysis. Overall, we propose a RegTech solution by which to systematically and eﬀectively detect escalating risk or potential malaise without the need to manually read individual employee emails",Document_346,Demonstrating the value of AI for compliance and risk management,0.10545438528060913,Business Case and Value Demonstration Strategies
"Viewing the GDPR through a De-Identification Lens: A Tool for Compliance, Clarification, and Consistency",Mike Hintze,"In May 2018, the General Data Protection Regulation (GDPR) will become enforceable as the basis for data protection law in the European Economic Area (EEA). Compared to the 1995 Data Protection Directive that it will replace, the GDPR reflects a more developed understanding of de-identification as encompassing a spectrum of different techniques and strengths. And under the GDPR, different levels of de-identification have concrete implications for organizations’ compliance obligations – including, in some cases, relief from certain obligations. Thus, organizations subject to the GDPR can and should consider de-identification as a key tool for GDPR compliance.Nevertheless, there are many respects in which GDPR obligations remains unclear. Regulators and policymakers can help advance the rights of data subjects and further the objectives of the GDPR, while providing additional clarity, by interpreting, applying, and enforcing these GDPR provisions in a way that encourages and rewards the appropriate use of de-identification.
This article examines how the GDPR addresses de-identification. It reviews several substantive obligations under the GDPR, including notice, consent, data subject rights to access or delete personal data, data retention limitations, data security, breach notification, privacy by design and by default, and others. In each case, it describes how the use of different levels of de-identification can play a role in complying with the relevant obligations. It proposes that the incentives to apply de-identification found in these provisions should be reinforced by guidance and enforcement decisions that will reward the use of de-identification and encourage the highest practical level of de-identification. Such an approach will bring clarity to the rules, enable practical tools for compliance, help foster greater consistency with data protection regimes in other jurisdictions, and advance the purposes of the regulation.",2017,2017,,-,Failed (JS Challenge/Bot Protection?) (URL Source: DOI Link),https://doi.org/10.2139/SSRN.2909121,10.2139/SSRN.2909121,https://doi.org/10.2139/SSRN.2909121,41,"In May 2018, the General Data Protection Regulation (GDPR) will become enforceable as the basis for data protection law in the European Economic Area (EEA). Compared to the 1995 Data Protection Directive that it will replace, the GDPR reflects a more developed understanding of de-identification as encompassing a spectrum of different techniques and strengths. And under the GDPR, different levels of de-identification have concrete implications for organizations’ compliance obligations – including, in some cases, relief from certain obligations. Thus, organizations subject to the GDPR can and should consider de-identification as a key tool for GDPR compliance.Nevertheless, there are many respects in which GDPR obligations remains unclear. Regulators and policymakers can help advance the rights of data subjects and further the objectives of the GDPR, while providing additional clarity, by interpreting, applying, and enforcing these GDPR provisions in a way that encourages and rewards the appropriate use of de-identification.
This article examines how the GDPR addresses de-identification. It reviews several substantive obligations under the GDPR, including notice, consent, data subject rights to access or delete personal data, data retention limitations, data security, breach notification, privacy by design and by default, and others. In each case, it describes how the use of different levels of de-identification can play a role in complying with the relevant obligations. It proposes that the incentives to apply de-identification found in these provisions should be reinforced by guidance and enforcement decisions that will reward the use of de-identification and encourage the highest practical level of de-identification. Such an approach will bring clarity to the rules, enable practical tools for compliance, help foster greater consistency with data protection regimes in other jurisdictions, and advance the purposes of the regulation.",Document_347,General discussion of financial or regulatory topics (non-AI focus),0.0629497841000557,Other Categories
Large Language Models Trained on Equipment Maintenance Text,"P. Y. Abijith, Piyush Patidar, Gaurav Nair, Rohan Pandya","Work orders, equipment information, technical records and best practices documents contain within them a wealth of insights related to Equipment Maintenance which can be unlocked with Natural Language Processing tasks like classification, clustering, named entity recognition or part of speech tagging. But obtaining large enough labelled data sets in Equipment Maintenance domain manually is prohibitive and very expensive. This lack of labeled Equipment Maintenance data can be overcome with Large Language Models (LLMs) such as GPT-3, BERT that are pretrained transformer networks, considered state-of-the-art when it comes to Natural Language Processing (NLP) tasks. However, the vocabulary understood by these LLMs are mostly from English Language and need to be fine-tuned to understand industry and organization specific vocabulary and acronyms. This paper explores the potential of a domain specific LLM model for oil and gas industries. Data that are of good quality and that provide a comprehensive overview of industry are collected. This corpus of text contains documents like work orders, equipment data and technical documents. A custom tokenizer is trained on this data to identify domain specific terminology. A comparative study is done with other off-the-shelf tokenizers: BERT and RoBERTa, to compare the effectiveness of the tokenization. With millions of work orders and equipment documents, training pipelines had to parallelized so that training can occur on multiple GPUs. A comprehensive study of multiple training methods is done in this paper. Model and tokenizer developed were packaged and archived to be consumed in machine learning pipelines to specific use-cases across the organization. For an organization adopting digital transformation, the availability of an organization specific LLM is an enabler to extract insights from millions of documents containing free text. The applicability of such models spans across multiple disciplines like Maintenance, Reliability, Safety etc. and streamlines the development of highly accurate and robust text analytics.",2023,2023,,"Day 2 Tue, October 03, 2023",Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.2118/216336-ms,10.2118/216336-ms,https://doi.org/10.2118/216336-ms,4,"Work orders, equipment information, technical records and best practices documents contain within them a wealth of insights related to Equipment Maintenance which can be unlocked with Natural Language Processing tasks like classification, clustering, named entity recognition or part of speech tagging. But obtaining large enough labelled data sets in Equipment Maintenance domain manually is prohibitive and very expensive. This lack of labeled Equipment Maintenance data can be overcome with Large Language Models (LLMs) such as GPT-3, BERT that are pretrained transformer networks, considered state-of-the-art when it comes to Natural Language Processing (NLP) tasks. However, the vocabulary understood by these LLMs are mostly from English Language and need to be fine-tuned to understand industry and organization specific vocabulary and acronyms. This paper explores the potential of a domain specific LLM model for oil and gas industries. Data that are of good quality and that provide a comprehensive overview of industry are collected. This corpus of text contains documents like work orders, equipment data and technical documents. A custom tokenizer is trained on this data to identify domain specific terminology. A comparative study is done with other off-the-shelf tokenizers: BERT and RoBERTa, to compare the effectiveness of the tokenization. With millions of work orders and equipment documents, training pipelines had to parallelized so that training can occur on multiple GPUs. A comprehensive study of multiple training methods is done in this paper. Model and tokenizer developed were packaged and archived to be consumed in machine learning pipelines to specific use-cases across the organization. For an organization adopting digital transformation, the availability of an organization specific LLM is an enabler to extract insights from millions of documents containing free text. The applicability of such models spans across multiple disciplines like Maintenance, Reliability, Safety etc. and streamlines the development of highly accurate and robust text analytics.",Document_348,Technical aspects or methods of AI or machine learning,0.20352575182914734,Other Categories
Natural Language Understanding for Safety and Risk Management in Oil and Gas Plants,"Diletta Milana, Maria Stella Darena, Nico Bettio, C. Cerruti, Guido Siliprandi, A. Fidanzi, Paolo Cerioli, G. Silvestri, Francesco Tarasconi, Matteo Caserio, Milad Botros, M. Gabrielli",,2019,2019,,"Day 2 Tue, November 12, 2019",Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.2118/197668-ms,10.2118/197668-ms,https://doi.org/10.2118/197668-ms,7,,Document_349,,,
A Survey on Bias in Deep NLP,"Ismael Garrido-Muñoz, A. Montejo-Ráez, F. Martínez-Santiago, L., Alfonso Ureña-López","Deep neural networks are hegemonic approaches to many machine learning areas, including natural language processing (NLP). Thanks to the availability of large corpora collections and the capability of deep architectures to shape internal language mechanisms in self-supervised learning processes (also known as “pre-training”), versatile and performing models are released continuously for every new network design. These networks, somehow, learn a probability distribution of words and relations across the training collection used, inheriting the potential flaws, inconsistencies and biases contained in such a collection. As pre-trained models have been found to be very useful approaches to transfer learning, dealing with bias has become a relevant issue in this new scenario. We introduce bias in a formal way and explore how it has been treated in several networks, in terms of detection and correction. In addition, available resources are identified and a strategy to deal with bias in deep NLP is proposed.",2021,2021,,Applied Sciences,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.20944/PREPRINTS202103.0049.V1,10.20944/PREPRINTS202103.0049.V1,https://doi.org/10.20944/PREPRINTS202103.0049.V1,142,"Deep neural networks are hegemonic approaches to many machine learning areas, including natural language processing (NLP). Thanks to the availability of large corpora collections and the capability of deep architectures to shape internal language mechanisms in self-supervised learning processes (also known as “pre-training”), versatile and performing models are released continuously for every new network design. These networks, somehow, learn a probability distribution of words and relations across the training collection used, inheriting the potential flaws, inconsistencies and biases contained in such a collection. As pre-trained models have been found to be very useful approaches to transfer learning, dealing with bias has become a relevant issue in this new scenario. We introduce bias in a formal way and explore how it has been treated in several networks, in terms of detection and correction. In addition, available resources are identified and a strategy to deal with bias in deep NLP is proposed.",Document_350,Technical aspects or methods of AI or machine learning,0.21114040911197662,Other Categories
On the Gap between Adoption and Understanding in NLP,"F. Bianchi, Dirk Hovy","There are some issues with current research trends in NLP that can hamper the free development of scientific research. We identify five of particular concern: 1) the early adoption of methods without sufficient understanding or analysis; 2) the preference for computational methods regardless of risks associated with their limitations; 3) the resulting bias in the papers we publish; 4) the impossibility of re-running some experiments due to their cost; 5) the dangers of unexplainable methods. If these issues are not addressed, we risk a loss of reproducibility, reputability, and subsequently public trust in our field. In this position paper, we outline each of these points and suggest ways forward.",2021,2021,8.0,Findings,"Abstract Not Found / Date (Meta (citation_publication_date)) / LLM (Filtered HTML) Failed (Answer too short, Score: 0.05) (URL Source: DOI Link)",https://doi.org/10.18653/v1/2021.findings-acl.340,10.18653/v1/2021.findings-acl.340,https://doi.org/10.18653/v1/2021.findings-acl.340,23,"There are some issues with current research trends in NLP that can hamper the free development of scientific research. We identify five of particular concern: 1) the early adoption of methods without sufficient understanding or analysis; 2) the preference for computational methods regardless of risks associated with their limitations; 3) the resulting bias in the papers we publish; 4) the impossibility of re-running some experiments due to their cost; 5) the dangers of unexplainable methods. If these issues are not addressed, we risk a loss of reproducibility, reputability, and subsequently public trust in our field. In this position paper, we outline each of these points and suggest ways forward.",Document_351,Technical aspects or methods of AI or machine learning,0.07401902228593826,Other Categories
TextBugger: Generating Adversarial Text Against Real-world Applications,"Jinfeng Li, S. Ji, Tianyu Du, Bo Li, Ting Wang","Deep Learning-based Text Understanding (DLTU) is the backbone technique behind various applications, including question answering, machine translation, and text classification. Despite its tremendous popularity, the security vulnerabilities of DLTU are still largely unknown, which is highly concerning given its increasing use in security-sensitive applications such as sentiment analysis and toxic content detection. In this paper, we show that DLTU is inherently vulnerable to adversarial text attacks, in which maliciously crafted texts trigger target DLTU systems and services to misbehave. Specifically, we present TextBugger, a general attack framework for generating adversarial texts. In contrast to prior works, TextBugger differs in significant ways: (i) effective -- it outperforms state-of-the-art attacks in terms of attack success rate; (ii) evasive -- it preserves the utility of benign text, with 94.9\% of the adversarial text correctly recognized by human readers; and (iii) efficient -- it generates adversarial text with computational complexity sub-linear to the text length. We empirically evaluate TextBugger on a set of real-world DLTU systems and services used for sentiment analysis and toxic content detection, demonstrating its effectiveness, evasiveness, and efficiency. For instance, TextBugger achieves 100\% success rate on the IMDB dataset based on Amazon AWS Comprehend within 4.61 seconds and preserves 97\% semantic similarity. We further discuss possible defense mechanisms to mitigate such attack and the adversary's potential countermeasures, which leads to promising directions for further research.",2018,2018,,Network and Distributed System Security Symposium,Skipped (Content is PDF) (URL Source: DOI Link),https://doi.org/10.14722/ndss.2019.23138,10.14722/ndss.2019.23138,https://doi.org/10.14722/ndss.2019.23138,687,"Deep Learning-based Text Understanding (DLTU) is the backbone technique behind various applications, including question answering, machine translation, and text classification. Despite its tremendous popularity, the security vulnerabilities of DLTU are still largely unknown, which is highly concerning given its increasing use in security-sensitive applications such as sentiment analysis and toxic content detection. In this paper, we show that DLTU is inherently vulnerable to adversarial text attacks, in which maliciously crafted texts trigger target DLTU systems and services to misbehave. Specifically, we present TextBugger, a general attack framework for generating adversarial texts. In contrast to prior works, TextBugger differs in significant ways: (i) effective -- it outperforms state-of-the-art attacks in terms of attack success rate; (ii) evasive -- it preserves the utility of benign text, with 94.9\% of the adversarial text correctly recognized by human readers; and (iii) efficient -- it generates adversarial text with computational complexity sub-linear to the text length. We empirically evaluate TextBugger on a set of real-world DLTU systems and services used for sentiment analysis and toxic content detection, demonstrating its effectiveness, evasiveness, and efficiency. For instance, TextBugger achieves 100\% success rate on the IMDB dataset based on Amazon AWS Comprehend within 4.61 seconds and preserves 97\% semantic similarity. We further discuss possible defense mechanisms to mitigate such attack and the adversary's potential countermeasures, which leads to promising directions for further research.",Document_352,Technical aspects or methods of AI or machine learning,0.15148571133613586,Other Categories
Personally Identifiable Information (PII) Detection in the Unstructured Large Text Corpus using Natural Language Processing and Unsupervised Learning Technique,"Poornima Kulkarni, Cauvery N K","Personally Identifiable Information (PII) has gained much attention with the rapid development of technologies and the exploitation of information relating to an individual. The corporates and other organizations store a large amount of information that is primarily disseminated in the form of emails that include personnel information of the user, employee, and customers. The security aspects of PII storage have been ignored, raising serious security concerns onindividual privacy. A significant concern arises about comprehending the responsibilities regarding the uses of PII. However, in real-time scenarios, email data is regarded as unstructured text data, detecting PII from such an unstructured large text corpus is quite challenging. This paper presents an intelligent clustering approach for automatically detecting personally identifiable information (PII) from a large text corpus. The focus of the proposed study is to design a model that receives text content and detects possible PII attributes. Therefore, this paper presents a clustering-based PII Model (C-PPIM) based on NLP and unsupervised learning to address detection of PII in the unstructured large text corpus. NLP is used to perform topic modeling, and Byte mLSTM, a different approach of sequence model, is implemented to address clustering problems in PII detection. The performance analysis of the proposed model is carried out existing hierarchical clustering concerning silhouette and cohesion score. The outcome indicatedthe effectiveness of the proposed system that highlights significant PII attributes, with significant scope in real-time implementation. In contrast, existing techniques are too expensive to function and fit in real-time environments.",2021,2021,,International Journal of Advanced Computer Science and Applications,Failed (JS Challenge/Bot Protection?) (URL Source: DOI Link),https://doi.org/10.14569/ijacsa.2021.0120957,10.14569/ijacsa.2021.0120957,https://doi.org/10.14569/ijacsa.2021.0120957,6,"Personally Identifiable Information (PII) has gained much attention with the rapid development of technologies and the exploitation of information relating to an individual. The corporates and other organizations store a large amount of information that is primarily disseminated in the form of emails that include personnel information of the user, employee, and customers. The security aspects of PII storage have been ignored, raising serious security concerns onindividual privacy. A significant concern arises about comprehending the responsibilities regarding the uses of PII. However, in real-time scenarios, email data is regarded as unstructured text data, detecting PII from such an unstructured large text corpus is quite challenging. This paper presents an intelligent clustering approach for automatically detecting personally identifiable information (PII) from a large text corpus. The focus of the proposed study is to design a model that receives text content and detects possible PII attributes. Therefore, this paper presents a clustering-based PII Model (C-PPIM) based on NLP and unsupervised learning to address detection of PII in the unstructured large text corpus. NLP is used to perform topic modeling, and Byte mLSTM, a different approach of sequence model, is implemented to address clustering problems in PII detection. The performance analysis of the proposed model is carried out existing hierarchical clustering concerning silhouette and cohesion score. The outcome indicatedthe effectiveness of the proposed system that highlights significant PII attributes, with significant scope in real-time implementation. In contrast, existing techniques are too expensive to function and fit in real-time environments.",Document_353,Technical aspects or methods of AI or machine learning,0.09566871076822281,Other Categories
EXPLORING BIM AND NLP APPLICATIONS: A SCIENTOMETRIC APPROACH,"Mirko Locatelli, E. Seghezzi, G. D. Di Giuda","In AECO (Architecture, Engineering, Construction and Owner-operated) industry information are mainly defined and exchanged in natural language through textual files and documents. On the contrary, a Building Information Modeling (BIM) approach requires machine processable data and information. Natural Language Processing (NLP) allows to process textual information into structured format. About BIM in AECO industry, and NLP in different sectors, several literature reviews have been conducted. However, none of them highlighted the possible connections between the two topics. This study provides a scientometric analysis aiming to investigate possible combined applications of BIM and NLP. A quantitative literature review approach is employed, using data visualization and science mapping applied on bibliometric meta- data. The performed analysis uncovered possible directions for further research on NLP and BIM combined applications in AECO sector. Most active authors, key research patterns, and institutional affiliations are identified. The main applications areas of a combined NLP and BIM approach in AECO are: Information Retrieval and Information Enrichment of BIM models, Automatic Compliance Checking, and Safety and Risk Management. The keywords pattern analysis highlighted the main tools which allows to link Semantic BIM and NLP methods and technologies, i.e. Ontology and Machine Learning algorithms. The scientometric analysis also reveals a gap related to the Preliminary design and Requirement definition phases, highlighting a possible research area not covered by the Academia as of now.",2021,2021,,Proceedings of International Structural Engineering and Construction,Skipped (Content is XML) (URL Source: DOI Link),https://doi.org/10.14455/isec.2021.8(1).con-12,10.14455/isec.2021.8(1).con-12,https://doi.org/10.14455/isec.2021.8(1).con-12,3,"In AECO (Architecture, Engineering, Construction and Owner-operated) industry information are mainly defined and exchanged in natural language through textual files and documents. On the contrary, a Building Information Modeling (BIM) approach requires machine processable data and information. Natural Language Processing (NLP) allows to process textual information into structured format. About BIM in AECO industry, and NLP in different sectors, several literature reviews have been conducted. However, none of them highlighted the possible connections between the two topics. This study provides a scientometric analysis aiming to investigate possible combined applications of BIM and NLP. A quantitative literature review approach is employed, using data visualization and science mapping applied on bibliometric meta- data. The performed analysis uncovered possible directions for further research on NLP and BIM combined applications in AECO sector. Most active authors, key research patterns, and institutional affiliations are identified. The main applications areas of a combined NLP and BIM approach in AECO are: Information Retrieval and Information Enrichment of BIM models, Automatic Compliance Checking, and Safety and Risk Management. The keywords pattern analysis highlighted the main tools which allows to link Semantic BIM and NLP methods and technologies, i.e. Ontology and Machine Learning algorithms. The scientometric analysis also reveals a gap related to the Preliminary design and Requirement definition phases, highlighting a possible research area not covered by the Academia as of now.",Document_354,Technical aspects or methods of AI or machine learning,0.12388938665390015,Other Categories
Best Practices for Managing Data Annotation Projects,"Tina Tseng, A. Stent, D. Maida","Annotation is the labeling of data by human effort. Annotation is critical to modern machine learning, and Bloomberg has developed years of experience of annotation at scale. This report captures a wealth of wisdom for applied annotation projects, collected from more than 30 experienced annotation project managers in Bloomberg's Global Data department.",2020,2020,,arXiv.org,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.13140/RG.2.2.34497.58727,10.13140/RG.2.2.34497.58727,https://doi.org/10.13140/RG.2.2.34497.58727,14,"Annotation is the labeling of data by human effort. Annotation is critical to modern machine learning, and Bloomberg has developed years of experience of annotation at scale. This report captures a wealth of wisdom for applied annotation projects, collected from more than 30 experienced annotation project managers in Bloomberg's Global Data department.",Document_355,Building internal AI expertise is key for financial institutions,0.15794409811496735,Expertise and Training Strategies
Expl(AI)ned: The Impact of Explainable Artificial Intelligence on Users' Information Processing,"Kevin Bauer, Moritz von Zahn, O. Hinz","Because of a growing number of initiatives and regulations, predictions of modern artificial intelligence (AI) systems increasingly come with explanations about why they behave the way they do. In this paper, we explore the impact of feature-based explanations on users’ information processing. We designed two complementary empirical studies where participants either made incentivized decisions on their own, with the aid of opaque predictions, or with explained predictions. In Study 1, laypeople engaged in the deliberately abstract investment game task. In Study 2, experts from the real estate industry estimated listing prices for real German apartments. Our results indicate that the provision of feature-based explanations paves the way for AI systems to reshape users’ sense making of information and understanding of the world around them. Specifically, explanations change users’ situational weighting of available information and evoke mental model adjustments. Crucially, mental model adjustments are subject to the confirmation bias so that misconceptions can persist and even accumulate, possibly leading to suboptimal or biased decisions. Additionally, mental model adjustments create spillover effects that alter user behavior in related yet disparate domains. Overall, this paper provides important insights into potential downstream consequences of the broad employment of modern explainable AI methods. In particular, side effects of mental model adjustments present a potential risk of manipulating user behavior, promoting discriminatory inclinations, and increasing noise in decision making. Our findings may inform the refinement of current efforts of companies building AI systems and regulators that aim to mitigate problems associated with the black-box nature of many modern AI systems.",2023,2023,,Information systems research,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.1287/isre.2023.1199,10.1287/isre.2023.1199,https://doi.org/10.1287/isre.2023.1199,52,"Because of a growing number of initiatives and regulations, predictions of modern artificial intelligence (AI) systems increasingly come with explanations about why they behave the way they do. In this paper, we explore the impact of feature-based explanations on users’ information processing. We designed two complementary empirical studies where participants either made incentivized decisions on their own, with the aid of opaque predictions, or with explained predictions. In Study 1, laypeople engaged in the deliberately abstract investment game task. In Study 2, experts from the real estate industry estimated listing prices for real German apartments. Our results indicate that the provision of feature-based explanations paves the way for AI systems to reshape users’ sense making of information and understanding of the world around them. Specifically, explanations change users’ situational weighting of available information and evoke mental model adjustments. Crucially, mental model adjustments are subject to the confirmation bias so that misconceptions can persist and even accumulate, possibly leading to suboptimal or biased decisions. Additionally, mental model adjustments create spillover effects that alter user behavior in related yet disparate domains. Overall, this paper provides important insights into potential downstream consequences of the broad employment of modern explainable AI methods. In particular, side effects of mental model adjustments present a potential risk of manipulating user behavior, promoting discriminatory inclinations, and increasing noise in decision making. Our findings may inform the refinement of current efforts of companies building AI systems and regulators that aim to mitigate problems associated with the black-box nature of many modern AI systems.",Document_356,Technical aspects or methods of AI or machine learning,0.10872747004032135,Other Categories
AI research ethics is in its infancy: the EU’s AI Act can make it a grown-up,"Anaïs Rességuier, Fabienne Ufert","As the artificial intelligence (AI) ethics field is currently working towards its operationalisation, ethics review as carried out by research ethics committees (RECs) constitutes a powerful, but so far underdeveloped, framework to make AI ethics effective in practice at the research level. This article contributes to the elaboration of research ethics frameworks for research projects developing and/or using AI. It highlights that these frameworks are still in their infancy and in need of a structure and criteria to ensure AI research projects advance in a way that respects norms and principles. This article proposes to draw from the European Union’s AI Act currently in development to shape these frameworks. Although, in the current form of the draft (as of August 2023), the obligations of the AI Act do not apply to scientific research, it is most likely that they will still have a strong impact on AI research considering the need to anticipate market placement or to test new tools in real world conditions. This article investigates what the risk-based approach in the AI Act implies for research ethics and highlights some AI Act obligations of particular value to implement for ethics review processes.",2023,2023,,Research Ethics,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.1177/17470161231220946,10.1177/17470161231220946,https://doi.org/10.1177/17470161231220946,3,"As the artificial intelligence (AI) ethics field is currently working towards its operationalisation, ethics review as carried out by research ethics committees (RECs) constitutes a powerful, but so far underdeveloped, framework to make AI ethics effective in practice at the research level. This article contributes to the elaboration of research ethics frameworks for research projects developing and/or using AI. It highlights that these frameworks are still in their infancy and in need of a structure and criteria to ensure AI research projects advance in a way that respects norms and principles. This article proposes to draw from the European Union’s AI Act currently in development to shape these frameworks. Although, in the current form of the draft (as of August 2023), the obligations of the AI Act do not apply to scientific research, it is most likely that they will still have a strong impact on AI research considering the need to anticipate market placement or to test new tools in real world conditions. This article investigates what the risk-based approach in the AI Act implies for research ethics and highlights some AI Act obligations of particular value to implement for ethics review processes.",Document_357,Demonstrating the value of AI for compliance and risk management,0.12826596200466156,Business Case and Value Demonstration Strategies
Methods to Integrate Natural Language Processing Into Qualitative Research,"Marissa D. Abram, Karen T. Mancini, R. Parker","Qualitative methods analyze contextualized, unstructured data. These methods are time and cost intensive, often resulting in small sample sizes and yielding findings that are complicated to replicate. Integrating natural language processing (NLP) into a qualitative project can increase efficiency through time and cost savings; increase sample sizes; and allow for validation through replication. This study compared the findings, costs, and time spent between a traditional qualitative method (Investigator only) to a method pairing a qualitative investigator with an NLP function (Investigator +NLP).
Methods:
Using secondary data from a previously published study, the investigators designed an NLP process in Python to yield a corpus, keywords, keyword influence, and the primary topics. A qualitative researcher reviewed and interpreted the output. These findings were compared to the previous study results.
Results:
Using comparative review, our results closely matched the original findings. The NLP + Investigator method reduced the project time by a minimum of 120 hours and costs by $1,500.
Discussion:
Qualitative research can evolve by incorporating NLP methods. These methods can increase sample size, reduce project time, and significantly reduce costs. The results of an integrated NLP process create a corpus and code which can be reviewed and verified, thus allowing a replicable, qualitative study. New data can be added over time and analyzed using the same interpretation and identification. Off the shelf qualitative software may be easier to use, but it can be expensive and may not offer a tailored approach or easily interpretable outcomes which further benefits researchers.",2020,2020,,International Journal of Qualitative Methods,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.1177/1609406920984608,10.1177/1609406920984608,https://doi.org/10.1177/1609406920984608,38,"Qualitative methods analyze contextualized, unstructured data. These methods are time and cost intensive, often resulting in small sample sizes and yielding findings that are complicated to replicate. Integrating natural language processing (NLP) into a qualitative project can increase efficiency through time and cost savings; increase sample sizes; and allow for validation through replication. This study compared the findings, costs, and time spent between a traditional qualitative method (Investigator only) to a method pairing a qualitative investigator with an NLP function (Investigator +NLP).
Methods:
Using secondary data from a previously published study, the investigators designed an NLP process in Python to yield a corpus, keywords, keyword influence, and the primary topics. A qualitative researcher reviewed and interpreted the output. These findings were compared to the previous study results.
Results:
Using comparative review, our results closely matched the original findings. The NLP + Investigator method reduced the project time by a minimum of 120 hours and costs by $1,500.
Discussion:
Qualitative research can evolve by incorporating NLP methods. These methods can increase sample size, reduce project time, and significantly reduce costs. The results of an integrated NLP process create a corpus and code which can be reviewed and verified, thus allowing a replicable, qualitative study. New data can be added over time and analyzed using the same interpretation and identification. Off the shelf qualitative software may be easier to use, but it can be expensive and may not offer a tailored approach or easily interpretable outcomes which further benefits researchers.",Document_358,Technical aspects or methods of AI or machine learning,0.057753268629312515,Other Categories
Regulation and ethics in artificial intelligence and machine learning technologies: Where are we now? Who is responsible? Can the information professional play a role?,Denise Carter,"Artificial intelligence (AI) and machine learning (ML) technologies are rapidly maturing and proliferating through all public and private sectors. The potential for these technologies to do good and to help us in our everyday lives is immense. But there is a risk that unless managed and controlled AI can also cause us harm. Questions about regulation, what form it takes and who is responsible for governance are only just beginning to be answered. In May 2019, 42 countries came together to support a global governance framework for AI. The Organisation for Economic Co-operation and Development (OECD) Principles on Artificial Intelligence (OECD (2019) OECD principles on AI. Available at: https://www.oecd.org/going-digital/ai/principles/ (accessed 2 March 2020)) saw like-minded democracies of the world commit to common AI values of trust and respect. In Europe, the European Commission’s (EC) new president, Ursula von der Leyen has made calls for a General Data Protection Regulation style. As a first step the EC has published a white paper: ‘On Artificial Intelligence – A European Approach to Excellence and Trust’ (European Commission (2020) Report, Europa, February). In February 2020, the UK government has published a report on ‘Artificial Intelligence in the Public Sector’ (The Committee on Standards in Public Life (2020) Artificial intelligence and public standards. Report, UK Government, February). This article discusses some of the potential threats AI may hold if left unregulated. It provides a brief overview of the regulatory activities for AI worldwide, and in more detail the current UK AI regulatory landscape. Finally, the article looks at the role that the information professional might play in AI and ML.",2020,2020,,Business Information Review,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.1177/0266382120923962,10.1177/0266382120923962,https://doi.org/10.1177/0266382120923962,29,"Artificial intelligence (AI) and machine learning (ML) technologies are rapidly maturing and proliferating through all public and private sectors. The potential for these technologies to do good and to help us in our everyday lives is immense. But there is a risk that unless managed and controlled AI can also cause us harm. Questions about regulation, what form it takes and who is responsible for governance are only just beginning to be answered. In May 2019, 42 countries came together to support a global governance framework for AI. The Organisation for Economic Co-operation and Development (OECD) Principles on Artificial Intelligence (OECD (2019) OECD principles on AI. Available at: https://www.oecd.org/going-digital/ai/principles/ (accessed 2 March 2020)) saw like-minded democracies of the world commit to common AI values of trust and respect. In Europe, the European Commission’s (EC) new president, Ursula von der Leyen has made calls for a General Data Protection Regulation style. As a first step the EC has published a white paper: ‘On Artificial Intelligence – A European Approach to Excellence and Trust’ (European Commission (2020) Report, Europa, February). In February 2020, the UK government has published a report on ‘Artificial Intelligence in the Public Sector’ (The Committee on Standards in Public Life (2020) Artificial intelligence and public standards. Report, UK Government, February). This article discusses some of the potential threats AI may hold if left unregulated. It provides a brief overview of the regulatory activities for AI worldwide, and in more detail the current UK AI regulatory landscape. Finally, the article looks at the role that the information professional might play in AI and ML.",Document_359,Technical aspects or methods of AI or machine learning,0.12854191660881042,Other Categories
A study of semantic integration across archaeological data and reports in different languages,"C. Binding, D. Tudhope, A. Vlachidis","This study investigates the semantic integration of data extracted from archaeological datasets with information extracted via natural language processing (NLP) across different languages. The investigation follows a broad theme relating to wooden objects and their dating via dendrochronological techniques, including types of wooden material, samples taken and wooden objects including shipwrecks. The outcomes are an integrated RDF dataset coupled with an associated interactive research demonstrator query builder application. The semantic framework combines the CIDOC Conceptual Reference Model (CRM) with the Getty Art and Architecture Thesaurus (AAT). The NLP, data cleansing and integration methods are described in detail together with illustrative scenarios from the web application Demonstrator. Reflections and recommendations from the study are discussed. The Demonstrator is a novel SPARQL web application, with CRM/AAT-based data integration. Functionality includes the combination of free text and semantic search with browsing on semantic links, hierarchical and associative relationship thesaurus query expansion. Queries concern wooden objects (e.g. samples of beech wood keels), optionally from a given date range, with automatic expansion over AAT hierarchies of wood types and specialised associative relationships. Following a ‘mapping pattern’ approach (via the STELETO tool) ensured validity and consistency of all RDF output. The user is shielded from the complexity of the underlying semantic framework by a query builder user interface. The study demonstrates the feasibility of connecting information extracted from datasets and grey literature reports in different languages and semantic cross-searching of the integrated information. The semantic linking of textual reports and datasets opens new possibilities for integrative research across diverse resources.",2018,2018,,Journal of information science,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.1177/0165551518789874,10.1177/0165551518789874,https://doi.org/10.1177/0165551518789874,20,"This study investigates the semantic integration of data extracted from archaeological datasets with information extracted via natural language processing (NLP) across different languages. The investigation follows a broad theme relating to wooden objects and their dating via dendrochronological techniques, including types of wooden material, samples taken and wooden objects including shipwrecks. The outcomes are an integrated RDF dataset coupled with an associated interactive research demonstrator query builder application. The semantic framework combines the CIDOC Conceptual Reference Model (CRM) with the Getty Art and Architecture Thesaurus (AAT). The NLP, data cleansing and integration methods are described in detail together with illustrative scenarios from the web application Demonstrator. Reflections and recommendations from the study are discussed. The Demonstrator is a novel SPARQL web application, with CRM/AAT-based data integration. Functionality includes the combination of free text and semantic search with browsing on semantic links, hierarchical and associative relationship thesaurus query expansion. Queries concern wooden objects (e.g. samples of beech wood keels), optionally from a given date range, with automatic expansion over AAT hierarchies of wood types and specialised associative relationships. Following a ‘mapping pattern’ approach (via the STELETO tool) ensured validity and consistency of all RDF output. The user is shielded from the complexity of the underlying semantic framework by a query builder user interface. The study demonstrates the feasibility of connecting information extracted from datasets and grey literature reports in different languages and semantic cross-searching of the integrated information. The semantic linking of textual reports and datasets opens new possibilities for integrative research across diverse resources.",Document_360,Technical aspects or methods of AI or machine learning,0.0790991336107254,Other Categories
Transparency Helps Reveal When Language Models Learn Meaning,"Zhaofeng Wu, William Merrill, Hao Peng, Iz Beltagy, Noah A. Smith","Many current NLP systems are built from language models trained to optimize unsupervised objectives on large amounts of raw text. Under what conditions might such a procedure acquire meaning? Our systematic experiments with synthetic data reveal that, with languages where all expressions have context-independent denotations (i.e., languages with strong transparency), both autoregressive and masked language models successfully learn to emulate semantic relations between expressions. However, when denotations are changed to be context-dependent with the language otherwise unmodified, this ability degrades. Turning to natural language, our experiments with a specific phenomenon—referential opacity—add to the growing body of evidence that current language models do not represent natural language semantics well. We show this failure relates to the context-dependent nature of natural language form-meaning mappings.",2022,2022,,Transactions of the Association for Computational Linguistics,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.1162/tacl_a_00565,10.1162/tacl_a_00565,https://doi.org/10.1162/tacl_a_00565,7,"Many current NLP systems are built from language models trained to optimize unsupervised objectives on large amounts of raw text. Under what conditions might such a procedure acquire meaning? Our systematic experiments with synthetic data reveal that, with languages where all expressions have context-independent denotations (i.e., languages with strong transparency), both autoregressive and masked language models successfully learn to emulate semantic relations between expressions. However, when denotations are changed to be context-dependent with the language otherwise unmodified, this ability degrades. Turning to natural language, our experiments with a specific phenomenon—referential opacity—add to the growing body of evidence that current language models do not represent natural language semantics well. We show this failure relates to the context-dependent nature of natural language form-meaning mappings.",Document_361,Technical aspects or methods of AI or machine learning,0.1261405050754547,Other Categories
Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets,"Isaac Caswell, Julia Kreutzer, Lisa Wang, Ahsan Wahab, D. Esch, Nasanbayar Ulzii-Orshikh, A. Tapo, Nishant Subramani, Artem Sokolov, Claytone Sikasote, Monang Setyawan, Supheakmungkol Sarin, Sokhar Samb, B. Sagot, Clara Rivera, Annette Rios Gonzales, Isabel Papadimitriou, Salomey Osei, Pedro Ortiz Suarez, Iroro Orife, Kelechi Ogueji, Andre Niyongabo Rubungo, Toan Q. Nguyen, Mathias Muller, A. Muller, Shamsuddeen Hassan Muhammad, N. Muhammad, Ayanda Mnyakeni, Jamshidbek Mirzakhalov, Tapiwanashe Matangira, Colin Leong, Nze Lawson, Sneha Kudugunta, Yacine Jernite, M. Jenny, Orhan Firat, Bonaventure F. P. Dossou, Sakhile Dlamini, Nisansa de Silva, Sakine cCabuk Balli, Stella Biderman, A. Battisti, Ahmed Baruwa, Ankur Bapna, P. Baljekar, Israel Abebe Azime, Ayodele Awokoya, Duygu Ataman, Orevaoghene Ahia, Oghenefego Ahia, Sweta Agrawal, Mofetoluwa Adeyemi",,2021,2021,,Transactions of the Association for Computational Linguistics,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.1162/tacl_a_00447,10.1162/tacl_a_00447,https://doi.org/10.1162/tacl_a_00447,250,,Document_362,,,
Explanation-Based Human Debugging of NLP Models: A Survey,"Piyawat Lertvittayakumjorn, Francesca Toni","Debugging a machine learning model is hard since the bug usually involves the training data and the learning process. This becomes even harder for an opaque deep learning model if we have no clue about how the model actually works. In this survey, we review papers that exploit explanations to enable humans to give feedback and debug NLP models. We call this problem explanation-based human debugging (EBHD). In particular, we categorize and discuss existing work along three dimensions of EBHD (the bug context, the workflow, and the experimental setting), compile findings on how EBHD components affect the feedback providers, and highlight open problems that could be future research directions.",2021,2021,,Transactions of the Association for Computational Linguistics,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.1162/tacl_a_00440,10.1162/tacl_a_00440,https://doi.org/10.1162/tacl_a_00440,78,"Debugging a machine learning model is hard since the bug usually involves the training data and the learning process. This becomes even harder for an opaque deep learning model if we have no clue about how the model actually works. In this survey, we review papers that exploit explanations to enable humans to give feedback and debug NLP models. We call this problem explanation-based human debugging (EBHD). In particular, we categorize and discuss existing work along three dimensions of EBHD (the bug context, the workflow, and the experimental setting), compile findings on how EBHD components affect the feedback providers, and highlight open problems that could be future research directions.",Document_363,Technical aspects or methods of AI or machine learning,0.31763315200805664,Other Categories
Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP,"Timo Schick, Sahana Udupa, Hinrich Schütze","When trained on large, unfiltered crawls from the internet, language models pick up and reproduce all kinds of undesirable biases that can be found in the data: they often generate racist, sexist, violent or otherwise toxic language. As large models require millions of training examples to achieve good performance, it is difficult to completely prevent them from being exposed to such content. In this paper, we first demonstrate a surprising finding: pretrained language models recognize, to a considerable degree, their undesirable biases and the toxicity of the content they produce. We refer to this capability as self-diagnosis. Based on this finding, we then propose a decoding algorithm that, given only a textual description of the undesired behavior, reduces the probability of a language model producing problematic text. We refer to this approach as self-debiasing. Self-debiasing does not rely on manually curated word lists, nor does it require any training data or changes to the model's parameters. While we by no means eliminate the issue of language models generating biased text, we believe our approach to be an important step in this direction.",2021,2021,,Transactions of the Association for Computational Linguistics,Access Forbidden (403) (URL Source: DOI Link),https://doi.org/10.1162/tacl_a_00434,10.1162/tacl_a_00434,https://doi.org/10.1162/tacl_a_00434,341,"When trained on large, unfiltered crawls from the internet, language models pick up and reproduce all kinds of undesirable biases that can be found in the data: they often generate racist, sexist, violent or otherwise toxic language. As large models require millions of training examples to achieve good performance, it is difficult to completely prevent them from being exposed to such content. In this paper, we first demonstrate a surprising finding: pretrained language models recognize, to a considerable degree, their undesirable biases and the toxicity of the content they produce. We refer to this capability as self-diagnosis. Based on this finding, we then propose a decoding algorithm that, given only a textual description of the undesired behavior, reduces the probability of a language model producing problematic text. We refer to this approach as self-debiasing. Self-debiasing does not rely on manually curated word lists, nor does it require any training data or changes to the model's parameters. While we by no means eliminate the issue of language models generating biased text, we believe our approach to be an important step in this direction.",Document_364,Demonstrating the value of AI for compliance and risk management,0.05756404995918274,Business Case and Value Demonstration Strategies
